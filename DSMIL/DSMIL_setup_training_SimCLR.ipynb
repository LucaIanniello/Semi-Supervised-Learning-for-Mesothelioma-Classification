{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luU_cmGWRONN",
        "outputId": "57e07aa5-4840-47e1-9ba3-22769f521ca0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'dsmil-wsi'...\n",
            "remote: Enumerating objects: 648, done.\u001b[K\n",
            "remote: Counting objects: 100% (189/189), done.\u001b[K\n",
            "remote: Compressing objects: 100% (71/71), done.\u001b[K\n",
            "remote: Total 648 (delta 139), reused 130 (delta 118), pack-reused 459 (from 1)\u001b[K\n",
            "Receiving objects: 100% (648/648), 49.23 MiB | 29.57 MiB/s, done.\n",
            "Resolving deltas: 100% (357/357), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/binli123/dsmil-wsi.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHkv-RIKRfUK",
        "outputId": "78eb109d-28c3-43d0-ba47-b7061b76d559"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â¬ Downloading https://github.com/jaimergp/miniforge/releases/download/24.11.2-1_colab/Miniforge3-colab-24.11.2-1_colab-Linux-x86_64.sh...\n",
            "ðŸ“¦ Installing...\n",
            "ðŸ“Œ Adjusting configuration...\n",
            "ðŸ©¹ Patching environment...\n",
            "â² Done in 0:00:11\n",
            "ðŸ” Restarting kernel...\n"
          ]
        }
      ],
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "wwjEbzTlRvS0",
        "outputId": "e4d7063d-4e30-4654-9679-1947f98b9008"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/dsmil-wsi\n",
            "Channels:\n",
            " - anaconda\n",
            " - conda-forge\n",
            " - defaults\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Solving environment: | \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "    current version: 24.11.2\n",
            "    latest version: 25.5.1\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "tesseract-5.2.0      | 171.4 MB  | :   0% 0/1 [00:00<?, ?it/s]\n",
            "mysql-8.4.0          | 67.1 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "python-3.13.5        | 42.8 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "opencv-4.10.0        | 36.8 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "icu-73.1             | 27.7 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scipy-1.15.3         | 26.6 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "qtbase-6.7.3         | 17.9 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "qtdeclarative-6.7.3  | 17.5 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pandas-2.2.3         | 16.5 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scikit-learn-1.6.1   | 12.7 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scikit-image-0.25.2  | 12.6 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenblas-0.3.29   | 10.8 MB   | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-6.1.1         | 9.9 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "matplotlib-base-3.10 | 9.2 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "numpy-base-2.3.1     | 9.1 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-ng-11.2.0     | 8.5 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "jupyterlab-4.3.4     | 7.9 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "qttools-6.7.3        | 7.1 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "babel-2.16.0         | 6.8 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tesseract-5.2.0      | 171.4 MB  | :   0% 0.0010941227303880373/1 [00:00<01:34, 94.20s/it]\n",
            "\n",
            "\n",
            "\n",
            "icu-73.1             | 27.7 MB   | :   0% 0.002258208048373948/1 [00:00<00:44, 44.68s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "opencv-4.10.0        | 36.8 MB   | :   1% 0.011040574338771755/1 [00:00<00:09,  9.38s/it]\u001b[A\u001b[A\u001b[A\n",
            "mysql-8.4.0          | 67.1 MB   | :   0% 0.0002328401936063936/1 [00:00<07:42, 462.77s/it]\u001b[A\n",
            "\n",
            "tesseract-5.2.0      | 171.4 MB  | :   3% 0.031000144027661058/1 [00:00<00:05,  5.61s/it] \n",
            "\n",
            "\n",
            "\n",
            "icu-73.1             | 27.7 MB   | :  15% 0.1473480751564001/1 [00:00<00:00,  1.16s/it]  \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "opencv-4.10.0        | 36.8 MB   | :  14% 0.1414042790311921/1 [00:00<00:01,  1.28s/it]  \u001b[A\u001b[A\u001b[A\n",
            "mysql-8.4.0          | 67.1 MB   | :   4% 0.043773956398001995/1 [00:00<00:03,  4.10s/it]  \u001b[A\n",
            "\n",
            "tesseract-5.2.0      | 171.4 MB  | :   6% 0.0616355804785261/1 [00:00<00:03,  4.24s/it]  \n",
            "\n",
            "\n",
            "\n",
            "icu-73.1             | 27.7 MB   | :  29% 0.2867924221434914/1 [00:00<00:00,  1.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "opencv-4.10.0        | 36.8 MB   | :  26% 0.2603027719102725/1 [00:00<00:00,  1.04s/it]\u001b[A\u001b[A\u001b[A\n",
            "mysql-8.4.0          | 67.1 MB   | :  11% 0.11083193215664336/1 [00:00<00:02,  2.32s/it] \u001b[A\n",
            "\n",
            "python-3.13.5        | 42.8 MB   | :  16% 0.16329441764224573/1 [00:00<00:01,  1.78s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "icu-73.1             | 27.7 MB   | :  45% 0.454464369735257/1 [00:00<00:00,  1.33it/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "mysql-8.4.0          | 67.1 MB   | :  18% 0.1848751137234765/1 [00:00<00:01,  1.82s/it] \u001b[A\n",
            "\n",
            "\n",
            "tesseract-5.2.0      | 171.4 MB  | :   9% 0.08543274986446592/1 [00:00<00:04,  4.64s/it]\n",
            "\n",
            "python-3.13.5        | 42.8 MB   | :  28% 0.27909828876661236/1 [00:00<00:00,  1.28s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "icu-73.1             | 27.7 MB   | :  60% 0.6018124448916571/1 [00:00<00:00,  1.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "mysql-8.4.0          | 67.1 MB   | :  25% 0.25216592967572427/1 [00:00<00:01,  1.68s/it]\u001b[A\n",
            "\n",
            "\n",
            "tesseract-5.2.0      | 171.4 MB  | :  11% 0.10740638136642566/1 [00:00<00:04,  4.62s/it]\n",
            "\n",
            "python-3.13.5        | 42.8 MB   | :  37% 0.36531189629137745/1 [00:00<00:00,  1.24s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "icu-73.1             | 27.7 MB   | :  75% 0.7519832801085247/1 [00:00<00:00,  1.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "opencv-4.10.0        | 36.8 MB   | :  63% 0.6301620122591263/1 [00:00<00:00,  1.16it/s]\u001b[A\u001b[A\u001b[A\n",
            "tesseract-5.2.0      | 171.4 MB  | :  14% 0.1354888647797186/1 [00:00<00:03,  4.29s/it] \n",
            "\n",
            "python-3.13.5        | 42.8 MB   | :  47% 0.46942578673442004/1 [00:00<00:00,  1.13s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "icu-73.1             | 27.7 MB   | :  91% 0.9128806035551684/1 [00:00<00:00,  1.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "mysql-8.4.0          | 67.1 MB   | :  37% 0.3741741911254745/1 [00:00<00:01,  1.70s/it] \u001b[A\n",
            "\n",
            "\n",
            "tesseract-5.2.0      | 171.4 MB  | :  16% 0.16056251068444446/1 [00:00<00:03,  4.19s/it]\n",
            "\n",
            "python-3.13.5        | 42.8 MB   | :  56% 0.5611190727035558/1 [00:00<00:00,  1.16s/it] \u001b[A\u001b[A\n",
            "mysql-8.4.0          | 67.1 MB   | :  43% 0.4335484404951049/1 [00:00<00:00,  1.72s/it]\u001b[A\n",
            "\n",
            "\n",
            "tesseract-5.2.0      | 171.4 MB  | :  18% 0.1845420338587823/1 [00:00<00:03,  4.45s/it] \n",
            "\n",
            "python-3.13.5        | 42.8 MB   | :  66% 0.6608492203911018/1 [00:00<00:00,  1.11s/it]\u001b[A\u001b[A\n",
            "mysql-8.4.0          | 67.1 MB   | :  50% 0.502236297608991/1 [00:00<00:00,  1.64s/it] \u001b[A\n",
            "\n",
            "\n",
            "tesseract-5.2.0      | 171.4 MB  | :  21% 0.21453923205025432/1 [00:00<00:03,  4.06s/it]\n",
            "\n",
            "python-3.13.5        | 42.8 MB   | :  76% 0.761675303767522/1 [00:00<00:00,  1.07s/it] \u001b[A\u001b[A\n",
            "tesseract-5.2.0      | 171.4 MB  | :  24% 0.24453643024172633/1 [00:01<00:02,  3.81s/it]\n",
            "\n",
            "python-3.13.5        | 42.8 MB   | :  88% 0.8800363581659283/1 [00:01<00:00,  1.01it/s]\u001b[A\u001b[A\n",
            "mysql-8.4.0          | 67.1 MB   | :  65% 0.6528839028723277/1 [00:01<00:00,  1.45s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tesseract-5.2.0      | 171.4 MB  | :  28% 0.2773601121533675/1 [00:01<00:02,  3.58s/it] \n",
            "\n",
            "python-3.13.5        | 42.8 MB   | :  99% 0.9885339913644674/1 [00:01<00:00,  1.03it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scipy-1.15.3         | 26.6 MB   | :   0% 0.0005866413276569769/1 [00:01<33:39, 2020.72s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "tesseract-5.2.0      | 171.4 MB  | :  31% 0.30553377246085944/1 [00:01<00:02,  3.62s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scipy-1.15.3         | 26.6 MB   | :  16% 0.15604659315675587/1 [00:01<00:05,  5.97s/it]    \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "tesseract-5.2.0      | 171.4 MB  | :  34% 0.33863098505509753/1 [00:01<00:02,  3.46s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scipy-1.15.3         | 26.6 MB   | :  29% 0.28628096789660473/1 [00:01<00:02,  3.14s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "tesseract-5.2.0      | 171.4 MB  | :  37% 0.36762523741038056/1 [00:01<00:02,  3.48s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scipy-1.15.3         | 26.6 MB   | :  46% 0.46227336619369785/1 [00:01<00:00,  1.83s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "tesseract-5.2.0      | 171.4 MB  | :  40% 0.39643713597726554/1 [00:01<00:02,  3.72s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scipy-1.15.3         | 26.6 MB   | :  60% 0.6030672848313723/1 [00:01<00:00,  1.42s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "tesseract-5.2.0      | 171.4 MB  | :  42% 0.42360785044856847/1 [00:01<00:02,  3.75s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scipy-1.15.3         | 26.6 MB   | :  79% 0.7866860203880061/1 [00:01<00:00,  1.06s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "qtbase-6.7.3         | 17.9 MB   | :   0% 0.0008726405509736541/1 [00:01<32:31, 1952.74s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scipy-1.15.3         | 26.6 MB   | :  94% 0.93921276557882/1 [00:01<00:00,  1.06it/s]  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tesseract-5.2.0      | 171.4 MB  | :  45% 0.4505050342372744/1 [00:01<00:02,  4.02s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tesseract-5.2.0      | 171.4 MB  | :  48% 0.4757610339303982/1 [00:01<00:02,  4.11s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tesseract-5.2.0      | 171.4 MB  | :  53% 0.526728917787641/1 [00:02<00:01,  4.07s/it] \n",
            "\n",
            "python-3.13.5        | 42.8 MB   | : 100% 1.0/1 [00:02<00:00,  1.03it/s]               \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tesseract-5.2.0      | 171.4 MB  | :  55% 0.5514378561155708/1 [00:02<00:01,  4.10s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tesseract-5.2.0      | 171.4 MB  | :  58% 0.5759644406551027/1 [00:02<00:01,  4.18s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scipy-1.15.3         | 26.6 MB   | : 100% 1.0/1 [00:02<00:00,  1.06it/s]             \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "qtdeclarative-6.7.3  | 17.5 MB   | :  44% 0.4431040850410046/1 [00:02<00:01,  3.34s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tesseract-5.2.0      | 171.4 MB  | :  60% 0.6000351407236395/1 [00:02<00:01,  4.43s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "qtdeclarative-6.7.3  | 17.5 MB   | :  63% 0.6321142782576907/1 [00:02<00:00,  2.17s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "qtbase-6.7.3         | 17.9 MB   | : 100% 1.0/1 [00:02<00:00,  1.37s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pandas-2.2.3         | 16.5 MB   | :  25% 0.2547669934559859/1 [00:02<00:05,  7.10s/it]     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scikit-learn-1.6.1   | 12.7 MB   | :   0% 0.0012307757951533545/1 [00:02<34:44, 2087.53s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tesseract-5.2.0      | 171.4 MB  | :  62% 0.6228293642733902/1 [00:02<00:01,  5.25s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pandas-2.2.3         | 16.5 MB   | :  44% 0.438502297286697/1 [00:02<00:02,  3.77s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tesseract-5.2.0      | 171.4 MB  | :  65% 0.6491794866969022/1 [00:02<00:01,  4.79s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pandas-2.2.3         | 16.5 MB   | :  66% 0.6601211689175547/1 [00:02<00:00,  2.23s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tesseract-5.2.0      | 171.4 MB  | :  67% 0.6711531181988619/1 [00:02<00:01,  4.76s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pandas-2.2.3         | 16.5 MB   | :  88% 0.8826871297434159/1 [00:02<00:00,  1.54s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scikit-learn-1.6.1   | 12.7 MB   | :  78% 0.7840041815126868/1 [00:02<00:00,  1.91s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "qtdeclarative-6.7.3  | 17.5 MB   | : 100% 1.0/1 [00:02<00:00,  1.33s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "mysql-8.4.0          | 67.1 MB   | : 100% 1.0/1 [00:03<00:00,  1.46s/it]               \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scikit-image-0.25.2  | 12.6 MB   | :   0% 0.001242598748451871/1 [00:03<40:14, 2417.32s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenblas-0.3.29   | 10.8 MB   | :   0% 0.0014470397068614095/1 [00:03<35:07, 2110.47s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scikit-image-0.25.2  | 12.6 MB   | :   8% 0.07828372115246787/1 [00:03<00:26, 28.37s/it]   \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenblas-0.3.29   | 10.8 MB   | :   2% 0.01881151618919832/1 [00:03<01:59, 121.93s/it]   \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenblas-0.3.29   | 10.8 MB   | :   4% 0.036175992671535234/1 [00:03<00:53, 55.30s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenblas-0.3.29   | 10.8 MB   | :   5% 0.053540469153872144/1 [00:03<00:31, 32.99s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scikit-image-0.25.2  | 12.6 MB   | :  12% 0.12053207859983148/1 [00:03<00:16, 18.99s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenblas-0.3.29   | 10.8 MB   | :   7% 0.07090494563620905/1 [00:03<00:20, 22.39s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenblas-0.3.29   | 10.8 MB   | :   9% 0.08826942211854598/1 [00:03<00:15, 16.47s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scikit-image-0.25.2  | 12.6 MB   | :  15% 0.15035444856267638/1 [00:03<00:13, 15.34s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenblas-0.3.29   | 10.8 MB   | :  11% 0.10708093830774429/1 [00:03<00:11, 12.64s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scikit-image-0.25.2  | 12.6 MB   | :  17% 0.17396382478326192/1 [00:03<00:10, 13.15s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenblas-0.3.29   | 10.8 MB   | :  12% 0.12444541479008121/1 [00:03<00:09, 10.55s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenblas-0.3.29   | 10.8 MB   | :  14% 0.14325693097927952/1 [00:03<00:07,  8.97s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scikit-image-0.25.2  | 12.6 MB   | :  20% 0.19508800350694375/1 [00:03<00:09, 11.61s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenblas-0.3.29   | 10.8 MB   | :  16% 0.16062140746161643/1 [00:04<00:06,  8.22s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tesseract-5.2.0      | 171.4 MB  | :  69% 0.6929443959124236/1 [00:04<00:05, 19.03s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scikit-image-0.25.2  | 12.6 MB   | :  21% 0.2137269847337218/1 [00:04<00:08, 10.49s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-6.1.1         | 9.9 MB    | :   0% 0.0015816467197434768/1 [00:04<42:35, 2559.27s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenblas-0.3.29   | 10.8 MB   | :  18% 0.17798588394395334/1 [00:04<00:06,  7.53s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-6.1.1         | 9.9 MB    | :   2% 0.020561407356665198/1 [00:04<02:23, 146.34s/it]  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scikit-image-0.25.2  | 12.6 MB   | :  23% 0.231123367212048/1 [00:04<00:07,  9.60s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenblas-0.3.29   | 10.8 MB   | :  20% 0.19679740013315167/1 [00:04<00:05,  6.91s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-6.1.1         | 9.9 MB    | :   4% 0.041122814713330395/1 [00:04<00:59, 62.48s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scikit-image-0.25.2  | 12.6 MB   | :  25% 0.2485197496903742/1 [00:04<00:06,  8.88s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenblas-0.3.29   | 10.8 MB   | :  21% 0.21416187661548858/1 [00:04<00:05,  6.60s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-6.1.1         | 9.9 MB    | :   6% 0.06010257535025211/1 [00:04<00:35, 37.50s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scikit-image-0.25.2  | 12.6 MB   | :  26% 0.2646735334202485/1 [00:04<00:06,  8.43s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenblas-0.3.29   | 10.8 MB   | :  23% 0.2315263530978255/1 [00:04<00:04,  6.40s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-6.1.1         | 9.9 MB    | :   8% 0.07908233598717383/1 [00:04<00:23, 25.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scikit-learn-1.6.1   | 12.7 MB   | : 100% 1.0/1 [00:04<00:00,  1.91s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scikit-image-0.25.2  | 12.6 MB   | :  28% 0.2808273171501228/1 [00:04<00:05,  7.97s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenblas-0.3.29   | 10.8 MB   | :  25% 0.25033786928702384/1 [00:04<00:04,  6.18s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "matplotlib-base-3.10 | 9.2 MB    | :   0% 0.0016966059699943885/1 [00:04<44:20, 2665.00s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-6.1.1         | 9.9 MB    | :  10% 0.09806209662409555/1 [00:04<00:16, 18.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scikit-image-0.25.2  | 12.6 MB   | :  30% 0.29698110087999713/1 [00:04<00:05,  7.67s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenblas-0.3.29   | 10.8 MB   | :  27% 0.26770234576936075/1 [00:04<00:04,  6.12s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "matplotlib-base-3.10 | 9.2 MB    | :   2% 0.02205587760992705/1 [00:04<02:28, 151.72s/it]   \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-6.1.1         | 9.9 MB    | :  12% 0.11862350398076076/1 [00:04<00:11, 13.49s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenblas-0.3.29   | 10.8 MB   | :  29% 0.28506682225169766/1 [00:04<00:04,  6.03s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scikit-image-0.25.2  | 12.6 MB   | :  31% 0.3131348846098715/1 [00:04<00:05,  7.41s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "matplotlib-base-3.10 | 9.2 MB    | :   4% 0.042415149249859715/1 [00:04<01:04, 67.42s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-6.1.1         | 9.9 MB    | :  14% 0.13760326461768246/1 [00:04<00:09, 10.92s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scikit-image-0.25.2  | 12.6 MB   | :  33% 0.3292886683397458/1 [00:04<00:04,  7.16s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenblas-0.3.29   | 10.8 MB   | :  30% 0.30387833844089596/1 [00:04<00:04,  5.91s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "matplotlib-base-3.10 | 9.2 MB    | :   6% 0.06447102685978676/1 [00:04<00:35, 37.95s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-6.1.1         | 9.9 MB    | :  16% 0.15816467197434766/1 [00:04<00:07,  9.04s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "matplotlib-base-3.10 | 9.2 MB    | :   8% 0.08313369252972504/1 [00:04<00:24, 26.26s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenblas-0.3.29   | 10.8 MB   | :  32% 0.32124281492323287/1 [00:04<00:04,  6.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scikit-image-0.25.2  | 12.6 MB   | :  35% 0.3454424520696201/1 [00:04<00:04,  7.30s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-6.1.1         | 9.9 MB    | :  18% 0.1771444326112694/1 [00:05<00:06,  8.13s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "matplotlib-base-3.10 | 9.2 MB    | :  10% 0.1034929641696577/1 [00:05<00:16, 18.60s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenblas-0.3.29   | 10.8 MB   | :  34% 0.3386072914055698/1 [00:05<00:03,  6.02s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scikit-image-0.25.2  | 12.6 MB   | :  36% 0.36035363705104256/1 [00:05<00:04,  7.21s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-6.1.1         | 9.9 MB    | :  20% 0.1961241932481911/1 [00:05<00:05,  7.28s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "matplotlib-base-3.10 | 9.2 MB    | :  12% 0.12385223580959036/1 [00:05<00:12, 14.00s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenblas-0.3.29   | 10.8 MB   | :  36% 0.3559717678879067/1 [00:05<00:03,  6.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scikit-image-0.25.2  | 12.6 MB   | :  38% 0.37526482203246503/1 [00:05<00:04,  7.20s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-6.1.1         | 9.9 MB    | :  22% 0.21510395388511283/1 [00:05<00:05,  6.80s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "matplotlib-base-3.10 | 9.2 MB    | :  14% 0.14421150744952302/1 [00:05<00:10, 12.57s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenblas-0.3.29   | 10.8 MB   | :  37% 0.3733362443702436/1 [00:05<00:04,  7.69s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scikit-image-0.25.2  | 12.6 MB   | :  39% 0.3901760070138875/1 [00:05<00:05,  8.93s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-6.1.1         | 9.9 MB    | :  23% 0.23408371452203455/1 [00:05<00:06,  7.91s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "matplotlib-base-3.10 | 9.2 MB    | :  16% 0.1645707790894557/1 [00:05<00:08, 10.18s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenblas-0.3.29   | 10.8 MB   | :  39% 0.3907007208525805/1 [00:05<00:04,  7.19s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scikit-image-0.25.2  | 12.6 MB   | :  41% 0.4050871919953099/1 [00:05<00:04,  8.30s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-6.1.1         | 9.9 MB    | :  25% 0.2530634751589563/1 [00:05<00:05,  7.18s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "matplotlib-base-3.10 | 9.2 MB    | :  18% 0.18493005072938834/1 [00:05<00:06,  8.58s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenblas-0.3.29   | 10.8 MB   | :  41% 0.4080651973349175/1 [00:05<00:04,  6.88s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scikit-image-0.25.2  | 12.6 MB   | :  42% 0.41999837697673237/1 [00:05<00:04,  7.88s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tesseract-5.2.0      | 171.4 MB  | :  71% 0.7087179986088512/1 [00:05<00:10, 37.28s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "matplotlib-base-3.10 | 9.2 MB    | :  21% 0.20528932236932101/1 [00:05<00:05,  7.45s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenblas-0.3.29   | 10.8 MB   | :  42% 0.42398263411039294/1 [00:05<00:04,  8.09s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scikit-image-0.25.2  | 12.6 MB   | :  43% 0.43366696320970294/1 [00:05<00:05,  9.36s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-6.1.1         | 9.9 MB    | :  29% 0.28944134971305624/1 [00:05<00:05,  7.58s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "matplotlib-base-3.10 | 9.2 MB    | :  23% 0.22564859400925366/1 [00:05<00:06,  7.93s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenblas-0.3.29   | 10.8 MB   | :  44% 0.44134711059272985/1 [00:05<00:04,  7.48s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scikit-image-0.25.2  | 12.6 MB   | :  45% 0.4498207469395773/1 [00:05<00:04,  8.49s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-6.1.1         | 9.9 MB    | :  31% 0.305257816910491/1 [00:05<00:05,  8.18s/it]  \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "matplotlib-base-3.10 | 9.2 MB    | :  24% 0.24261465370919755/1 [00:05<00:06,  8.22s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenblas-0.3.29   | 10.8 MB   | :  46% 0.45581750766134393/1 [00:06<00:04,  8.36s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scikit-image-0.25.2  | 12.6 MB   | :  46% 0.46348933317254787/1 [00:06<00:05,  9.51s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-6.1.1         | 9.9 MB    | :  32% 0.3242375775474127/1 [00:06<00:04,  7.31s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "matplotlib-base-3.10 | 9.2 MB    | :  26% 0.2629739253491302/1 [00:06<00:05,  7.23s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenblas-0.3.29   | 10.8 MB   | :  47% 0.47318198414368084/1 [00:06<00:03,  7.58s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scikit-image-0.25.2  | 12.6 MB   | :  48% 0.4784005181539703/1 [00:06<00:04,  8.68s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-6.1.1         | 9.9 MB    | :  34% 0.3432173381843344/1 [00:06<00:04,  6.75s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "matplotlib-base-3.10 | 9.2 MB    | :  28% 0.2833331969890629/1 [00:06<00:04,  6.56s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenblas-0.3.29   | 10.8 MB   | :  49% 0.4919935003328792/1 [00:06<00:03,  6.96s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scikit-image-0.25.2  | 12.6 MB   | :  49% 0.49455430188384464/1 [00:06<00:04,  8.04s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-6.1.1         | 9.9 MB    | :  36% 0.36377874554099965/1 [00:06<00:03,  6.28s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "matplotlib-base-3.10 | 9.2 MB    | :  31% 0.30538907459898995/1 [00:06<00:04,  5.99s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenblas-0.3.29   | 10.8 MB   | :  55% 0.5484280489004741/1 [00:06<00:01,  3.94s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tesseract-5.2.0      | 171.4 MB  | :  72% 0.7201151103837266/1 [00:06<00:11, 41.96s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-6.1.1         | 9.9 MB    | :  60% 0.5962808133432907/1 [00:06<00:00,  1.37s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "matplotlib-base-3.10 | 9.2 MB    | :  69% 0.6888220238177217/1 [00:06<00:00,  1.12it/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenblas-0.3.29   | 10.8 MB   | :  90% 0.9029527770815194/1 [00:06<00:00,  1.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tesseract-5.2.0      | 171.4 MB  | :  79% 0.7928742719545311/1 [00:06<00:02, 14.46s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "matplotlib-base-3.10 | 9.2 MB    | : 100% 1.0/1 [00:06<00:00,  1.12it/s]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenblas-0.3.29   | 10.8 MB   | : 100% 1.0/1 [00:06<00:00,  1.15it/s]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "matplotlib-base-3.10 | 9.2 MB    | : 100% 1.0/1 [00:06<00:00,  1.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-6.1.1         | 9.9 MB    | : 100% 1.0/1 [00:06<00:00,  1.01s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-6.1.1         | 9.9 MB    | : 100% 1.0/1 [00:06<00:00,  1.01s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scikit-image-0.25.2  | 12.6 MB   | : 100% 1.0/1 [00:06<00:00,  1.14it/s]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "numpy-base-2.3.1     | 9.1 MB    | :   0% 0.0017241078131422392/1 [00:06<1:04:52, 3899.08s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-ng-11.2.0     | 8.5 MB    | :   0% 0.0018419038522591651/1 [00:06<1:00:44, 3651.19s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tesseract-5.2.0      | 171.4 MB  | :  84% 0.8354538815454655/1 [00:06<00:01,  9.09s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "qttools-6.7.3        | 7.1 MB    | :   0% 0.0022107809033004647/1 [00:06<50:45, 3051.94s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "numpy-base-2.3.1     | 9.1 MB    | :  35% 0.353442101694159/1 [00:06<00:08, 13.62s/it]        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-ng-11.2.0     | 8.5 MB    | :  35% 0.35180363578150053/1 [00:06<00:08, 13.69s/it]      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "jupyterlab-4.3.4     | 7.9 MB    | :  41% 0.409044250455871/1 [00:06<00:06, 11.79s/it]     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tesseract-5.2.0      | 171.4 MB  | :  86% 0.8613481194979824/1 [00:06<00:01,  7.94s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "numpy-base-2.3.1     | 9.1 MB    | :  70% 0.6965395565094646/1 [00:06<00:01,  5.87s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-ng-11.2.0     | 8.5 MB    | :  81% 0.8122795988462919/1 [00:06<00:00,  4.91s/it] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "jupyterlab-4.3.4     | 7.9 MB    | :  86% 0.8574196788401912/1 [00:06<00:00,  4.74s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tesseract-5.2.0      | 171.4 MB  | :  89% 0.8857835271433152/1 [00:07<00:00,  7.01s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tesseract-5.2.0      | 171.4 MB  | :  91% 0.909307165846658/1 [00:07<00:00,  6.73s/it] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "babel-2.16.0         | 6.8 MB    | :   0% 0.0022934119976634744/1 [00:07<51:53, 3120.69s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "jupyterlab-4.3.4     | 7.9 MB    | : 100% 1.0/1 [00:07<00:00,  4.74s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tesseract-5.2.0      | 171.4 MB  | :  93% 0.9317366818196128/1 [00:07<00:00,  6.12s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "numpy-base-2.3.1     | 9.1 MB    | : 100% 1.0/1 [00:07<00:00,  3.82s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "numpy-base-2.3.1     | 9.1 MB    | : 100% 1.0/1 [00:07<00:00,  3.82s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "babel-2.16.0         | 6.8 MB    | :  74% 0.7430654872429657/1 [00:07<00:01,  6.89s/it]     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tesseract-5.2.0      | 171.4 MB  | :  97% 0.9741339376221493/1 [00:07<00:00,  5.74s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "babel-2.16.0         | 6.8 MB    | : 100% 1.0/1 [00:07<00:00,  6.89s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tesseract-5.2.0      | 171.4 MB  | : 100% 1.0/1 [00:10<00:00, 39.32s/it]\n",
            "\n",
            "\n",
            "\n",
            "icu-73.1             | 27.7 MB   | : 100% 1.0/1 [00:13<00:00,  1.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "opencv-4.10.0        | 36.8 MB   | : 100% 1.0/1 [00:15<00:00,  1.06it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "python-3.13.5        | 42.8 MB   | : 100% 1.0/1 [00:22<00:00,  1.03it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scipy-1.15.3         | 26.6 MB   | : 100% 1.0/1 [00:23<00:00,  1.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "qtbase-6.7.3         | 17.9 MB   | : 100% 1.0/1 [00:28<00:00,  1.37s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "qtdeclarative-6.7.3  | 17.5 MB   | : 100% 1.0/1 [00:29<00:00,  1.33s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pandas-2.2.3         | 16.5 MB   | : 100% 1.0/1 [00:34<00:00,  1.54s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scikit-learn-1.6.1   | 12.7 MB   | : 100% 1.0/1 [00:38<00:00,  1.91s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "matplotlib-base-3.10 | 9.2 MB    | : 100% 1.0/1 [00:40<00:00,  1.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "mysql-8.4.0          | 67.1 MB   | : 100% 1.0/1 [00:43<00:00,  1.46s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libopenblas-0.3.29   | 10.8 MB   | : 100% 1.0/1 [00:44<00:00,  1.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ffmpeg-6.1.1         | 9.9 MB    | : 100% 1.0/1 [00:45<00:00,  1.01s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scikit-image-0.25.2  | 12.6 MB   | : 100% 1.0/1 [00:46<00:00,  1.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "qttools-6.7.3        | 7.1 MB    | : 100% 1.0/1 [00:47<00:00,  4.54s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-ng-11.2.0     | 8.5 MB    | : 100% 1.0/1 [00:48<00:00,  4.91s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "jupyterlab-4.3.4     | 7.9 MB    | : 100% 1.0/1 [00:48<00:00,  4.74s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "babel-2.16.0         | 6.8 MB    | : 100% 1.0/1 [00:50<00:00,  6.89s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "numpy-base-2.3.1     | 9.1 MB    | : 100% 1.0/1 [00:51<00:00,  3.82s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tesseract-5.2.0      | 171.4 MB  | : 100% 1.0/1 [01:35<00:00, 39.32s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \n",
            "                                                                        \u001b[A\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "Preparing transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Verifying transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Executing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate dsmil\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n",
            "Collecting torch\n",
            "  Downloading torch-2.7.1-cp313-cp313-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
            "Collecting filelock (from torch)\n",
            "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/envs/dsmil/lib/python3.13/site-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/envs/dsmil/lib/python3.13/site-packages (from torch) (72.1.0)\n",
            "Collecting sympy>=1.13.3 (from torch)\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/envs/dsmil/lib/python3.13/site-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/envs/dsmil/lib/python3.13/site-packages (from torch) (3.1.6)\n",
            "Collecting fsspec (from torch)\n",
            "  Downloading fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.7.77 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.26.2 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.6.77 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch)\n",
            "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.3.1 (from torch)\n",
            "  Downloading triton-3.3.1-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/envs/dsmil/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading torch-2.7.1-cp313-cp313-manylinux_2_28_x86_64.whl (821.0 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 821.0/821.0 MB 31.9 MB/s eta 0:00:00\n",
            "Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 393.1/393.1 MB 37.3 MB/s eta 0:00:00\n",
            "Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 8.9/8.9 MB 162.9 MB/s eta 0:00:00\n",
            "Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 23.7/23.7 MB 165.8 MB/s eta 0:00:00\n",
            "Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 897.7/897.7 kB 50.2 MB/s eta 0:00:00\n",
            "Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 571.0/571.0 MB 38.9 MB/s eta 0:00:00\n",
            "Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 200.2/200.2 MB 55.1 MB/s eta 0:00:00\n",
            "Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.1/1.1 MB 45.9 MB/s eta 0:00:00\n",
            "Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 56.3/56.3 MB 47.7 MB/s eta 0:00:00\n",
            "Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 158.2/158.2 MB 57.9 MB/s eta 0:00:00\n",
            "Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 216.6/216.6 MB 66.7 MB/s eta 0:00:00\n",
            "Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 156.8/156.8 MB 62.5 MB/s eta 0:00:00\n",
            "Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 201.3/201.3 MB 68.7 MB/s eta 0:00:00\n",
            "Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 19.7/19.7 MB 134.0 MB/s eta 0:00:00\n",
            "Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "Downloading triton-3.3.1-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.7 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 155.7/155.7 MB 62.0 MB/s eta 0:00:00\n",
            "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 6.3/6.3 MB 89.6 MB/s eta 0:00:00\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 536.2/536.2 kB 23.5 MB/s eta 0:00:00\n",
            "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Downloading fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
            "Installing collected packages: nvidia-cusparselt-cu12, mpmath, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fsspec, filelock, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
            "\n",
            "Successfully installed filelock-3.18.0 fsspec-2025.5.1 mpmath-1.3.0 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 sympy-1.14.0 torch-2.7.1 triton-3.3.1\n",
            "\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.22.1-cp313-cp313-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/envs/dsmil/lib/python3.13/site-packages (from torchvision) (2.3.1)\n",
            "Requirement already satisfied: torch==2.7.1 in /usr/local/envs/dsmil/lib/python3.13/site-packages (from torchvision) (2.7.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/envs/dsmil/lib/python3.13/site-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/envs/dsmil/lib/python3.13/site-packages (from torch==2.7.1->torchvision) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/envs/dsmil/lib/python3.13/site-packages (from torch==2.7.1->torchvision) (4.12.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/envs/dsmil/lib/python3.13/site-packages (from torch==2.7.1->torchvision) (72.1.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/envs/dsmil/lib/python3.13/site-packages (from torch==2.7.1->torchvision) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/envs/dsmil/lib/python3.13/site-packages (from torch==2.7.1->torchvision) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/envs/dsmil/lib/python3.13/site-packages (from torch==2.7.1->torchvision) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/envs/dsmil/lib/python3.13/site-packages (from torch==2.7.1->torchvision) (2025.5.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/envs/dsmil/lib/python3.13/site-packages (from torch==2.7.1->torchvision) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/envs/dsmil/lib/python3.13/site-packages (from torch==2.7.1->torchvision) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/envs/dsmil/lib/python3.13/site-packages (from torch==2.7.1->torchvision) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/envs/dsmil/lib/python3.13/site-packages (from torch==2.7.1->torchvision) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/envs/dsmil/lib/python3.13/site-packages (from torch==2.7.1->torchvision) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/envs/dsmil/lib/python3.13/site-packages (from torch==2.7.1->torchvision) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/envs/dsmil/lib/python3.13/site-packages (from torch==2.7.1->torchvision) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/envs/dsmil/lib/python3.13/site-packages (from torch==2.7.1->torchvision) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/envs/dsmil/lib/python3.13/site-packages (from torch==2.7.1->torchvision) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/envs/dsmil/lib/python3.13/site-packages (from torch==2.7.1->torchvision) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/envs/dsmil/lib/python3.13/site-packages (from torch==2.7.1->torchvision) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/envs/dsmil/lib/python3.13/site-packages (from torch==2.7.1->torchvision) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/envs/dsmil/lib/python3.13/site-packages (from torch==2.7.1->torchvision) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/envs/dsmil/lib/python3.13/site-packages (from torch==2.7.1->torchvision) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.3.1 in /usr/local/envs/dsmil/lib/python3.13/site-packages (from torch==2.7.1->torchvision) (3.3.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/envs/dsmil/lib/python3.13/site-packages (from sympy>=1.13.3->torch==2.7.1->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/envs/dsmil/lib/python3.13/site-packages (from jinja2->torch==2.7.1->torchvision) (3.0.2)\n",
            "Downloading torchvision-0.22.1-cp313-cp313-manylinux_2_28_x86_64.whl (7.5 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7.5/7.5 MB 26.2 MB/s eta 0:00:00\n",
            "Installing collected packages: torchvision\n",
            "Successfully installed torchvision-0.22.1\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%cd /content/dsmil-wsi\n",
        "!conda env create -f env.yml\n",
        "!conda run -n dsmil pip install torch\n",
        "!conda run -n dsmil pip install torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jADnmpOKjXiM"
      },
      "outputs": [],
      "source": [
        "!conda run -n dsmil conda list\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### With pre-extracted features (UNI: https://huggingface.co/MahmoodLab/UNI)"
      ],
      "metadata": {
        "id": "l6po_sM-3mK6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFw1RnR-Wbcr",
        "outputId": "eb74c3ff-3354-4fdd-db2e-03ac3557bccc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/dsmil-wsi\n",
            "--2025-06-26 12:27:45--  https://zenodo.org/records/15547611/files/datasetUnified_PT.zip?download=1\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.43.25, 188.185.45.92, 188.185.48.194, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.43.25|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2005901570 (1.9G) [application/octet-stream]\n",
            "Saving to: â€˜MLiA_features.zipâ€™\n",
            "\n",
            "MLiA_features.zip   100%[===================>]   1.87G  18.7MB/s    in 1m 49s  \n",
            "\n",
            "2025-06-26 12:29:35 (17.5 MB/s) - â€˜MLiA_features.zipâ€™ saved [2005901570/2005901570]\n",
            "\n",
            "Extracted files: ['tcga-download', 'README.md', 'results_features', 'MLiA_features.zip', 'train_mil.py', 'compute_feats.py', 'testing_c16.py', 'deepzoom_tiler.py', 'test_crop_single.py', 'init.pth', '.gitignore', 'thumbnails', 'testing_tcga.py', 'simclr', 'dsmil.py', 'env.yml', 'train_tcga.py', 'example_aggregator_weights', '.git', 'LICENSE', 'download.py', 'attention_map.py']\n"
          ]
        }
      ],
      "source": [
        "%cd /content/dsmil-wsi\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "# URL for the dataset\n",
        "url = \"https://zenodo.org/records/15547611/files/datasetUnified_PT.zip?download=1\"\n",
        "\n",
        "# Download the file using wget\n",
        "!wget -O MLiA_features.zip \"$url\"\n",
        "\n",
        "# Define the extraction path\n",
        "extract_path = './'\n",
        "\n",
        "# Create the extraction directory if it doesn't exist\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "# Extract the ZIP file\n",
        "with zipfile.ZipFile('MLiA_features.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "# List the contents of the extracted folder\n",
        "extracted_files = os.listdir(extract_path)\n",
        "print(\"Extracted files:\", extracted_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNOmlYTbZMOm",
        "outputId": "bef8d81f-7f7b-4240-9c6c-edab1952d159"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/dsmil-wsi/results_features/h5_files\n",
            "(19043, 1024)\n",
            "/content/dsmil-wsi/results_features/pt_files\n",
            "torch.Size([19043, 1024])\n"
          ]
        }
      ],
      "source": [
        "%cd /content/dsmil-wsi/results_features/h5_files\n",
        "import h5py\n",
        "with h5py.File('M-1.h5', 'r') as f:\n",
        "    features = f['features'][:]  # or f['data'][:] depending on your key\n",
        "print(features.shape)  # (num_patches, feature_dim)\n",
        "\n",
        "%cd /content/dsmil-wsi/results_features/pt_files/\n",
        "import torch\n",
        "features = torch.load('M-1.pt')\n",
        "print(features.shape)  # (num_patches, feature_dim)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9119aa4c",
        "outputId": "6e15603f-425a-4d20-e1d7-7f1c9d1f90e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully converted M-105.h5 to M-105.csv\n",
            "Successfully converted M-111.h5 to M-111.csv\n",
            "Successfully converted M-109.h5 to M-109.csv\n",
            "Successfully converted M-10.h5 to M-10.csv\n",
            "Successfully converted M-108.h5 to M-108.csv\n",
            "Successfully converted M-103.h5 to M-103.csv\n",
            "Successfully converted M-30.h5 to M-30.csv\n",
            "Successfully converted M-112.h5 to M-112.csv\n",
            "Successfully converted M-11.h5 to M-11.csv\n",
            "Successfully converted M-1.h5 to M-1.csv\n",
            "Successfully converted M-114.h5 to M-114.csv\n",
            "Successfully converted M-86.h5 to M-86.csv\n",
            "Successfully converted M-110.h5 to M-110.csv\n",
            "Successfully converted M-100.h5 to M-100.csv\n",
            "Successfully converted M-104.h5 to M-104.csv\n",
            "Successfully converted M-87.h5 to M-87.csv\n",
            "Successfully converted M-113.h5 to M-113.csv\n",
            "Successfully converted M-32.h5 to M-32.csv\n",
            "Successfully converted M-65.h5 to M-65.csv\n",
            "Successfully converted M-121.h5 to M-121.csv\n",
            "Successfully converted M-24.h5 to M-24.csv\n",
            "Successfully converted M-101.h5 to M-101.csv\n"
          ]
        }
      ],
      "source": [
        "import h5py\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "h5_dir = '/content/dsmil-wsi/results_features/h5_files'\n",
        "\n",
        "# Get a list of all .h5 files in the directory\n",
        "all_files = os.listdir(h5_dir)\n",
        "h5_files = [f for f in all_files if f.endswith('.h5')]\n",
        "\n",
        "# Iterate through each .h5 file and convert to CSV\n",
        "for h5_filename in h5_files:\n",
        "    h5_file_path = os.path.join(h5_dir, h5_filename)\n",
        "    csv_filename = os.path.splitext(h5_filename)[0] + '.csv'\n",
        "    csv_output_path = os.path.join(h5_dir, csv_filename)\n",
        "\n",
        "    try:\n",
        "        # Read data from the HDF5 file\n",
        "        with h5py.File(h5_file_path, 'r') as f:\n",
        "            # Assuming your data is stored under the key 'features'\n",
        "            features_data = f['features'][:]\n",
        "\n",
        "        # Convert the numpy array to a pandas DataFrame\n",
        "        df = pd.DataFrame(features_data)\n",
        "\n",
        "        # Add a patch number column (starting from 1)\n",
        "        #df.insert(0, 'patch_number', range(1, 1 + len(df)))\n",
        "\n",
        "        # Write the DataFrame to a CSV file\n",
        "        df.to_csv(csv_output_path, index=False, header=False)\n",
        "\n",
        "        print(f\"Successfully converted {h5_filename} to {csv_filename}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error converting {h5_filename}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "227aa49c"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "label_dict = {\n",
        "    'M-1': 'B', 'M-104': 'B', 'M-105': 'B', 'M-108': 'B', 'M-112': 'B',\n",
        "    'M-121': 'B', 'M-24': 'B', 'M-30': 'B', 'M-32': 'B',\n",
        "    'M-10': 'E', 'M-100': 'E', 'M-103': 'E', 'M-109': 'E', 'M-11': 'E',\n",
        "    'M-110': 'E', 'M-111': 'E', 'M-113': 'E',\n",
        "    'M-101': 'S', 'M-114': 'S', 'M-65': 'S', 'M-86': 'S', 'M-87': 'S'\n",
        "}\n",
        "\n",
        "label_map = {'B': 0, 'S': 1, 'E': 2}\n",
        "\n",
        "csv_dir = '/content/dsmil-wsi/results_features/h5_files'\n",
        "csv_files = [f for f in os.listdir(csv_dir) if f.endswith('.csv')]\n",
        "\n",
        "csv_data = []\n",
        "\n",
        "for f in csv_files:\n",
        "    slide_id = os.path.splitext(f)[0]\n",
        "    if slide_id in label_dict:\n",
        "        label_int = label_map[label_dict[slide_id]]\n",
        "        csv_data.append([os.path.join(csv_dir, f), label_int])\n",
        "\n",
        "# Save without header and without index\n",
        "output_path = '/content/dsmil-wsi/results_features/MLiA_dataset.csv'\n",
        "pd.DataFrame(csv_data).to_csv(output_path, index=False, header=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9vF_4YwXc2oc",
        "outputId": "063f5717-1ce7-420e-bc6a-a31411357819"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mOutput streaming troncato alle ultime 5000 righe.\u001b[0m\n",
            " Training bag [6/10] bag loss: 0.6743\n",
            " Training bag [7/10] bag loss: 0.6685\n",
            " Training bag [8/10] bag loss: 0.6706\n",
            " Training bag [9/10] bag loss: 0.6688\n",
            " Testing bag [0/11] bag loss: 0.7149\n",
            " Testing bag [1/11] bag loss: 0.7111\n",
            " Testing bag [2/11] bag loss: 0.6692\n",
            " Testing bag [3/11] bag loss: 0.6701\n",
            " Testing bag [4/11] bag loss: 0.6685\n",
            " Testing bag [5/11] bag loss: 0.6645\n",
            " Testing bag [6/11] bag loss: 0.6714\n",
            " Testing bag [7/11] bag loss: 0.7140\n",
            " Testing bag [8/11] bag loss: 0.6694\n",
            " Testing bag [9/11] bag loss: 0.6676\n",
            " Testing bag [10/11] bag loss: 0.6726ROC AUC score: 0.6785714285714285\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.6785714285714286\n",
            "\n",
            " Epoch [50/300] train loss: 0.6798 test loss: 0.6812, average score: 0.5455, AUC: class-0>>0.6785714285714285|class-1>>1.0|class-2>>0.6785714285714286\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6724\n",
            " Training bag [1/10] bag loss: 0.6714\n",
            " Training bag [2/10] bag loss: 0.6728\n",
            " Training bag [3/10] bag loss: 0.7164\n",
            " Training bag [4/10] bag loss: 0.6633\n",
            " Training bag [5/10] bag loss: 0.6709\n",
            " Training bag [6/10] bag loss: 0.6682\n",
            " Training bag [7/10] bag loss: 0.6733\n",
            " Training bag [8/10] bag loss: 0.6673\n",
            " Training bag [9/10] bag loss: 0.7160\n",
            " Testing bag [0/11] bag loss: 0.7159\n",
            " Testing bag [1/11] bag loss: 0.7124\n",
            " Testing bag [2/11] bag loss: 0.6678\n",
            " Testing bag [3/11] bag loss: 0.6685\n",
            " Testing bag [4/11] bag loss: 0.6688\n",
            " Testing bag [5/11] bag loss: 0.6638\n",
            " Testing bag [6/11] bag loss: 0.6698\n",
            " Testing bag [7/11] bag loss: 0.7145\n",
            " Testing bag [8/11] bag loss: 0.6690\n",
            " Testing bag [9/11] bag loss: 0.6673\n",
            " Testing bag [10/11] bag loss: 0.6730ROC AUC score: 0.6785714285714285\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.7142857142857143\n",
            "\n",
            " Epoch [51/300] train loss: 0.6792 test loss: 0.6810, average score: 0.5455, AUC: class-0>>0.6785714285714285|class-1>>1.0|class-2>>0.7142857142857143\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6682\n",
            " Training bag [1/10] bag loss: 0.7167\n",
            " Training bag [2/10] bag loss: 0.6636\n",
            " Training bag [3/10] bag loss: 0.6723\n",
            " Training bag [4/10] bag loss: 0.6705\n",
            " Training bag [5/10] bag loss: 0.6731\n",
            " Training bag [6/10] bag loss: 0.6719\n",
            " Training bag [7/10] bag loss: 0.7158\n",
            " Training bag [8/10] bag loss: 0.6673\n",
            " Training bag [9/10] bag loss: 0.6734\n",
            " Testing bag [0/11] bag loss: 0.7157\n",
            " Testing bag [1/11] bag loss: 0.7129\n",
            " Testing bag [2/11] bag loss: 0.6671\n",
            " Testing bag [3/11] bag loss: 0.6687\n",
            " Testing bag [4/11] bag loss: 0.6673\n",
            " Testing bag [5/11] bag loss: 0.6633\n",
            " Testing bag [6/11] bag loss: 0.6701\n",
            " Testing bag [7/11] bag loss: 0.7147\n",
            " Testing bag [8/11] bag loss: 0.6684\n",
            " Testing bag [9/11] bag loss: 0.6671\n",
            " Testing bag [10/11] bag loss: 0.6717ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.7142857142857143\n",
            "\n",
            " Epoch [52/300] train loss: 0.6793 test loss: 0.6806, average score: 0.5455, AUC: class-0>>0.6428571428571428|class-1>>1.0|class-2>>0.7142857142857143\n",
            "\n",
            " Training bag [0/10] bag loss: 0.7171\n",
            " Training bag [1/10] bag loss: 0.6715\n",
            " Training bag [2/10] bag loss: 0.6710\n",
            " Training bag [3/10] bag loss: 0.6697\n",
            " Training bag [4/10] bag loss: 0.7160\n",
            " Training bag [5/10] bag loss: 0.6682\n",
            " Training bag [6/10] bag loss: 0.6620\n",
            " Training bag [7/10] bag loss: 0.6722\n",
            " Training bag [8/10] bag loss: 0.6719\n",
            " Training bag [9/10] bag loss: 0.6668\n",
            " Testing bag [0/11] bag loss: 0.7160\n",
            " Testing bag [1/11] bag loss: 0.7116\n",
            " Testing bag [2/11] bag loss: 0.6666\n",
            " Testing bag [3/11] bag loss: 0.6673\n",
            " Testing bag [4/11] bag loss: 0.6663\n",
            " Testing bag [5/11] bag loss: 0.6630\n",
            " Testing bag [6/11] bag loss: 0.6684\n",
            " Testing bag [7/11] bag loss: 0.7148\n",
            " Testing bag [8/11] bag loss: 0.6669\n",
            " Testing bag [9/11] bag loss: 0.6664\n",
            " Testing bag [10/11] bag loss: 0.6711ROC AUC score: 0.6785714285714285\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.7142857142857143\n",
            "\n",
            " Epoch [53/300] train loss: 0.6786 test loss: 0.6798, average score: 0.5455, AUC: class-0>>0.6785714285714285|class-1>>1.0|class-2>>0.7142857142857143\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6693\n",
            " Training bag [1/10] bag loss: 0.6667\n",
            " Training bag [2/10] bag loss: 0.6693\n",
            " Training bag [3/10] bag loss: 0.6664\n",
            " Training bag [4/10] bag loss: 0.6611\n",
            " Training bag [5/10] bag loss: 0.6704\n",
            " Training bag [6/10] bag loss: 0.6709\n",
            " Training bag [7/10] bag loss: 0.7178\n",
            " Training bag [8/10] bag loss: 0.7189\n",
            " Training bag [9/10] bag loss: 0.6716\n",
            " Testing bag [0/11] bag loss: 0.7159\n",
            " Testing bag [1/11] bag loss: 0.7127\n",
            " Testing bag [2/11] bag loss: 0.6654\n",
            " Testing bag [3/11] bag loss: 0.6673\n",
            " Testing bag [4/11] bag loss: 0.6667\n",
            " Testing bag [5/11] bag loss: 0.6609\n",
            " Testing bag [6/11] bag loss: 0.6683\n",
            " Testing bag [7/11] bag loss: 0.7156\n",
            " Testing bag [8/11] bag loss: 0.6676\n",
            " Testing bag [9/11] bag loss: 0.6651\n",
            " Testing bag [10/11] bag loss: 0.6709ROC AUC score: 0.6785714285714285\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.7142857142857143\n",
            "\n",
            " Epoch [54/300] train loss: 0.6782 test loss: 0.6797, average score: 0.5455, AUC: class-0>>0.6785714285714285|class-1>>1.0|class-2>>0.7142857142857143\n",
            "\n",
            " Training bag [0/10] bag loss: 0.7173\n",
            " Training bag [1/10] bag loss: 0.6609\n",
            " Training bag [2/10] bag loss: 0.6662\n",
            " Training bag [3/10] bag loss: 0.6654\n",
            " Training bag [4/10] bag loss: 0.6709\n",
            " Training bag [5/10] bag loss: 0.6699\n",
            " Training bag [6/10] bag loss: 0.7170\n",
            " Training bag [7/10] bag loss: 0.6717\n",
            " Training bag [8/10] bag loss: 0.6693\n",
            " Training bag [9/10] bag loss: 0.6702\n",
            " Testing bag [0/11] bag loss: 0.7158\n",
            " Testing bag [1/11] bag loss: 0.7130\n",
            " Testing bag [2/11] bag loss: 0.6659\n",
            " Testing bag [3/11] bag loss: 0.6666\n",
            " Testing bag [4/11] bag loss: 0.6646\n",
            " Testing bag [5/11] bag loss: 0.6618\n",
            " Testing bag [6/11] bag loss: 0.6673\n",
            " Testing bag [7/11] bag loss: 0.7153\n",
            " Testing bag [8/11] bag loss: 0.6664\n",
            " Testing bag [9/11] bag loss: 0.6653\n",
            " Testing bag [10/11] bag loss: 0.6707ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.7142857142857143\n",
            "\n",
            " Epoch [55/300] train loss: 0.6779 test loss: 0.6793, average score: 0.5455, AUC: class-0>>0.6428571428571428|class-1>>1.0|class-2>>0.7142857142857143\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6691\n",
            " Training bag [1/10] bag loss: 0.7185\n",
            " Training bag [2/10] bag loss: 0.6693\n",
            " Training bag [3/10] bag loss: 0.7171\n",
            " Training bag [4/10] bag loss: 0.6605\n",
            " Training bag [5/10] bag loss: 0.6650\n",
            " Training bag [6/10] bag loss: 0.6676\n",
            " Training bag [7/10] bag loss: 0.6704\n",
            " Training bag [8/10] bag loss: 0.6661\n",
            " Training bag [9/10] bag loss: 0.6700\n",
            " Testing bag [0/11] bag loss: 0.7163\n",
            " Testing bag [1/11] bag loss: 0.7138\n",
            " Testing bag [2/11] bag loss: 0.6657\n",
            " Testing bag [3/11] bag loss: 0.6661\n",
            " Testing bag [4/11] bag loss: 0.6642\n",
            " Testing bag [5/11] bag loss: 0.6610\n",
            " Testing bag [6/11] bag loss: 0.6667\n",
            " Testing bag [7/11] bag loss: 0.7151\n",
            " Testing bag [8/11] bag loss: 0.6658\n",
            " Testing bag [9/11] bag loss: 0.6638\n",
            " Testing bag [10/11] bag loss: 0.6692ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.7142857142857143\n",
            "\n",
            " Epoch [56/300] train loss: 0.6773 test loss: 0.6789, average score: 0.5455, AUC: class-0>>0.6428571428571428|class-1>>1.0|class-2>>0.7142857142857143\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6708\n",
            " Training bag [1/10] bag loss: 0.7177\n",
            " Training bag [2/10] bag loss: 0.6642\n",
            " Training bag [3/10] bag loss: 0.6668\n",
            " Training bag [4/10] bag loss: 0.6689\n",
            " Training bag [5/10] bag loss: 0.6694\n",
            " Training bag [6/10] bag loss: 0.6595\n",
            " Training bag [7/10] bag loss: 0.7168\n",
            " Training bag [8/10] bag loss: 0.6684\n",
            " Training bag [9/10] bag loss: 0.6638\n",
            " Testing bag [0/11] bag loss: 0.7167\n",
            " Testing bag [1/11] bag loss: 0.7135\n",
            " Testing bag [2/11] bag loss: 0.6640\n",
            " Testing bag [3/11] bag loss: 0.6661\n",
            " Testing bag [4/11] bag loss: 0.6653\n",
            " Testing bag [5/11] bag loss: 0.6612\n",
            " Testing bag [6/11] bag loss: 0.6665\n",
            " Testing bag [7/11] bag loss: 0.7166\n",
            " Testing bag [8/11] bag loss: 0.6658\n",
            " Testing bag [9/11] bag loss: 0.6644\n",
            " Testing bag [10/11] bag loss: 0.6698ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.7142857142857143\n",
            "\n",
            " Epoch [57/300] train loss: 0.6766 test loss: 0.6791, average score: 0.5455, AUC: class-0>>0.6428571428571428|class-1>>1.0|class-2>>0.7142857142857143\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6703\n",
            " Training bag [1/10] bag loss: 0.6687\n",
            " Training bag [2/10] bag loss: 0.6590\n",
            " Training bag [3/10] bag loss: 0.7194\n",
            " Training bag [4/10] bag loss: 0.6668\n",
            " Training bag [5/10] bag loss: 0.6647\n",
            " Training bag [6/10] bag loss: 0.7176\n",
            " Training bag [7/10] bag loss: 0.6668\n",
            " Training bag [8/10] bag loss: 0.6638\n",
            " Training bag [9/10] bag loss: 0.6683\n",
            " Testing bag [0/11] bag loss: 0.7173\n",
            " Testing bag [1/11] bag loss: 0.7152\n",
            " Testing bag [2/11] bag loss: 0.6639\n",
            " Testing bag [3/11] bag loss: 0.6650\n",
            " Testing bag [4/11] bag loss: 0.6651\n",
            " Testing bag [5/11] bag loss: 0.6587\n",
            " Testing bag [6/11] bag loss: 0.6667\n",
            " Testing bag [7/11] bag loss: 0.7162\n",
            " Testing bag [8/11] bag loss: 0.6651\n",
            " Testing bag [9/11] bag loss: 0.6639\n",
            " Testing bag [10/11] bag loss: 0.6696ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.7142857142857143\n",
            "\n",
            " Epoch [58/300] train loss: 0.6765 test loss: 0.6788, average score: 0.5455, AUC: class-0>>0.6428571428571428|class-1>>1.0|class-2>>0.7142857142857143\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6692\n",
            " Training bag [1/10] bag loss: 0.7192\n",
            " Training bag [2/10] bag loss: 0.6678\n",
            " Training bag [3/10] bag loss: 0.6643\n",
            " Training bag [4/10] bag loss: 0.6634\n",
            " Training bag [5/10] bag loss: 0.6664\n",
            " Training bag [6/10] bag loss: 0.7187\n",
            " Training bag [7/10] bag loss: 0.6679\n",
            " Training bag [8/10] bag loss: 0.6572\n",
            " Training bag [9/10] bag loss: 0.6674\n",
            " Testing bag [0/11] bag loss: 0.7175\n",
            " Testing bag [1/11] bag loss: 0.7137\n",
            " Testing bag [2/11] bag loss: 0.6629\n",
            " Testing bag [3/11] bag loss: 0.6648\n",
            " Testing bag [4/11] bag loss: 0.6642\n",
            " Testing bag [5/11] bag loss: 0.6595\n",
            " Testing bag [6/11] bag loss: 0.6665\n",
            " Testing bag [7/11] bag loss: 0.7157\n",
            " Testing bag [8/11] bag loss: 0.6642\n",
            " Testing bag [9/11] bag loss: 0.6631\n",
            " Testing bag [10/11] bag loss: 0.6686ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.7142857142857143\n",
            "\n",
            " Epoch [59/300] train loss: 0.6762 test loss: 0.6782, average score: 0.5455, AUC: class-0>>0.6428571428571428|class-1>>1.0|class-2>>0.7142857142857143\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6632\n",
            " Training bag [1/10] bag loss: 0.7180\n",
            " Training bag [2/10] bag loss: 0.6584\n",
            " Training bag [3/10] bag loss: 0.6668\n",
            " Training bag [4/10] bag loss: 0.6696\n",
            " Training bag [5/10] bag loss: 0.7180\n",
            " Training bag [6/10] bag loss: 0.6676\n",
            " Training bag [7/10] bag loss: 0.6672\n",
            " Training bag [8/10] bag loss: 0.6613\n",
            " Training bag [9/10] bag loss: 0.6672\n",
            " Testing bag [0/11] bag loss: 0.7177\n",
            " Testing bag [1/11] bag loss: 0.7155\n",
            " Testing bag [2/11] bag loss: 0.6621\n",
            " Testing bag [3/11] bag loss: 0.6641\n",
            " Testing bag [4/11] bag loss: 0.6631\n",
            " Testing bag [5/11] bag loss: 0.6585\n",
            " Testing bag [6/11] bag loss: 0.6651\n",
            " Testing bag [7/11] bag loss: 0.7161\n",
            " Testing bag [8/11] bag loss: 0.6638\n",
            " Testing bag [9/11] bag loss: 0.6626\n",
            " Testing bag [10/11] bag loss: 0.6674ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.7142857142857143\n",
            "\n",
            " Epoch [60/300] train loss: 0.6757 test loss: 0.6778, average score: 0.5455, AUC: class-0>>0.6428571428571428|class-1>>1.0|class-2>>0.7142857142857143\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6616\n",
            " Training bag [1/10] bag loss: 0.6559\n",
            " Training bag [2/10] bag loss: 0.6657\n",
            " Training bag [3/10] bag loss: 0.7199\n",
            " Training bag [4/10] bag loss: 0.6677\n",
            " Training bag [5/10] bag loss: 0.6670\n",
            " Training bag [6/10] bag loss: 0.7179\n",
            " Training bag [7/10] bag loss: 0.6614\n",
            " Training bag [8/10] bag loss: 0.6658\n",
            " Training bag [9/10] bag loss: 0.6689\n",
            " Testing bag [0/11] bag loss: 0.7169\n",
            " Testing bag [1/11] bag loss: 0.7153\n",
            " Testing bag [2/11] bag loss: 0.6614\n",
            " Testing bag [3/11] bag loss: 0.6629\n",
            " Testing bag [4/11] bag loss: 0.6631\n",
            " Testing bag [5/11] bag loss: 0.6573\n",
            " Testing bag [6/11] bag loss: 0.6653\n",
            " Testing bag [7/11] bag loss: 0.7166\n",
            " Testing bag [8/11] bag loss: 0.6636\n",
            " Testing bag [9/11] bag loss: 0.6620\n",
            " Testing bag [10/11] bag loss: 0.6684ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.7142857142857143\n",
            "\n",
            " Epoch [61/300] train loss: 0.6752 test loss: 0.6775, average score: 0.5455, AUC: class-0>>0.6428571428571428|class-1>>1.0|class-2>>0.7142857142857143\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6666\n",
            " Training bag [1/10] bag loss: 0.7188\n",
            " Training bag [2/10] bag loss: 0.7183\n",
            " Training bag [3/10] bag loss: 0.6682\n",
            " Training bag [4/10] bag loss: 0.6624\n",
            " Training bag [5/10] bag loss: 0.6662\n",
            " Training bag [6/10] bag loss: 0.6652\n",
            " Training bag [7/10] bag loss: 0.6613\n",
            " Training bag [8/10] bag loss: 0.6568\n",
            " Training bag [9/10] bag loss: 0.6645\n",
            " Testing bag [0/11] bag loss: 0.7173\n",
            " Testing bag [1/11] bag loss: 0.7139\n",
            " Testing bag [2/11] bag loss: 0.6613\n",
            " Testing bag [3/11] bag loss: 0.6629\n",
            " Testing bag [4/11] bag loss: 0.6607\n",
            " Testing bag [5/11] bag loss: 0.6574\n",
            " Testing bag [6/11] bag loss: 0.6652\n",
            " Testing bag [7/11] bag loss: 0.7173\n",
            " Testing bag [8/11] bag loss: 0.6627\n",
            " Testing bag [9/11] bag loss: 0.6621\n",
            " Testing bag [10/11] bag loss: 0.6684ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.7142857142857143\n",
            "\n",
            " Epoch [62/300] train loss: 0.6748 test loss: 0.6772, average score: 0.5455, AUC: class-0>>0.6428571428571428|class-1>>1.0|class-2>>0.7142857142857143\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6610\n",
            " Training bag [1/10] bag loss: 0.6638\n",
            " Training bag [2/10] bag loss: 0.6659\n",
            " Training bag [3/10] bag loss: 0.6612\n",
            " Training bag [4/10] bag loss: 0.7186\n",
            " Training bag [5/10] bag loss: 0.6668\n",
            " Training bag [6/10] bag loss: 0.7196\n",
            " Training bag [7/10] bag loss: 0.6548\n",
            " Training bag [8/10] bag loss: 0.6637\n",
            " Training bag [9/10] bag loss: 0.6658\n",
            " Testing bag [0/11] bag loss: 0.7179\n",
            " Testing bag [1/11] bag loss: 0.7149\n",
            " Testing bag [2/11] bag loss: 0.6612\n",
            " Testing bag [3/11] bag loss: 0.6630\n",
            " Testing bag [4/11] bag loss: 0.6622\n",
            " Testing bag [5/11] bag loss: 0.6552\n",
            " Testing bag [6/11] bag loss: 0.6643\n",
            " Testing bag [7/11] bag loss: 0.7176\n",
            " Testing bag [8/11] bag loss: 0.6628\n",
            " Testing bag [9/11] bag loss: 0.6615\n",
            " Testing bag [10/11] bag loss: 0.6667ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.7142857142857143\n",
            "\n",
            " Epoch [63/300] train loss: 0.6741 test loss: 0.6770, average score: 0.5455, AUC: class-0>>0.6428571428571428|class-1>>1.0|class-2>>0.7142857142857143\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6642\n",
            " Training bag [1/10] bag loss: 0.6640\n",
            " Training bag [2/10] bag loss: 0.6660\n",
            " Training bag [3/10] bag loss: 0.7198\n",
            " Training bag [4/10] bag loss: 0.6609\n",
            " Training bag [5/10] bag loss: 0.6552\n",
            " Training bag [6/10] bag loss: 0.6653\n",
            " Training bag [7/10] bag loss: 0.6609\n",
            " Training bag [8/10] bag loss: 0.6646\n",
            " Training bag [9/10] bag loss: 0.7201\n",
            " Testing bag [0/11] bag loss: 0.7189\n",
            " Testing bag [1/11] bag loss: 0.7155\n",
            " Testing bag [2/11] bag loss: 0.6598\n",
            " Testing bag [3/11] bag loss: 0.6616\n",
            " Testing bag [4/11] bag loss: 0.6609\n",
            " Testing bag [5/11] bag loss: 0.6564\n",
            " Testing bag [6/11] bag loss: 0.6637\n",
            " Testing bag [7/11] bag loss: 0.7171\n",
            " Testing bag [8/11] bag loss: 0.6620\n",
            " Testing bag [9/11] bag loss: 0.6604\n",
            " Testing bag [10/11] bag loss: 0.6664ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.7142857142857143\n",
            "\n",
            " Epoch [64/300] train loss: 0.6741 test loss: 0.6766, average score: 0.5455, AUC: class-0>>0.6428571428571428|class-1>>1.0|class-2>>0.7142857142857143\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6645\n",
            " Training bag [1/10] bag loss: 0.6624\n",
            " Training bag [2/10] bag loss: 0.7194\n",
            " Training bag [3/10] bag loss: 0.6664\n",
            " Training bag [4/10] bag loss: 0.6596\n",
            " Training bag [5/10] bag loss: 0.6651\n",
            " Training bag [6/10] bag loss: 0.6552\n",
            " Training bag [7/10] bag loss: 0.6596\n",
            " Training bag [8/10] bag loss: 0.6635\n",
            " Training bag [9/10] bag loss: 0.7213\n",
            " Testing bag [0/11] bag loss: 0.7185\n",
            " Testing bag [1/11] bag loss: 0.7152\n",
            " Testing bag [2/11] bag loss: 0.6588\n",
            " Testing bag [3/11] bag loss: 0.6609\n",
            " Testing bag [4/11] bag loss: 0.6599\n",
            " Testing bag [5/11] bag loss: 0.6560\n",
            " Testing bag [6/11] bag loss: 0.6628\n",
            " Testing bag [7/11] bag loss: 0.7181\n",
            " Testing bag [8/11] bag loss: 0.6612\n",
            " Testing bag [9/11] bag loss: 0.6604\n",
            " Testing bag [10/11] bag loss: 0.6660ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.7142857142857143\n",
            "\n",
            " Epoch [65/300] train loss: 0.6737 test loss: 0.6761, average score: 0.5455, AUC: class-0>>0.6428571428571428|class-1>>1.0|class-2>>0.7142857142857143\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6630\n",
            " Training bag [1/10] bag loss: 0.6647\n",
            " Training bag [2/10] bag loss: 0.6663\n",
            " Training bag [3/10] bag loss: 0.6634\n",
            " Training bag [4/10] bag loss: 0.6588\n",
            " Training bag [5/10] bag loss: 0.6527\n",
            " Training bag [6/10] bag loss: 0.7208\n",
            " Training bag [7/10] bag loss: 0.6637\n",
            " Training bag [8/10] bag loss: 0.7203\n",
            " Training bag [9/10] bag loss: 0.6590\n",
            " Testing bag [0/11] bag loss: 0.7189\n",
            " Testing bag [1/11] bag loss: 0.7154\n",
            " Testing bag [2/11] bag loss: 0.6591\n",
            " Testing bag [3/11] bag loss: 0.6604\n",
            " Testing bag [4/11] bag loss: 0.6602\n",
            " Testing bag [5/11] bag loss: 0.6545\n",
            " Testing bag [6/11] bag loss: 0.6620\n",
            " Testing bag [7/11] bag loss: 0.7182\n",
            " Testing bag [8/11] bag loss: 0.6611\n",
            " Testing bag [9/11] bag loss: 0.6600\n",
            " Testing bag [10/11] bag loss: 0.6662ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.7142857142857143\n",
            "\n",
            " Epoch [66/300] train loss: 0.6733 test loss: 0.6760, average score: 0.5455, AUC: class-0>>0.6428571428571428|class-1>>1.0|class-2>>0.7142857142857143\n",
            "\n",
            " Training bag [0/10] bag loss: 0.7213\n",
            " Training bag [1/10] bag loss: 0.6638\n",
            " Training bag [2/10] bag loss: 0.7197\n",
            " Training bag [3/10] bag loss: 0.6638\n",
            " Training bag [4/10] bag loss: 0.6599\n",
            " Training bag [5/10] bag loss: 0.6534\n",
            " Training bag [6/10] bag loss: 0.6598\n",
            " Training bag [7/10] bag loss: 0.6650\n",
            " Training bag [8/10] bag loss: 0.6624\n",
            " Training bag [9/10] bag loss: 0.6625\n",
            " Testing bag [0/11] bag loss: 0.7193\n",
            " Testing bag [1/11] bag loss: 0.7171\n",
            " Testing bag [2/11] bag loss: 0.6584\n",
            " Testing bag [3/11] bag loss: 0.6609\n",
            " Testing bag [4/11] bag loss: 0.6596\n",
            " Testing bag [5/11] bag loss: 0.6554\n",
            " Testing bag [6/11] bag loss: 0.6623\n",
            " Testing bag [7/11] bag loss: 0.7182\n",
            " Testing bag [8/11] bag loss: 0.6600\n",
            " Testing bag [9/11] bag loss: 0.6594\n",
            " Testing bag [10/11] bag loss: 0.6652ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.6785714285714286\n",
            "\n",
            " Epoch [67/300] train loss: 0.6732 test loss: 0.6760, average score: 0.5455, AUC: class-0>>0.6428571428571428|class-1>>1.0|class-2>>0.6785714285714286\n",
            "\n",
            " Training bag [0/10] bag loss: 0.7214\n",
            " Training bag [1/10] bag loss: 0.6638\n",
            " Training bag [2/10] bag loss: 0.6585\n",
            " Training bag [3/10] bag loss: 0.6521\n",
            " Training bag [4/10] bag loss: 0.6661\n",
            " Training bag [5/10] bag loss: 0.6624\n",
            " Training bag [6/10] bag loss: 0.6622\n",
            " Training bag [7/10] bag loss: 0.6611\n",
            " Training bag [8/10] bag loss: 0.7203\n",
            " Training bag [9/10] bag loss: 0.6588\n",
            " Testing bag [0/11] bag loss: 0.7193\n",
            " Testing bag [1/11] bag loss: 0.7161\n",
            " Testing bag [2/11] bag loss: 0.6582\n",
            " Testing bag [3/11] bag loss: 0.6596\n",
            " Testing bag [4/11] bag loss: 0.6578\n",
            " Testing bag [5/11] bag loss: 0.6543\n",
            " Testing bag [6/11] bag loss: 0.6612\n",
            " Testing bag [7/11] bag loss: 0.7187\n",
            " Testing bag [8/11] bag loss: 0.6596\n",
            " Testing bag [9/11] bag loss: 0.6592\n",
            " Testing bag [10/11] bag loss: 0.6646ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.6785714285714286\n",
            "\n",
            " Epoch [68/300] train loss: 0.6727 test loss: 0.6753, average score: 0.5455, AUC: class-0>>0.6428571428571428|class-1>>1.0|class-2>>0.6785714285714286\n",
            "\n",
            " Training bag [0/10] bag loss: 0.7212\n",
            " Training bag [1/10] bag loss: 0.6648\n",
            " Training bag [2/10] bag loss: 0.6617\n",
            " Training bag [3/10] bag loss: 0.6622\n",
            " Training bag [4/10] bag loss: 0.6620\n",
            " Training bag [5/10] bag loss: 0.6625\n",
            " Training bag [6/10] bag loss: 0.6531\n",
            " Training bag [7/10] bag loss: 0.6578\n",
            " Training bag [8/10] bag loss: 0.6577\n",
            " Training bag [9/10] bag loss: 0.7224\n",
            " Testing bag [0/11] bag loss: 0.7197\n",
            " Testing bag [1/11] bag loss: 0.7166\n",
            " Testing bag [2/11] bag loss: 0.6574\n",
            " Testing bag [3/11] bag loss: 0.6592\n",
            " Testing bag [4/11] bag loss: 0.6584\n",
            " Testing bag [5/11] bag loss: 0.6523\n",
            " Testing bag [6/11] bag loss: 0.6607\n",
            " Testing bag [7/11] bag loss: 0.7198\n",
            " Testing bag [8/11] bag loss: 0.6599\n",
            " Testing bag [9/11] bag loss: 0.6587\n",
            " Testing bag [10/11] bag loss: 0.6646ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.6785714285714286\n",
            "\n",
            " Epoch [69/300] train loss: 0.6725 test loss: 0.6752, average score: 0.5455, AUC: class-0>>0.6428571428571428|class-1>>1.0|class-2>>0.6785714285714286\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6608\n",
            " Training bag [1/10] bag loss: 0.6566\n",
            " Training bag [2/10] bag loss: 0.7209\n",
            " Training bag [3/10] bag loss: 0.6566\n",
            " Training bag [4/10] bag loss: 0.7212\n",
            " Training bag [5/10] bag loss: 0.6624\n",
            " Training bag [6/10] bag loss: 0.6612\n",
            " Training bag [7/10] bag loss: 0.6638\n",
            " Training bag [8/10] bag loss: 0.6505\n",
            " Training bag [9/10] bag loss: 0.6608\n",
            " Testing bag [0/11] bag loss: 0.7201\n",
            " Testing bag [1/11] bag loss: 0.7171\n",
            " Testing bag [2/11] bag loss: 0.6566\n",
            " Testing bag [3/11] bag loss: 0.6602\n",
            " Testing bag [4/11] bag loss: 0.6579\n",
            " Testing bag [5/11] bag loss: 0.6509\n",
            " Testing bag [6/11] bag loss: 0.6606\n",
            " Testing bag [7/11] bag loss: 0.7192\n",
            " Testing bag [8/11] bag loss: 0.6599\n",
            " Testing bag [9/11] bag loss: 0.6585\n",
            " Testing bag [10/11] bag loss: 0.6643ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 0.9583333333333334\n",
            "ROC AUC score: 0.7142857142857143\n",
            "\n",
            " Epoch [70/300] train loss: 0.6715 test loss: 0.6750, average score: 0.5455, AUC: class-0>>0.6428571428571428|class-1>>0.9583333333333334|class-2>>0.7142857142857143\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6610\n",
            " Training bag [1/10] bag loss: 0.6502\n",
            " Training bag [2/10] bag loss: 0.6604\n",
            " Training bag [3/10] bag loss: 0.7207\n",
            " Training bag [4/10] bag loss: 0.6566\n",
            " Training bag [5/10] bag loss: 0.6621\n",
            " Training bag [6/10] bag loss: 0.6568\n",
            " Training bag [7/10] bag loss: 0.6611\n",
            " Training bag [8/10] bag loss: 0.6625\n",
            " Training bag [9/10] bag loss: 0.7216\n",
            " Testing bag [0/11] bag loss: 0.7202\n",
            " Testing bag [1/11] bag loss: 0.7171\n",
            " Testing bag [2/11] bag loss: 0.6559\n",
            " Testing bag [3/11] bag loss: 0.6583\n",
            " Testing bag [4/11] bag loss: 0.6563\n",
            " Testing bag [5/11] bag loss: 0.6514\n",
            " Testing bag [6/11] bag loss: 0.6597\n",
            " Testing bag [7/11] bag loss: 0.7202\n",
            " Testing bag [8/11] bag loss: 0.6588\n",
            " Testing bag [9/11] bag loss: 0.6579\n",
            " Testing bag [10/11] bag loss: 0.6633ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.7142857142857143\n",
            "\n",
            " Epoch [71/300] train loss: 0.6713 test loss: 0.6745, average score: 0.5455, AUC: class-0>>0.6428571428571428|class-1>>1.0|class-2>>0.7142857142857143\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6498\n",
            " Training bag [1/10] bag loss: 0.6608\n",
            " Training bag [2/10] bag loss: 0.6629\n",
            " Training bag [3/10] bag loss: 0.6607\n",
            " Training bag [4/10] bag loss: 0.6567\n",
            " Training bag [5/10] bag loss: 0.7207\n",
            " Training bag [6/10] bag loss: 0.7228\n",
            " Training bag [7/10] bag loss: 0.6563\n",
            " Training bag [8/10] bag loss: 0.6598\n",
            " Training bag [9/10] bag loss: 0.6611\n",
            " Testing bag [0/11] bag loss: 0.7209\n",
            " Testing bag [1/11] bag loss: 0.7163\n",
            " Testing bag [2/11] bag loss: 0.6560\n",
            " Testing bag [3/11] bag loss: 0.6585\n",
            " Testing bag [4/11] bag loss: 0.6567\n",
            " Testing bag [5/11] bag loss: 0.6520\n",
            " Testing bag [6/11] bag loss: 0.6587\n",
            " Testing bag [7/11] bag loss: 0.7200\n",
            " Testing bag [8/11] bag loss: 0.6593\n",
            " Testing bag [9/11] bag loss: 0.6574\n",
            " Testing bag [10/11] bag loss: 0.6627ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 0.9583333333333334\n",
            "ROC AUC score: 0.6785714285714286\n",
            "\n",
            " Epoch [72/300] train loss: 0.6712 test loss: 0.6744, average score: 0.5455, AUC: class-0>>0.6428571428571428|class-1>>0.9583333333333334|class-2>>0.6785714285714286\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6502\n",
            " Training bag [1/10] bag loss: 0.7216\n",
            " Training bag [2/10] bag loss: 0.6614\n",
            " Training bag [3/10] bag loss: 0.6549\n",
            " Training bag [4/10] bag loss: 0.6595\n",
            " Training bag [5/10] bag loss: 0.6619\n",
            " Training bag [6/10] bag loss: 0.6553\n",
            " Training bag [7/10] bag loss: 0.7203\n",
            " Training bag [8/10] bag loss: 0.6610\n",
            " Training bag [9/10] bag loss: 0.6591\n",
            " Testing bag [0/11] bag loss: 0.7203\n",
            " Testing bag [1/11] bag loss: 0.7178\n",
            " Testing bag [2/11] bag loss: 0.6552\n",
            " Testing bag [3/11] bag loss: 0.6578\n",
            " Testing bag [4/11] bag loss: 0.6561\n",
            " Testing bag [5/11] bag loss: 0.6517\n",
            " Testing bag [6/11] bag loss: 0.6591\n",
            " Testing bag [7/11] bag loss: 0.7193\n",
            " Testing bag [8/11] bag loss: 0.6574\n",
            " Testing bag [9/11] bag loss: 0.6569\n",
            " Testing bag [10/11] bag loss: 0.6626ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 0.875\n",
            "ROC AUC score: 0.7142857142857143\n",
            "\n",
            " Epoch [73/300] train loss: 0.6705 test loss: 0.6740, average score: 0.4545, AUC: class-0>>0.6428571428571428|class-1>>0.875|class-2>>0.7142857142857143\n",
            "\n",
            " Training bag [0/10] bag loss: 0.7228\n",
            " Training bag [1/10] bag loss: 0.6584\n",
            " Training bag [2/10] bag loss: 0.6617\n",
            " Training bag [3/10] bag loss: 0.6594\n",
            " Training bag [4/10] bag loss: 0.6596\n",
            " Training bag [5/10] bag loss: 0.6559\n",
            " Training bag [6/10] bag loss: 0.6547\n",
            " Training bag [7/10] bag loss: 0.6477\n",
            " Training bag [8/10] bag loss: 0.6605\n",
            " Training bag [9/10] bag loss: 0.7211\n",
            " Testing bag [0/11] bag loss: 0.7206\n",
            " Testing bag [1/11] bag loss: 0.7178\n",
            " Testing bag [2/11] bag loss: 0.6552\n",
            " Testing bag [3/11] bag loss: 0.6570\n",
            " Testing bag [4/11] bag loss: 0.6551\n",
            " Testing bag [5/11] bag loss: 0.6495\n",
            " Testing bag [6/11] bag loss: 0.6590\n",
            " Testing bag [7/11] bag loss: 0.7205\n",
            " Testing bag [8/11] bag loss: 0.6574\n",
            " Testing bag [9/11] bag loss: 0.6566\n",
            " Testing bag [10/11] bag loss: 0.6629ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 0.9166666666666666\n",
            "ROC AUC score: 0.6785714285714286\n",
            "\n",
            " Epoch [74/300] train loss: 0.6702 test loss: 0.6738, average score: 0.3636, AUC: class-0>>0.6428571428571428|class-1>>0.9166666666666666|class-2>>0.6785714285714286\n",
            "\n",
            " Training bag [0/10] bag loss: 0.7234\n",
            " Training bag [1/10] bag loss: 0.6545\n",
            " Training bag [2/10] bag loss: 0.6477\n",
            " Training bag [3/10] bag loss: 0.6602\n",
            " Training bag [4/10] bag loss: 0.6599\n",
            " Training bag [5/10] bag loss: 0.6589\n",
            " Training bag [6/10] bag loss: 0.6620\n",
            " Training bag [7/10] bag loss: 0.6551\n",
            " Training bag [8/10] bag loss: 0.6589\n",
            " Training bag [9/10] bag loss: 0.7219\n",
            " Testing bag [0/11] bag loss: 0.7214\n",
            " Testing bag [1/11] bag loss: 0.7183\n",
            " Testing bag [2/11] bag loss: 0.6544\n",
            " Testing bag [3/11] bag loss: 0.6567\n",
            " Testing bag [4/11] bag loss: 0.6551\n",
            " Testing bag [5/11] bag loss: 0.6486\n",
            " Testing bag [6/11] bag loss: 0.6584\n",
            " Testing bag [7/11] bag loss: 0.7207\n",
            " Testing bag [8/11] bag loss: 0.6576\n",
            " Testing bag [9/11] bag loss: 0.6562\n",
            " Testing bag [10/11] bag loss: 0.6610ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 0.875\n",
            "ROC AUC score: 0.6785714285714286\n",
            "\n",
            " Epoch [75/300] train loss: 0.6703 test loss: 0.6735, average score: 0.4545, AUC: class-0>>0.6428571428571428|class-1>>0.875|class-2>>0.6785714285714286\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6484\n",
            " Training bag [1/10] bag loss: 0.7220\n",
            " Training bag [2/10] bag loss: 0.6589\n",
            " Training bag [3/10] bag loss: 0.7220\n",
            " Training bag [4/10] bag loss: 0.6582\n",
            " Training bag [5/10] bag loss: 0.6585\n",
            " Training bag [6/10] bag loss: 0.6543\n",
            " Training bag [7/10] bag loss: 0.6531\n",
            " Training bag [8/10] bag loss: 0.6598\n",
            " Training bag [9/10] bag loss: 0.6617\n",
            " Testing bag [0/11] bag loss: 0.7212\n",
            " Testing bag [1/11] bag loss: 0.7185\n",
            " Testing bag [2/11] bag loss: 0.6532\n",
            " Testing bag [3/11] bag loss: 0.6562\n",
            " Testing bag [4/11] bag loss: 0.6545\n",
            " Testing bag [5/11] bag loss: 0.6490\n",
            " Testing bag [6/11] bag loss: 0.6577\n",
            " Testing bag [7/11] bag loss: 0.7206\n",
            " Testing bag [8/11] bag loss: 0.6567\n",
            " Testing bag [9/11] bag loss: 0.6553\n",
            " Testing bag [10/11] bag loss: 0.6618ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 0.875\n",
            "ROC AUC score: 0.7142857142857143\n",
            "\n",
            " Epoch [76/300] train loss: 0.6697 test loss: 0.6731, average score: 0.4545, AUC: class-0>>0.6428571428571428|class-1>>0.875|class-2>>0.7142857142857143\n",
            "\n",
            " Training bag [0/10] bag loss: 0.7224\n",
            " Training bag [1/10] bag loss: 0.6599\n",
            " Training bag [2/10] bag loss: 0.6462\n",
            " Training bag [3/10] bag loss: 0.6592\n",
            " Training bag [4/10] bag loss: 0.6541\n",
            " Training bag [5/10] bag loss: 0.6571\n",
            " Training bag [6/10] bag loss: 0.6522\n",
            " Training bag [7/10] bag loss: 0.7221\n",
            " Training bag [8/10] bag loss: 0.6581\n",
            " Training bag [9/10] bag loss: 0.6603\n",
            " Testing bag [0/11] bag loss: 0.7216\n",
            " Testing bag [1/11] bag loss: 0.7183\n",
            " Testing bag [2/11] bag loss: 0.6524\n",
            " Testing bag [3/11] bag loss: 0.6559\n",
            " Testing bag [4/11] bag loss: 0.6543\n",
            " Testing bag [5/11] bag loss: 0.6482\n",
            " Testing bag [6/11] bag loss: 0.6579\n",
            " Testing bag [7/11] bag loss: 0.7213\n",
            " Testing bag [8/11] bag loss: 0.6565\n",
            " Testing bag [9/11] bag loss: 0.6558\n",
            " Testing bag [10/11] bag loss: 0.6602ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 0.8333333333333333\n",
            "ROC AUC score: 0.6785714285714286\n",
            "\n",
            " Epoch [77/300] train loss: 0.6692 test loss: 0.6729, average score: 0.4545, AUC: class-0>>0.6428571428571428|class-1>>0.8333333333333333|class-2>>0.6785714285714286\n",
            "\n",
            " Training bag [0/10] bag loss: 0.7210\n",
            " Training bag [1/10] bag loss: 0.6528\n",
            " Training bag [2/10] bag loss: 0.6452\n",
            " Training bag [3/10] bag loss: 0.6569\n",
            " Training bag [4/10] bag loss: 0.7239\n",
            " Training bag [5/10] bag loss: 0.6583\n",
            " Training bag [6/10] bag loss: 0.6595\n",
            " Training bag [7/10] bag loss: 0.6610\n",
            " Training bag [8/10] bag loss: 0.6526\n",
            " Training bag [9/10] bag loss: 0.6571\n",
            " Testing bag [0/11] bag loss: 0.7216\n",
            " Testing bag [1/11] bag loss: 0.7189\n",
            " Testing bag [2/11] bag loss: 0.6524\n",
            " Testing bag [3/11] bag loss: 0.6551\n",
            " Testing bag [4/11] bag loss: 0.6543\n",
            " Testing bag [5/11] bag loss: 0.6489\n",
            " Testing bag [6/11] bag loss: 0.6574\n",
            " Testing bag [7/11] bag loss: 0.7213\n",
            " Testing bag [8/11] bag loss: 0.6564\n",
            " Testing bag [9/11] bag loss: 0.6546\n",
            " Testing bag [10/11] bag loss: 0.6599ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 0.875\n",
            "ROC AUC score: 0.7142857142857143\n",
            "\n",
            " Epoch [78/300] train loss: 0.6688 test loss: 0.6728, average score: 0.4545, AUC: class-0>>0.6428571428571428|class-1>>0.875|class-2>>0.7142857142857143\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6566\n",
            " Training bag [1/10] bag loss: 0.6523\n",
            " Training bag [2/10] bag loss: 0.6584\n",
            " Training bag [3/10] bag loss: 0.7229\n",
            " Training bag [4/10] bag loss: 0.6581\n",
            " Training bag [5/10] bag loss: 0.6595\n",
            " Training bag [6/10] bag loss: 0.6467\n",
            " Training bag [7/10] bag loss: 0.6517\n",
            " Training bag [8/10] bag loss: 0.6583\n",
            " Training bag [9/10] bag loss: 0.7238\n",
            " Testing bag [0/11] bag loss: 0.7222\n",
            " Testing bag [1/11] bag loss: 0.7193\n",
            " Testing bag [2/11] bag loss: 0.6527\n",
            " Testing bag [3/11] bag loss: 0.6554\n",
            " Testing bag [4/11] bag loss: 0.6529\n",
            " Testing bag [5/11] bag loss: 0.6475\n",
            " Testing bag [6/11] bag loss: 0.6568\n",
            " Testing bag [7/11] bag loss: 0.7221\n",
            " Testing bag [8/11] bag loss: 0.6554\n",
            " Testing bag [9/11] bag loss: 0.6545\n",
            " Testing bag [10/11] bag loss: 0.6604ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 0.8333333333333333\n",
            "ROC AUC score: 0.7142857142857143\n",
            "\n",
            " Epoch [79/300] train loss: 0.6688 test loss: 0.6727, average score: 0.4545, AUC: class-0>>0.6428571428571428|class-1>>0.8333333333333333|class-2>>0.7142857142857143\n",
            "\n",
            " Training bag [0/10] bag loss: 0.7226\n",
            " Training bag [1/10] bag loss: 0.6516\n",
            " Training bag [2/10] bag loss: 0.6592\n",
            " Training bag [3/10] bag loss: 0.6583\n",
            " Training bag [4/10] bag loss: 0.7244\n",
            " Training bag [5/10] bag loss: 0.6576\n",
            " Training bag [6/10] bag loss: 0.6565\n",
            " Training bag [7/10] bag loss: 0.6561\n",
            " Training bag [8/10] bag loss: 0.6451\n",
            " Training bag [9/10] bag loss: 0.6515\n",
            " Testing bag [0/11] bag loss: 0.7216\n",
            " Testing bag [1/11] bag loss: 0.7195\n",
            " Testing bag [2/11] bag loss: 0.6518\n",
            " Testing bag [3/11] bag loss: 0.6542\n",
            " Testing bag [4/11] bag loss: 0.6536\n",
            " Testing bag [5/11] bag loss: 0.6455\n",
            " Testing bag [6/11] bag loss: 0.6555\n",
            " Testing bag [7/11] bag loss: 0.7222\n",
            " Testing bag [8/11] bag loss: 0.6555\n",
            " Testing bag [9/11] bag loss: 0.6535\n",
            " Testing bag [10/11] bag loss: 0.6585ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 0.8333333333333333\n",
            "ROC AUC score: 0.7142857142857143\n",
            "\n",
            " Epoch [80/300] train loss: 0.6683 test loss: 0.6719, average score: 0.4545, AUC: class-0>>0.6428571428571428|class-1>>0.8333333333333333|class-2>>0.7142857142857143\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6570\n",
            " Training bag [1/10] bag loss: 0.6550\n",
            " Training bag [2/10] bag loss: 0.6582\n",
            " Training bag [3/10] bag loss: 0.7247\n",
            " Training bag [4/10] bag loss: 0.6560\n",
            " Training bag [5/10] bag loss: 0.7239\n",
            " Training bag [6/10] bag loss: 0.6441\n",
            " Training bag [7/10] bag loss: 0.6515\n",
            " Training bag [8/10] bag loss: 0.6512\n",
            " Training bag [9/10] bag loss: 0.6562\n",
            " Testing bag [0/11] bag loss: 0.7220\n",
            " Testing bag [1/11] bag loss: 0.7208\n",
            " Testing bag [2/11] bag loss: 0.6511\n",
            " Testing bag [3/11] bag loss: 0.6535\n",
            " Testing bag [4/11] bag loss: 0.6528\n",
            " Testing bag [5/11] bag loss: 0.6464\n",
            " Testing bag [6/11] bag loss: 0.6552\n",
            " Testing bag [7/11] bag loss: 0.7219\n",
            " Testing bag [8/11] bag loss: 0.6551\n",
            " Testing bag [9/11] bag loss: 0.6532\n",
            " Testing bag [10/11] bag loss: 0.6581ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 0.8333333333333333\n",
            "ROC AUC score: 0.7142857142857143\n",
            "\n",
            " Epoch [81/300] train loss: 0.6678 test loss: 0.6718, average score: 0.4545, AUC: class-0>>0.6428571428571428|class-1>>0.8333333333333333|class-2>>0.7142857142857143\n",
            "\n",
            " Training bag [0/10] bag loss: 0.7246\n",
            " Training bag [1/10] bag loss: 0.6517\n",
            " Training bag [2/10] bag loss: 0.7225\n",
            " Training bag [3/10] bag loss: 0.6568\n",
            " Training bag [4/10] bag loss: 0.6549\n",
            " Training bag [5/10] bag loss: 0.6436\n",
            " Training bag [6/10] bag loss: 0.6509\n",
            " Training bag [7/10] bag loss: 0.6587\n",
            " Training bag [8/10] bag loss: 0.6561\n",
            " Training bag [9/10] bag loss: 0.6569\n",
            " Testing bag [0/11] bag loss: 0.7221\n",
            " Testing bag [1/11] bag loss: 0.7208\n",
            " Testing bag [2/11] bag loss: 0.6503\n",
            " Testing bag [3/11] bag loss: 0.6532\n",
            " Testing bag [4/11] bag loss: 0.6521\n",
            " Testing bag [5/11] bag loss: 0.6466\n",
            " Testing bag [6/11] bag loss: 0.6550\n",
            " Testing bag [7/11] bag loss: 0.7222\n",
            " Testing bag [8/11] bag loss: 0.6552\n",
            " Testing bag [9/11] bag loss: 0.6533\n",
            " Testing bag [10/11] bag loss: 0.6587ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 0.8333333333333333\n",
            "ROC AUC score: 0.6428571428571429\n",
            "\n",
            " Epoch [82/300] train loss: 0.6677 test loss: 0.6718, average score: 0.4545, AUC: class-0>>0.6428571428571428|class-1>>0.8333333333333333|class-2>>0.6428571428571429\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6556\n",
            " Training bag [1/10] bag loss: 0.6497\n",
            " Training bag [2/10] bag loss: 0.6541\n",
            " Training bag [3/10] bag loss: 0.6445\n",
            " Training bag [4/10] bag loss: 0.6588\n",
            " Training bag [5/10] bag loss: 0.6570\n",
            " Training bag [6/10] bag loss: 0.6557\n",
            " Training bag [7/10] bag loss: 0.7238\n",
            " Training bag [8/10] bag loss: 0.6505\n",
            " Training bag [9/10] bag loss: 0.7249\n",
            " Testing bag [0/11] bag loss: 0.7233\n",
            " Testing bag [1/11] bag loss: 0.7194\n",
            " Testing bag [2/11] bag loss: 0.6501\n",
            " Testing bag [3/11] bag loss: 0.6530\n",
            " Testing bag [4/11] bag loss: 0.6509\n",
            " Testing bag [5/11] bag loss: 0.6456\n",
            " Testing bag [6/11] bag loss: 0.6549\n",
            " Testing bag [7/11] bag loss: 0.7236\n",
            " Testing bag [8/11] bag loss: 0.6537\n",
            " Testing bag [9/11] bag loss: 0.6520\n",
            " Testing bag [10/11] bag loss: 0.6577ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 0.8333333333333333\n",
            "ROC AUC score: 0.6785714285714286\n",
            "\n",
            " Epoch [83/300] train loss: 0.6675 test loss: 0.6713, average score: 0.4545, AUC: class-0>>0.6428571428571428|class-1>>0.8333333333333333|class-2>>0.6785714285714286\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6430\n",
            " Training bag [1/10] bag loss: 0.6574\n",
            " Training bag [2/10] bag loss: 0.7241\n",
            " Training bag [3/10] bag loss: 0.6492\n",
            " Training bag [4/10] bag loss: 0.6562\n",
            " Training bag [5/10] bag loss: 0.6501\n",
            " Training bag [6/10] bag loss: 0.6560\n",
            " Training bag [7/10] bag loss: 0.7255\n",
            " Training bag [8/10] bag loss: 0.6536\n",
            " Training bag [9/10] bag loss: 0.6555\n",
            " Testing bag [0/11] bag loss: 0.7230\n",
            " Testing bag [1/11] bag loss: 0.7210\n",
            " Testing bag [2/11] bag loss: 0.6496\n",
            " Testing bag [3/11] bag loss: 0.6526\n",
            " Testing bag [4/11] bag loss: 0.6504\n",
            " Testing bag [5/11] bag loss: 0.6450\n",
            " Testing bag [6/11] bag loss: 0.6544\n",
            " Testing bag [7/11] bag loss: 0.7230\n",
            " Testing bag [8/11] bag loss: 0.6548\n",
            " Testing bag [9/11] bag loss: 0.6520\n",
            " Testing bag [10/11] bag loss: 0.6575ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 0.8333333333333333\n",
            "ROC AUC score: 0.6785714285714286\n",
            "\n",
            " Epoch [84/300] train loss: 0.6670 test loss: 0.6712, average score: 0.4545, AUC: class-0>>0.6428571428571428|class-1>>0.8333333333333333|class-2>>0.6785714285714286\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6491\n",
            " Training bag [1/10] bag loss: 0.7227\n",
            " Training bag [2/10] bag loss: 0.6419\n",
            " Training bag [3/10] bag loss: 0.6539\n",
            " Training bag [4/10] bag loss: 0.6483\n",
            " Training bag [5/10] bag loss: 0.7246\n",
            " Training bag [6/10] bag loss: 0.6532\n",
            " Training bag [7/10] bag loss: 0.6568\n",
            " Training bag [8/10] bag loss: 0.6549\n",
            " Training bag [9/10] bag loss: 0.6575\n",
            " Testing bag [0/11] bag loss: 0.7231\n",
            " Testing bag [1/11] bag loss: 0.7203\n",
            " Testing bag [2/11] bag loss: 0.6490\n",
            " Testing bag [3/11] bag loss: 0.6521\n",
            " Testing bag [4/11] bag loss: 0.6501\n",
            " Testing bag [5/11] bag loss: 0.6448\n",
            " Testing bag [6/11] bag loss: 0.6545\n",
            " Testing bag [7/11] bag loss: 0.7235\n",
            " Testing bag [8/11] bag loss: 0.6535\n",
            " Testing bag [9/11] bag loss: 0.6518\n",
            " Testing bag [10/11] bag loss: 0.6571ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 0.8333333333333333\n",
            "ROC AUC score: 0.6785714285714286\n",
            "\n",
            " Epoch [85/300] train loss: 0.6663 test loss: 0.6709, average score: 0.4545, AUC: class-0>>0.6428571428571428|class-1>>0.8333333333333333|class-2>>0.6785714285714286\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6488\n",
            " Training bag [1/10] bag loss: 0.6542\n",
            " Training bag [2/10] bag loss: 0.6415\n",
            " Training bag [3/10] bag loss: 0.6556\n",
            " Training bag [4/10] bag loss: 0.6536\n",
            " Training bag [5/10] bag loss: 0.7252\n",
            " Training bag [6/10] bag loss: 0.6570\n",
            " Training bag [7/10] bag loss: 0.7244\n",
            " Training bag [8/10] bag loss: 0.6527\n",
            " Training bag [9/10] bag loss: 0.6485\n",
            " Testing bag [0/11] bag loss: 0.7243\n",
            " Testing bag [1/11] bag loss: 0.7217\n",
            " Testing bag [2/11] bag loss: 0.6495\n",
            " Testing bag [3/11] bag loss: 0.6521\n",
            " Testing bag [4/11] bag loss: 0.6500\n",
            " Testing bag [5/11] bag loss: 0.6447\n",
            " Testing bag [6/11] bag loss: 0.6536\n",
            " Testing bag [7/11] bag loss: 0.7233\n",
            " Testing bag [8/11] bag loss: 0.6537\n",
            " Testing bag [9/11] bag loss: 0.6515\n",
            " Testing bag [10/11] bag loss: 0.6570ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 0.8333333333333333\n",
            "ROC AUC score: 0.6428571428571429\n",
            "\n",
            " Epoch [86/300] train loss: 0.6662 test loss: 0.6710, average score: 0.4545, AUC: class-0>>0.6428571428571428|class-1>>0.8333333333333333|class-2>>0.6428571428571429\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6524\n",
            " Training bag [1/10] bag loss: 0.6536\n",
            " Training bag [2/10] bag loss: 0.6556\n",
            " Training bag [3/10] bag loss: 0.7252\n",
            " Training bag [4/10] bag loss: 0.7249\n",
            " Training bag [5/10] bag loss: 0.6537\n",
            " Training bag [6/10] bag loss: 0.6494\n",
            " Training bag [7/10] bag loss: 0.6566\n",
            " Training bag [8/10] bag loss: 0.6417\n",
            " Training bag [9/10] bag loss: 0.6478\n",
            " Testing bag [0/11] bag loss: 0.7241\n",
            " Testing bag [1/11] bag loss: 0.7209\n",
            " Testing bag [2/11] bag loss: 0.6487\n",
            " Testing bag [3/11] bag loss: 0.6507\n",
            " Testing bag [4/11] bag loss: 0.6491\n",
            " Testing bag [5/11] bag loss: 0.6439\n",
            " Testing bag [6/11] bag loss: 0.6532\n",
            " Testing bag [7/11] bag loss: 0.7237\n",
            " Testing bag [8/11] bag loss: 0.6521\n",
            " Testing bag [9/11] bag loss: 0.6511\n",
            " Testing bag [10/11] bag loss: 0.6571ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 0.8333333333333333\n",
            "ROC AUC score: 0.7142857142857143\n",
            "\n",
            " Epoch [87/300] train loss: 0.6661 test loss: 0.6704, average score: 0.4545, AUC: class-0>>0.6428571428571428|class-1>>0.8333333333333333|class-2>>0.7142857142857143\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6474\n",
            " Training bag [1/10] bag loss: 0.6485\n",
            " Training bag [2/10] bag loss: 0.6545\n",
            " Training bag [3/10] bag loss: 0.6401\n",
            " Training bag [4/10] bag loss: 0.7266\n",
            " Training bag [5/10] bag loss: 0.6512\n",
            " Training bag [6/10] bag loss: 0.7238\n",
            " Training bag [7/10] bag loss: 0.6533\n",
            " Training bag [8/10] bag loss: 0.6560\n",
            " Training bag [9/10] bag loss: 0.6547\n",
            " Testing bag [0/11] bag loss: 0.7243\n",
            " Testing bag [1/11] bag loss: 0.7209\n",
            " Testing bag [2/11] bag loss: 0.6479\n",
            " Testing bag [3/11] bag loss: 0.6508\n",
            " Testing bag [4/11] bag loss: 0.6495\n",
            " Testing bag [5/11] bag loss: 0.6433\n",
            " Testing bag [6/11] bag loss: 0.6532\n",
            " Testing bag [7/11] bag loss: 0.7245\n",
            " Testing bag [8/11] bag loss: 0.6519\n",
            " Testing bag [9/11] bag loss: 0.6511\n",
            " Testing bag [10/11] bag loss: 0.6571ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 0.8333333333333333\n",
            "ROC AUC score: 0.7142857142857143\n",
            "\n",
            " Epoch [88/300] train loss: 0.6656 test loss: 0.6704, average score: 0.4545, AUC: class-0>>0.6428571428571428|class-1>>0.8333333333333333|class-2>>0.7142857142857143\n",
            "\n",
            " Training bag [0/10] bag loss: 0.7248\n",
            " Training bag [1/10] bag loss: 0.6523\n",
            " Training bag [2/10] bag loss: 0.6539\n",
            " Training bag [3/10] bag loss: 0.6516\n",
            " Training bag [4/10] bag loss: 0.6480\n",
            " Training bag [5/10] bag loss: 0.6561\n",
            " Training bag [6/10] bag loss: 0.6396\n",
            " Training bag [7/10] bag loss: 0.6479\n",
            " Training bag [8/10] bag loss: 0.6524\n",
            " Training bag [9/10] bag loss: 0.7256\n",
            " Testing bag [0/11] bag loss: 0.7244\n",
            " Testing bag [1/11] bag loss: 0.7226\n",
            " Testing bag [2/11] bag loss: 0.6483\n",
            " Testing bag [3/11] bag loss: 0.6506\n",
            " Testing bag [4/11] bag loss: 0.6486\n",
            " Testing bag [5/11] bag loss: 0.6423\n",
            " Testing bag [6/11] bag loss: 0.6522\n",
            " Testing bag [7/11] bag loss: 0.7246\n",
            " Testing bag [8/11] bag loss: 0.6518\n",
            " Testing bag [9/11] bag loss: 0.6497\n",
            " Testing bag [10/11] bag loss: 0.6565ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 0.8333333333333333\n",
            "ROC AUC score: 0.7142857142857143\n",
            "\n",
            " Epoch [89/300] train loss: 0.6652 test loss: 0.6701, average score: 0.4545, AUC: class-0>>0.6428571428571428|class-1>>0.8333333333333333|class-2>>0.7142857142857143\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6523\n",
            " Training bag [1/10] bag loss: 0.6556\n",
            " Training bag [2/10] bag loss: 0.6536\n",
            " Training bag [3/10] bag loss: 0.7252\n",
            " Training bag [4/10] bag loss: 0.7260\n",
            " Training bag [5/10] bag loss: 0.6485\n",
            " Training bag [6/10] bag loss: 0.6482\n",
            " Training bag [7/10] bag loss: 0.6395\n",
            " Training bag [8/10] bag loss: 0.6521\n",
            " Training bag [9/10] bag loss: 0.6504\n",
            " Testing bag [0/11] bag loss: 0.7250\n",
            " Testing bag [1/11] bag loss: 0.7212\n",
            " Testing bag [2/11] bag loss: 0.6472\n",
            " Testing bag [3/11] bag loss: 0.6507\n",
            " Testing bag [4/11] bag loss: 0.6484\n",
            " Testing bag [5/11] bag loss: 0.6428\n",
            " Testing bag [6/11] bag loss: 0.6521\n",
            " Testing bag [7/11] bag loss: 0.7243\n",
            " Testing bag [8/11] bag loss: 0.6514\n",
            " Testing bag [9/11] bag loss: 0.6499\n",
            " Testing bag [10/11] bag loss: 0.6557ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.6428571428571429\n",
            "\n",
            " Epoch [90/300] train loss: 0.6652 test loss: 0.6699, average score: 0.4545, AUC: class-0>>0.6428571428571428|class-1>>0.7916666666666667|class-2>>0.6428571428571429\n",
            "\n",
            " Training bag [0/10] bag loss: 0.7267\n",
            " Training bag [1/10] bag loss: 0.6473\n",
            " Training bag [2/10] bag loss: 0.7241\n",
            " Training bag [3/10] bag loss: 0.6536\n",
            " Training bag [4/10] bag loss: 0.6556\n",
            " Training bag [5/10] bag loss: 0.6503\n",
            " Training bag [6/10] bag loss: 0.6392\n",
            " Training bag [7/10] bag loss: 0.6523\n",
            " Training bag [8/10] bag loss: 0.6465\n",
            " Training bag [9/10] bag loss: 0.6512\n",
            " Testing bag [0/11] bag loss: 0.7249\n",
            " Testing bag [1/11] bag loss: 0.7228\n",
            " Testing bag [2/11] bag loss: 0.6471\n",
            " Testing bag [3/11] bag loss: 0.6493\n",
            " Testing bag [4/11] bag loss: 0.6473\n",
            " Testing bag [5/11] bag loss: 0.6408\n",
            " Testing bag [6/11] bag loss: 0.6521\n",
            " Testing bag [7/11] bag loss: 0.7242\n",
            " Testing bag [8/11] bag loss: 0.6502\n",
            " Testing bag [9/11] bag loss: 0.6497\n",
            " Testing bag [10/11] bag loss: 0.6553ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 0.8333333333333333\n",
            "ROC AUC score: 0.6785714285714286\n",
            "\n",
            " Epoch [91/300] train loss: 0.6647 test loss: 0.6694, average score: 0.4545, AUC: class-0>>0.6428571428571428|class-1>>0.8333333333333333|class-2>>0.6785714285714286\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6387\n",
            " Training bag [1/10] bag loss: 0.6512\n",
            " Training bag [2/10] bag loss: 0.6540\n",
            " Training bag [3/10] bag loss: 0.6523\n",
            " Training bag [4/10] bag loss: 0.6457\n",
            " Training bag [5/10] bag loss: 0.7256\n",
            " Training bag [6/10] bag loss: 0.6523\n",
            " Training bag [7/10] bag loss: 0.6499\n",
            " Training bag [8/10] bag loss: 0.7269\n",
            " Training bag [9/10] bag loss: 0.6467\n",
            " Testing bag [0/11] bag loss: 0.7250\n",
            " Testing bag [1/11] bag loss: 0.7222\n",
            " Testing bag [2/11] bag loss: 0.6470\n",
            " Testing bag [3/11] bag loss: 0.6481\n",
            " Testing bag [4/11] bag loss: 0.6476\n",
            " Testing bag [5/11] bag loss: 0.6428\n",
            " Testing bag [6/11] bag loss: 0.6507\n",
            " Testing bag [7/11] bag loss: 0.7252\n",
            " Testing bag [8/11] bag loss: 0.6503\n",
            " Testing bag [9/11] bag loss: 0.6489\n",
            " Testing bag [10/11] bag loss: 0.6540ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.6428571428571429\n",
            "\n",
            " Epoch [92/300] train loss: 0.6643 test loss: 0.6693, average score: 0.4545, AUC: class-0>>0.6428571428571428|class-1>>0.7916666666666667|class-2>>0.6428571428571429\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6521\n",
            " Training bag [1/10] bag loss: 0.7274\n",
            " Training bag [2/10] bag loss: 0.6503\n",
            " Training bag [3/10] bag loss: 0.6533\n",
            " Training bag [4/10] bag loss: 0.6386\n",
            " Training bag [5/10] bag loss: 0.6495\n",
            " Training bag [6/10] bag loss: 0.6499\n",
            " Training bag [7/10] bag loss: 0.6463\n",
            " Training bag [8/10] bag loss: 0.7262\n",
            " Training bag [9/10] bag loss: 0.6465\n",
            " Testing bag [0/11] bag loss: 0.7252\n",
            " Testing bag [1/11] bag loss: 0.7227\n",
            " Testing bag [2/11] bag loss: 0.6461\n",
            " Testing bag [3/11] bag loss: 0.6488\n",
            " Testing bag [4/11] bag loss: 0.6467\n",
            " Testing bag [5/11] bag loss: 0.6424\n",
            " Testing bag [6/11] bag loss: 0.6508\n",
            " Testing bag [7/11] bag loss: 0.7258\n",
            " Testing bag [8/11] bag loss: 0.6495\n",
            " Testing bag [9/11] bag loss: 0.6479\n",
            " Testing bag [10/11] bag loss: 0.6549ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 0.7916666666666666\n",
            "ROC AUC score: 0.6785714285714286\n",
            "\n",
            " Epoch [93/300] train loss: 0.6640 test loss: 0.6691, average score: 0.4545, AUC: class-0>>0.6428571428571428|class-1>>0.7916666666666666|class-2>>0.6785714285714286\n",
            "\n",
            " Training bag [0/10] bag loss: 0.7273\n",
            " Training bag [1/10] bag loss: 0.6508\n",
            " Training bag [2/10] bag loss: 0.6377\n",
            " Training bag [3/10] bag loss: 0.6448\n",
            " Training bag [4/10] bag loss: 0.6521\n",
            " Training bag [5/10] bag loss: 0.6489\n",
            " Training bag [6/10] bag loss: 0.6532\n",
            " Training bag [7/10] bag loss: 0.6497\n",
            " Training bag [8/10] bag loss: 0.6453\n",
            " Training bag [9/10] bag loss: 0.7264\n",
            " Testing bag [0/11] bag loss: 0.7252\n",
            " Testing bag [1/11] bag loss: 0.7235\n",
            " Testing bag [2/11] bag loss: 0.6457\n",
            " Testing bag [3/11] bag loss: 0.6476\n",
            " Testing bag [4/11] bag loss: 0.6465\n",
            " Testing bag [5/11] bag loss: 0.6410\n",
            " Testing bag [6/11] bag loss: 0.6505\n",
            " Testing bag [7/11] bag loss: 0.7256\n",
            " Testing bag [8/11] bag loss: 0.6494\n",
            " Testing bag [9/11] bag loss: 0.6476\n",
            " Testing bag [10/11] bag loss: 0.6536ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.7142857142857143\n",
            "\n",
            " Epoch [94/300] train loss: 0.6636 test loss: 0.6687, average score: 0.4545, AUC: class-0>>0.6428571428571428|class-1>>0.75|class-2>>0.7142857142857143\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6488\n",
            " Training bag [1/10] bag loss: 0.7269\n",
            " Training bag [2/10] bag loss: 0.6456\n",
            " Training bag [3/10] bag loss: 0.6509\n",
            " Training bag [4/10] bag loss: 0.6510\n",
            " Training bag [5/10] bag loss: 0.6373\n",
            " Training bag [6/10] bag loss: 0.6519\n",
            " Training bag [7/10] bag loss: 0.6537\n",
            " Training bag [8/10] bag loss: 0.7279\n",
            " Training bag [9/10] bag loss: 0.6444\n",
            " Testing bag [0/11] bag loss: 0.7256\n",
            " Testing bag [1/11] bag loss: 0.7239\n",
            " Testing bag [2/11] bag loss: 0.6451\n",
            " Testing bag [3/11] bag loss: 0.6477\n",
            " Testing bag [4/11] bag loss: 0.6470\n",
            " Testing bag [5/11] bag loss: 0.6401\n",
            " Testing bag [6/11] bag loss: 0.6506\n",
            " Testing bag [7/11] bag loss: 0.7261\n",
            " Testing bag [8/11] bag loss: 0.6493\n",
            " Testing bag [9/11] bag loss: 0.6475\n",
            " Testing bag [10/11] bag loss: 0.6523ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.6785714285714286\n",
            "\n",
            " Epoch [95/300] train loss: 0.6638 test loss: 0.6687, average score: 0.4545, AUC: class-0>>0.6428571428571428|class-1>>0.75|class-2>>0.6785714285714286\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6502\n",
            " Training bag [1/10] bag loss: 0.6482\n",
            " Training bag [2/10] bag loss: 0.6509\n",
            " Training bag [3/10] bag loss: 0.7268\n",
            " Training bag [4/10] bag loss: 0.6532\n",
            " Training bag [5/10] bag loss: 0.6368\n",
            " Training bag [6/10] bag loss: 0.6441\n",
            " Training bag [7/10] bag loss: 0.6500\n",
            " Training bag [8/10] bag loss: 0.6443\n",
            " Training bag [9/10] bag loss: 0.7285\n",
            " Testing bag [0/11] bag loss: 0.7266\n",
            " Testing bag [1/11] bag loss: 0.7233\n",
            " Testing bag [2/11] bag loss: 0.6444\n",
            " Testing bag [3/11] bag loss: 0.6479\n",
            " Testing bag [4/11] bag loss: 0.6449\n",
            " Testing bag [5/11] bag loss: 0.6396\n",
            " Testing bag [6/11] bag loss: 0.6498\n",
            " Testing bag [7/11] bag loss: 0.7259\n",
            " Testing bag [8/11] bag loss: 0.6482\n",
            " Testing bag [9/11] bag loss: 0.6474\n",
            " Testing bag [10/11] bag loss: 0.6538ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 0.7916666666666666\n",
            "ROC AUC score: 0.7142857142857143\n",
            "\n",
            " Epoch [96/300] train loss: 0.6633 test loss: 0.6684, average score: 0.4545, AUC: class-0>>0.6428571428571428|class-1>>0.7916666666666666|class-2>>0.7142857142857143\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6517\n",
            " Training bag [1/10] bag loss: 0.6495\n",
            " Training bag [2/10] bag loss: 0.6479\n",
            " Training bag [3/10] bag loss: 0.6445\n",
            " Training bag [4/10] bag loss: 0.6379\n",
            " Training bag [5/10] bag loss: 0.6505\n",
            " Training bag [6/10] bag loss: 0.6495\n",
            " Training bag [7/10] bag loss: 0.6435\n",
            " Training bag [8/10] bag loss: 0.7271\n",
            " Training bag [9/10] bag loss: 0.7287\n",
            " Testing bag [0/11] bag loss: 0.7270\n",
            " Testing bag [1/11] bag loss: 0.7240\n",
            " Testing bag [2/11] bag loss: 0.6435\n",
            " Testing bag [3/11] bag loss: 0.6465\n",
            " Testing bag [4/11] bag loss: 0.6459\n",
            " Testing bag [5/11] bag loss: 0.6394\n",
            " Testing bag [6/11] bag loss: 0.6487\n",
            " Testing bag [7/11] bag loss: 0.7266\n",
            " Testing bag [8/11] bag loss: 0.6484\n",
            " Testing bag [9/11] bag loss: 0.6468\n",
            " Testing bag [10/11] bag loss: 0.6526ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.6428571428571429\n",
            "\n",
            " Epoch [97/300] train loss: 0.6631 test loss: 0.6681, average score: 0.4545, AUC: class-0>>0.6428571428571428|class-1>>0.75|class-2>>0.6428571428571429\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6437\n",
            " Training bag [1/10] bag loss: 0.6523\n",
            " Training bag [2/10] bag loss: 0.7269\n",
            " Training bag [3/10] bag loss: 0.6508\n",
            " Training bag [4/10] bag loss: 0.6486\n",
            " Training bag [5/10] bag loss: 0.6355\n",
            " Training bag [6/10] bag loss: 0.6496\n",
            " Training bag [7/10] bag loss: 0.6445\n",
            " Training bag [8/10] bag loss: 0.7281\n",
            " Training bag [9/10] bag loss: 0.6468\n",
            " Testing bag [0/11] bag loss: 0.7273\n",
            " Testing bag [1/11] bag loss: 0.7233\n",
            " Testing bag [2/11] bag loss: 0.6436\n",
            " Testing bag [3/11] bag loss: 0.6470\n",
            " Testing bag [4/11] bag loss: 0.6448\n",
            " Testing bag [5/11] bag loss: 0.6398\n",
            " Testing bag [6/11] bag loss: 0.6485\n",
            " Testing bag [7/11] bag loss: 0.7270\n",
            " Testing bag [8/11] bag loss: 0.6476\n",
            " Testing bag [9/11] bag loss: 0.6470\n",
            " Testing bag [10/11] bag loss: 0.6528ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.6785714285714286\n",
            "\n",
            " Epoch [98/300] train loss: 0.6627 test loss: 0.6681, average score: 0.4545, AUC: class-0>>0.6428571428571428|class-1>>0.75|class-2>>0.6785714285714286\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6471\n",
            " Training bag [1/10] bag loss: 0.6513\n",
            " Training bag [2/10] bag loss: 0.6430\n",
            " Training bag [3/10] bag loss: 0.6501\n",
            " Training bag [4/10] bag loss: 0.7269\n",
            " Training bag [5/10] bag loss: 0.6498\n",
            " Training bag [6/10] bag loss: 0.6343\n",
            " Training bag [7/10] bag loss: 0.6425\n",
            " Training bag [8/10] bag loss: 0.7294\n",
            " Training bag [9/10] bag loss: 0.6496\n",
            " Testing bag [0/11] bag loss: 0.7271\n",
            " Testing bag [1/11] bag loss: 0.7251\n",
            " Testing bag [2/11] bag loss: 0.6433\n",
            " Testing bag [3/11] bag loss: 0.6468\n",
            " Testing bag [4/11] bag loss: 0.6454\n",
            " Testing bag [5/11] bag loss: 0.6387\n",
            " Testing bag [6/11] bag loss: 0.6488\n",
            " Testing bag [7/11] bag loss: 0.7274\n",
            " Testing bag [8/11] bag loss: 0.6482\n",
            " Testing bag [9/11] bag loss: 0.6462\n",
            " Testing bag [10/11] bag loss: 0.6519ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.6428571428571429\n",
            "\n",
            " Epoch [99/300] train loss: 0.6624 test loss: 0.6681, average score: 0.4545, AUC: class-0>>0.6428571428571428|class-1>>0.75|class-2>>0.6428571428571429\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6428\n",
            " Training bag [1/10] bag loss: 0.6422\n",
            " Training bag [2/10] bag loss: 0.7286\n",
            " Training bag [3/10] bag loss: 0.6496\n",
            " Training bag [4/10] bag loss: 0.7293\n",
            " Training bag [5/10] bag loss: 0.6491\n",
            " Training bag [6/10] bag loss: 0.6497\n",
            " Training bag [7/10] bag loss: 0.6465\n",
            " Training bag [8/10] bag loss: 0.6358\n",
            " Training bag [9/10] bag loss: 0.6514\n",
            " Testing bag [0/11] bag loss: 0.7269\n",
            " Testing bag [1/11] bag loss: 0.7247\n",
            " Testing bag [2/11] bag loss: 0.6425\n",
            " Testing bag [3/11] bag loss: 0.6463\n",
            " Testing bag [4/11] bag loss: 0.6438\n",
            " Testing bag [5/11] bag loss: 0.6374\n",
            " Testing bag [6/11] bag loss: 0.6480\n",
            " Testing bag [7/11] bag loss: 0.7269\n",
            " Testing bag [8/11] bag loss: 0.6476\n",
            " Testing bag [9/11] bag loss: 0.6460\n",
            " Testing bag [10/11] bag loss: 0.6514ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.6785714285714286\n",
            "\n",
            " Epoch [100/300] train loss: 0.6625 test loss: 0.6674, average score: 0.4545, AUC: class-0>>0.6428571428571428|class-1>>0.75|class-2>>0.6785714285714286\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6499\n",
            " Training bag [1/10] bag loss: 0.6345\n",
            " Training bag [2/10] bag loss: 0.6497\n",
            " Training bag [3/10] bag loss: 0.6424\n",
            " Training bag [4/10] bag loss: 0.6414\n",
            " Training bag [5/10] bag loss: 0.7295\n",
            " Training bag [6/10] bag loss: 0.6453\n",
            " Training bag [7/10] bag loss: 0.6516\n",
            " Training bag [8/10] bag loss: 0.7281\n",
            " Training bag [9/10] bag loss: 0.6489\n",
            " Testing bag [0/11] bag loss: 0.7272\n",
            " Testing bag [1/11] bag loss: 0.7248\n",
            " Testing bag [2/11] bag loss: 0.6414\n",
            " Testing bag [3/11] bag loss: 0.6458\n",
            " Testing bag [4/11] bag loss: 0.6437\n",
            " Testing bag [5/11] bag loss: 0.6382\n",
            " Testing bag [6/11] bag loss: 0.6481\n",
            " Testing bag [7/11] bag loss: 0.7266\n",
            " Testing bag [8/11] bag loss: 0.6475\n",
            " Testing bag [9/11] bag loss: 0.6462\n",
            " Testing bag [10/11] bag loss: 0.6514ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.6428571428571429\n",
            "\n",
            " Epoch [101/300] train loss: 0.6621 test loss: 0.6673, average score: 0.4545, AUC: class-0>>0.6428571428571428|class-1>>0.75|class-2>>0.6428571428571429\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6415\n",
            " Training bag [1/10] bag loss: 0.6450\n",
            " Training bag [2/10] bag loss: 0.6419\n",
            " Training bag [3/10] bag loss: 0.7295\n",
            " Training bag [4/10] bag loss: 0.6493\n",
            " Training bag [5/10] bag loss: 0.6343\n",
            " Training bag [6/10] bag loss: 0.6487\n",
            " Training bag [7/10] bag loss: 0.7272\n",
            " Training bag [8/10] bag loss: 0.6515\n",
            " Training bag [9/10] bag loss: 0.6490\n",
            " Testing bag [0/11] bag loss: 0.7280\n",
            " Testing bag [1/11] bag loss: 0.7246\n",
            " Testing bag [2/11] bag loss: 0.6426\n",
            " Testing bag [3/11] bag loss: 0.6453\n",
            " Testing bag [4/11] bag loss: 0.6432\n",
            " Testing bag [5/11] bag loss: 0.6374\n",
            " Testing bag [6/11] bag loss: 0.6474\n",
            " Testing bag [7/11] bag loss: 0.7284\n",
            " Testing bag [8/11] bag loss: 0.6467\n",
            " Testing bag [9/11] bag loss: 0.6458\n",
            " Testing bag [10/11] bag loss: 0.6514ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.7142857142857143\n",
            "\n",
            " Epoch [102/300] train loss: 0.6618 test loss: 0.6673, average score: 0.4545, AUC: class-0>>0.6428571428571428|class-1>>0.75|class-2>>0.7142857142857143\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6476\n",
            " Training bag [1/10] bag loss: 0.7299\n",
            " Training bag [2/10] bag loss: 0.6419\n",
            " Training bag [3/10] bag loss: 0.6448\n",
            " Training bag [4/10] bag loss: 0.6498\n",
            " Training bag [5/10] bag loss: 0.6477\n",
            " Training bag [6/10] bag loss: 0.7275\n",
            " Training bag [7/10] bag loss: 0.6352\n",
            " Training bag [8/10] bag loss: 0.6484\n",
            " Training bag [9/10] bag loss: 0.6406\n",
            " Testing bag [0/11] bag loss: 0.7278\n",
            " Testing bag [1/11] bag loss: 0.7262\n",
            " Testing bag [2/11] bag loss: 0.6413\n",
            " Testing bag [3/11] bag loss: 0.6454\n",
            " Testing bag [4/11] bag loss: 0.6440\n",
            " Testing bag [5/11] bag loss: 0.6353\n",
            " Testing bag [6/11] bag loss: 0.6472\n",
            " Testing bag [7/11] bag loss: 0.7287\n",
            " Testing bag [8/11] bag loss: 0.6466\n",
            " Testing bag [9/11] bag loss: 0.6451\n",
            " Testing bag [10/11] bag loss: 0.6519ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.6428571428571429\n",
            "\n",
            " Epoch [103/300] train loss: 0.6613 test loss: 0.6672, average score: 0.4545, AUC: class-0>>0.6428571428571428|class-1>>0.75|class-2>>0.6428571428571429\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6337\n",
            " Training bag [1/10] bag loss: 0.7296\n",
            " Training bag [2/10] bag loss: 0.6405\n",
            " Training bag [3/10] bag loss: 0.6443\n",
            " Training bag [4/10] bag loss: 0.7288\n",
            " Training bag [5/10] bag loss: 0.6472\n",
            " Training bag [6/10] bag loss: 0.6492\n",
            " Training bag [7/10] bag loss: 0.6415\n",
            " Training bag [8/10] bag loss: 0.6496\n",
            " Training bag [9/10] bag loss: 0.6484\n",
            " Testing bag [0/11] bag loss: 0.7280\n",
            " Testing bag [1/11] bag loss: 0.7257\n",
            " Testing bag [2/11] bag loss: 0.6415\n",
            " Testing bag [3/11] bag loss: 0.6441\n",
            " Testing bag [4/11] bag loss: 0.6419\n",
            " Testing bag [5/11] bag loss: 0.6369\n",
            " Testing bag [6/11] bag loss: 0.6471\n",
            " Testing bag [7/11] bag loss: 0.7277\n",
            " Testing bag [8/11] bag loss: 0.6471\n",
            " Testing bag [9/11] bag loss: 0.6455\n",
            " Testing bag [10/11] bag loss: 0.6500ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.6428571428571429\n",
            "\n",
            " Epoch [104/300] train loss: 0.6613 test loss: 0.6669, average score: 0.4545, AUC: class-0>>0.6428571428571428|class-1>>0.75|class-2>>0.6428571428571429\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6441\n",
            " Training bag [1/10] bag loss: 0.6499\n",
            " Training bag [2/10] bag loss: 0.7291\n",
            " Training bag [3/10] bag loss: 0.6461\n",
            " Training bag [4/10] bag loss: 0.6408\n",
            " Training bag [5/10] bag loss: 0.6323\n",
            " Training bag [6/10] bag loss: 0.7284\n",
            " Training bag [7/10] bag loss: 0.6402\n",
            " Training bag [8/10] bag loss: 0.6489\n",
            " Training bag [9/10] bag loss: 0.6469\n",
            " Testing bag [0/11] bag loss: 0.7283\n",
            " Testing bag [1/11] bag loss: 0.7261\n",
            " Testing bag [2/11] bag loss: 0.6415\n",
            " Testing bag [3/11] bag loss: 0.6443\n",
            " Testing bag [4/11] bag loss: 0.6425\n",
            " Testing bag [5/11] bag loss: 0.6356\n",
            " Testing bag [6/11] bag loss: 0.6462\n",
            " Testing bag [7/11] bag loss: 0.7284\n",
            " Testing bag [8/11] bag loss: 0.6469\n",
            " Testing bag [9/11] bag loss: 0.6448\n",
            " Testing bag [10/11] bag loss: 0.6508ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.7142857142857143\n",
            "\n",
            " Epoch [105/300] train loss: 0.6607 test loss: 0.6669, average score: 0.4545, AUC: class-0>>0.6428571428571428|class-1>>0.75|class-2>>0.7142857142857143\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6430\n",
            " Training bag [1/10] bag loss: 0.6403\n",
            " Training bag [2/10] bag loss: 0.6400\n",
            " Training bag [3/10] bag loss: 0.6485\n",
            " Training bag [4/10] bag loss: 0.7306\n",
            " Training bag [5/10] bag loss: 0.6473\n",
            " Training bag [6/10] bag loss: 0.6466\n",
            " Training bag [7/10] bag loss: 0.6474\n",
            " Training bag [8/10] bag loss: 0.7299\n",
            " Training bag [9/10] bag loss: 0.6319\n",
            " Testing bag [0/11] bag loss: 0.7280\n",
            " Testing bag [1/11] bag loss: 0.7256\n",
            " Testing bag [2/11] bag loss: 0.6409\n",
            " Testing bag [3/11] bag loss: 0.6430\n",
            " Testing bag [4/11] bag loss: 0.6417\n",
            " Testing bag [5/11] bag loss: 0.6352\n",
            " Testing bag [6/11] bag loss: 0.6461\n",
            " Testing bag [7/11] bag loss: 0.7286\n",
            " Testing bag [8/11] bag loss: 0.6462\n",
            " Testing bag [9/11] bag loss: 0.6441\n",
            " Testing bag [10/11] bag loss: 0.6491ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.6428571428571429\n",
            "\n",
            " Epoch [106/300] train loss: 0.6606 test loss: 0.6662, average score: 0.4545, AUC: class-0>>0.6428571428571428|class-1>>0.75|class-2>>0.6428571428571429\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6493\n",
            " Training bag [1/10] bag loss: 0.7306\n",
            " Training bag [2/10] bag loss: 0.7285\n",
            " Training bag [3/10] bag loss: 0.6434\n",
            " Training bag [4/10] bag loss: 0.6458\n",
            " Training bag [5/10] bag loss: 0.6466\n",
            " Training bag [6/10] bag loss: 0.6402\n",
            " Training bag [7/10] bag loss: 0.6327\n",
            " Training bag [8/10] bag loss: 0.6394\n",
            " Training bag [9/10] bag loss: 0.6470\n",
            " Testing bag [0/11] bag loss: 0.7285\n",
            " Testing bag [1/11] bag loss: 0.7265\n",
            " Testing bag [2/11] bag loss: 0.6387\n",
            " Testing bag [3/11] bag loss: 0.6438\n",
            " Testing bag [4/11] bag loss: 0.6407\n",
            " Testing bag [5/11] bag loss: 0.6340\n",
            " Testing bag [6/11] bag loss: 0.6461\n",
            " Testing bag [7/11] bag loss: 0.7291\n",
            " Testing bag [8/11] bag loss: 0.6457\n",
            " Testing bag [9/11] bag loss: 0.6441\n",
            " Testing bag [10/11] bag loss: 0.6491ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 0.7916666666666666\n",
            "ROC AUC score: 0.6428571428571429\n",
            "\n",
            " Epoch [107/300] train loss: 0.6604 test loss: 0.6660, average score: 0.4545, AUC: class-0>>0.6428571428571428|class-1>>0.7916666666666666|class-2>>0.6428571428571429\n",
            "\n",
            " Training bag [0/10] bag loss: 0.7291\n",
            " Training bag [1/10] bag loss: 0.6456\n",
            " Training bag [2/10] bag loss: 0.6405\n",
            " Training bag [3/10] bag loss: 0.6463\n",
            " Training bag [4/10] bag loss: 0.6477\n",
            " Training bag [5/10] bag loss: 0.6315\n",
            " Training bag [6/10] bag loss: 0.6394\n",
            " Training bag [7/10] bag loss: 0.6466\n",
            " Training bag [8/10] bag loss: 0.7310\n",
            " Training bag [9/10] bag loss: 0.6428\n",
            " Testing bag [0/11] bag loss: 0.7285\n",
            " Testing bag [1/11] bag loss: 0.7260\n",
            " Testing bag [2/11] bag loss: 0.6395\n",
            " Testing bag [3/11] bag loss: 0.6439\n",
            " Testing bag [4/11] bag loss: 0.6408\n",
            " Testing bag [5/11] bag loss: 0.6340\n",
            " Testing bag [6/11] bag loss: 0.6456\n",
            " Testing bag [7/11] bag loss: 0.7295\n",
            " Testing bag [8/11] bag loss: 0.6449\n",
            " Testing bag [9/11] bag loss: 0.6433\n",
            " Testing bag [10/11] bag loss: 0.6488ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.6428571428571429\n",
            "\n",
            " Epoch [108/300] train loss: 0.6601 test loss: 0.6659, average score: 0.4545, AUC: class-0>>0.6428571428571428|class-1>>0.75|class-2>>0.6428571428571429\n",
            "\n",
            " Training bag [0/10] bag loss: 0.7292\n",
            " Training bag [1/10] bag loss: 0.6391\n",
            " Training bag [2/10] bag loss: 0.6470\n",
            " Training bag [3/10] bag loss: 0.6488\n",
            " Training bag [4/10] bag loss: 0.6423\n",
            " Training bag [5/10] bag loss: 0.7313\n",
            " Training bag [6/10] bag loss: 0.6401\n",
            " Training bag [7/10] bag loss: 0.6308\n",
            " Training bag [8/10] bag loss: 0.6464\n",
            " Training bag [9/10] bag loss: 0.6464\n",
            " Testing bag [0/11] bag loss: 0.7294\n",
            " Testing bag [1/11] bag loss: 0.7270\n",
            " Testing bag [2/11] bag loss: 0.6388\n",
            " Testing bag [3/11] bag loss: 0.6420\n",
            " Testing bag [4/11] bag loss: 0.6408\n",
            " Testing bag [5/11] bag loss: 0.6334\n",
            " Testing bag [6/11] bag loss: 0.6447\n",
            " Testing bag [7/11] bag loss: 0.7294\n",
            " Testing bag [8/11] bag loss: 0.6443\n",
            " Testing bag [9/11] bag loss: 0.6437\n",
            " Testing bag [10/11] bag loss: 0.6495ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.6785714285714286\n",
            "\n",
            " Epoch [109/300] train loss: 0.6601 test loss: 0.6657, average score: 0.4545, AUC: class-0>>0.6428571428571428|class-1>>0.75|class-2>>0.6785714285714286\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6471\n",
            " Training bag [1/10] bag loss: 0.6422\n",
            " Training bag [2/10] bag loss: 0.6451\n",
            " Training bag [3/10] bag loss: 0.7299\n",
            " Training bag [4/10] bag loss: 0.7313\n",
            " Training bag [5/10] bag loss: 0.6320\n",
            " Training bag [6/10] bag loss: 0.6389\n",
            " Training bag [7/10] bag loss: 0.6448\n",
            " Training bag [8/10] bag loss: 0.6391\n",
            " Training bag [9/10] bag loss: 0.6472\n",
            " Testing bag [0/11] bag loss: 0.7298\n",
            " Testing bag [1/11] bag loss: 0.7268\n",
            " Testing bag [2/11] bag loss: 0.6383\n",
            " Testing bag [3/11] bag loss: 0.6427\n",
            " Testing bag [4/11] bag loss: 0.6396\n",
            " Testing bag [5/11] bag loss: 0.6342\n",
            " Testing bag [6/11] bag loss: 0.6450\n",
            " Testing bag [7/11] bag loss: 0.7297\n",
            " Testing bag [8/11] bag loss: 0.6448\n",
            " Testing bag [9/11] bag loss: 0.6429\n",
            " Testing bag [10/11] bag loss: 0.6493ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.6428571428571429\n",
            "\n",
            " Epoch [110/300] train loss: 0.6598 test loss: 0.6657, average score: 0.4545, AUC: class-0>>0.6428571428571428|class-1>>0.75|class-2>>0.6428571428571429\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6465\n",
            " Training bag [1/10] bag loss: 0.6453\n",
            " Training bag [2/10] bag loss: 0.6415\n",
            " Training bag [3/10] bag loss: 0.6381\n",
            " Training bag [4/10] bag loss: 0.6301\n",
            " Training bag [5/10] bag loss: 0.6388\n",
            " Training bag [6/10] bag loss: 0.6439\n",
            " Training bag [7/10] bag loss: 0.7316\n",
            " Training bag [8/10] bag loss: 0.7299\n",
            " Training bag [9/10] bag loss: 0.6468\n",
            " Testing bag [0/11] bag loss: 0.7301\n",
            " Testing bag [1/11] bag loss: 0.7268\n",
            " Testing bag [2/11] bag loss: 0.6387\n",
            " Testing bag [3/11] bag loss: 0.6414\n",
            " Testing bag [4/11] bag loss: 0.6391\n",
            " Testing bag [5/11] bag loss: 0.6348\n",
            " Testing bag [6/11] bag loss: 0.6444\n",
            " Testing bag [7/11] bag loss: 0.7301\n",
            " Testing bag [8/11] bag loss: 0.6438\n",
            " Testing bag [9/11] bag loss: 0.6432\n",
            " Testing bag [10/11] bag loss: 0.6493ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.6785714285714286\n",
            "\n",
            " Epoch [111/300] train loss: 0.6592 test loss: 0.6656, average score: 0.4545, AUC: class-0>>0.6428571428571428|class-1>>0.75|class-2>>0.6785714285714286\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6451\n",
            " Training bag [1/10] bag loss: 0.7312\n",
            " Training bag [2/10] bag loss: 0.7290\n",
            " Training bag [3/10] bag loss: 0.6289\n",
            " Training bag [4/10] bag loss: 0.6386\n",
            " Training bag [5/10] bag loss: 0.6378\n",
            " Training bag [6/10] bag loss: 0.6460\n",
            " Training bag [7/10] bag loss: 0.6407\n",
            " Training bag [8/10] bag loss: 0.6468\n",
            " Training bag [9/10] bag loss: 0.6439\n",
            " Testing bag [0/11] bag loss: 0.7298\n",
            " Testing bag [1/11] bag loss: 0.7277\n",
            " Testing bag [2/11] bag loss: 0.6383\n",
            " Testing bag [3/11] bag loss: 0.6414\n",
            " Testing bag [4/11] bag loss: 0.6387\n",
            " Testing bag [5/11] bag loss: 0.6328\n",
            " Testing bag [6/11] bag loss: 0.6439\n",
            " Testing bag [7/11] bag loss: 0.7304\n",
            " Testing bag [8/11] bag loss: 0.6433\n",
            " Testing bag [9/11] bag loss: 0.6428\n",
            " Testing bag [10/11] bag loss: 0.6489ROC AUC score: 0.6428571428571428\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.6785714285714286\n",
            "\n",
            " Epoch [112/300] train loss: 0.6588 test loss: 0.6653, average score: 0.4545, AUC: class-0>>0.6428571428571428|class-1>>0.75|class-2>>0.6785714285714286\n",
            "\n",
            " Training bag [0/10] bag loss: 0.7317\n",
            " Training bag [1/10] bag loss: 0.7306\n",
            " Training bag [2/10] bag loss: 0.6307\n",
            " Training bag [3/10] bag loss: 0.6447\n",
            " Training bag [4/10] bag loss: 0.6454\n",
            " Training bag [5/10] bag loss: 0.6459\n",
            " Training bag [6/10] bag loss: 0.6387\n",
            " Training bag [7/10] bag loss: 0.6447\n",
            " Training bag [8/10] bag loss: 0.6411\n",
            " Training bag [9/10] bag loss: 0.6369\n",
            " Testing bag [0/11] bag loss: 0.7302\n",
            " Testing bag [1/11] bag loss: 0.7280\n",
            " Testing bag [2/11] bag loss: 0.6369\n",
            " Testing bag [3/11] bag loss: 0.6416\n",
            " Testing bag [4/11] bag loss: 0.6381\n",
            " Testing bag [5/11] bag loss: 0.6332\n",
            " Testing bag [6/11] bag loss: 0.6439\n",
            " Testing bag [7/11] bag loss: 0.7311\n",
            " Testing bag [8/11] bag loss: 0.6427\n",
            " Testing bag [9/11] bag loss: 0.6420\n",
            " Testing bag [10/11] bag loss: 0.6472ROC AUC score: 0.6071428571428571\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.6428571428571429\n",
            "\n",
            " Epoch [113/300] train loss: 0.6590 test loss: 0.6650, average score: 0.4545, AUC: class-0>>0.6071428571428571|class-1>>0.75|class-2>>0.6428571428571429\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6443\n",
            " Training bag [1/10] bag loss: 0.6286\n",
            " Training bag [2/10] bag loss: 0.6362\n",
            " Training bag [3/10] bag loss: 0.6458\n",
            " Training bag [4/10] bag loss: 0.6371\n",
            " Training bag [5/10] bag loss: 0.7316\n",
            " Training bag [6/10] bag loss: 0.7325\n",
            " Training bag [7/10] bag loss: 0.6443\n",
            " Training bag [8/10] bag loss: 0.6405\n",
            " Training bag [9/10] bag loss: 0.6448\n",
            " Testing bag [0/11] bag loss: 0.7308\n",
            " Testing bag [1/11] bag loss: 0.7281\n",
            " Testing bag [2/11] bag loss: 0.6375\n",
            " Testing bag [3/11] bag loss: 0.6411\n",
            " Testing bag [4/11] bag loss: 0.6397\n",
            " Testing bag [5/11] bag loss: 0.6321\n",
            " Testing bag [6/11] bag loss: 0.6430\n",
            " Testing bag [7/11] bag loss: 0.7315\n",
            " Testing bag [8/11] bag loss: 0.6443\n",
            " Testing bag [9/11] bag loss: 0.6416\n",
            " Testing bag [10/11] bag loss: 0.6471ROC AUC score: 0.6071428571428571\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.6428571428571429\n",
            "\n",
            " Epoch [114/300] train loss: 0.6586 test loss: 0.6652, average score: 0.4545, AUC: class-0>>0.6071428571428571|class-1>>0.75|class-2>>0.6428571428571429\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6447\n",
            " Training bag [1/10] bag loss: 0.6402\n",
            " Training bag [2/10] bag loss: 0.6451\n",
            " Training bag [3/10] bag loss: 0.6370\n",
            " Training bag [4/10] bag loss: 0.7333\n",
            " Training bag [5/10] bag loss: 0.6429\n",
            " Training bag [6/10] bag loss: 0.6376\n",
            " Training bag [7/10] bag loss: 0.7309\n",
            " Training bag [8/10] bag loss: 0.6463\n",
            " Training bag [9/10] bag loss: 0.6291\n",
            " Testing bag [0/11] bag loss: 0.7307\n",
            " Testing bag [1/11] bag loss: 0.7286\n",
            " Testing bag [2/11] bag loss: 0.6366\n",
            " Testing bag [3/11] bag loss: 0.6407\n",
            " Testing bag [4/11] bag loss: 0.6391\n",
            " Testing bag [5/11] bag loss: 0.6320\n",
            " Testing bag [6/11] bag loss: 0.6426\n",
            " Testing bag [7/11] bag loss: 0.7304\n",
            " Testing bag [8/11] bag loss: 0.6431\n",
            " Testing bag [9/11] bag loss: 0.6415\n",
            " Testing bag [10/11] bag loss: 0.6467ROC AUC score: 0.6071428571428571\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.6785714285714286\n",
            "\n",
            " Epoch [115/300] train loss: 0.6587 test loss: 0.6647, average score: 0.4545, AUC: class-0>>0.6071428571428571|class-1>>0.75|class-2>>0.6785714285714286\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6464\n",
            " Training bag [1/10] bag loss: 0.6435\n",
            " Training bag [2/10] bag loss: 0.6398\n",
            " Training bag [3/10] bag loss: 0.6356\n",
            " Training bag [4/10] bag loss: 0.6374\n",
            " Training bag [5/10] bag loss: 0.6296\n",
            " Training bag [6/10] bag loss: 0.6434\n",
            " Training bag [7/10] bag loss: 0.7329\n",
            " Training bag [8/10] bag loss: 0.6442\n",
            " Training bag [9/10] bag loss: 0.7324\n",
            " Testing bag [0/11] bag loss: 0.7312\n",
            " Testing bag [1/11] bag loss: 0.7284\n",
            " Testing bag [2/11] bag loss: 0.6364\n",
            " Testing bag [3/11] bag loss: 0.6400\n",
            " Testing bag [4/11] bag loss: 0.6386\n",
            " Testing bag [5/11] bag loss: 0.6326\n",
            " Testing bag [6/11] bag loss: 0.6429\n",
            " Testing bag [7/11] bag loss: 0.7316\n",
            " Testing bag [8/11] bag loss: 0.6427\n",
            " Testing bag [9/11] bag loss: 0.6400\n",
            " Testing bag [10/11] bag loss: 0.6469ROC AUC score: 0.6071428571428571\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.6428571428571429\n",
            "\n",
            " Epoch [116/300] train loss: 0.6585 test loss: 0.6647, average score: 0.4545, AUC: class-0>>0.6071428571428571|class-1>>0.75|class-2>>0.6428571428571429\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6356\n",
            " Training bag [1/10] bag loss: 0.7330\n",
            " Training bag [2/10] bag loss: 0.6292\n",
            " Training bag [3/10] bag loss: 0.6422\n",
            " Training bag [4/10] bag loss: 0.7315\n",
            " Training bag [5/10] bag loss: 0.6371\n",
            " Training bag [6/10] bag loss: 0.6442\n",
            " Training bag [7/10] bag loss: 0.6431\n",
            " Training bag [8/10] bag loss: 0.6449\n",
            " Training bag [9/10] bag loss: 0.6389\n",
            " Testing bag [0/11] bag loss: 0.7310\n",
            " Testing bag [1/11] bag loss: 0.7286\n",
            " Testing bag [2/11] bag loss: 0.6375\n",
            " Testing bag [3/11] bag loss: 0.6403\n",
            " Testing bag [4/11] bag loss: 0.6373\n",
            " Testing bag [5/11] bag loss: 0.6314\n",
            " Testing bag [6/11] bag loss: 0.6425\n",
            " Testing bag [7/11] bag loss: 0.7313\n",
            " Testing bag [8/11] bag loss: 0.6416\n",
            " Testing bag [9/11] bag loss: 0.6410\n",
            " Testing bag [10/11] bag loss: 0.6460ROC AUC score: 0.6071428571428571\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.6428571428571429\n",
            "\n",
            " Epoch [117/300] train loss: 0.6580 test loss: 0.6644, average score: 0.4545, AUC: class-0>>0.6071428571428571|class-1>>0.75|class-2>>0.6428571428571429\n",
            "\n",
            " Training bag [0/10] bag loss: 0.7311\n",
            " Training bag [1/10] bag loss: 0.6271\n",
            " Training bag [2/10] bag loss: 0.6440\n",
            " Training bag [3/10] bag loss: 0.6358\n",
            " Training bag [4/10] bag loss: 0.6439\n",
            " Training bag [5/10] bag loss: 0.6390\n",
            " Training bag [6/10] bag loss: 0.7334\n",
            " Training bag [7/10] bag loss: 0.6422\n",
            " Training bag [8/10] bag loss: 0.6355\n",
            " Training bag [9/10] bag loss: 0.6457\n",
            " Testing bag [0/11] bag loss: 0.7310\n",
            " Testing bag [1/11] bag loss: 0.7293\n",
            " Testing bag [2/11] bag loss: 0.6365\n",
            " Testing bag [3/11] bag loss: 0.6396\n",
            " Testing bag [4/11] bag loss: 0.6356\n",
            " Testing bag [5/11] bag loss: 0.6310\n",
            " Testing bag [6/11] bag loss: 0.6424\n",
            " Testing bag [7/11] bag loss: 0.7321\n",
            " Testing bag [8/11] bag loss: 0.6413\n",
            " Testing bag [9/11] bag loss: 0.6408\n",
            " Testing bag [10/11] bag loss: 0.6471ROC AUC score: 0.6071428571428571\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.6785714285714286\n",
            "\n",
            " Epoch [118/300] train loss: 0.6578 test loss: 0.6643, average score: 0.4545, AUC: class-0>>0.6071428571428571|class-1>>0.75|class-2>>0.6785714285714286\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6427\n",
            " Training bag [1/10] bag loss: 0.6387\n",
            " Training bag [2/10] bag loss: 0.6278\n",
            " Training bag [3/10] bag loss: 0.6424\n",
            " Training bag [4/10] bag loss: 0.7314\n",
            " Training bag [5/10] bag loss: 0.6347\n",
            " Training bag [6/10] bag loss: 0.6359\n",
            " Training bag [7/10] bag loss: 0.7347\n",
            " Training bag [8/10] bag loss: 0.6424\n",
            " Training bag [9/10] bag loss: 0.6443\n",
            " Testing bag [0/11] bag loss: 0.7312\n",
            " Testing bag [1/11] bag loss: 0.7286\n",
            " Testing bag [2/11] bag loss: 0.6352\n",
            " Testing bag [3/11] bag loss: 0.6392\n",
            " Testing bag [4/11] bag loss: 0.6372\n",
            " Testing bag [5/11] bag loss: 0.6309\n",
            " Testing bag [6/11] bag loss: 0.6412\n",
            " Testing bag [7/11] bag loss: 0.7320\n",
            " Testing bag [8/11] bag loss: 0.6409\n",
            " Testing bag [9/11] bag loss: 0.6404\n",
            " Testing bag [10/11] bag loss: 0.6457ROC AUC score: 0.6071428571428571\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.6428571428571429\n",
            "\n",
            " Epoch [119/300] train loss: 0.6575 test loss: 0.6639, average score: 0.4545, AUC: class-0>>0.6071428571428571|class-1>>0.75|class-2>>0.6428571428571429\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6427\n",
            " Training bag [1/10] bag loss: 0.6381\n",
            " Training bag [2/10] bag loss: 0.7330\n",
            " Training bag [3/10] bag loss: 0.6273\n",
            " Training bag [4/10] bag loss: 0.6356\n",
            " Training bag [5/10] bag loss: 0.7331\n",
            " Training bag [6/10] bag loss: 0.6347\n",
            " Training bag [7/10] bag loss: 0.6443\n",
            " Training bag [8/10] bag loss: 0.6412\n",
            " Training bag [9/10] bag loss: 0.6424\n",
            " Testing bag [0/11] bag loss: 0.7323\n",
            " Testing bag [1/11] bag loss: 0.7287\n",
            " Testing bag [2/11] bag loss: 0.6352\n",
            " Testing bag [3/11] bag loss: 0.6389\n",
            " Testing bag [4/11] bag loss: 0.6369\n",
            " Testing bag [5/11] bag loss: 0.6302\n",
            " Testing bag [6/11] bag loss: 0.6414\n",
            " Testing bag [7/11] bag loss: 0.7318\n",
            " Testing bag [8/11] bag loss: 0.6414\n",
            " Testing bag [9/11] bag loss: 0.6392\n",
            " Testing bag [10/11] bag loss: 0.6464ROC AUC score: 0.6071428571428571\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.6428571428571429\n",
            "\n",
            " Epoch [120/300] train loss: 0.6573 test loss: 0.6639, average score: 0.4545, AUC: class-0>>0.6071428571428571|class-1>>0.75|class-2>>0.6428571428571429\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6260\n",
            " Training bag [1/10] bag loss: 0.6419\n",
            " Training bag [2/10] bag loss: 0.7341\n",
            " Training bag [3/10] bag loss: 0.6342\n",
            " Training bag [4/10] bag loss: 0.6376\n",
            " Training bag [5/10] bag loss: 0.6432\n",
            " Training bag [6/10] bag loss: 0.6419\n",
            " Training bag [7/10] bag loss: 0.6427\n",
            " Training bag [8/10] bag loss: 0.6357\n",
            " Training bag [9/10] bag loss: 0.7322\n",
            " Testing bag [0/11] bag loss: 0.7324\n",
            " Testing bag [1/11] bag loss: 0.7295\n",
            " Testing bag [2/11] bag loss: 0.6353\n",
            " Testing bag [3/11] bag loss: 0.6385\n",
            " Testing bag [4/11] bag loss: 0.6349\n",
            " Testing bag [5/11] bag loss: 0.6304\n",
            " Testing bag [6/11] bag loss: 0.6414\n",
            " Testing bag [7/11] bag loss: 0.7335\n",
            " Testing bag [8/11] bag loss: 0.6420\n",
            " Testing bag [9/11] bag loss: 0.6394\n",
            " Testing bag [10/11] bag loss: 0.6448ROC AUC score: 0.6071428571428571\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.6428571428571429\n",
            "\n",
            " Epoch [121/300] train loss: 0.6569 test loss: 0.6638, average score: 0.4545, AUC: class-0>>0.6071428571428571|class-1>>0.75|class-2>>0.6428571428571429\n",
            "\n",
            " Training bag [0/10] bag loss: 0.7342\n",
            " Training bag [1/10] bag loss: 0.6357\n",
            " Training bag [2/10] bag loss: 0.6417\n",
            " Training bag [3/10] bag loss: 0.7321\n",
            " Training bag [4/10] bag loss: 0.6341\n",
            " Training bag [5/10] bag loss: 0.6422\n",
            " Training bag [6/10] bag loss: 0.6425\n",
            " Training bag [7/10] bag loss: 0.6260\n",
            " Training bag [8/10] bag loss: 0.6443\n",
            " Training bag [9/10] bag loss: 0.6374\n",
            " Testing bag [0/11] bag loss: 0.7324\n",
            " Testing bag [1/11] bag loss: 0.7295\n",
            " Testing bag [2/11] bag loss: 0.6345\n",
            " Testing bag [3/11] bag loss: 0.6375\n",
            " Testing bag [4/11] bag loss: 0.6354\n",
            " Testing bag [5/11] bag loss: 0.6285\n",
            " Testing bag [6/11] bag loss: 0.6407\n",
            " Testing bag [7/11] bag loss: 0.7327\n",
            " Testing bag [8/11] bag loss: 0.6410\n",
            " Testing bag [9/11] bag loss: 0.6387\n",
            " Testing bag [10/11] bag loss: 0.6456ROC AUC score: 0.6071428571428571\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.6428571428571429\n",
            "\n",
            " Epoch [122/300] train loss: 0.6570 test loss: 0.6633, average score: 0.4545, AUC: class-0>>0.6071428571428571|class-1>>0.75|class-2>>0.6428571428571429\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6421\n",
            " Training bag [1/10] bag loss: 0.6421\n",
            " Training bag [2/10] bag loss: 0.7349\n",
            " Training bag [3/10] bag loss: 0.6339\n",
            " Training bag [4/10] bag loss: 0.6257\n",
            " Training bag [5/10] bag loss: 0.7329\n",
            " Training bag [6/10] bag loss: 0.6374\n",
            " Training bag [7/10] bag loss: 0.6344\n",
            " Training bag [8/10] bag loss: 0.6412\n",
            " Training bag [9/10] bag loss: 0.6444\n",
            " Testing bag [0/11] bag loss: 0.7323\n",
            " Testing bag [1/11] bag loss: 0.7292\n",
            " Testing bag [2/11] bag loss: 0.6350\n",
            " Testing bag [3/11] bag loss: 0.6379\n",
            " Testing bag [4/11] bag loss: 0.6356\n",
            " Testing bag [5/11] bag loss: 0.6299\n",
            " Testing bag [6/11] bag loss: 0.6405\n",
            " Testing bag [7/11] bag loss: 0.7330\n",
            " Testing bag [8/11] bag loss: 0.6397\n",
            " Testing bag [9/11] bag loss: 0.6393\n",
            " Testing bag [10/11] bag loss: 0.6454ROC AUC score: 0.6071428571428571\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.6785714285714286\n",
            "\n",
            " Epoch [123/300] train loss: 0.6569 test loss: 0.6634, average score: 0.4545, AUC: class-0>>0.6071428571428571|class-1>>0.75|class-2>>0.6785714285714286\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6410\n",
            " Training bag [1/10] bag loss: 0.6427\n",
            " Training bag [2/10] bag loss: 0.6411\n",
            " Training bag [3/10] bag loss: 0.6371\n",
            " Training bag [4/10] bag loss: 0.6341\n",
            " Training bag [5/10] bag loss: 0.6409\n",
            " Training bag [6/10] bag loss: 0.6266\n",
            " Training bag [7/10] bag loss: 0.7349\n",
            " Training bag [8/10] bag loss: 0.7336\n",
            " Training bag [9/10] bag loss: 0.6338\n",
            " Testing bag [0/11] bag loss: 0.7330\n",
            " Testing bag [1/11] bag loss: 0.7304\n",
            " Testing bag [2/11] bag loss: 0.6331\n",
            " Testing bag [3/11] bag loss: 0.6376\n",
            " Testing bag [4/11] bag loss: 0.6353\n",
            " Testing bag [5/11] bag loss: 0.6297\n",
            " Testing bag [6/11] bag loss: 0.6404\n",
            " Testing bag [7/11] bag loss: 0.7332\n",
            " Testing bag [8/11] bag loss: 0.6398\n",
            " Testing bag [9/11] bag loss: 0.6387\n",
            " Testing bag [10/11] bag loss: 0.6436ROC AUC score: 0.6071428571428571\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.6428571428571429\n",
            "\n",
            " Epoch [124/300] train loss: 0.6566 test loss: 0.6632, average score: 0.4545, AUC: class-0>>0.6071428571428571|class-1>>0.75|class-2>>0.6428571428571429\n",
            "\n",
            " Training bag [0/10] bag loss: 0.6343\n",
            " Training bag [1/10] bag loss: 0.7336\n",
            " Training bag [2/10] bag loss: 0.6242\n",
            " Training bag [3/10] bag loss: 0.6410\n",
            " Training bag [4/10] bag loss: 0.6371\n",
            " Training bag [5/10] bag loss: 0.6438\n",
            " Training bag [6/10] bag loss: 0.6411\n",
            " Training bag [7/10] bag loss: 0.6330\n",
            " Training bag [8/10] bag loss: 0.7351\n",
            " Training bag [9/10] bag loss: 0.6408\n",
            " Testing bag [0/11] bag loss: 0.7333\n",
            " Testing bag [1/11] bag loss: 0.7305\n",
            " Testing bag [2/11] bag loss: 0.6338\n",
            " Testing bag [3/11] bag loss: 0.6370\n",
            " Testing bag [4/11] bag loss: 0.6347\n",
            " Testing bag [5/11] bag loss: 0.6279\n",
            " Testing bag [6/11] bag loss: 0.6402\n",
            " Testing bag [7/11] bag loss: 0.7342\n",
            " Testing bag [8/11] bag loss: 0.6398\n",
            " Testing bag [9/11] bag loss: 0.6386\n",
            " Testing bag [10/11] bag loss: 0.6436ROC AUC score: 0.6071428571428571\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.6785714285714286\n",
            "\n",
            " Epoch [125/300] train loss: 0.6564 test loss: 0.6630, average score: 0.4545, AUC: class-0>>0.6071428571428571|class-1>>0.75|class-2>>0.6785714285714286\n",
            "Starting CV fold 1.\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6989\n",
            " Training bag [1/11] bag loss: 0.6993\n",
            " Training bag [2/11] bag loss: 0.6972\n",
            " Training bag [3/11] bag loss: 0.6999\n",
            " Training bag [4/11] bag loss: 0.6962\n",
            " Training bag [5/11] bag loss: 0.7163\n",
            " Training bag [6/11] bag loss: 0.6924\n",
            " Training bag [7/11] bag loss: 0.6963\n",
            " Training bag [8/11] bag loss: 0.7011\n",
            " Training bag [9/11] bag loss: 0.7083\n",
            " Training bag [10/11] bag loss: 0.7127\n",
            " Testing bag [0/10] bag loss: 0.7095\n",
            " Testing bag [1/10] bag loss: 0.7008\n",
            " Testing bag [2/10] bag loss: 0.6977\n",
            " Testing bag [3/10] bag loss: 0.6979\n",
            " Testing bag [4/10] bag loss: 0.7016\n",
            " Testing bag [5/10] bag loss: 0.7126\n",
            " Testing bag [6/10] bag loss: 0.6933\n",
            " Testing bag [7/10] bag loss: 0.6941\n",
            " Testing bag [8/10] bag loss: 0.6988\n",
            " Testing bag [9/10] bag loss: 0.6981ROC AUC score: 0.875\n",
            "ROC AUC score: 0.5625\n",
            "ROC AUC score: 0.5833333333333333\n",
            "\n",
            " Epoch [1/300] train loss: 0.7017 test loss: 0.7004, average score: 0.4000, AUC: class-0>>0.875|class-1>>0.5625|class-2>>0.5833333333333333\n",
            "Best model saved at: weights/20250626/fold_1_5.pth\n",
            "Best thresholds ===>>> class-0>>0.503872811794281|class-1>>0.4839051365852356|class-2>>0.504250168800354\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6960\n",
            " Training bag [1/11] bag loss: 0.6973\n",
            " Training bag [2/11] bag loss: 0.6970\n",
            " Training bag [3/11] bag loss: 0.6914\n",
            " Training bag [4/11] bag loss: 0.6967\n",
            " Training bag [5/11] bag loss: 0.6996\n",
            " Training bag [6/11] bag loss: 0.6988\n",
            " Training bag [7/11] bag loss: 0.7080\n",
            " Training bag [8/11] bag loss: 0.7133\n",
            " Training bag [9/11] bag loss: 0.6953\n",
            " Training bag [10/11] bag loss: 0.7155\n",
            " Testing bag [0/10] bag loss: 0.7095\n",
            " Testing bag [1/10] bag loss: 0.7001\n",
            " Testing bag [2/10] bag loss: 0.6959\n",
            " Testing bag [3/10] bag loss: 0.6965\n",
            " Testing bag [4/10] bag loss: 0.6992\n",
            " Testing bag [5/10] bag loss: 0.7134\n",
            " Testing bag [6/10] bag loss: 0.6939\n",
            " Testing bag [7/10] bag loss: 0.6960\n",
            " Testing bag [8/10] bag loss: 0.6983\n",
            " Testing bag [9/10] bag loss: 0.6962ROC AUC score: 0.875\n",
            "ROC AUC score: 0.5625\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [2/300] train loss: 0.7008 test loss: 0.6999, average score: 0.4000, AUC: class-0>>0.875|class-1>>0.5625|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6989\n",
            " Training bag [1/11] bag loss: 0.6962\n",
            " Training bag [2/11] bag loss: 0.6954\n",
            " Training bag [3/11] bag loss: 0.7120\n",
            " Training bag [4/11] bag loss: 0.6907\n",
            " Training bag [5/11] bag loss: 0.7159\n",
            " Training bag [6/11] bag loss: 0.6963\n",
            " Training bag [7/11] bag loss: 0.6968\n",
            " Training bag [8/11] bag loss: 0.6984\n",
            " Training bag [9/11] bag loss: 0.6949\n",
            " Training bag [10/11] bag loss: 0.7076\n",
            " Testing bag [0/10] bag loss: 0.7100\n",
            " Testing bag [1/10] bag loss: 0.6998\n",
            " Testing bag [2/10] bag loss: 0.6962\n",
            " Testing bag [3/10] bag loss: 0.6964\n",
            " Testing bag [4/10] bag loss: 0.6996\n",
            " Testing bag [5/10] bag loss: 0.7105\n",
            " Testing bag [6/10] bag loss: 0.6925\n",
            " Testing bag [7/10] bag loss: 0.6973\n",
            " Testing bag [8/10] bag loss: 0.6993\n",
            " Testing bag [9/10] bag loss: 0.6960ROC AUC score: 0.875\n",
            "ROC AUC score: 0.5625\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [3/300] train loss: 0.7003 test loss: 0.6998, average score: 0.4000, AUC: class-0>>0.875|class-1>>0.5625|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6956\n",
            " Training bag [1/11] bag loss: 0.6906\n",
            " Training bag [2/11] bag loss: 0.6943\n",
            " Training bag [3/11] bag loss: 0.6958\n",
            " Training bag [4/11] bag loss: 0.6946\n",
            " Training bag [5/11] bag loss: 0.7151\n",
            " Training bag [6/11] bag loss: 0.7083\n",
            " Training bag [7/11] bag loss: 0.6990\n",
            " Training bag [8/11] bag loss: 0.7118\n",
            " Training bag [9/11] bag loss: 0.6962\n",
            " Training bag [10/11] bag loss: 0.6990\n",
            " Testing bag [0/10] bag loss: 0.7073\n",
            " Testing bag [1/10] bag loss: 0.6994\n",
            " Testing bag [2/10] bag loss: 0.6953\n",
            " Testing bag [3/10] bag loss: 0.6951\n",
            " Testing bag [4/10] bag loss: 0.6975\n",
            " Testing bag [5/10] bag loss: 0.7113\n",
            " Testing bag [6/10] bag loss: 0.6913\n",
            " Testing bag [7/10] bag loss: 0.6941\n",
            " Testing bag [8/10] bag loss: 0.6975\n",
            " Testing bag [9/10] bag loss: 0.6957ROC AUC score: 0.875\n",
            "ROC AUC score: 0.5625\n",
            "ROC AUC score: 0.5416666666666667\n",
            "\n",
            " Epoch [4/300] train loss: 0.7000 test loss: 0.6984, average score: 0.4000, AUC: class-0>>0.875|class-1>>0.5625|class-2>>0.5416666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6982\n",
            " Training bag [1/11] bag loss: 0.6967\n",
            " Training bag [2/11] bag loss: 0.6947\n",
            " Training bag [3/11] bag loss: 0.6953\n",
            " Training bag [4/11] bag loss: 0.6933\n",
            " Training bag [5/11] bag loss: 0.7080\n",
            " Training bag [6/11] bag loss: 0.6972\n",
            " Training bag [7/11] bag loss: 0.6894\n",
            " Training bag [8/11] bag loss: 0.6926\n",
            " Training bag [9/11] bag loss: 0.7124\n",
            " Training bag [10/11] bag loss: 0.7167\n",
            " Testing bag [0/10] bag loss: 0.7095\n",
            " Testing bag [1/10] bag loss: 0.6982\n",
            " Testing bag [2/10] bag loss: 0.6937\n",
            " Testing bag [3/10] bag loss: 0.6943\n",
            " Testing bag [4/10] bag loss: 0.6984\n",
            " Testing bag [5/10] bag loss: 0.7118\n",
            " Testing bag [6/10] bag loss: 0.6903\n",
            " Testing bag [7/10] bag loss: 0.6940\n",
            " Testing bag [8/10] bag loss: 0.6969\n",
            " Testing bag [9/10] bag loss: 0.6957ROC AUC score: 0.875\n",
            "ROC AUC score: 0.5625\n",
            "ROC AUC score: 0.5833333333333334\n",
            "\n",
            " Epoch [5/300] train loss: 0.6995 test loss: 0.6983, average score: 0.4000, AUC: class-0>>0.875|class-1>>0.5625|class-2>>0.5833333333333334\n",
            "Best model saved at: weights/20250626/fold_1_5.pth\n",
            "Best thresholds ===>>> class-0>>0.500191867351532|class-1>>0.4783034324645996|class-2>>0.49631160497665405\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6953\n",
            " Training bag [1/11] bag loss: 0.6974\n",
            " Training bag [2/11] bag loss: 0.6936\n",
            " Training bag [3/11] bag loss: 0.6935\n",
            " Training bag [4/11] bag loss: 0.7123\n",
            " Training bag [5/11] bag loss: 0.6915\n",
            " Training bag [6/11] bag loss: 0.6891\n",
            " Training bag [7/11] bag loss: 0.6934\n",
            " Training bag [8/11] bag loss: 0.7073\n",
            " Training bag [9/11] bag loss: 0.7152\n",
            " Training bag [10/11] bag loss: 0.6960\n",
            " Testing bag [0/10] bag loss: 0.7077\n",
            " Testing bag [1/10] bag loss: 0.6964\n",
            " Testing bag [2/10] bag loss: 0.6932\n",
            " Testing bag [3/10] bag loss: 0.6945\n",
            " Testing bag [4/10] bag loss: 0.6985\n",
            " Testing bag [5/10] bag loss: 0.7104\n",
            " Testing bag [6/10] bag loss: 0.6884\n",
            " Testing bag [7/10] bag loss: 0.6929\n",
            " Testing bag [8/10] bag loss: 0.6959\n",
            " Testing bag [9/10] bag loss: 0.6940ROC AUC score: 0.875\n",
            "ROC AUC score: 0.5625\n",
            "ROC AUC score: 0.5416666666666667\n",
            "\n",
            " Epoch [6/300] train loss: 0.6986 test loss: 0.6972, average score: 0.4000, AUC: class-0>>0.875|class-1>>0.5625|class-2>>0.5416666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7064\n",
            " Training bag [1/11] bag loss: 0.6939\n",
            " Training bag [2/11] bag loss: 0.6881\n",
            " Training bag [3/11] bag loss: 0.7158\n",
            " Training bag [4/11] bag loss: 0.6912\n",
            " Training bag [5/11] bag loss: 0.6953\n",
            " Training bag [6/11] bag loss: 0.6926\n",
            " Training bag [7/11] bag loss: 0.6930\n",
            " Training bag [8/11] bag loss: 0.6959\n",
            " Training bag [9/11] bag loss: 0.7114\n",
            " Training bag [10/11] bag loss: 0.6971\n",
            " Testing bag [0/10] bag loss: 0.7088\n",
            " Testing bag [1/10] bag loss: 0.6958\n",
            " Testing bag [2/10] bag loss: 0.6920\n",
            " Testing bag [3/10] bag loss: 0.6927\n",
            " Testing bag [4/10] bag loss: 0.6975\n",
            " Testing bag [5/10] bag loss: 0.7103\n",
            " Testing bag [6/10] bag loss: 0.6887\n",
            " Testing bag [7/10] bag loss: 0.6928\n",
            " Testing bag [8/10] bag loss: 0.6968\n",
            " Testing bag [9/10] bag loss: 0.6937ROC AUC score: 0.9166666666666667\n",
            "ROC AUC score: 0.5625\n",
            "ROC AUC score: 0.5833333333333334\n",
            "\n",
            " Epoch [7/300] train loss: 0.6982 test loss: 0.6969, average score: 0.4000, AUC: class-0>>0.9166666666666667|class-1>>0.5625|class-2>>0.5833333333333334\n",
            "Best model saved at: weights/20250626/fold_1_5.pth\n",
            "Best thresholds ===>>> class-0>>0.4984085261821747|class-1>>0.47584328055381775|class-2>>0.4941495656967163\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7113\n",
            " Training bag [1/11] bag loss: 0.6967\n",
            " Training bag [2/11] bag loss: 0.7148\n",
            " Training bag [3/11] bag loss: 0.6927\n",
            " Training bag [4/11] bag loss: 0.7059\n",
            " Training bag [5/11] bag loss: 0.6922\n",
            " Training bag [6/11] bag loss: 0.6954\n",
            " Training bag [7/11] bag loss: 0.6878\n",
            " Training bag [8/11] bag loss: 0.6922\n",
            " Training bag [9/11] bag loss: 0.6923\n",
            " Training bag [10/11] bag loss: 0.6934\n",
            " Testing bag [0/10] bag loss: 0.7074\n",
            " Testing bag [1/10] bag loss: 0.6965\n",
            " Testing bag [2/10] bag loss: 0.6920\n",
            " Testing bag [3/10] bag loss: 0.6935\n",
            " Testing bag [4/10] bag loss: 0.6961\n",
            " Testing bag [5/10] bag loss: 0.7100\n",
            " Testing bag [6/10] bag loss: 0.6882\n",
            " Testing bag [7/10] bag loss: 0.6908\n",
            " Testing bag [8/10] bag loss: 0.6946\n",
            " Testing bag [9/10] bag loss: 0.6927ROC AUC score: 0.875\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5416666666666667\n",
            "\n",
            " Epoch [8/300] train loss: 0.6977 test loss: 0.6962, average score: 0.4000, AUC: class-0>>0.875|class-1>>0.5|class-2>>0.5416666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7056\n",
            " Training bag [1/11] bag loss: 0.6928\n",
            " Training bag [2/11] bag loss: 0.6919\n",
            " Training bag [3/11] bag loss: 0.6874\n",
            " Training bag [4/11] bag loss: 0.6951\n",
            " Training bag [5/11] bag loss: 0.6890\n",
            " Training bag [6/11] bag loss: 0.6927\n",
            " Training bag [7/11] bag loss: 0.7152\n",
            " Training bag [8/11] bag loss: 0.6908\n",
            " Training bag [9/11] bag loss: 0.7108\n",
            " Training bag [10/11] bag loss: 0.6950\n",
            " Testing bag [0/10] bag loss: 0.7098\n",
            " Testing bag [1/10] bag loss: 0.6948\n",
            " Testing bag [2/10] bag loss: 0.6908\n",
            " Testing bag [3/10] bag loss: 0.6929\n",
            " Testing bag [4/10] bag loss: 0.6966\n",
            " Testing bag [5/10] bag loss: 0.7118\n",
            " Testing bag [6/10] bag loss: 0.6881\n",
            " Testing bag [7/10] bag loss: 0.6920\n",
            " Testing bag [8/10] bag loss: 0.6939\n",
            " Testing bag [9/10] bag loss: 0.6932ROC AUC score: 0.9166666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5833333333333334\n",
            "\n",
            " Epoch [9/300] train loss: 0.6969 test loss: 0.6964, average score: 0.4000, AUC: class-0>>0.9166666666666667|class-1>>0.5|class-2>>0.5833333333333334\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7111\n",
            " Training bag [1/11] bag loss: 0.6945\n",
            " Training bag [2/11] bag loss: 0.6874\n",
            " Training bag [3/11] bag loss: 0.6938\n",
            " Training bag [4/11] bag loss: 0.6883\n",
            " Training bag [5/11] bag loss: 0.6923\n",
            " Training bag [6/11] bag loss: 0.7148\n",
            " Training bag [7/11] bag loss: 0.6927\n",
            " Training bag [8/11] bag loss: 0.7064\n",
            " Training bag [9/11] bag loss: 0.6908\n",
            " Training bag [10/11] bag loss: 0.6895\n",
            " Testing bag [0/10] bag loss: 0.7083\n",
            " Testing bag [1/10] bag loss: 0.6950\n",
            " Testing bag [2/10] bag loss: 0.6922\n",
            " Testing bag [3/10] bag loss: 0.6925\n",
            " Testing bag [4/10] bag loss: 0.6941\n",
            " Testing bag [5/10] bag loss: 0.7115\n",
            " Testing bag [6/10] bag loss: 0.6883\n",
            " Testing bag [7/10] bag loss: 0.6866\n",
            " Testing bag [8/10] bag loss: 0.6932\n",
            " Testing bag [9/10] bag loss: 0.6924ROC AUC score: 0.9166666666666667\n",
            "ROC AUC score: 0.4375\n",
            "ROC AUC score: 0.5416666666666667\n",
            "\n",
            " Epoch [10/300] train loss: 0.6965 test loss: 0.6954, average score: 0.4000, AUC: class-0>>0.9166666666666667|class-1>>0.4375|class-2>>0.5416666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6903\n",
            " Training bag [1/11] bag loss: 0.6898\n",
            " Training bag [2/11] bag loss: 0.6857\n",
            " Training bag [3/11] bag loss: 0.7058\n",
            " Training bag [4/11] bag loss: 0.6949\n",
            " Training bag [5/11] bag loss: 0.6904\n",
            " Training bag [6/11] bag loss: 0.6897\n",
            " Training bag [7/11] bag loss: 0.6932\n",
            " Training bag [8/11] bag loss: 0.7150\n",
            " Training bag [9/11] bag loss: 0.7103\n",
            " Training bag [10/11] bag loss: 0.6918\n",
            " Testing bag [0/10] bag loss: 0.7094\n",
            " Testing bag [1/10] bag loss: 0.6931\n",
            " Testing bag [2/10] bag loss: 0.6913\n",
            " Testing bag [3/10] bag loss: 0.6927\n",
            " Testing bag [4/10] bag loss: 0.6955\n",
            " Testing bag [5/10] bag loss: 0.7086\n",
            " Testing bag [6/10] bag loss: 0.6869\n",
            " Testing bag [7/10] bag loss: 0.6883\n",
            " Testing bag [8/10] bag loss: 0.6933\n",
            " Testing bag [9/10] bag loss: 0.6912ROC AUC score: 0.9166666666666667\n",
            "ROC AUC score: 0.4375\n",
            "ROC AUC score: 0.5833333333333334\n",
            "\n",
            " Epoch [11/300] train loss: 0.6961 test loss: 0.6950, average score: 0.4000, AUC: class-0>>0.9166666666666667|class-1>>0.4375|class-2>>0.5833333333333334\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7141\n",
            " Training bag [1/11] bag loss: 0.6896\n",
            " Training bag [2/11] bag loss: 0.7051\n",
            " Training bag [3/11] bag loss: 0.7106\n",
            " Training bag [4/11] bag loss: 0.6848\n",
            " Training bag [5/11] bag loss: 0.6898\n",
            " Training bag [6/11] bag loss: 0.6901\n",
            " Training bag [7/11] bag loss: 0.6922\n",
            " Training bag [8/11] bag loss: 0.6940\n",
            " Training bag [9/11] bag loss: 0.6893\n",
            " Training bag [10/11] bag loss: 0.6889\n",
            " Testing bag [0/10] bag loss: 0.7066\n",
            " Testing bag [1/10] bag loss: 0.6941\n",
            " Testing bag [2/10] bag loss: 0.6906\n",
            " Testing bag [3/10] bag loss: 0.6901\n",
            " Testing bag [4/10] bag loss: 0.6947\n",
            " Testing bag [5/10] bag loss: 0.7102\n",
            " Testing bag [6/10] bag loss: 0.6877\n",
            " Testing bag [7/10] bag loss: 0.6896\n",
            " Testing bag [8/10] bag loss: 0.6914\n",
            " Testing bag [9/10] bag loss: 0.6910ROC AUC score: 0.9166666666666667\n",
            "ROC AUC score: 0.4375\n",
            "ROC AUC score: 0.5833333333333334\n",
            "\n",
            " Epoch [12/300] train loss: 0.6953 test loss: 0.6946, average score: 0.4000, AUC: class-0>>0.9166666666666667|class-1>>0.4375|class-2>>0.5833333333333334\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6895\n",
            " Training bag [1/11] bag loss: 0.6925\n",
            " Training bag [2/11] bag loss: 0.6901\n",
            " Training bag [3/11] bag loss: 0.6898\n",
            " Training bag [4/11] bag loss: 0.7103\n",
            " Training bag [5/11] bag loss: 0.6875\n",
            " Training bag [6/11] bag loss: 0.6927\n",
            " Training bag [7/11] bag loss: 0.6882\n",
            " Training bag [8/11] bag loss: 0.7143\n",
            " Training bag [9/11] bag loss: 0.6850\n",
            " Training bag [10/11] bag loss: 0.7061\n",
            " Testing bag [0/10] bag loss: 0.7064\n",
            " Testing bag [1/10] bag loss: 0.6917\n",
            " Testing bag [2/10] bag loss: 0.6891\n",
            " Testing bag [3/10] bag loss: 0.6906\n",
            " Testing bag [4/10] bag loss: 0.6909\n",
            " Testing bag [5/10] bag loss: 0.7112\n",
            " Testing bag [6/10] bag loss: 0.6849\n",
            " Testing bag [7/10] bag loss: 0.6894\n",
            " Testing bag [8/10] bag loss: 0.6915\n",
            " Testing bag [9/10] bag loss: 0.6910ROC AUC score: 0.9166666666666667\n",
            "ROC AUC score: 0.4375\n",
            "ROC AUC score: 0.5833333333333334\n",
            "\n",
            " Epoch [13/300] train loss: 0.6951 test loss: 0.6937, average score: 0.4000, AUC: class-0>>0.9166666666666667|class-1>>0.4375|class-2>>0.5833333333333334\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7062\n",
            " Training bag [1/11] bag loss: 0.6876\n",
            " Training bag [2/11] bag loss: 0.6934\n",
            " Training bag [3/11] bag loss: 0.6847\n",
            " Training bag [4/11] bag loss: 0.6891\n",
            " Training bag [5/11] bag loss: 0.7098\n",
            " Training bag [6/11] bag loss: 0.6911\n",
            " Training bag [7/11] bag loss: 0.6884\n",
            " Training bag [8/11] bag loss: 0.7144\n",
            " Training bag [9/11] bag loss: 0.6887\n",
            " Training bag [10/11] bag loss: 0.6884\n",
            " Testing bag [0/10] bag loss: 0.7061\n",
            " Testing bag [1/10] bag loss: 0.6928\n",
            " Testing bag [2/10] bag loss: 0.6897\n",
            " Testing bag [3/10] bag loss: 0.6892\n",
            " Testing bag [4/10] bag loss: 0.6910\n",
            " Testing bag [5/10] bag loss: 0.7093\n",
            " Testing bag [6/10] bag loss: 0.6849\n",
            " Testing bag [7/10] bag loss: 0.6883\n",
            " Testing bag [8/10] bag loss: 0.6914\n",
            " Testing bag [9/10] bag loss: 0.6889ROC AUC score: 0.9166666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5833333333333334\n",
            "\n",
            " Epoch [14/300] train loss: 0.6947 test loss: 0.6932, average score: 0.5000, AUC: class-0>>0.9166666666666667|class-1>>0.5|class-2>>0.5833333333333334\n",
            "Best model saved at: weights/20250626/fold_1_5.pth\n",
            "Best thresholds ===>>> class-0>>0.4918619990348816|class-1>>0.46643221378326416|class-2>>0.4883298873901367\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6870\n",
            " Training bag [1/11] bag loss: 0.6921\n",
            " Training bag [2/11] bag loss: 0.6872\n",
            " Training bag [3/11] bag loss: 0.6888\n",
            " Training bag [4/11] bag loss: 0.7101\n",
            " Training bag [5/11] bag loss: 0.7055\n",
            " Training bag [6/11] bag loss: 0.6875\n",
            " Training bag [7/11] bag loss: 0.6910\n",
            " Training bag [8/11] bag loss: 0.6882\n",
            " Training bag [9/11] bag loss: 0.6829\n",
            " Training bag [10/11] bag loss: 0.7125\n",
            " Testing bag [0/10] bag loss: 0.7074\n",
            " Testing bag [1/10] bag loss: 0.6922\n",
            " Testing bag [2/10] bag loss: 0.6872\n",
            " Testing bag [3/10] bag loss: 0.6891\n",
            " Testing bag [4/10] bag loss: 0.6916\n",
            " Testing bag [5/10] bag loss: 0.7108\n",
            " Testing bag [6/10] bag loss: 0.6848\n",
            " Testing bag [7/10] bag loss: 0.6866\n",
            " Testing bag [8/10] bag loss: 0.6894\n",
            " Testing bag [9/10] bag loss: 0.6891ROC AUC score: 0.875\n",
            "ROC AUC score: 0.4375\n",
            "ROC AUC score: 0.5833333333333334\n",
            "\n",
            " Epoch [15/300] train loss: 0.6939 test loss: 0.6928, average score: 0.4000, AUC: class-0>>0.875|class-1>>0.4375|class-2>>0.5833333333333334\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6833\n",
            " Training bag [1/11] bag loss: 0.6872\n",
            " Training bag [2/11] bag loss: 0.7102\n",
            " Training bag [3/11] bag loss: 0.6860\n",
            " Training bag [4/11] bag loss: 0.6909\n",
            " Training bag [5/11] bag loss: 0.6874\n",
            " Training bag [6/11] bag loss: 0.7057\n",
            " Training bag [7/11] bag loss: 0.7133\n",
            " Training bag [8/11] bag loss: 0.6867\n",
            " Training bag [9/11] bag loss: 0.6869\n",
            " Training bag [10/11] bag loss: 0.6922\n",
            " Testing bag [0/10] bag loss: 0.7068\n",
            " Testing bag [1/10] bag loss: 0.6903\n",
            " Testing bag [2/10] bag loss: 0.6883\n",
            " Testing bag [3/10] bag loss: 0.6883\n",
            " Testing bag [4/10] bag loss: 0.6913\n",
            " Testing bag [5/10] bag loss: 0.7105\n",
            " Testing bag [6/10] bag loss: 0.6827\n",
            " Testing bag [7/10] bag loss: 0.6874\n",
            " Testing bag [8/10] bag loss: 0.6892\n",
            " Testing bag [9/10] bag loss: 0.6886ROC AUC score: 0.875\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5833333333333334\n",
            "\n",
            " Epoch [16/300] train loss: 0.6936 test loss: 0.6923, average score: 0.4000, AUC: class-0>>0.875|class-1>>0.5|class-2>>0.5833333333333334\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6850\n",
            " Training bag [1/11] bag loss: 0.6874\n",
            " Training bag [2/11] bag loss: 0.6910\n",
            " Training bag [3/11] bag loss: 0.6894\n",
            " Training bag [4/11] bag loss: 0.7100\n",
            " Training bag [5/11] bag loss: 0.6824\n",
            " Training bag [6/11] bag loss: 0.6872\n",
            " Training bag [7/11] bag loss: 0.7123\n",
            " Training bag [8/11] bag loss: 0.7050\n",
            " Training bag [9/11] bag loss: 0.6857\n",
            " Training bag [10/11] bag loss: 0.6875\n",
            " Testing bag [0/10] bag loss: 0.7053\n",
            " Testing bag [1/10] bag loss: 0.6913\n",
            " Testing bag [2/10] bag loss: 0.6880\n",
            " Testing bag [3/10] bag loss: 0.6883\n",
            " Testing bag [4/10] bag loss: 0.6917\n",
            " Testing bag [5/10] bag loss: 0.7070\n",
            " Testing bag [6/10] bag loss: 0.6845\n",
            " Testing bag [7/10] bag loss: 0.6864\n",
            " Testing bag [8/10] bag loss: 0.6892\n",
            " Testing bag [9/10] bag loss: 0.6889ROC AUC score: 0.875\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5833333333333334\n",
            "\n",
            " Epoch [17/300] train loss: 0.6930 test loss: 0.6921, average score: 0.4000, AUC: class-0>>0.875|class-1>>0.5|class-2>>0.5833333333333334\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6859\n",
            " Training bag [1/11] bag loss: 0.6853\n",
            " Training bag [2/11] bag loss: 0.7044\n",
            " Training bag [3/11] bag loss: 0.6857\n",
            " Training bag [4/11] bag loss: 0.6892\n",
            " Training bag [5/11] bag loss: 0.7138\n",
            " Training bag [6/11] bag loss: 0.6913\n",
            " Training bag [7/11] bag loss: 0.6881\n",
            " Training bag [8/11] bag loss: 0.7099\n",
            " Training bag [9/11] bag loss: 0.6806\n",
            " Training bag [10/11] bag loss: 0.6842\n",
            " Testing bag [0/10] bag loss: 0.7077\n",
            " Testing bag [1/10] bag loss: 0.6905\n",
            " Testing bag [2/10] bag loss: 0.6861\n",
            " Testing bag [3/10] bag loss: 0.6876\n",
            " Testing bag [4/10] bag loss: 0.6912\n",
            " Testing bag [5/10] bag loss: 0.7074\n",
            " Testing bag [6/10] bag loss: 0.6820\n",
            " Testing bag [7/10] bag loss: 0.6823\n",
            " Testing bag [8/10] bag loss: 0.6890\n",
            " Testing bag [9/10] bag loss: 0.6860ROC AUC score: 0.875\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5833333333333334\n",
            "\n",
            " Epoch [18/300] train loss: 0.6926 test loss: 0.6910, average score: 0.4000, AUC: class-0>>0.875|class-1>>0.5|class-2>>0.5833333333333334\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6887\n",
            " Training bag [1/11] bag loss: 0.6856\n",
            " Training bag [2/11] bag loss: 0.6849\n",
            " Training bag [3/11] bag loss: 0.7053\n",
            " Training bag [4/11] bag loss: 0.7096\n",
            " Training bag [5/11] bag loss: 0.6853\n",
            " Training bag [6/11] bag loss: 0.7139\n",
            " Training bag [7/11] bag loss: 0.6898\n",
            " Training bag [8/11] bag loss: 0.6814\n",
            " Training bag [9/11] bag loss: 0.6838\n",
            " Training bag [10/11] bag loss: 0.6854\n",
            " Testing bag [0/10] bag loss: 0.7041\n",
            " Testing bag [1/10] bag loss: 0.6881\n",
            " Testing bag [2/10] bag loss: 0.6874\n",
            " Testing bag [3/10] bag loss: 0.6865\n",
            " Testing bag [4/10] bag loss: 0.6901\n",
            " Testing bag [5/10] bag loss: 0.7093\n",
            " Testing bag [6/10] bag loss: 0.6833\n",
            " Testing bag [7/10] bag loss: 0.6844\n",
            " Testing bag [8/10] bag loss: 0.6885\n",
            " Testing bag [9/10] bag loss: 0.6865ROC AUC score: 0.875\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5833333333333334\n",
            "\n",
            " Epoch [19/300] train loss: 0.6922 test loss: 0.6908, average score: 0.4000, AUC: class-0>>0.875|class-1>>0.5|class-2>>0.5833333333333334\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6808\n",
            " Training bag [1/11] bag loss: 0.6821\n",
            " Training bag [2/11] bag loss: 0.7075\n",
            " Training bag [3/11] bag loss: 0.6840\n",
            " Training bag [4/11] bag loss: 0.7131\n",
            " Training bag [5/11] bag loss: 0.6878\n",
            " Training bag [6/11] bag loss: 0.6843\n",
            " Training bag [7/11] bag loss: 0.6844\n",
            " Training bag [8/11] bag loss: 0.6908\n",
            " Training bag [9/11] bag loss: 0.6849\n",
            " Training bag [10/11] bag loss: 0.7044\n",
            " Testing bag [0/10] bag loss: 0.7060\n",
            " Testing bag [1/10] bag loss: 0.6883\n",
            " Testing bag [2/10] bag loss: 0.6858\n",
            " Testing bag [3/10] bag loss: 0.6865\n",
            " Testing bag [4/10] bag loss: 0.6901\n",
            " Testing bag [5/10] bag loss: 0.7100\n",
            " Testing bag [6/10] bag loss: 0.6803\n",
            " Testing bag [7/10] bag loss: 0.6848\n",
            " Testing bag [8/10] bag loss: 0.6879\n",
            " Testing bag [9/10] bag loss: 0.6850ROC AUC score: 0.875\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5833333333333334\n",
            "\n",
            " Epoch [20/300] train loss: 0.6913 test loss: 0.6905, average score: 0.4000, AUC: class-0>>0.875|class-1>>0.5|class-2>>0.5833333333333334\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6841\n",
            " Training bag [1/11] bag loss: 0.6877\n",
            " Training bag [2/11] bag loss: 0.7048\n",
            " Training bag [3/11] bag loss: 0.7092\n",
            " Training bag [4/11] bag loss: 0.6843\n",
            " Training bag [5/11] bag loss: 0.6849\n",
            " Training bag [6/11] bag loss: 0.6831\n",
            " Training bag [7/11] bag loss: 0.6796\n",
            " Training bag [8/11] bag loss: 0.6874\n",
            " Training bag [9/11] bag loss: 0.7133\n",
            " Training bag [10/11] bag loss: 0.6822\n",
            " Testing bag [0/10] bag loss: 0.7071\n",
            " Testing bag [1/10] bag loss: 0.6894\n",
            " Testing bag [2/10] bag loss: 0.6842\n",
            " Testing bag [3/10] bag loss: 0.6860\n",
            " Testing bag [4/10] bag loss: 0.6895\n",
            " Testing bag [5/10] bag loss: 0.7083\n",
            " Testing bag [6/10] bag loss: 0.6827\n",
            " Testing bag [7/10] bag loss: 0.6845\n",
            " Testing bag [8/10] bag loss: 0.6887\n",
            " Testing bag [9/10] bag loss: 0.6848ROC AUC score: 0.875\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5833333333333334\n",
            "\n",
            " Epoch [21/300] train loss: 0.6910 test loss: 0.6905, average score: 0.4000, AUC: class-0>>0.875|class-1>>0.5|class-2>>0.5833333333333334\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6828\n",
            " Training bag [1/11] bag loss: 0.7132\n",
            " Training bag [2/11] bag loss: 0.6873\n",
            " Training bag [3/11] bag loss: 0.6837\n",
            " Training bag [4/11] bag loss: 0.6820\n",
            " Training bag [5/11] bag loss: 0.6851\n",
            " Training bag [6/11] bag loss: 0.6827\n",
            " Training bag [7/11] bag loss: 0.6783\n",
            " Training bag [8/11] bag loss: 0.6872\n",
            " Training bag [9/11] bag loss: 0.7095\n",
            " Training bag [10/11] bag loss: 0.7035\n",
            " Testing bag [0/10] bag loss: 0.7065\n",
            " Testing bag [1/10] bag loss: 0.6872\n",
            " Testing bag [2/10] bag loss: 0.6850\n",
            " Testing bag [3/10] bag loss: 0.6856\n",
            " Testing bag [4/10] bag loss: 0.6874\n",
            " Testing bag [5/10] bag loss: 0.7076\n",
            " Testing bag [6/10] bag loss: 0.6800\n",
            " Testing bag [7/10] bag loss: 0.6824\n",
            " Testing bag [8/10] bag loss: 0.6876\n",
            " Testing bag [9/10] bag loss: 0.6842ROC AUC score: 0.875\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5833333333333334\n",
            "\n",
            " Epoch [22/300] train loss: 0.6905 test loss: 0.6893, average score: 0.4000, AUC: class-0>>0.875|class-1>>0.5|class-2>>0.5833333333333334\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6828\n",
            " Training bag [1/11] bag loss: 0.7085\n",
            " Training bag [2/11] bag loss: 0.6863\n",
            " Training bag [3/11] bag loss: 0.7121\n",
            " Training bag [4/11] bag loss: 0.6778\n",
            " Training bag [5/11] bag loss: 0.6884\n",
            " Training bag [6/11] bag loss: 0.6829\n",
            " Training bag [7/11] bag loss: 0.6818\n",
            " Training bag [8/11] bag loss: 0.6831\n",
            " Training bag [9/11] bag loss: 0.6820\n",
            " Training bag [10/11] bag loss: 0.7038\n",
            " Testing bag [0/10] bag loss: 0.7070\n",
            " Testing bag [1/10] bag loss: 0.6859\n",
            " Testing bag [2/10] bag loss: 0.6838\n",
            " Testing bag [3/10] bag loss: 0.6847\n",
            " Testing bag [4/10] bag loss: 0.6856\n",
            " Testing bag [5/10] bag loss: 0.7070\n",
            " Testing bag [6/10] bag loss: 0.6804\n",
            " Testing bag [7/10] bag loss: 0.6813\n",
            " Testing bag [8/10] bag loss: 0.6857\n",
            " Testing bag [9/10] bag loss: 0.6840ROC AUC score: 0.875\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5833333333333334\n",
            "\n",
            " Epoch [23/300] train loss: 0.6900 test loss: 0.6885, average score: 0.4000, AUC: class-0>>0.875|class-1>>0.5|class-2>>0.5833333333333334\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6835\n",
            " Training bag [1/11] bag loss: 0.7038\n",
            " Training bag [2/11] bag loss: 0.7084\n",
            " Training bag [3/11] bag loss: 0.6828\n",
            " Training bag [4/11] bag loss: 0.6886\n",
            " Training bag [5/11] bag loss: 0.6847\n",
            " Training bag [6/11] bag loss: 0.6804\n",
            " Training bag [7/11] bag loss: 0.7116\n",
            " Training bag [8/11] bag loss: 0.6822\n",
            " Training bag [9/11] bag loss: 0.6864\n",
            " Training bag [10/11] bag loss: 0.6779\n",
            " Testing bag [0/10] bag loss: 0.7056\n",
            " Testing bag [1/10] bag loss: 0.6873\n",
            " Testing bag [2/10] bag loss: 0.6837\n",
            " Testing bag [3/10] bag loss: 0.6853\n",
            " Testing bag [4/10] bag loss: 0.6878\n",
            " Testing bag [5/10] bag loss: 0.7076\n",
            " Testing bag [6/10] bag loss: 0.6791\n",
            " Testing bag [7/10] bag loss: 0.6829\n",
            " Testing bag [8/10] bag loss: 0.6868\n",
            " Testing bag [9/10] bag loss: 0.6851ROC AUC score: 0.875\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5833333333333334\n",
            "\n",
            " Epoch [24/300] train loss: 0.6900 test loss: 0.6891, average score: 0.4000, AUC: class-0>>0.875|class-1>>0.5|class-2>>0.5833333333333334\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7082\n",
            " Training bag [1/11] bag loss: 0.6826\n",
            " Training bag [2/11] bag loss: 0.6824\n",
            " Training bag [3/11] bag loss: 0.6813\n",
            " Training bag [4/11] bag loss: 0.6811\n",
            " Training bag [5/11] bag loss: 0.6819\n",
            " Training bag [6/11] bag loss: 0.7118\n",
            " Training bag [7/11] bag loss: 0.7034\n",
            " Training bag [8/11] bag loss: 0.6849\n",
            " Training bag [9/11] bag loss: 0.6871\n",
            " Training bag [10/11] bag loss: 0.6776\n",
            " Testing bag [0/10] bag loss: 0.7065\n",
            " Testing bag [1/10] bag loss: 0.6846\n",
            " Testing bag [2/10] bag loss: 0.6822\n",
            " Testing bag [3/10] bag loss: 0.6834\n",
            " Testing bag [4/10] bag loss: 0.6855\n",
            " Testing bag [5/10] bag loss: 0.7092\n",
            " Testing bag [6/10] bag loss: 0.6781\n",
            " Testing bag [7/10] bag loss: 0.6811\n",
            " Testing bag [8/10] bag loss: 0.6839\n",
            " Testing bag [9/10] bag loss: 0.6845ROC AUC score: 0.875\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5833333333333334\n",
            "\n",
            " Epoch [25/300] train loss: 0.6893 test loss: 0.6879, average score: 0.4000, AUC: class-0>>0.875|class-1>>0.5|class-2>>0.5833333333333334\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6794\n",
            " Training bag [1/11] bag loss: 0.7023\n",
            " Training bag [2/11] bag loss: 0.6816\n",
            " Training bag [3/11] bag loss: 0.6873\n",
            " Training bag [4/11] bag loss: 0.7086\n",
            " Training bag [5/11] bag loss: 0.6774\n",
            " Training bag [6/11] bag loss: 0.6811\n",
            " Training bag [7/11] bag loss: 0.6808\n",
            " Training bag [8/11] bag loss: 0.7116\n",
            " Training bag [9/11] bag loss: 0.6846\n",
            " Training bag [10/11] bag loss: 0.6830\n",
            " Testing bag [0/10] bag loss: 0.7046\n",
            " Testing bag [1/10] bag loss: 0.6854\n",
            " Testing bag [2/10] bag loss: 0.6823\n",
            " Testing bag [3/10] bag loss: 0.6841\n",
            " Testing bag [4/10] bag loss: 0.6851\n",
            " Testing bag [5/10] bag loss: 0.7090\n",
            " Testing bag [6/10] bag loss: 0.6778\n",
            " Testing bag [7/10] bag loss: 0.6793\n",
            " Testing bag [8/10] bag loss: 0.6838\n",
            " Testing bag [9/10] bag loss: 0.6824ROC AUC score: 0.875\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5833333333333334\n",
            "\n",
            " Epoch [26/300] train loss: 0.6889 test loss: 0.6874, average score: 0.4000, AUC: class-0>>0.875|class-1>>0.5|class-2>>0.5833333333333334\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6796\n",
            " Training bag [1/11] bag loss: 0.7035\n",
            " Training bag [2/11] bag loss: 0.6797\n",
            " Training bag [3/11] bag loss: 0.6811\n",
            " Training bag [4/11] bag loss: 0.6759\n",
            " Training bag [5/11] bag loss: 0.7073\n",
            " Training bag [6/11] bag loss: 0.6805\n",
            " Training bag [7/11] bag loss: 0.6844\n",
            " Training bag [8/11] bag loss: 0.7111\n",
            " Training bag [9/11] bag loss: 0.6836\n",
            " Training bag [10/11] bag loss: 0.6810\n",
            " Testing bag [0/10] bag loss: 0.7050\n",
            " Testing bag [1/10] bag loss: 0.6857\n",
            " Testing bag [2/10] bag loss: 0.6819\n",
            " Testing bag [3/10] bag loss: 0.6832\n",
            " Testing bag [4/10] bag loss: 0.6854\n",
            " Testing bag [5/10] bag loss: 0.7089\n",
            " Testing bag [6/10] bag loss: 0.6780\n",
            " Testing bag [7/10] bag loss: 0.6800\n",
            " Testing bag [8/10] bag loss: 0.6833\n",
            " Testing bag [9/10] bag loss: 0.6828ROC AUC score: 0.875\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5833333333333334\n",
            "\n",
            " Epoch [27/300] train loss: 0.6880 test loss: 0.6874, average score: 0.4000, AUC: class-0>>0.875|class-1>>0.5|class-2>>0.5833333333333334\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6841\n",
            " Training bag [1/11] bag loss: 0.6804\n",
            " Training bag [2/11] bag loss: 0.6796\n",
            " Training bag [3/11] bag loss: 0.6794\n",
            " Training bag [4/11] bag loss: 0.7039\n",
            " Training bag [5/11] bag loss: 0.6793\n",
            " Training bag [6/11] bag loss: 0.7125\n",
            " Training bag [7/11] bag loss: 0.6849\n",
            " Training bag [8/11] bag loss: 0.7081\n",
            " Training bag [9/11] bag loss: 0.6786\n",
            " Training bag [10/11] bag loss: 0.6754\n",
            " Testing bag [0/10] bag loss: 0.7051\n",
            " Testing bag [1/10] bag loss: 0.6854\n",
            " Testing bag [2/10] bag loss: 0.6826\n",
            " Testing bag [3/10] bag loss: 0.6829\n",
            " Testing bag [4/10] bag loss: 0.6854\n",
            " Testing bag [5/10] bag loss: 0.7088\n",
            " Testing bag [6/10] bag loss: 0.6785\n",
            " Testing bag [7/10] bag loss: 0.6794\n",
            " Testing bag [8/10] bag loss: 0.6834\n",
            " Testing bag [9/10] bag loss: 0.6823ROC AUC score: 0.875\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5833333333333334\n",
            "\n",
            " Epoch [28/300] train loss: 0.6878 test loss: 0.6874, average score: 0.4000, AUC: class-0>>0.875|class-1>>0.5|class-2>>0.5833333333333334\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6807\n",
            " Training bag [1/11] bag loss: 0.6755\n",
            " Training bag [2/11] bag loss: 0.6789\n",
            " Training bag [3/11] bag loss: 0.7031\n",
            " Training bag [4/11] bag loss: 0.6870\n",
            " Training bag [5/11] bag loss: 0.6837\n",
            " Training bag [6/11] bag loss: 0.7112\n",
            " Training bag [7/11] bag loss: 0.6799\n",
            " Training bag [8/11] bag loss: 0.6781\n",
            " Training bag [9/11] bag loss: 0.7080\n",
            " Training bag [10/11] bag loss: 0.6785\n",
            " Testing bag [0/10] bag loss: 0.7049\n",
            " Testing bag [1/10] bag loss: 0.6828\n",
            " Testing bag [2/10] bag loss: 0.6800\n",
            " Testing bag [3/10] bag loss: 0.6822\n",
            " Testing bag [4/10] bag loss: 0.6844\n",
            " Testing bag [5/10] bag loss: 0.7072\n",
            " Testing bag [6/10] bag loss: 0.6763\n",
            " Testing bag [7/10] bag loss: 0.6741\n",
            " Testing bag [8/10] bag loss: 0.6821\n",
            " Testing bag [9/10] bag loss: 0.6824ROC AUC score: 0.875\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5833333333333334\n",
            "\n",
            " Epoch [29/300] train loss: 0.6877 test loss: 0.6856, average score: 0.4000, AUC: class-0>>0.875|class-1>>0.5|class-2>>0.5833333333333334\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6791\n",
            " Training bag [1/11] bag loss: 0.6796\n",
            " Training bag [2/11] bag loss: 0.7078\n",
            " Training bag [3/11] bag loss: 0.6789\n",
            " Training bag [4/11] bag loss: 0.6736\n",
            " Training bag [5/11] bag loss: 0.6779\n",
            " Training bag [6/11] bag loss: 0.6840\n",
            " Training bag [7/11] bag loss: 0.6772\n",
            " Training bag [8/11] bag loss: 0.7117\n",
            " Training bag [9/11] bag loss: 0.7035\n",
            " Training bag [10/11] bag loss: 0.6829\n",
            " Testing bag [0/10] bag loss: 0.7051\n",
            " Testing bag [1/10] bag loss: 0.6827\n",
            " Testing bag [2/10] bag loss: 0.6791\n",
            " Testing bag [3/10] bag loss: 0.6811\n",
            " Testing bag [4/10] bag loss: 0.6836\n",
            " Testing bag [5/10] bag loss: 0.7051\n",
            " Testing bag [6/10] bag loss: 0.6772\n",
            " Testing bag [7/10] bag loss: 0.6790\n",
            " Testing bag [8/10] bag loss: 0.6843\n",
            " Testing bag [9/10] bag loss: 0.6804ROC AUC score: 0.875\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5833333333333334\n",
            "\n",
            " Epoch [30/300] train loss: 0.6869 test loss: 0.6858, average score: 0.4000, AUC: class-0>>0.875|class-1>>0.5|class-2>>0.5833333333333334\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6820\n",
            " Training bag [1/11] bag loss: 0.6805\n",
            " Training bag [2/11] bag loss: 0.6740\n",
            " Training bag [3/11] bag loss: 0.7029\n",
            " Training bag [4/11] bag loss: 0.6785\n",
            " Training bag [5/11] bag loss: 0.7076\n",
            " Training bag [6/11] bag loss: 0.7104\n",
            " Training bag [7/11] bag loss: 0.6767\n",
            " Training bag [8/11] bag loss: 0.6784\n",
            " Training bag [9/11] bag loss: 0.6779\n",
            " Training bag [10/11] bag loss: 0.6840\n",
            " Testing bag [0/10] bag loss: 0.7046\n",
            " Testing bag [1/10] bag loss: 0.6822\n",
            " Testing bag [2/10] bag loss: 0.6789\n",
            " Testing bag [3/10] bag loss: 0.6811\n",
            " Testing bag [4/10] bag loss: 0.6835\n",
            " Testing bag [5/10] bag loss: 0.7067\n",
            " Testing bag [6/10] bag loss: 0.6760\n",
            " Testing bag [7/10] bag loss: 0.6782\n",
            " Testing bag [8/10] bag loss: 0.6822\n",
            " Testing bag [9/10] bag loss: 0.6799ROC AUC score: 0.875\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5416666666666667\n",
            "\n",
            " Epoch [31/300] train loss: 0.6866 test loss: 0.6853, average score: 0.4000, AUC: class-0>>0.875|class-1>>0.5|class-2>>0.5416666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6768\n",
            " Training bag [1/11] bag loss: 0.6762\n",
            " Training bag [2/11] bag loss: 0.6834\n",
            " Training bag [3/11] bag loss: 0.7084\n",
            " Training bag [4/11] bag loss: 0.7118\n",
            " Training bag [5/11] bag loss: 0.6732\n",
            " Training bag [6/11] bag loss: 0.6778\n",
            " Training bag [7/11] bag loss: 0.6815\n",
            " Training bag [8/11] bag loss: 0.6794\n",
            " Training bag [9/11] bag loss: 0.6783\n",
            " Training bag [10/11] bag loss: 0.7027\n",
            " Testing bag [0/10] bag loss: 0.7065\n",
            " Testing bag [1/10] bag loss: 0.6816\n",
            " Testing bag [2/10] bag loss: 0.6804\n",
            " Testing bag [3/10] bag loss: 0.6807\n",
            " Testing bag [4/10] bag loss: 0.6825\n",
            " Testing bag [5/10] bag loss: 0.7069\n",
            " Testing bag [6/10] bag loss: 0.6746\n",
            " Testing bag [7/10] bag loss: 0.6764\n",
            " Testing bag [8/10] bag loss: 0.6811\n",
            " Testing bag [9/10] bag loss: 0.6808ROC AUC score: 0.875\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5833333333333334\n",
            "\n",
            " Epoch [32/300] train loss: 0.6863 test loss: 0.6852, average score: 0.4000, AUC: class-0>>0.875|class-1>>0.5|class-2>>0.5833333333333334\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6767\n",
            " Training bag [1/11] bag loss: 0.7025\n",
            " Training bag [2/11] bag loss: 0.7073\n",
            " Training bag [3/11] bag loss: 0.6725\n",
            " Training bag [4/11] bag loss: 0.6810\n",
            " Training bag [5/11] bag loss: 0.6793\n",
            " Training bag [6/11] bag loss: 0.7104\n",
            " Training bag [7/11] bag loss: 0.6775\n",
            " Training bag [8/11] bag loss: 0.6788\n",
            " Training bag [9/11] bag loss: 0.6759\n",
            " Training bag [10/11] bag loss: 0.6822\n",
            " Testing bag [0/10] bag loss: 0.7030\n",
            " Testing bag [1/10] bag loss: 0.6809\n",
            " Testing bag [2/10] bag loss: 0.6791\n",
            " Testing bag [3/10] bag loss: 0.6803\n",
            " Testing bag [4/10] bag loss: 0.6812\n",
            " Testing bag [5/10] bag loss: 0.7074\n",
            " Testing bag [6/10] bag loss: 0.6750\n",
            " Testing bag [7/10] bag loss: 0.6735\n",
            " Testing bag [8/10] bag loss: 0.6810\n",
            " Testing bag [9/10] bag loss: 0.6796ROC AUC score: 0.875\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5833333333333334\n",
            "\n",
            " Epoch [33/300] train loss: 0.6858 test loss: 0.6841, average score: 0.4000, AUC: class-0>>0.875|class-1>>0.5|class-2>>0.5833333333333334\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6807\n",
            " Training bag [1/11] bag loss: 0.6810\n",
            " Training bag [2/11] bag loss: 0.7071\n",
            " Training bag [3/11] bag loss: 0.7021\n",
            " Training bag [4/11] bag loss: 0.6770\n",
            " Training bag [5/11] bag loss: 0.6757\n",
            " Training bag [6/11] bag loss: 0.6761\n",
            " Training bag [7/11] bag loss: 0.6725\n",
            " Training bag [8/11] bag loss: 0.6765\n",
            " Training bag [9/11] bag loss: 0.7108\n",
            " Training bag [10/11] bag loss: 0.6755\n",
            " Testing bag [0/10] bag loss: 0.7030\n",
            " Testing bag [1/10] bag loss: 0.6806\n",
            " Testing bag [2/10] bag loss: 0.6773\n",
            " Testing bag [3/10] bag loss: 0.6798\n",
            " Testing bag [4/10] bag loss: 0.6796\n",
            " Testing bag [5/10] bag loss: 0.7066\n",
            " Testing bag [6/10] bag loss: 0.6730\n",
            " Testing bag [7/10] bag loss: 0.6735\n",
            " Testing bag [8/10] bag loss: 0.6803\n",
            " Testing bag [9/10] bag loss: 0.6800ROC AUC score: 0.875\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5833333333333334\n",
            "\n",
            " Epoch [34/300] train loss: 0.6850 test loss: 0.6834, average score: 0.4000, AUC: class-0>>0.875|class-1>>0.5|class-2>>0.5833333333333334\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6819\n",
            " Training bag [1/11] bag loss: 0.6761\n",
            " Training bag [2/11] bag loss: 0.7109\n",
            " Training bag [3/11] bag loss: 0.6737\n",
            " Training bag [4/11] bag loss: 0.6765\n",
            " Training bag [5/11] bag loss: 0.6747\n",
            " Training bag [6/11] bag loss: 0.7066\n",
            " Training bag [7/11] bag loss: 0.6766\n",
            " Training bag [8/11] bag loss: 0.7020\n",
            " Training bag [9/11] bag loss: 0.6718\n",
            " Training bag [10/11] bag loss: 0.6805\n",
            " Testing bag [0/10] bag loss: 0.7054\n",
            " Testing bag [1/10] bag loss: 0.6798\n",
            " Testing bag [2/10] bag loss: 0.6773\n",
            " Testing bag [3/10] bag loss: 0.6790\n",
            " Testing bag [4/10] bag loss: 0.6815\n",
            " Testing bag [5/10] bag loss: 0.7070\n",
            " Testing bag [6/10] bag loss: 0.6736\n",
            " Testing bag [7/10] bag loss: 0.6743\n",
            " Testing bag [8/10] bag loss: 0.6804\n",
            " Testing bag [9/10] bag loss: 0.6793ROC AUC score: 0.875\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5833333333333334\n",
            "\n",
            " Epoch [35/300] train loss: 0.6847 test loss: 0.6838, average score: 0.4000, AUC: class-0>>0.875|class-1>>0.5|class-2>>0.5833333333333334\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6758\n",
            " Training bag [1/11] bag loss: 0.7019\n",
            " Training bag [2/11] bag loss: 0.6750\n",
            " Training bag [3/11] bag loss: 0.6749\n",
            " Training bag [4/11] bag loss: 0.6808\n",
            " Training bag [5/11] bag loss: 0.6706\n",
            " Training bag [6/11] bag loss: 0.7113\n",
            " Training bag [7/11] bag loss: 0.7071\n",
            " Training bag [8/11] bag loss: 0.6781\n",
            " Training bag [9/11] bag loss: 0.6745\n",
            " Training bag [10/11] bag loss: 0.6805\n",
            " Testing bag [0/10] bag loss: 0.7041\n",
            " Testing bag [1/10] bag loss: 0.6793\n",
            " Testing bag [2/10] bag loss: 0.6772\n",
            " Testing bag [3/10] bag loss: 0.6788\n",
            " Testing bag [4/10] bag loss: 0.6799\n",
            " Testing bag [5/10] bag loss: 0.7070\n",
            " Testing bag [6/10] bag loss: 0.6741\n",
            " Testing bag [7/10] bag loss: 0.6739\n",
            " Testing bag [8/10] bag loss: 0.6809\n",
            " Testing bag [9/10] bag loss: 0.6790ROC AUC score: 0.875\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5833333333333334\n",
            "\n",
            " Epoch [36/300] train loss: 0.6846 test loss: 0.6834, average score: 0.4000, AUC: class-0>>0.875|class-1>>0.5|class-2>>0.5833333333333334\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7063\n",
            " Training bag [1/11] bag loss: 0.6800\n",
            " Training bag [2/11] bag loss: 0.7108\n",
            " Training bag [3/11] bag loss: 0.6795\n",
            " Training bag [4/11] bag loss: 0.6770\n",
            " Training bag [5/11] bag loss: 0.7019\n",
            " Training bag [6/11] bag loss: 0.6760\n",
            " Training bag [7/11] bag loss: 0.6732\n",
            " Training bag [8/11] bag loss: 0.6763\n",
            " Training bag [9/11] bag loss: 0.6703\n",
            " Training bag [10/11] bag loss: 0.6736\n",
            " Testing bag [0/10] bag loss: 0.7038\n",
            " Testing bag [1/10] bag loss: 0.6798\n",
            " Testing bag [2/10] bag loss: 0.6746\n",
            " Testing bag [3/10] bag loss: 0.6782\n",
            " Testing bag [4/10] bag loss: 0.6795\n",
            " Testing bag [5/10] bag loss: 0.7054\n",
            " Testing bag [6/10] bag loss: 0.6724\n",
            " Testing bag [7/10] bag loss: 0.6733\n",
            " Testing bag [8/10] bag loss: 0.6792\n",
            " Testing bag [9/10] bag loss: 0.6778ROC AUC score: 0.875\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5416666666666667\n",
            "\n",
            " Epoch [37/300] train loss: 0.6841 test loss: 0.6824, average score: 0.4000, AUC: class-0>>0.875|class-1>>0.5|class-2>>0.5416666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6789\n",
            " Training bag [1/11] bag loss: 0.6748\n",
            " Training bag [2/11] bag loss: 0.7066\n",
            " Training bag [3/11] bag loss: 0.6791\n",
            " Training bag [4/11] bag loss: 0.6706\n",
            " Training bag [5/11] bag loss: 0.6750\n",
            " Training bag [6/11] bag loss: 0.7096\n",
            " Training bag [7/11] bag loss: 0.6725\n",
            " Training bag [8/11] bag loss: 0.7015\n",
            " Training bag [9/11] bag loss: 0.6731\n",
            " Training bag [10/11] bag loss: 0.6740\n",
            " Testing bag [0/10] bag loss: 0.7037\n",
            " Testing bag [1/10] bag loss: 0.6802\n",
            " Testing bag [2/10] bag loss: 0.6755\n",
            " Testing bag [3/10] bag loss: 0.6781\n",
            " Testing bag [4/10] bag loss: 0.6804\n",
            " Testing bag [5/10] bag loss: 0.7069\n",
            " Testing bag [6/10] bag loss: 0.6726\n",
            " Testing bag [7/10] bag loss: 0.6739\n",
            " Testing bag [8/10] bag loss: 0.6782\n",
            " Testing bag [9/10] bag loss: 0.6774ROC AUC score: 0.8333333333333333\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5833333333333334\n",
            "\n",
            " Epoch [38/300] train loss: 0.6832 test loss: 0.6827, average score: 0.4000, AUC: class-0>>0.8333333333333333|class-1>>0.5|class-2>>0.5833333333333334\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7061\n",
            " Training bag [1/11] bag loss: 0.6725\n",
            " Training bag [2/11] bag loss: 0.6785\n",
            " Training bag [3/11] bag loss: 0.6760\n",
            " Training bag [4/11] bag loss: 0.6700\n",
            " Training bag [5/11] bag loss: 0.7105\n",
            " Training bag [6/11] bag loss: 0.6792\n",
            " Training bag [7/11] bag loss: 0.7008\n",
            " Training bag [8/11] bag loss: 0.6749\n",
            " Training bag [9/11] bag loss: 0.6741\n",
            " Training bag [10/11] bag loss: 0.6721\n",
            " Testing bag [0/10] bag loss: 0.7038\n",
            " Testing bag [1/10] bag loss: 0.6787\n",
            " Testing bag [2/10] bag loss: 0.6752\n",
            " Testing bag [3/10] bag loss: 0.6770\n",
            " Testing bag [4/10] bag loss: 0.6802\n",
            " Testing bag [5/10] bag loss: 0.7067\n",
            " Testing bag [6/10] bag loss: 0.6715\n",
            " Testing bag [7/10] bag loss: 0.6722\n",
            " Testing bag [8/10] bag loss: 0.6777\n",
            " Testing bag [9/10] bag loss: 0.6775ROC AUC score: 0.8333333333333333\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5416666666666667\n",
            "\n",
            " Epoch [39/300] train loss: 0.6832 test loss: 0.6820, average score: 0.3000, AUC: class-0>>0.8333333333333333|class-1>>0.5|class-2>>0.5416666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6737\n",
            " Training bag [1/11] bag loss: 0.6723\n",
            " Training bag [2/11] bag loss: 0.6688\n",
            " Training bag [3/11] bag loss: 0.6781\n",
            " Training bag [4/11] bag loss: 0.6745\n",
            " Training bag [5/11] bag loss: 0.7105\n",
            " Training bag [6/11] bag loss: 0.6785\n",
            " Training bag [7/11] bag loss: 0.6733\n",
            " Training bag [8/11] bag loss: 0.7069\n",
            " Training bag [9/11] bag loss: 0.7012\n",
            " Training bag [10/11] bag loss: 0.6717\n",
            " Testing bag [0/10] bag loss: 0.7029\n",
            " Testing bag [1/10] bag loss: 0.6786\n",
            " Testing bag [2/10] bag loss: 0.6747\n",
            " Testing bag [3/10] bag loss: 0.6771\n",
            " Testing bag [4/10] bag loss: 0.6788\n",
            " Testing bag [5/10] bag loss: 0.7075\n",
            " Testing bag [6/10] bag loss: 0.6699\n",
            " Testing bag [7/10] bag loss: 0.6710\n",
            " Testing bag [8/10] bag loss: 0.6786\n",
            " Testing bag [9/10] bag loss: 0.6764ROC AUC score: 0.8333333333333333\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5833333333333334\n",
            "\n",
            " Epoch [40/300] train loss: 0.6827 test loss: 0.6816, average score: 0.4000, AUC: class-0>>0.8333333333333333|class-1>>0.5|class-2>>0.5833333333333334\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7100\n",
            " Training bag [1/11] bag loss: 0.7062\n",
            " Training bag [2/11] bag loss: 0.6714\n",
            " Training bag [3/11] bag loss: 0.7008\n",
            " Training bag [4/11] bag loss: 0.6716\n",
            " Training bag [5/11] bag loss: 0.6735\n",
            " Training bag [6/11] bag loss: 0.6778\n",
            " Training bag [7/11] bag loss: 0.6681\n",
            " Training bag [8/11] bag loss: 0.6736\n",
            " Training bag [9/11] bag loss: 0.6748\n",
            " Training bag [10/11] bag loss: 0.6792\n",
            " Testing bag [0/10] bag loss: 0.7035\n",
            " Testing bag [1/10] bag loss: 0.6792\n",
            " Testing bag [2/10] bag loss: 0.6740\n",
            " Testing bag [3/10] bag loss: 0.6764\n",
            " Testing bag [4/10] bag loss: 0.6794\n",
            " Testing bag [5/10] bag loss: 0.7056\n",
            " Testing bag [6/10] bag loss: 0.6705\n",
            " Testing bag [7/10] bag loss: 0.6731\n",
            " Testing bag [8/10] bag loss: 0.6775\n",
            " Testing bag [9/10] bag loss: 0.6756ROC AUC score: 0.8333333333333333\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5416666666666667\n",
            "\n",
            " Epoch [41/300] train loss: 0.6825 test loss: 0.6815, average score: 0.3000, AUC: class-0>>0.8333333333333333|class-1>>0.5|class-2>>0.5416666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7096\n",
            " Training bag [1/11] bag loss: 0.6729\n",
            " Training bag [2/11] bag loss: 0.6753\n",
            " Training bag [3/11] bag loss: 0.7009\n",
            " Training bag [4/11] bag loss: 0.6673\n",
            " Training bag [5/11] bag loss: 0.6778\n",
            " Training bag [6/11] bag loss: 0.6725\n",
            " Training bag [7/11] bag loss: 0.6717\n",
            " Training bag [8/11] bag loss: 0.7060\n",
            " Training bag [9/11] bag loss: 0.6755\n",
            " Training bag [10/11] bag loss: 0.6726\n",
            " Testing bag [0/10] bag loss: 0.7020\n",
            " Testing bag [1/10] bag loss: 0.6785\n",
            " Testing bag [2/10] bag loss: 0.6745\n",
            " Testing bag [3/10] bag loss: 0.6756\n",
            " Testing bag [4/10] bag loss: 0.6760\n",
            " Testing bag [5/10] bag loss: 0.7056\n",
            " Testing bag [6/10] bag loss: 0.6709\n",
            " Testing bag [7/10] bag loss: 0.6720\n",
            " Testing bag [8/10] bag loss: 0.6787\n",
            " Testing bag [9/10] bag loss: 0.6744ROC AUC score: 0.8333333333333333\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5833333333333334\n",
            "\n",
            " Epoch [42/300] train loss: 0.6820 test loss: 0.6808, average score: 0.4000, AUC: class-0>>0.8333333333333333|class-1>>0.5|class-2>>0.5833333333333334\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7059\n",
            " Training bag [1/11] bag loss: 0.6720\n",
            " Training bag [2/11] bag loss: 0.6755\n",
            " Training bag [3/11] bag loss: 0.6670\n",
            " Training bag [4/11] bag loss: 0.6709\n",
            " Training bag [5/11] bag loss: 0.6736\n",
            " Training bag [6/11] bag loss: 0.7010\n",
            " Training bag [7/11] bag loss: 0.7095\n",
            " Training bag [8/11] bag loss: 0.6697\n",
            " Training bag [9/11] bag loss: 0.6781\n",
            " Training bag [10/11] bag loss: 0.6726\n",
            " Testing bag [0/10] bag loss: 0.7021\n",
            " Testing bag [1/10] bag loss: 0.6781\n",
            " Testing bag [2/10] bag loss: 0.6725\n",
            " Testing bag [3/10] bag loss: 0.6759\n",
            " Testing bag [4/10] bag loss: 0.6763\n",
            " Testing bag [5/10] bag loss: 0.7049\n",
            " Testing bag [6/10] bag loss: 0.6695\n",
            " Testing bag [7/10] bag loss: 0.6717\n",
            " Testing bag [8/10] bag loss: 0.6776\n",
            " Testing bag [9/10] bag loss: 0.6749ROC AUC score: 0.8333333333333333\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5416666666666666\n",
            "\n",
            " Epoch [43/300] train loss: 0.6814 test loss: 0.6803, average score: 0.4000, AUC: class-0>>0.8333333333333333|class-1>>0.5|class-2>>0.5416666666666666\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7056\n",
            " Training bag [1/11] bag loss: 0.6669\n",
            " Training bag [2/11] bag loss: 0.6766\n",
            " Training bag [3/11] bag loss: 0.6718\n",
            " Training bag [4/11] bag loss: 0.6707\n",
            " Training bag [5/11] bag loss: 0.7008\n",
            " Training bag [6/11] bag loss: 0.7101\n",
            " Training bag [7/11] bag loss: 0.6720\n",
            " Training bag [8/11] bag loss: 0.6719\n",
            " Training bag [9/11] bag loss: 0.6771\n",
            " Training bag [10/11] bag loss: 0.6698\n",
            " Testing bag [0/10] bag loss: 0.7032\n",
            " Testing bag [1/10] bag loss: 0.6759\n",
            " Testing bag [2/10] bag loss: 0.6719\n",
            " Testing bag [3/10] bag loss: 0.6750\n",
            " Testing bag [4/10] bag loss: 0.6758\n",
            " Testing bag [5/10] bag loss: 0.7061\n",
            " Testing bag [6/10] bag loss: 0.6681\n",
            " Testing bag [7/10] bag loss: 0.6709\n",
            " Testing bag [8/10] bag loss: 0.6762\n",
            " Testing bag [9/10] bag loss: 0.6739ROC AUC score: 0.8333333333333333\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5833333333333334\n",
            "\n",
            " Epoch [44/300] train loss: 0.6812 test loss: 0.6797, average score: 0.4000, AUC: class-0>>0.8333333333333333|class-1>>0.5|class-2>>0.5833333333333334\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6665\n",
            " Training bag [1/11] bag loss: 0.6693\n",
            " Training bag [2/11] bag loss: 0.7056\n",
            " Training bag [3/11] bag loss: 0.6708\n",
            " Training bag [4/11] bag loss: 0.6758\n",
            " Training bag [5/11] bag loss: 0.7097\n",
            " Training bag [6/11] bag loss: 0.6692\n",
            " Training bag [7/11] bag loss: 0.7008\n",
            " Training bag [8/11] bag loss: 0.6705\n",
            " Training bag [9/11] bag loss: 0.6732\n",
            " Training bag [10/11] bag loss: 0.6768\n",
            " Testing bag [0/10] bag loss: 0.7029\n",
            " Testing bag [1/10] bag loss: 0.6772\n",
            " Testing bag [2/10] bag loss: 0.6718\n",
            " Testing bag [3/10] bag loss: 0.6731\n",
            " Testing bag [4/10] bag loss: 0.6756\n",
            " Testing bag [5/10] bag loss: 0.7052\n",
            " Testing bag [6/10] bag loss: 0.6673\n",
            " Testing bag [7/10] bag loss: 0.6702\n",
            " Testing bag [8/10] bag loss: 0.6756\n",
            " Testing bag [9/10] bag loss: 0.6733ROC AUC score: 0.8333333333333333\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5416666666666667\n",
            "\n",
            " Epoch [45/300] train loss: 0.6807 test loss: 0.6792, average score: 0.3000, AUC: class-0>>0.8333333333333333|class-1>>0.5|class-2>>0.5416666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7058\n",
            " Training bag [1/11] bag loss: 0.6738\n",
            " Training bag [2/11] bag loss: 0.7002\n",
            " Training bag [3/11] bag loss: 0.6667\n",
            " Training bag [4/11] bag loss: 0.6693\n",
            " Training bag [5/11] bag loss: 0.6717\n",
            " Training bag [6/11] bag loss: 0.7082\n",
            " Training bag [7/11] bag loss: 0.6774\n",
            " Training bag [8/11] bag loss: 0.6688\n",
            " Training bag [9/11] bag loss: 0.6701\n",
            " Training bag [10/11] bag loss: 0.6707\n",
            " Testing bag [0/10] bag loss: 0.7028\n",
            " Testing bag [1/10] bag loss: 0.6773\n",
            " Testing bag [2/10] bag loss: 0.6714\n",
            " Testing bag [3/10] bag loss: 0.6744\n",
            " Testing bag [4/10] bag loss: 0.6753\n",
            " Testing bag [5/10] bag loss: 0.7068\n",
            " Testing bag [6/10] bag loss: 0.6673\n",
            " Testing bag [7/10] bag loss: 0.6664\n",
            " Testing bag [8/10] bag loss: 0.6743\n",
            " Testing bag [9/10] bag loss: 0.6729ROC AUC score: 0.8333333333333333\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5833333333333334\n",
            "\n",
            " Epoch [46/300] train loss: 0.6803 test loss: 0.6789, average score: 0.4000, AUC: class-0>>0.8333333333333333|class-1>>0.5|class-2>>0.5833333333333334\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6707\n",
            " Training bag [1/11] bag loss: 0.6700\n",
            " Training bag [2/11] bag loss: 0.6741\n",
            " Training bag [3/11] bag loss: 0.6693\n",
            " Training bag [4/11] bag loss: 0.7095\n",
            " Training bag [5/11] bag loss: 0.6750\n",
            " Training bag [6/11] bag loss: 0.6700\n",
            " Training bag [7/11] bag loss: 0.7005\n",
            " Training bag [8/11] bag loss: 0.6661\n",
            " Training bag [9/11] bag loss: 0.7063\n",
            " Training bag [10/11] bag loss: 0.6678\n",
            " Testing bag [0/10] bag loss: 0.7031\n",
            " Testing bag [1/10] bag loss: 0.6748\n",
            " Testing bag [2/10] bag loss: 0.6710\n",
            " Testing bag [3/10] bag loss: 0.6736\n",
            " Testing bag [4/10] bag loss: 0.6736\n",
            " Testing bag [5/10] bag loss: 0.7060\n",
            " Testing bag [6/10] bag loss: 0.6687\n",
            " Testing bag [7/10] bag loss: 0.6687\n",
            " Testing bag [8/10] bag loss: 0.6750\n",
            " Testing bag [9/10] bag loss: 0.6736ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5833333333333334\n",
            "\n",
            " Epoch [47/300] train loss: 0.6799 test loss: 0.6788, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5833333333333334\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7006\n",
            " Training bag [1/11] bag loss: 0.6686\n",
            " Training bag [2/11] bag loss: 0.7056\n",
            " Training bag [3/11] bag loss: 0.6697\n",
            " Training bag [4/11] bag loss: 0.6747\n",
            " Training bag [5/11] bag loss: 0.6700\n",
            " Training bag [6/11] bag loss: 0.6651\n",
            " Training bag [7/11] bag loss: 0.6690\n",
            " Training bag [8/11] bag loss: 0.7094\n",
            " Training bag [9/11] bag loss: 0.6704\n",
            " Training bag [10/11] bag loss: 0.6728\n",
            " Testing bag [0/10] bag loss: 0.7029\n",
            " Testing bag [1/10] bag loss: 0.6745\n",
            " Testing bag [2/10] bag loss: 0.6725\n",
            " Testing bag [3/10] bag loss: 0.6733\n",
            " Testing bag [4/10] bag loss: 0.6747\n",
            " Testing bag [5/10] bag loss: 0.7051\n",
            " Testing bag [6/10] bag loss: 0.6671\n",
            " Testing bag [7/10] bag loss: 0.6680\n",
            " Testing bag [8/10] bag loss: 0.6744\n",
            " Testing bag [9/10] bag loss: 0.6726ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [48/300] train loss: 0.6796 test loss: 0.6785, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6746\n",
            " Training bag [1/11] bag loss: 0.6684\n",
            " Training bag [2/11] bag loss: 0.6749\n",
            " Training bag [3/11] bag loss: 0.6692\n",
            " Training bag [4/11] bag loss: 0.6663\n",
            " Training bag [5/11] bag loss: 0.7061\n",
            " Training bag [6/11] bag loss: 0.6646\n",
            " Training bag [7/11] bag loss: 0.6705\n",
            " Training bag [8/11] bag loss: 0.7102\n",
            " Training bag [9/11] bag loss: 0.7005\n",
            " Training bag [10/11] bag loss: 0.6685\n",
            " Testing bag [0/10] bag loss: 0.7017\n",
            " Testing bag [1/10] bag loss: 0.6748\n",
            " Testing bag [2/10] bag loss: 0.6696\n",
            " Testing bag [3/10] bag loss: 0.6729\n",
            " Testing bag [4/10] bag loss: 0.6723\n",
            " Testing bag [5/10] bag loss: 0.7068\n",
            " Testing bag [6/10] bag loss: 0.6666\n",
            " Testing bag [7/10] bag loss: 0.6676\n",
            " Testing bag [8/10] bag loss: 0.6729\n",
            " Testing bag [9/10] bag loss: 0.6710ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [49/300] train loss: 0.6794 test loss: 0.6776, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6669\n",
            " Training bag [1/11] bag loss: 0.6692\n",
            " Training bag [2/11] bag loss: 0.6645\n",
            " Training bag [3/11] bag loss: 0.7005\n",
            " Training bag [4/11] bag loss: 0.6736\n",
            " Training bag [5/11] bag loss: 0.6698\n",
            " Training bag [6/11] bag loss: 0.6678\n",
            " Training bag [7/11] bag loss: 0.6678\n",
            " Training bag [8/11] bag loss: 0.7067\n",
            " Training bag [9/11] bag loss: 0.7092\n",
            " Training bag [10/11] bag loss: 0.6736\n",
            " Testing bag [0/10] bag loss: 0.7045\n",
            " Testing bag [1/10] bag loss: 0.6750\n",
            " Testing bag [2/10] bag loss: 0.6708\n",
            " Testing bag [3/10] bag loss: 0.6732\n",
            " Testing bag [4/10] bag loss: 0.6734\n",
            " Testing bag [5/10] bag loss: 0.7050\n",
            " Testing bag [6/10] bag loss: 0.6658\n",
            " Testing bag [7/10] bag loss: 0.6672\n",
            " Testing bag [8/10] bag loss: 0.6720\n",
            " Testing bag [9/10] bag loss: 0.6711ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5833333333333334\n",
            "\n",
            " Epoch [50/300] train loss: 0.6790 test loss: 0.6778, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5833333333333334\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6670\n",
            " Training bag [1/11] bag loss: 0.6648\n",
            " Training bag [2/11] bag loss: 0.6684\n",
            " Training bag [3/11] bag loss: 0.6662\n",
            " Training bag [4/11] bag loss: 0.6672\n",
            " Training bag [5/11] bag loss: 0.7100\n",
            " Training bag [6/11] bag loss: 0.6708\n",
            " Training bag [7/11] bag loss: 0.6728\n",
            " Training bag [8/11] bag loss: 0.6752\n",
            " Training bag [9/11] bag loss: 0.7009\n",
            " Training bag [10/11] bag loss: 0.7044\n",
            " Testing bag [0/10] bag loss: 0.7036\n",
            " Testing bag [1/10] bag loss: 0.6749\n",
            " Testing bag [2/10] bag loss: 0.6707\n",
            " Testing bag [3/10] bag loss: 0.6715\n",
            " Testing bag [4/10] bag loss: 0.6729\n",
            " Testing bag [5/10] bag loss: 0.7051\n",
            " Testing bag [6/10] bag loss: 0.6653\n",
            " Testing bag [7/10] bag loss: 0.6670\n",
            " Testing bag [8/10] bag loss: 0.6748\n",
            " Testing bag [9/10] bag loss: 0.6717ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5416666666666666\n",
            "\n",
            " Epoch [51/300] train loss: 0.6789 test loss: 0.6777, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5416666666666666\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6680\n",
            " Training bag [1/11] bag loss: 0.6718\n",
            " Training bag [2/11] bag loss: 0.7006\n",
            " Training bag [3/11] bag loss: 0.6679\n",
            " Training bag [4/11] bag loss: 0.6628\n",
            " Training bag [5/11] bag loss: 0.6671\n",
            " Training bag [6/11] bag loss: 0.7104\n",
            " Training bag [7/11] bag loss: 0.6665\n",
            " Training bag [8/11] bag loss: 0.7051\n",
            " Training bag [9/11] bag loss: 0.6753\n",
            " Training bag [10/11] bag loss: 0.6672\n",
            " Testing bag [0/10] bag loss: 0.7007\n",
            " Testing bag [1/10] bag loss: 0.6730\n",
            " Testing bag [2/10] bag loss: 0.6697\n",
            " Testing bag [3/10] bag loss: 0.6718\n",
            " Testing bag [4/10] bag loss: 0.6719\n",
            " Testing bag [5/10] bag loss: 0.7058\n",
            " Testing bag [6/10] bag loss: 0.6653\n",
            " Testing bag [7/10] bag loss: 0.6641\n",
            " Testing bag [8/10] bag loss: 0.6722\n",
            " Testing bag [9/10] bag loss: 0.6715ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5416666666666666\n",
            "\n",
            " Epoch [52/300] train loss: 0.6784 test loss: 0.6766, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5416666666666666\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6696\n",
            " Training bag [1/11] bag loss: 0.6745\n",
            " Training bag [2/11] bag loss: 0.7087\n",
            " Training bag [3/11] bag loss: 0.6719\n",
            " Training bag [4/11] bag loss: 0.6999\n",
            " Training bag [5/11] bag loss: 0.6666\n",
            " Training bag [6/11] bag loss: 0.7046\n",
            " Training bag [7/11] bag loss: 0.6650\n",
            " Training bag [8/11] bag loss: 0.6676\n",
            " Training bag [9/11] bag loss: 0.6685\n",
            " Training bag [10/11] bag loss: 0.6628\n",
            " Testing bag [0/10] bag loss: 0.7015\n",
            " Testing bag [1/10] bag loss: 0.6733\n",
            " Testing bag [2/10] bag loss: 0.6694\n",
            " Testing bag [3/10] bag loss: 0.6714\n",
            " Testing bag [4/10] bag loss: 0.6723\n",
            " Testing bag [5/10] bag loss: 0.7035\n",
            " Testing bag [6/10] bag loss: 0.6660\n",
            " Testing bag [7/10] bag loss: 0.6640\n",
            " Testing bag [8/10] bag loss: 0.6714\n",
            " Testing bag [9/10] bag loss: 0.6706ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5416666666666666\n",
            "\n",
            " Epoch [53/300] train loss: 0.6781 test loss: 0.6764, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5416666666666666\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6683\n",
            " Training bag [1/11] bag loss: 0.6709\n",
            " Training bag [2/11] bag loss: 0.7050\n",
            " Training bag [3/11] bag loss: 0.6727\n",
            " Training bag [4/11] bag loss: 0.6647\n",
            " Training bag [5/11] bag loss: 0.6633\n",
            " Training bag [6/11] bag loss: 0.6660\n",
            " Training bag [7/11] bag loss: 0.7004\n",
            " Training bag [8/11] bag loss: 0.7089\n",
            " Training bag [9/11] bag loss: 0.6676\n",
            " Training bag [10/11] bag loss: 0.6669\n",
            " Testing bag [0/10] bag loss: 0.7023\n",
            " Testing bag [1/10] bag loss: 0.6734\n",
            " Testing bag [2/10] bag loss: 0.6676\n",
            " Testing bag [3/10] bag loss: 0.6712\n",
            " Testing bag [4/10] bag loss: 0.6726\n",
            " Testing bag [5/10] bag loss: 0.7062\n",
            " Testing bag [6/10] bag loss: 0.6636\n",
            " Testing bag [7/10] bag loss: 0.6645\n",
            " Testing bag [8/10] bag loss: 0.6712\n",
            " Testing bag [9/10] bag loss: 0.6705ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5416666666666666\n",
            "\n",
            " Epoch [54/300] train loss: 0.6777 test loss: 0.6763, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5416666666666666\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6618\n",
            " Training bag [1/11] bag loss: 0.7088\n",
            " Training bag [2/11] bag loss: 0.6718\n",
            " Training bag [3/11] bag loss: 0.6650\n",
            " Training bag [4/11] bag loss: 0.6999\n",
            " Training bag [5/11] bag loss: 0.6654\n",
            " Training bag [6/11] bag loss: 0.6705\n",
            " Training bag [7/11] bag loss: 0.6683\n",
            " Training bag [8/11] bag loss: 0.7049\n",
            " Training bag [9/11] bag loss: 0.6662\n",
            " Training bag [10/11] bag loss: 0.6666\n",
            " Testing bag [0/10] bag loss: 0.7019\n",
            " Testing bag [1/10] bag loss: 0.6728\n",
            " Testing bag [2/10] bag loss: 0.6686\n",
            " Testing bag [3/10] bag loss: 0.6709\n",
            " Testing bag [4/10] bag loss: 0.6711\n",
            " Testing bag [5/10] bag loss: 0.7053\n",
            " Testing bag [6/10] bag loss: 0.6631\n",
            " Testing bag [7/10] bag loss: 0.6652\n",
            " Testing bag [8/10] bag loss: 0.6711\n",
            " Testing bag [9/10] bag loss: 0.6697ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [55/300] train loss: 0.6772 test loss: 0.6760, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6998\n",
            " Training bag [1/11] bag loss: 0.6654\n",
            " Training bag [2/11] bag loss: 0.6674\n",
            " Training bag [3/11] bag loss: 0.7046\n",
            " Training bag [4/11] bag loss: 0.6652\n",
            " Training bag [5/11] bag loss: 0.6658\n",
            " Training bag [6/11] bag loss: 0.7087\n",
            " Training bag [7/11] bag loss: 0.6638\n",
            " Training bag [8/11] bag loss: 0.6714\n",
            " Training bag [9/11] bag loss: 0.6720\n",
            " Training bag [10/11] bag loss: 0.6608\n",
            " Testing bag [0/10] bag loss: 0.7021\n",
            " Testing bag [1/10] bag loss: 0.6724\n",
            " Testing bag [2/10] bag loss: 0.6667\n",
            " Testing bag [3/10] bag loss: 0.6702\n",
            " Testing bag [4/10] bag loss: 0.6707\n",
            " Testing bag [5/10] bag loss: 0.7046\n",
            " Testing bag [6/10] bag loss: 0.6643\n",
            " Testing bag [7/10] bag loss: 0.6654\n",
            " Testing bag [8/10] bag loss: 0.6717\n",
            " Testing bag [9/10] bag loss: 0.6699ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [56/300] train loss: 0.6768 test loss: 0.6758, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6614\n",
            " Training bag [1/11] bag loss: 0.6995\n",
            " Training bag [2/11] bag loss: 0.6702\n",
            " Training bag [3/11] bag loss: 0.6651\n",
            " Training bag [4/11] bag loss: 0.6674\n",
            " Training bag [5/11] bag loss: 0.6668\n",
            " Training bag [6/11] bag loss: 0.6630\n",
            " Training bag [7/11] bag loss: 0.7092\n",
            " Training bag [8/11] bag loss: 0.6630\n",
            " Training bag [9/11] bag loss: 0.6714\n",
            " Training bag [10/11] bag loss: 0.7053\n",
            " Testing bag [0/10] bag loss: 0.7023\n",
            " Testing bag [1/10] bag loss: 0.6714\n",
            " Testing bag [2/10] bag loss: 0.6655\n",
            " Testing bag [3/10] bag loss: 0.6693\n",
            " Testing bag [4/10] bag loss: 0.6704\n",
            " Testing bag [5/10] bag loss: 0.7062\n",
            " Testing bag [6/10] bag loss: 0.6627\n",
            " Testing bag [7/10] bag loss: 0.6648\n",
            " Testing bag [8/10] bag loss: 0.6711\n",
            " Testing bag [9/10] bag loss: 0.6699ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [57/300] train loss: 0.6766 test loss: 0.6754, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6640\n",
            " Training bag [1/11] bag loss: 0.6632\n",
            " Training bag [2/11] bag loss: 0.6651\n",
            " Training bag [3/11] bag loss: 0.6650\n",
            " Training bag [4/11] bag loss: 0.7089\n",
            " Training bag [5/11] bag loss: 0.6684\n",
            " Training bag [6/11] bag loss: 0.6643\n",
            " Training bag [7/11] bag loss: 0.6998\n",
            " Training bag [8/11] bag loss: 0.7040\n",
            " Training bag [9/11] bag loss: 0.6700\n",
            " Training bag [10/11] bag loss: 0.6601\n",
            " Testing bag [0/10] bag loss: 0.7010\n",
            " Testing bag [1/10] bag loss: 0.6717\n",
            " Testing bag [2/10] bag loss: 0.6666\n",
            " Testing bag [3/10] bag loss: 0.6689\n",
            " Testing bag [4/10] bag loss: 0.6716\n",
            " Testing bag [5/10] bag loss: 0.7060\n",
            " Testing bag [6/10] bag loss: 0.6618\n",
            " Testing bag [7/10] bag loss: 0.6631\n",
            " Testing bag [8/10] bag loss: 0.6698\n",
            " Testing bag [9/10] bag loss: 0.6685ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5416666666666666\n",
            "\n",
            " Epoch [58/300] train loss: 0.6757 test loss: 0.6749, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5416666666666666\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7090\n",
            " Training bag [1/11] bag loss: 0.7045\n",
            " Training bag [2/11] bag loss: 0.6659\n",
            " Training bag [3/11] bag loss: 0.6697\n",
            " Training bag [4/11] bag loss: 0.6993\n",
            " Training bag [5/11] bag loss: 0.6635\n",
            " Training bag [6/11] bag loss: 0.6631\n",
            " Training bag [7/11] bag loss: 0.6646\n",
            " Training bag [8/11] bag loss: 0.6655\n",
            " Training bag [9/11] bag loss: 0.6599\n",
            " Training bag [10/11] bag loss: 0.6699\n",
            " Testing bag [0/10] bag loss: 0.7006\n",
            " Testing bag [1/10] bag loss: 0.6715\n",
            " Testing bag [2/10] bag loss: 0.6667\n",
            " Testing bag [3/10] bag loss: 0.6693\n",
            " Testing bag [4/10] bag loss: 0.6699\n",
            " Testing bag [5/10] bag loss: 0.7036\n",
            " Testing bag [6/10] bag loss: 0.6623\n",
            " Testing bag [7/10] bag loss: 0.6621\n",
            " Testing bag [8/10] bag loss: 0.6712\n",
            " Testing bag [9/10] bag loss: 0.6683ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [59/300] train loss: 0.6759 test loss: 0.6745, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7046\n",
            " Training bag [1/11] bag loss: 0.6689\n",
            " Training bag [2/11] bag loss: 0.6703\n",
            " Training bag [3/11] bag loss: 0.6595\n",
            " Training bag [4/11] bag loss: 0.6636\n",
            " Training bag [5/11] bag loss: 0.7074\n",
            " Training bag [6/11] bag loss: 0.6628\n",
            " Training bag [7/11] bag loss: 0.6989\n",
            " Training bag [8/11] bag loss: 0.6641\n",
            " Training bag [9/11] bag loss: 0.6642\n",
            " Training bag [10/11] bag loss: 0.6619\n",
            " Testing bag [0/10] bag loss: 0.7028\n",
            " Testing bag [1/10] bag loss: 0.6697\n",
            " Testing bag [2/10] bag loss: 0.6666\n",
            " Testing bag [3/10] bag loss: 0.6689\n",
            " Testing bag [4/10] bag loss: 0.6703\n",
            " Testing bag [5/10] bag loss: 0.7054\n",
            " Testing bag [6/10] bag loss: 0.6616\n",
            " Testing bag [7/10] bag loss: 0.6624\n",
            " Testing bag [8/10] bag loss: 0.6697\n",
            " Testing bag [9/10] bag loss: 0.6679ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5416666666666666\n",
            "\n",
            " Epoch [60/300] train loss: 0.6751 test loss: 0.6745, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5416666666666666\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7038\n",
            " Training bag [1/11] bag loss: 0.6629\n",
            " Training bag [2/11] bag loss: 0.6598\n",
            " Training bag [3/11] bag loss: 0.6637\n",
            " Training bag [4/11] bag loss: 0.6686\n",
            " Training bag [5/11] bag loss: 0.6616\n",
            " Training bag [6/11] bag loss: 0.7083\n",
            " Training bag [7/11] bag loss: 0.6703\n",
            " Training bag [8/11] bag loss: 0.6633\n",
            " Training bag [9/11] bag loss: 0.6664\n",
            " Training bag [10/11] bag loss: 0.6996\n",
            " Testing bag [0/10] bag loss: 0.7011\n",
            " Testing bag [1/10] bag loss: 0.6698\n",
            " Testing bag [2/10] bag loss: 0.6652\n",
            " Testing bag [3/10] bag loss: 0.6684\n",
            " Testing bag [4/10] bag loss: 0.6681\n",
            " Testing bag [5/10] bag loss: 0.7052\n",
            " Testing bag [6/10] bag loss: 0.6619\n",
            " Testing bag [7/10] bag loss: 0.6605\n",
            " Testing bag [8/10] bag loss: 0.6703\n",
            " Testing bag [9/10] bag loss: 0.6673ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5416666666666666\n",
            "\n",
            " Epoch [61/300] train loss: 0.6753 test loss: 0.6738, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5416666666666666\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7046\n",
            " Training bag [1/11] bag loss: 0.6640\n",
            " Training bag [2/11] bag loss: 0.6615\n",
            " Training bag [3/11] bag loss: 0.6635\n",
            " Training bag [4/11] bag loss: 0.6997\n",
            " Training bag [5/11] bag loss: 0.7079\n",
            " Training bag [6/11] bag loss: 0.6648\n",
            " Training bag [7/11] bag loss: 0.6694\n",
            " Training bag [8/11] bag loss: 0.6687\n",
            " Training bag [9/11] bag loss: 0.6629\n",
            " Training bag [10/11] bag loss: 0.6585\n",
            " Testing bag [0/10] bag loss: 0.7032\n",
            " Testing bag [1/10] bag loss: 0.6703\n",
            " Testing bag [2/10] bag loss: 0.6652\n",
            " Testing bag [3/10] bag loss: 0.6678\n",
            " Testing bag [4/10] bag loss: 0.6688\n",
            " Testing bag [5/10] bag loss: 0.7034\n",
            " Testing bag [6/10] bag loss: 0.6617\n",
            " Testing bag [7/10] bag loss: 0.6576\n",
            " Testing bag [8/10] bag loss: 0.6685\n",
            " Testing bag [9/10] bag loss: 0.6672ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5416666666666666\n",
            "\n",
            " Epoch [62/300] train loss: 0.6751 test loss: 0.6734, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5416666666666666\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6991\n",
            " Training bag [1/11] bag loss: 0.6635\n",
            " Training bag [2/11] bag loss: 0.6618\n",
            " Training bag [3/11] bag loss: 0.6645\n",
            " Training bag [4/11] bag loss: 0.6584\n",
            " Training bag [5/11] bag loss: 0.6704\n",
            " Training bag [6/11] bag loss: 0.6626\n",
            " Training bag [7/11] bag loss: 0.7041\n",
            " Training bag [8/11] bag loss: 0.6656\n",
            " Training bag [9/11] bag loss: 0.7080\n",
            " Training bag [10/11] bag loss: 0.6621\n",
            " Testing bag [0/10] bag loss: 0.7027\n",
            " Testing bag [1/10] bag loss: 0.6688\n",
            " Testing bag [2/10] bag loss: 0.6664\n",
            " Testing bag [3/10] bag loss: 0.6672\n",
            " Testing bag [4/10] bag loss: 0.6683\n",
            " Testing bag [5/10] bag loss: 0.7042\n",
            " Testing bag [6/10] bag loss: 0.6618\n",
            " Testing bag [7/10] bag loss: 0.6612\n",
            " Testing bag [8/10] bag loss: 0.6692\n",
            " Testing bag [9/10] bag loss: 0.6671ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [63/300] train loss: 0.6746 test loss: 0.6737, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6659\n",
            " Training bag [1/11] bag loss: 0.6618\n",
            " Training bag [2/11] bag loss: 0.6688\n",
            " Training bag [3/11] bag loss: 0.6998\n",
            " Training bag [4/11] bag loss: 0.6576\n",
            " Training bag [5/11] bag loss: 0.7086\n",
            " Training bag [6/11] bag loss: 0.7045\n",
            " Training bag [7/11] bag loss: 0.6636\n",
            " Training bag [8/11] bag loss: 0.6619\n",
            " Training bag [9/11] bag loss: 0.6613\n",
            " Training bag [10/11] bag loss: 0.6635\n",
            " Testing bag [0/10] bag loss: 0.7010\n",
            " Testing bag [1/10] bag loss: 0.6695\n",
            " Testing bag [2/10] bag loss: 0.6642\n",
            " Testing bag [3/10] bag loss: 0.6668\n",
            " Testing bag [4/10] bag loss: 0.6689\n",
            " Testing bag [5/10] bag loss: 0.7044\n",
            " Testing bag [6/10] bag loss: 0.6607\n",
            " Testing bag [7/10] bag loss: 0.6622\n",
            " Testing bag [8/10] bag loss: 0.6680\n",
            " Testing bag [9/10] bag loss: 0.6659ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5416666666666666\n",
            "\n",
            " Epoch [64/300] train loss: 0.6743 test loss: 0.6731, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5416666666666666\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6619\n",
            " Training bag [1/11] bag loss: 0.6566\n",
            " Training bag [2/11] bag loss: 0.6666\n",
            " Training bag [3/11] bag loss: 0.6600\n",
            " Training bag [4/11] bag loss: 0.6619\n",
            " Training bag [5/11] bag loss: 0.6606\n",
            " Training bag [6/11] bag loss: 0.6998\n",
            " Training bag [7/11] bag loss: 0.6684\n",
            " Training bag [8/11] bag loss: 0.7045\n",
            " Training bag [9/11] bag loss: 0.7087\n",
            " Training bag [10/11] bag loss: 0.6637\n",
            " Testing bag [0/10] bag loss: 0.7017\n",
            " Testing bag [1/10] bag loss: 0.6675\n",
            " Testing bag [2/10] bag loss: 0.6642\n",
            " Testing bag [3/10] bag loss: 0.6666\n",
            " Testing bag [4/10] bag loss: 0.6671\n",
            " Testing bag [5/10] bag loss: 0.7053\n",
            " Testing bag [6/10] bag loss: 0.6586\n",
            " Testing bag [7/10] bag loss: 0.6591\n",
            " Testing bag [8/10] bag loss: 0.6671\n",
            " Testing bag [9/10] bag loss: 0.6647ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5416666666666666\n",
            "\n",
            " Epoch [65/300] train loss: 0.6739 test loss: 0.6722, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5416666666666666\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7000\n",
            " Training bag [1/11] bag loss: 0.6682\n",
            " Training bag [2/11] bag loss: 0.6655\n",
            " Training bag [3/11] bag loss: 0.7089\n",
            " Training bag [4/11] bag loss: 0.6590\n",
            " Training bag [5/11] bag loss: 0.6572\n",
            " Training bag [6/11] bag loss: 0.7033\n",
            " Training bag [7/11] bag loss: 0.6625\n",
            " Training bag [8/11] bag loss: 0.6615\n",
            " Training bag [9/11] bag loss: 0.6618\n",
            " Training bag [10/11] bag loss: 0.6603\n",
            " Testing bag [0/10] bag loss: 0.7031\n",
            " Testing bag [1/10] bag loss: 0.6674\n",
            " Testing bag [2/10] bag loss: 0.6649\n",
            " Testing bag [3/10] bag loss: 0.6666\n",
            " Testing bag [4/10] bag loss: 0.6674\n",
            " Testing bag [5/10] bag loss: 0.7037\n",
            " Testing bag [6/10] bag loss: 0.6602\n",
            " Testing bag [7/10] bag loss: 0.6588\n",
            " Testing bag [8/10] bag loss: 0.6674\n",
            " Testing bag [9/10] bag loss: 0.6658ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [66/300] train loss: 0.6735 test loss: 0.6725, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6678\n",
            " Training bag [1/11] bag loss: 0.6990\n",
            " Training bag [2/11] bag loss: 0.6614\n",
            " Training bag [3/11] bag loss: 0.6620\n",
            " Training bag [4/11] bag loss: 0.6647\n",
            " Training bag [5/11] bag loss: 0.6561\n",
            " Training bag [6/11] bag loss: 0.7039\n",
            " Training bag [7/11] bag loss: 0.7082\n",
            " Training bag [8/11] bag loss: 0.6591\n",
            " Training bag [9/11] bag loss: 0.6590\n",
            " Training bag [10/11] bag loss: 0.6616\n",
            " Testing bag [0/10] bag loss: 0.7002\n",
            " Testing bag [1/10] bag loss: 0.6674\n",
            " Testing bag [2/10] bag loss: 0.6630\n",
            " Testing bag [3/10] bag loss: 0.6655\n",
            " Testing bag [4/10] bag loss: 0.6666\n",
            " Testing bag [5/10] bag loss: 0.7040\n",
            " Testing bag [6/10] bag loss: 0.6594\n",
            " Testing bag [7/10] bag loss: 0.6590\n",
            " Testing bag [8/10] bag loss: 0.6674\n",
            " Testing bag [9/10] bag loss: 0.6642ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5416666666666666\n",
            "\n",
            " Epoch [67/300] train loss: 0.6730 test loss: 0.6717, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5416666666666666\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7077\n",
            " Training bag [1/11] bag loss: 0.6602\n",
            " Training bag [2/11] bag loss: 0.6600\n",
            " Training bag [3/11] bag loss: 0.6997\n",
            " Training bag [4/11] bag loss: 0.6567\n",
            " Training bag [5/11] bag loss: 0.6611\n",
            " Training bag [6/11] bag loss: 0.6674\n",
            " Training bag [7/11] bag loss: 0.6631\n",
            " Training bag [8/11] bag loss: 0.6599\n",
            " Training bag [9/11] bag loss: 0.6678\n",
            " Training bag [10/11] bag loss: 0.7046\n",
            " Testing bag [0/10] bag loss: 0.7024\n",
            " Testing bag [1/10] bag loss: 0.6685\n",
            " Testing bag [2/10] bag loss: 0.6636\n",
            " Testing bag [3/10] bag loss: 0.6655\n",
            " Testing bag [4/10] bag loss: 0.6653\n",
            " Testing bag [5/10] bag loss: 0.7048\n",
            " Testing bag [6/10] bag loss: 0.6583\n",
            " Testing bag [7/10] bag loss: 0.6601\n",
            " Testing bag [8/10] bag loss: 0.6665\n",
            " Testing bag [9/10] bag loss: 0.6628ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [68/300] train loss: 0.6735 test loss: 0.6718, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7068\n",
            " Training bag [1/11] bag loss: 0.6628\n",
            " Training bag [2/11] bag loss: 0.6663\n",
            " Training bag [3/11] bag loss: 0.6592\n",
            " Training bag [4/11] bag loss: 0.6615\n",
            " Training bag [5/11] bag loss: 0.6657\n",
            " Training bag [6/11] bag loss: 0.6602\n",
            " Training bag [7/11] bag loss: 0.7044\n",
            " Training bag [8/11] bag loss: 0.6551\n",
            " Training bag [9/11] bag loss: 0.6586\n",
            " Training bag [10/11] bag loss: 0.6992\n",
            " Testing bag [0/10] bag loss: 0.7025\n",
            " Testing bag [1/10] bag loss: 0.6683\n",
            " Testing bag [2/10] bag loss: 0.6627\n",
            " Testing bag [3/10] bag loss: 0.6654\n",
            " Testing bag [4/10] bag loss: 0.6675\n",
            " Testing bag [5/10] bag loss: 0.7025\n",
            " Testing bag [6/10] bag loss: 0.6579\n",
            " Testing bag [7/10] bag loss: 0.6597\n",
            " Testing bag [8/10] bag loss: 0.6649\n",
            " Testing bag [9/10] bag loss: 0.6633ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5416666666666666\n",
            "\n",
            " Epoch [69/300] train loss: 0.6727 test loss: 0.6715, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5416666666666666\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6612\n",
            " Training bag [1/11] bag loss: 0.6582\n",
            " Training bag [2/11] bag loss: 0.6607\n",
            " Training bag [3/11] bag loss: 0.6647\n",
            " Training bag [4/11] bag loss: 0.7077\n",
            " Training bag [5/11] bag loss: 0.7041\n",
            " Training bag [6/11] bag loss: 0.6654\n",
            " Training bag [7/11] bag loss: 0.6985\n",
            " Training bag [8/11] bag loss: 0.6578\n",
            " Training bag [9/11] bag loss: 0.6552\n",
            " Training bag [10/11] bag loss: 0.6600\n",
            " Testing bag [0/10] bag loss: 0.7021\n",
            " Testing bag [1/10] bag loss: 0.6679\n",
            " Testing bag [2/10] bag loss: 0.6621\n",
            " Testing bag [3/10] bag loss: 0.6652\n",
            " Testing bag [4/10] bag loss: 0.6656\n",
            " Testing bag [5/10] bag loss: 0.7054\n",
            " Testing bag [6/10] bag loss: 0.6569\n",
            " Testing bag [7/10] bag loss: 0.6575\n",
            " Testing bag [8/10] bag loss: 0.6650\n",
            " Testing bag [9/10] bag loss: 0.6635ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [70/300] train loss: 0.6721 test loss: 0.6711, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6609\n",
            " Training bag [1/11] bag loss: 0.6545\n",
            " Training bag [2/11] bag loss: 0.6599\n",
            " Training bag [3/11] bag loss: 0.7084\n",
            " Training bag [4/11] bag loss: 0.6631\n",
            " Training bag [5/11] bag loss: 0.6649\n",
            " Training bag [6/11] bag loss: 0.6600\n",
            " Training bag [7/11] bag loss: 0.7046\n",
            " Training bag [8/11] bag loss: 0.6986\n",
            " Training bag [9/11] bag loss: 0.6565\n",
            " Training bag [10/11] bag loss: 0.6599\n",
            " Testing bag [0/10] bag loss: 0.7010\n",
            " Testing bag [1/10] bag loss: 0.6656\n",
            " Testing bag [2/10] bag loss: 0.6606\n",
            " Testing bag [3/10] bag loss: 0.6643\n",
            " Testing bag [4/10] bag loss: 0.6656\n",
            " Testing bag [5/10] bag loss: 0.7024\n",
            " Testing bag [6/10] bag loss: 0.6585\n",
            " Testing bag [7/10] bag loss: 0.6571\n",
            " Testing bag [8/10] bag loss: 0.6653\n",
            " Testing bag [9/10] bag loss: 0.6628ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [71/300] train loss: 0.6719 test loss: 0.6703, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6570\n",
            " Training bag [1/11] bag loss: 0.6613\n",
            " Training bag [2/11] bag loss: 0.6594\n",
            " Training bag [3/11] bag loss: 0.6645\n",
            " Training bag [4/11] bag loss: 0.7075\n",
            " Training bag [5/11] bag loss: 0.6635\n",
            " Training bag [6/11] bag loss: 0.6595\n",
            " Training bag [7/11] bag loss: 0.7044\n",
            " Training bag [8/11] bag loss: 0.6576\n",
            " Training bag [9/11] bag loss: 0.6993\n",
            " Training bag [10/11] bag loss: 0.6542\n",
            " Testing bag [0/10] bag loss: 0.6991\n",
            " Testing bag [1/10] bag loss: 0.6671\n",
            " Testing bag [2/10] bag loss: 0.6609\n",
            " Testing bag [3/10] bag loss: 0.6645\n",
            " Testing bag [4/10] bag loss: 0.6663\n",
            " Testing bag [5/10] bag loss: 0.7045\n",
            " Testing bag [6/10] bag loss: 0.6567\n",
            " Testing bag [7/10] bag loss: 0.6557\n",
            " Testing bag [8/10] bag loss: 0.6654\n",
            " Testing bag [9/10] bag loss: 0.6635ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [72/300] train loss: 0.6717 test loss: 0.6704, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6982\n",
            " Training bag [1/11] bag loss: 0.6649\n",
            " Training bag [2/11] bag loss: 0.6563\n",
            " Training bag [3/11] bag loss: 0.6542\n",
            " Training bag [4/11] bag loss: 0.6590\n",
            " Training bag [5/11] bag loss: 0.6671\n",
            " Training bag [6/11] bag loss: 0.6571\n",
            " Training bag [7/11] bag loss: 0.6606\n",
            " Training bag [8/11] bag loss: 0.6584\n",
            " Training bag [9/11] bag loss: 0.7043\n",
            " Training bag [10/11] bag loss: 0.7088\n",
            " Testing bag [0/10] bag loss: 0.6997\n",
            " Testing bag [1/10] bag loss: 0.6665\n",
            " Testing bag [2/10] bag loss: 0.6622\n",
            " Testing bag [3/10] bag loss: 0.6636\n",
            " Testing bag [4/10] bag loss: 0.6629\n",
            " Testing bag [5/10] bag loss: 0.7041\n",
            " Testing bag [6/10] bag loss: 0.6572\n",
            " Testing bag [7/10] bag loss: 0.6571\n",
            " Testing bag [8/10] bag loss: 0.6639\n",
            " Testing bag [9/10] bag loss: 0.6632ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [73/300] train loss: 0.6717 test loss: 0.6701, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7080\n",
            " Training bag [1/11] bag loss: 0.6574\n",
            " Training bag [2/11] bag loss: 0.6547\n",
            " Training bag [3/11] bag loss: 0.6584\n",
            " Training bag [4/11] bag loss: 0.6659\n",
            " Training bag [5/11] bag loss: 0.6988\n",
            " Training bag [6/11] bag loss: 0.7038\n",
            " Training bag [7/11] bag loss: 0.6590\n",
            " Training bag [8/11] bag loss: 0.6611\n",
            " Training bag [9/11] bag loss: 0.6568\n",
            " Training bag [10/11] bag loss: 0.6645\n",
            " Testing bag [0/10] bag loss: 0.6997\n",
            " Testing bag [1/10] bag loss: 0.6667\n",
            " Testing bag [2/10] bag loss: 0.6605\n",
            " Testing bag [3/10] bag loss: 0.6638\n",
            " Testing bag [4/10] bag loss: 0.6658\n",
            " Testing bag [5/10] bag loss: 0.7051\n",
            " Testing bag [6/10] bag loss: 0.6558\n",
            " Testing bag [7/10] bag loss: 0.6558\n",
            " Testing bag [8/10] bag loss: 0.6646\n",
            " Testing bag [9/10] bag loss: 0.6615ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5416666666666666\n",
            "\n",
            " Epoch [74/300] train loss: 0.6717 test loss: 0.6699, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5416666666666666\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6567\n",
            " Training bag [1/11] bag loss: 0.6650\n",
            " Training bag [2/11] bag loss: 0.6575\n",
            " Training bag [3/11] bag loss: 0.6615\n",
            " Training bag [4/11] bag loss: 0.7047\n",
            " Training bag [5/11] bag loss: 0.6592\n",
            " Training bag [6/11] bag loss: 0.6524\n",
            " Training bag [7/11] bag loss: 0.6564\n",
            " Training bag [8/11] bag loss: 0.6995\n",
            " Training bag [9/11] bag loss: 0.6604\n",
            " Training bag [10/11] bag loss: 0.7085\n",
            " Testing bag [0/10] bag loss: 0.7022\n",
            " Testing bag [1/10] bag loss: 0.6651\n",
            " Testing bag [2/10] bag loss: 0.6603\n",
            " Testing bag [3/10] bag loss: 0.6629\n",
            " Testing bag [4/10] bag loss: 0.6637\n",
            " Testing bag [5/10] bag loss: 0.7047\n",
            " Testing bag [6/10] bag loss: 0.6559\n",
            " Testing bag [7/10] bag loss: 0.6563\n",
            " Testing bag [8/10] bag loss: 0.6645\n",
            " Testing bag [9/10] bag loss: 0.6625ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [75/300] train loss: 0.6711 test loss: 0.6698, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6634\n",
            " Training bag [1/11] bag loss: 0.6648\n",
            " Training bag [2/11] bag loss: 0.7035\n",
            " Training bag [3/11] bag loss: 0.7086\n",
            " Training bag [4/11] bag loss: 0.6524\n",
            " Training bag [5/11] bag loss: 0.6566\n",
            " Training bag [6/11] bag loss: 0.6575\n",
            " Training bag [7/11] bag loss: 0.6993\n",
            " Training bag [8/11] bag loss: 0.6548\n",
            " Training bag [9/11] bag loss: 0.6580\n",
            " Training bag [10/11] bag loss: 0.6568\n",
            " Testing bag [0/10] bag loss: 0.7020\n",
            " Testing bag [1/10] bag loss: 0.6656\n",
            " Testing bag [2/10] bag loss: 0.6591\n",
            " Testing bag [3/10] bag loss: 0.6626\n",
            " Testing bag [4/10] bag loss: 0.6637\n",
            " Testing bag [5/10] bag loss: 0.7035\n",
            " Testing bag [6/10] bag loss: 0.6570\n",
            " Testing bag [7/10] bag loss: 0.6537\n",
            " Testing bag [8/10] bag loss: 0.6637\n",
            " Testing bag [9/10] bag loss: 0.6609ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [76/300] train loss: 0.6705 test loss: 0.6692, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6525\n",
            " Training bag [1/11] bag loss: 0.6991\n",
            " Training bag [2/11] bag loss: 0.6572\n",
            " Training bag [3/11] bag loss: 0.6575\n",
            " Training bag [4/11] bag loss: 0.7037\n",
            " Training bag [5/11] bag loss: 0.7064\n",
            " Training bag [6/11] bag loss: 0.6639\n",
            " Training bag [7/11] bag loss: 0.6551\n",
            " Training bag [8/11] bag loss: 0.6602\n",
            " Training bag [9/11] bag loss: 0.6625\n",
            " Training bag [10/11] bag loss: 0.6567\n",
            " Testing bag [0/10] bag loss: 0.7026\n",
            " Testing bag [1/10] bag loss: 0.6656\n",
            " Testing bag [2/10] bag loss: 0.6614\n",
            " Testing bag [3/10] bag loss: 0.6630\n",
            " Testing bag [4/10] bag loss: 0.6630\n",
            " Testing bag [5/10] bag loss: 0.7042\n",
            " Testing bag [6/10] bag loss: 0.6546\n",
            " Testing bag [7/10] bag loss: 0.6552\n",
            " Testing bag [8/10] bag loss: 0.6625\n",
            " Testing bag [9/10] bag loss: 0.6611ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [77/300] train loss: 0.6704 test loss: 0.6693, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6546\n",
            " Training bag [1/11] bag loss: 0.7037\n",
            " Training bag [2/11] bag loss: 0.6638\n",
            " Training bag [3/11] bag loss: 0.6574\n",
            " Training bag [4/11] bag loss: 0.6565\n",
            " Training bag [5/11] bag loss: 0.6606\n",
            " Training bag [6/11] bag loss: 0.6583\n",
            " Training bag [7/11] bag loss: 0.7073\n",
            " Training bag [8/11] bag loss: 0.6571\n",
            " Training bag [9/11] bag loss: 0.6521\n",
            " Training bag [10/11] bag loss: 0.6988\n",
            " Testing bag [0/10] bag loss: 0.7012\n",
            " Testing bag [1/10] bag loss: 0.6647\n",
            " Testing bag [2/10] bag loss: 0.6594\n",
            " Testing bag [3/10] bag loss: 0.6627\n",
            " Testing bag [4/10] bag loss: 0.6628\n",
            " Testing bag [5/10] bag loss: 0.7020\n",
            " Testing bag [6/10] bag loss: 0.6551\n",
            " Testing bag [7/10] bag loss: 0.6534\n",
            " Testing bag [8/10] bag loss: 0.6621\n",
            " Testing bag [9/10] bag loss: 0.6623ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5416666666666666\n",
            "\n",
            " Epoch [78/300] train loss: 0.6700 test loss: 0.6686, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5416666666666666\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6567\n",
            " Training bag [1/11] bag loss: 0.6546\n",
            " Training bag [2/11] bag loss: 0.6582\n",
            " Training bag [3/11] bag loss: 0.6562\n",
            " Training bag [4/11] bag loss: 0.6522\n",
            " Training bag [5/11] bag loss: 0.6615\n",
            " Training bag [6/11] bag loss: 0.7073\n",
            " Training bag [7/11] bag loss: 0.6639\n",
            " Training bag [8/11] bag loss: 0.6536\n",
            " Training bag [9/11] bag loss: 0.7040\n",
            " Training bag [10/11] bag loss: 0.6981\n",
            " Testing bag [0/10] bag loss: 0.7013\n",
            " Testing bag [1/10] bag loss: 0.6634\n",
            " Testing bag [2/10] bag loss: 0.6577\n",
            " Testing bag [3/10] bag loss: 0.6617\n",
            " Testing bag [4/10] bag loss: 0.6634\n",
            " Testing bag [5/10] bag loss: 0.7045\n",
            " Testing bag [6/10] bag loss: 0.6549\n",
            " Testing bag [7/10] bag loss: 0.6540\n",
            " Testing bag [8/10] bag loss: 0.6624\n",
            " Testing bag [9/10] bag loss: 0.6610ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [79/300] train loss: 0.6696 test loss: 0.6684, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7080\n",
            " Training bag [1/11] bag loss: 0.6547\n",
            " Training bag [2/11] bag loss: 0.6512\n",
            " Training bag [3/11] bag loss: 0.6635\n",
            " Training bag [4/11] bag loss: 0.6560\n",
            " Training bag [5/11] bag loss: 0.6580\n",
            " Training bag [6/11] bag loss: 0.6987\n",
            " Training bag [7/11] bag loss: 0.7031\n",
            " Training bag [8/11] bag loss: 0.6560\n",
            " Training bag [9/11] bag loss: 0.6597\n",
            " Training bag [10/11] bag loss: 0.6577\n",
            " Testing bag [0/10] bag loss: 0.6997\n",
            " Testing bag [1/10] bag loss: 0.6635\n",
            " Testing bag [2/10] bag loss: 0.6600\n",
            " Testing bag [3/10] bag loss: 0.6621\n",
            " Testing bag [4/10] bag loss: 0.6637\n",
            " Testing bag [5/10] bag loss: 0.7032\n",
            " Testing bag [6/10] bag loss: 0.6557\n",
            " Testing bag [7/10] bag loss: 0.6536\n",
            " Testing bag [8/10] bag loss: 0.6634\n",
            " Testing bag [9/10] bag loss: 0.6614ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [80/300] train loss: 0.6697 test loss: 0.6686, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6615\n",
            " Training bag [1/11] bag loss: 0.7017\n",
            " Training bag [2/11] bag loss: 0.6987\n",
            " Training bag [3/11] bag loss: 0.7067\n",
            " Training bag [4/11] bag loss: 0.6555\n",
            " Training bag [5/11] bag loss: 0.6613\n",
            " Training bag [6/11] bag loss: 0.6534\n",
            " Training bag [7/11] bag loss: 0.6513\n",
            " Training bag [8/11] bag loss: 0.6572\n",
            " Training bag [9/11] bag loss: 0.6568\n",
            " Training bag [10/11] bag loss: 0.6560\n",
            " Testing bag [0/10] bag loss: 0.7014\n",
            " Testing bag [1/10] bag loss: 0.6639\n",
            " Testing bag [2/10] bag loss: 0.6598\n",
            " Testing bag [3/10] bag loss: 0.6618\n",
            " Testing bag [4/10] bag loss: 0.6628\n",
            " Testing bag [5/10] bag loss: 0.7042\n",
            " Testing bag [6/10] bag loss: 0.6536\n",
            " Testing bag [7/10] bag loss: 0.6533\n",
            " Testing bag [8/10] bag loss: 0.6622\n",
            " Testing bag [9/10] bag loss: 0.6597ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [81/300] train loss: 0.6691 test loss: 0.6683, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6531\n",
            " Training bag [1/11] bag loss: 0.6557\n",
            " Training bag [2/11] bag loss: 0.6546\n",
            " Training bag [3/11] bag loss: 0.6615\n",
            " Training bag [4/11] bag loss: 0.7074\n",
            " Training bag [5/11] bag loss: 0.7037\n",
            " Training bag [6/11] bag loss: 0.6542\n",
            " Training bag [7/11] bag loss: 0.6577\n",
            " Training bag [8/11] bag loss: 0.6982\n",
            " Training bag [9/11] bag loss: 0.6617\n",
            " Training bag [10/11] bag loss: 0.6509\n",
            " Testing bag [0/10] bag loss: 0.7023\n",
            " Testing bag [1/10] bag loss: 0.6638\n",
            " Testing bag [2/10] bag loss: 0.6592\n",
            " Testing bag [3/10] bag loss: 0.6610\n",
            " Testing bag [4/10] bag loss: 0.6625\n",
            " Testing bag [5/10] bag loss: 0.7024\n",
            " Testing bag [6/10] bag loss: 0.6537\n",
            " Testing bag [7/10] bag loss: 0.6530\n",
            " Testing bag [8/10] bag loss: 0.6615\n",
            " Testing bag [9/10] bag loss: 0.6602ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [82/300] train loss: 0.6690 test loss: 0.6680, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6514\n",
            " Training bag [1/11] bag loss: 0.6553\n",
            " Training bag [2/11] bag loss: 0.6626\n",
            " Training bag [3/11] bag loss: 0.6599\n",
            " Training bag [4/11] bag loss: 0.6991\n",
            " Training bag [5/11] bag loss: 0.6538\n",
            " Training bag [6/11] bag loss: 0.6551\n",
            " Training bag [7/11] bag loss: 0.6568\n",
            " Training bag [8/11] bag loss: 0.7078\n",
            " Training bag [9/11] bag loss: 0.7033\n",
            " Training bag [10/11] bag loss: 0.6529\n",
            " Testing bag [0/10] bag loss: 0.7001\n",
            " Testing bag [1/10] bag loss: 0.6619\n",
            " Testing bag [2/10] bag loss: 0.6589\n",
            " Testing bag [3/10] bag loss: 0.6610\n",
            " Testing bag [4/10] bag loss: 0.6624\n",
            " Testing bag [5/10] bag loss: 0.7043\n",
            " Testing bag [6/10] bag loss: 0.6526\n",
            " Testing bag [7/10] bag loss: 0.6537\n",
            " Testing bag [8/10] bag loss: 0.6621\n",
            " Testing bag [9/10] bag loss: 0.6595ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [83/300] train loss: 0.6689 test loss: 0.6677, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7082\n",
            " Training bag [1/11] bag loss: 0.7030\n",
            " Training bag [2/11] bag loss: 0.6983\n",
            " Training bag [3/11] bag loss: 0.6546\n",
            " Training bag [4/11] bag loss: 0.6524\n",
            " Training bag [5/11] bag loss: 0.6623\n",
            " Training bag [6/11] bag loss: 0.6498\n",
            " Training bag [7/11] bag loss: 0.6545\n",
            " Training bag [8/11] bag loss: 0.6553\n",
            " Training bag [9/11] bag loss: 0.6607\n",
            " Training bag [10/11] bag loss: 0.6562\n",
            " Testing bag [0/10] bag loss: 0.7005\n",
            " Testing bag [1/10] bag loss: 0.6630\n",
            " Testing bag [2/10] bag loss: 0.6575\n",
            " Testing bag [3/10] bag loss: 0.6608\n",
            " Testing bag [4/10] bag loss: 0.6609\n",
            " Testing bag [5/10] bag loss: 0.7033\n",
            " Testing bag [6/10] bag loss: 0.6532\n",
            " Testing bag [7/10] bag loss: 0.6517\n",
            " Testing bag [8/10] bag loss: 0.6623\n",
            " Testing bag [9/10] bag loss: 0.6593ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5416666666666666\n",
            "\n",
            " Epoch [84/300] train loss: 0.6687 test loss: 0.6672, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5416666666666666\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6583\n",
            " Training bag [1/11] bag loss: 0.6541\n",
            " Training bag [2/11] bag loss: 0.6499\n",
            " Training bag [3/11] bag loss: 0.6518\n",
            " Training bag [4/11] bag loss: 0.7033\n",
            " Training bag [5/11] bag loss: 0.6533\n",
            " Training bag [6/11] bag loss: 0.6543\n",
            " Training bag [7/11] bag loss: 0.6984\n",
            " Training bag [8/11] bag loss: 0.6546\n",
            " Training bag [9/11] bag loss: 0.7069\n",
            " Training bag [10/11] bag loss: 0.6618\n",
            " Testing bag [0/10] bag loss: 0.7008\n",
            " Testing bag [1/10] bag loss: 0.6630\n",
            " Testing bag [2/10] bag loss: 0.6572\n",
            " Testing bag [3/10] bag loss: 0.6604\n",
            " Testing bag [4/10] bag loss: 0.6621\n",
            " Testing bag [5/10] bag loss: 0.7034\n",
            " Testing bag [6/10] bag loss: 0.6540\n",
            " Testing bag [7/10] bag loss: 0.6534\n",
            " Testing bag [8/10] bag loss: 0.6605\n",
            " Testing bag [9/10] bag loss: 0.6579ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5416666666666666\n",
            "\n",
            " Epoch [85/300] train loss: 0.6679 test loss: 0.6672, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5416666666666666\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6535\n",
            " Training bag [1/11] bag loss: 0.7064\n",
            " Training bag [2/11] bag loss: 0.6597\n",
            " Training bag [3/11] bag loss: 0.6990\n",
            " Training bag [4/11] bag loss: 0.7033\n",
            " Training bag [5/11] bag loss: 0.6548\n",
            " Training bag [6/11] bag loss: 0.6547\n",
            " Training bag [7/11] bag loss: 0.6630\n",
            " Training bag [8/11] bag loss: 0.6542\n",
            " Training bag [9/11] bag loss: 0.6514\n",
            " Training bag [10/11] bag loss: 0.6497\n",
            " Testing bag [0/10] bag loss: 0.7004\n",
            " Testing bag [1/10] bag loss: 0.6625\n",
            " Testing bag [2/10] bag loss: 0.6583\n",
            " Testing bag [3/10] bag loss: 0.6598\n",
            " Testing bag [4/10] bag loss: 0.6612\n",
            " Testing bag [5/10] bag loss: 0.7036\n",
            " Testing bag [6/10] bag loss: 0.6532\n",
            " Testing bag [7/10] bag loss: 0.6515\n",
            " Testing bag [8/10] bag loss: 0.6605\n",
            " Testing bag [9/10] bag loss: 0.6578ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [86/300] train loss: 0.6682 test loss: 0.6669, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6532\n",
            " Training bag [1/11] bag loss: 0.6594\n",
            " Training bag [2/11] bag loss: 0.6548\n",
            " Training bag [3/11] bag loss: 0.6990\n",
            " Training bag [4/11] bag loss: 0.7035\n",
            " Training bag [5/11] bag loss: 0.6608\n",
            " Training bag [6/11] bag loss: 0.7070\n",
            " Training bag [7/11] bag loss: 0.6489\n",
            " Training bag [8/11] bag loss: 0.6509\n",
            " Training bag [9/11] bag loss: 0.6543\n",
            " Training bag [10/11] bag loss: 0.6526\n",
            " Testing bag [0/10] bag loss: 0.7006\n",
            " Testing bag [1/10] bag loss: 0.6614\n",
            " Testing bag [2/10] bag loss: 0.6565\n",
            " Testing bag [3/10] bag loss: 0.6597\n",
            " Testing bag [4/10] bag loss: 0.6612\n",
            " Testing bag [5/10] bag loss: 0.7032\n",
            " Testing bag [6/10] bag loss: 0.6529\n",
            " Testing bag [7/10] bag loss: 0.6483\n",
            " Testing bag [8/10] bag loss: 0.6595\n",
            " Testing bag [9/10] bag loss: 0.6586ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5416666666666666\n",
            "\n",
            " Epoch [87/300] train loss: 0.6677 test loss: 0.6662, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5416666666666666\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6543\n",
            " Training bag [1/11] bag loss: 0.6988\n",
            " Training bag [2/11] bag loss: 0.6510\n",
            " Training bag [3/11] bag loss: 0.6540\n",
            " Training bag [4/11] bag loss: 0.7077\n",
            " Training bag [5/11] bag loss: 0.6605\n",
            " Training bag [6/11] bag loss: 0.6485\n",
            " Training bag [7/11] bag loss: 0.6584\n",
            " Training bag [8/11] bag loss: 0.6531\n",
            " Training bag [9/11] bag loss: 0.6541\n",
            " Training bag [10/11] bag loss: 0.7031\n",
            " Testing bag [0/10] bag loss: 0.7006\n",
            " Testing bag [1/10] bag loss: 0.6604\n",
            " Testing bag [2/10] bag loss: 0.6575\n",
            " Testing bag [3/10] bag loss: 0.6596\n",
            " Testing bag [4/10] bag loss: 0.6605\n",
            " Testing bag [5/10] bag loss: 0.7035\n",
            " Testing bag [6/10] bag loss: 0.6514\n",
            " Testing bag [7/10] bag loss: 0.6491\n",
            " Testing bag [8/10] bag loss: 0.6593\n",
            " Testing bag [9/10] bag loss: 0.6588ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [88/300] train loss: 0.6676 test loss: 0.6661, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6979\n",
            " Training bag [1/11] bag loss: 0.6531\n",
            " Training bag [2/11] bag loss: 0.6521\n",
            " Training bag [3/11] bag loss: 0.7076\n",
            " Training bag [4/11] bag loss: 0.6513\n",
            " Training bag [5/11] bag loss: 0.6573\n",
            " Training bag [6/11] bag loss: 0.6549\n",
            " Training bag [7/11] bag loss: 0.6534\n",
            " Training bag [8/11] bag loss: 0.7029\n",
            " Training bag [9/11] bag loss: 0.6477\n",
            " Training bag [10/11] bag loss: 0.6613\n",
            " Testing bag [0/10] bag loss: 0.7003\n",
            " Testing bag [1/10] bag loss: 0.6616\n",
            " Testing bag [2/10] bag loss: 0.6555\n",
            " Testing bag [3/10] bag loss: 0.6595\n",
            " Testing bag [4/10] bag loss: 0.6609\n",
            " Testing bag [5/10] bag loss: 0.7039\n",
            " Testing bag [6/10] bag loss: 0.6519\n",
            " Testing bag [7/10] bag loss: 0.6515\n",
            " Testing bag [8/10] bag loss: 0.6595\n",
            " Testing bag [9/10] bag loss: 0.6566ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [89/300] train loss: 0.6672 test loss: 0.6661, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6545\n",
            " Training bag [1/11] bag loss: 0.7031\n",
            " Training bag [2/11] bag loss: 0.6532\n",
            " Training bag [3/11] bag loss: 0.6600\n",
            " Training bag [4/11] bag loss: 0.6521\n",
            " Training bag [5/11] bag loss: 0.6505\n",
            " Training bag [6/11] bag loss: 0.6566\n",
            " Training bag [7/11] bag loss: 0.6476\n",
            " Training bag [8/11] bag loss: 0.6984\n",
            " Training bag [9/11] bag loss: 0.6524\n",
            " Training bag [10/11] bag loss: 0.7067\n",
            " Testing bag [0/10] bag loss: 0.7008\n",
            " Testing bag [1/10] bag loss: 0.6614\n",
            " Testing bag [2/10] bag loss: 0.6561\n",
            " Testing bag [3/10] bag loss: 0.6589\n",
            " Testing bag [4/10] bag loss: 0.6601\n",
            " Testing bag [5/10] bag loss: 0.7050\n",
            " Testing bag [6/10] bag loss: 0.6525\n",
            " Testing bag [7/10] bag loss: 0.6517\n",
            " Testing bag [8/10] bag loss: 0.6592\n",
            " Testing bag [9/10] bag loss: 0.6574ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [90/300] train loss: 0.6668 test loss: 0.6663, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6507\n",
            " Training bag [1/11] bag loss: 0.6987\n",
            " Training bag [2/11] bag loss: 0.6524\n",
            " Training bag [3/11] bag loss: 0.6532\n",
            " Training bag [4/11] bag loss: 0.7055\n",
            " Training bag [5/11] bag loss: 0.6508\n",
            " Training bag [6/11] bag loss: 0.7032\n",
            " Training bag [7/11] bag loss: 0.6607\n",
            " Training bag [8/11] bag loss: 0.6577\n",
            " Training bag [9/11] bag loss: 0.6534\n",
            " Training bag [10/11] bag loss: 0.6483\n",
            " Testing bag [0/10] bag loss: 0.7017\n",
            " Testing bag [1/10] bag loss: 0.6614\n",
            " Testing bag [2/10] bag loss: 0.6558\n",
            " Testing bag [3/10] bag loss: 0.6588\n",
            " Testing bag [4/10] bag loss: 0.6585\n",
            " Testing bag [5/10] bag loss: 0.7040\n",
            " Testing bag [6/10] bag loss: 0.6509\n",
            " Testing bag [7/10] bag loss: 0.6503\n",
            " Testing bag [8/10] bag loss: 0.6586\n",
            " Testing bag [9/10] bag loss: 0.6572ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [91/300] train loss: 0.6668 test loss: 0.6657, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7029\n",
            " Training bag [1/11] bag loss: 0.6485\n",
            " Training bag [2/11] bag loss: 0.6516\n",
            " Training bag [3/11] bag loss: 0.6513\n",
            " Training bag [4/11] bag loss: 0.7063\n",
            " Training bag [5/11] bag loss: 0.6519\n",
            " Training bag [6/11] bag loss: 0.6979\n",
            " Training bag [7/11] bag loss: 0.6568\n",
            " Training bag [8/11] bag loss: 0.6500\n",
            " Training bag [9/11] bag loss: 0.6553\n",
            " Training bag [10/11] bag loss: 0.6597\n",
            " Testing bag [0/10] bag loss: 0.6990\n",
            " Testing bag [1/10] bag loss: 0.6614\n",
            " Testing bag [2/10] bag loss: 0.6546\n",
            " Testing bag [3/10] bag loss: 0.6579\n",
            " Testing bag [4/10] bag loss: 0.6598\n",
            " Testing bag [5/10] bag loss: 0.7048\n",
            " Testing bag [6/10] bag loss: 0.6498\n",
            " Testing bag [7/10] bag loss: 0.6493\n",
            " Testing bag [8/10] bag loss: 0.6580\n",
            " Testing bag [9/10] bag loss: 0.6561ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [92/300] train loss: 0.6666 test loss: 0.6651, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6520\n",
            " Training bag [1/11] bag loss: 0.6490\n",
            " Training bag [2/11] bag loss: 0.6581\n",
            " Training bag [3/11] bag loss: 0.6524\n",
            " Training bag [4/11] bag loss: 0.7072\n",
            " Training bag [5/11] bag loss: 0.6473\n",
            " Training bag [6/11] bag loss: 0.6988\n",
            " Training bag [7/11] bag loss: 0.6509\n",
            " Training bag [8/11] bag loss: 0.7037\n",
            " Training bag [9/11] bag loss: 0.6552\n",
            " Training bag [10/11] bag loss: 0.6506\n",
            " Testing bag [0/10] bag loss: 0.7012\n",
            " Testing bag [1/10] bag loss: 0.6601\n",
            " Testing bag [2/10] bag loss: 0.6540\n",
            " Testing bag [3/10] bag loss: 0.6582\n",
            " Testing bag [4/10] bag loss: 0.6596\n",
            " Testing bag [5/10] bag loss: 0.7043\n",
            " Testing bag [6/10] bag loss: 0.6497\n",
            " Testing bag [7/10] bag loss: 0.6497\n",
            " Testing bag [8/10] bag loss: 0.6580\n",
            " Testing bag [9/10] bag loss: 0.6566ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [93/300] train loss: 0.6659 test loss: 0.6651, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6564\n",
            " Training bag [1/11] bag loss: 0.6524\n",
            " Training bag [2/11] bag loss: 0.6458\n",
            " Training bag [3/11] bag loss: 0.6486\n",
            " Training bag [4/11] bag loss: 0.6520\n",
            " Training bag [5/11] bag loss: 0.7073\n",
            " Training bag [6/11] bag loss: 0.6499\n",
            " Training bag [7/11] bag loss: 0.6506\n",
            " Training bag [8/11] bag loss: 0.6589\n",
            " Training bag [9/11] bag loss: 0.7035\n",
            " Training bag [10/11] bag loss: 0.6980\n",
            " Testing bag [0/10] bag loss: 0.7012\n",
            " Testing bag [1/10] bag loss: 0.6604\n",
            " Testing bag [2/10] bag loss: 0.6545\n",
            " Testing bag [3/10] bag loss: 0.6573\n",
            " Testing bag [4/10] bag loss: 0.6576\n",
            " Testing bag [5/10] bag loss: 0.7031\n",
            " Testing bag [6/10] bag loss: 0.6508\n",
            " Testing bag [7/10] bag loss: 0.6488\n",
            " Testing bag [8/10] bag loss: 0.6581\n",
            " Testing bag [9/10] bag loss: 0.6556ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [94/300] train loss: 0.6658 test loss: 0.6647, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6996\n",
            " Training bag [1/11] bag loss: 0.6496\n",
            " Training bag [2/11] bag loss: 0.6518\n",
            " Training bag [3/11] bag loss: 0.6584\n",
            " Training bag [4/11] bag loss: 0.6461\n",
            " Training bag [5/11] bag loss: 0.7030\n",
            " Training bag [6/11] bag loss: 0.6495\n",
            " Training bag [7/11] bag loss: 0.6535\n",
            " Training bag [8/11] bag loss: 0.6486\n",
            " Training bag [9/11] bag loss: 0.7060\n",
            " Training bag [10/11] bag loss: 0.6563\n",
            " Testing bag [0/10] bag loss: 0.7005\n",
            " Testing bag [1/10] bag loss: 0.6589\n",
            " Testing bag [2/10] bag loss: 0.6550\n",
            " Testing bag [3/10] bag loss: 0.6571\n",
            " Testing bag [4/10] bag loss: 0.6596\n",
            " Testing bag [5/10] bag loss: 0.7023\n",
            " Testing bag [6/10] bag loss: 0.6493\n",
            " Testing bag [7/10] bag loss: 0.6487\n",
            " Testing bag [8/10] bag loss: 0.6579\n",
            " Testing bag [9/10] bag loss: 0.6557ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [95/300] train loss: 0.6657 test loss: 0.6645, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6972\n",
            " Training bag [1/11] bag loss: 0.6496\n",
            " Training bag [2/11] bag loss: 0.6462\n",
            " Training bag [3/11] bag loss: 0.7062\n",
            " Training bag [4/11] bag loss: 0.6511\n",
            " Training bag [5/11] bag loss: 0.6489\n",
            " Training bag [6/11] bag loss: 0.6521\n",
            " Training bag [7/11] bag loss: 0.7026\n",
            " Training bag [8/11] bag loss: 0.6484\n",
            " Training bag [9/11] bag loss: 0.6557\n",
            " Training bag [10/11] bag loss: 0.6603\n",
            " Testing bag [0/10] bag loss: 0.6986\n",
            " Testing bag [1/10] bag loss: 0.6592\n",
            " Testing bag [2/10] bag loss: 0.6539\n",
            " Testing bag [3/10] bag loss: 0.6571\n",
            " Testing bag [4/10] bag loss: 0.6576\n",
            " Testing bag [5/10] bag loss: 0.7031\n",
            " Testing bag [6/10] bag loss: 0.6491\n",
            " Testing bag [7/10] bag loss: 0.6454\n",
            " Testing bag [8/10] bag loss: 0.6563\n",
            " Testing bag [9/10] bag loss: 0.6563ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [96/300] train loss: 0.6653 test loss: 0.6637, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6507\n",
            " Training bag [1/11] bag loss: 0.6494\n",
            " Training bag [2/11] bag loss: 0.6583\n",
            " Training bag [3/11] bag loss: 0.7078\n",
            " Training bag [4/11] bag loss: 0.6492\n",
            " Training bag [5/11] bag loss: 0.7032\n",
            " Training bag [6/11] bag loss: 0.6486\n",
            " Training bag [7/11] bag loss: 0.6453\n",
            " Training bag [8/11] bag loss: 0.6519\n",
            " Training bag [9/11] bag loss: 0.6984\n",
            " Training bag [10/11] bag loss: 0.6553\n",
            " Testing bag [0/10] bag loss: 0.7002\n",
            " Testing bag [1/10] bag loss: 0.6584\n",
            " Testing bag [2/10] bag loss: 0.6525\n",
            " Testing bag [3/10] bag loss: 0.6568\n",
            " Testing bag [4/10] bag loss: 0.6569\n",
            " Testing bag [5/10] bag loss: 0.7038\n",
            " Testing bag [6/10] bag loss: 0.6495\n",
            " Testing bag [7/10] bag loss: 0.6479\n",
            " Testing bag [8/10] bag loss: 0.6581\n",
            " Testing bag [9/10] bag loss: 0.6558ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [97/300] train loss: 0.6653 test loss: 0.6640, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6449\n",
            " Training bag [1/11] bag loss: 0.6491\n",
            " Training bag [2/11] bag loss: 0.6983\n",
            " Training bag [3/11] bag loss: 0.7030\n",
            " Training bag [4/11] bag loss: 0.6508\n",
            " Training bag [5/11] bag loss: 0.6513\n",
            " Training bag [6/11] bag loss: 0.7065\n",
            " Training bag [7/11] bag loss: 0.6482\n",
            " Training bag [8/11] bag loss: 0.6560\n",
            " Training bag [9/11] bag loss: 0.6491\n",
            " Training bag [10/11] bag loss: 0.6567\n",
            " Testing bag [0/10] bag loss: 0.7014\n",
            " Testing bag [1/10] bag loss: 0.6585\n",
            " Testing bag [2/10] bag loss: 0.6542\n",
            " Testing bag [3/10] bag loss: 0.6570\n",
            " Testing bag [4/10] bag loss: 0.6585\n",
            " Testing bag [5/10] bag loss: 0.7030\n",
            " Testing bag [6/10] bag loss: 0.6493\n",
            " Testing bag [7/10] bag loss: 0.6483\n",
            " Testing bag [8/10] bag loss: 0.6574\n",
            " Testing bag [9/10] bag loss: 0.6544ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [98/300] train loss: 0.6649 test loss: 0.6642, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7029\n",
            " Training bag [1/11] bag loss: 0.6980\n",
            " Training bag [2/11] bag loss: 0.6474\n",
            " Training bag [3/11] bag loss: 0.6506\n",
            " Training bag [4/11] bag loss: 0.6495\n",
            " Training bag [5/11] bag loss: 0.7058\n",
            " Training bag [6/11] bag loss: 0.6582\n",
            " Training bag [7/11] bag loss: 0.6448\n",
            " Training bag [8/11] bag loss: 0.6515\n",
            " Training bag [9/11] bag loss: 0.6547\n",
            " Training bag [10/11] bag loss: 0.6499\n",
            " Testing bag [0/10] bag loss: 0.6993\n",
            " Testing bag [1/10] bag loss: 0.6592\n",
            " Testing bag [2/10] bag loss: 0.6528\n",
            " Testing bag [3/10] bag loss: 0.6567\n",
            " Testing bag [4/10] bag loss: 0.6579\n",
            " Testing bag [5/10] bag loss: 0.7023\n",
            " Testing bag [6/10] bag loss: 0.6480\n",
            " Testing bag [7/10] bag loss: 0.6479\n",
            " Testing bag [8/10] bag loss: 0.6562\n",
            " Testing bag [9/10] bag loss: 0.6556ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [99/300] train loss: 0.6648 test loss: 0.6636, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7027\n",
            " Training bag [1/11] bag loss: 0.6971\n",
            " Training bag [2/11] bag loss: 0.6456\n",
            " Training bag [3/11] bag loss: 0.6548\n",
            " Training bag [4/11] bag loss: 0.6502\n",
            " Training bag [5/11] bag loss: 0.7062\n",
            " Training bag [6/11] bag loss: 0.6514\n",
            " Training bag [7/11] bag loss: 0.6495\n",
            " Training bag [8/11] bag loss: 0.6478\n",
            " Training bag [9/11] bag loss: 0.6493\n",
            " Training bag [10/11] bag loss: 0.6583\n",
            " Testing bag [0/10] bag loss: 0.6995\n",
            " Testing bag [1/10] bag loss: 0.6581\n",
            " Testing bag [2/10] bag loss: 0.6534\n",
            " Testing bag [3/10] bag loss: 0.6563\n",
            " Testing bag [4/10] bag loss: 0.6565\n",
            " Testing bag [5/10] bag loss: 0.7019\n",
            " Testing bag [6/10] bag loss: 0.6469\n",
            " Testing bag [7/10] bag loss: 0.6476\n",
            " Testing bag [8/10] bag loss: 0.6576\n",
            " Testing bag [9/10] bag loss: 0.6530ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [100/300] train loss: 0.6648 test loss: 0.6631, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7028\n",
            " Training bag [1/11] bag loss: 0.6566\n",
            " Training bag [2/11] bag loss: 0.6474\n",
            " Training bag [3/11] bag loss: 0.6986\n",
            " Training bag [4/11] bag loss: 0.6514\n",
            " Training bag [5/11] bag loss: 0.6495\n",
            " Training bag [6/11] bag loss: 0.6482\n",
            " Training bag [7/11] bag loss: 0.6449\n",
            " Training bag [8/11] bag loss: 0.7065\n",
            " Training bag [9/11] bag loss: 0.6553\n",
            " Training bag [10/11] bag loss: 0.6499\n",
            " Testing bag [0/10] bag loss: 0.6993\n",
            " Testing bag [1/10] bag loss: 0.6585\n",
            " Testing bag [2/10] bag loss: 0.6537\n",
            " Testing bag [3/10] bag loss: 0.6562\n",
            " Testing bag [4/10] bag loss: 0.6572\n",
            " Testing bag [5/10] bag loss: 0.7046\n",
            " Testing bag [6/10] bag loss: 0.6479\n",
            " Testing bag [7/10] bag loss: 0.6472\n",
            " Testing bag [8/10] bag loss: 0.6562\n",
            " Testing bag [9/10] bag loss: 0.6546ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [101/300] train loss: 0.6647 test loss: 0.6636, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6538\n",
            " Training bag [1/11] bag loss: 0.6496\n",
            " Training bag [2/11] bag loss: 0.6466\n",
            " Training bag [3/11] bag loss: 0.6490\n",
            " Training bag [4/11] bag loss: 0.6486\n",
            " Training bag [5/11] bag loss: 0.7033\n",
            " Training bag [6/11] bag loss: 0.6995\n",
            " Training bag [7/11] bag loss: 0.6483\n",
            " Training bag [8/11] bag loss: 0.6549\n",
            " Training bag [9/11] bag loss: 0.7068\n",
            " Training bag [10/11] bag loss: 0.6439\n",
            " Testing bag [0/10] bag loss: 0.7009\n",
            " Testing bag [1/10] bag loss: 0.6568\n",
            " Testing bag [2/10] bag loss: 0.6514\n",
            " Testing bag [3/10] bag loss: 0.6560\n",
            " Testing bag [4/10] bag loss: 0.6555\n",
            " Testing bag [5/10] bag loss: 0.7050\n",
            " Testing bag [6/10] bag loss: 0.6472\n",
            " Testing bag [7/10] bag loss: 0.6445\n",
            " Testing bag [8/10] bag loss: 0.6557\n",
            " Testing bag [9/10] bag loss: 0.6551ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [102/300] train loss: 0.6640 test loss: 0.6628, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6444\n",
            " Training bag [1/11] bag loss: 0.7028\n",
            " Training bag [2/11] bag loss: 0.7072\n",
            " Training bag [3/11] bag loss: 0.6494\n",
            " Training bag [4/11] bag loss: 0.6469\n",
            " Training bag [5/11] bag loss: 0.6475\n",
            " Training bag [6/11] bag loss: 0.6570\n",
            " Training bag [7/11] bag loss: 0.6477\n",
            " Training bag [8/11] bag loss: 0.6972\n",
            " Training bag [9/11] bag loss: 0.6548\n",
            " Training bag [10/11] bag loss: 0.6497\n",
            " Testing bag [0/10] bag loss: 0.6993\n",
            " Testing bag [1/10] bag loss: 0.6581\n",
            " Testing bag [2/10] bag loss: 0.6510\n",
            " Testing bag [3/10] bag loss: 0.6549\n",
            " Testing bag [4/10] bag loss: 0.6568\n",
            " Testing bag [5/10] bag loss: 0.7023\n",
            " Testing bag [6/10] bag loss: 0.6466\n",
            " Testing bag [7/10] bag loss: 0.6442\n",
            " Testing bag [8/10] bag loss: 0.6571\n",
            " Testing bag [9/10] bag loss: 0.6528ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [103/300] train loss: 0.6641 test loss: 0.6623, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6506\n",
            " Training bag [1/11] bag loss: 0.6438\n",
            " Training bag [2/11] bag loss: 0.6538\n",
            " Training bag [3/11] bag loss: 0.7033\n",
            " Training bag [4/11] bag loss: 0.6442\n",
            " Training bag [5/11] bag loss: 0.6989\n",
            " Training bag [6/11] bag loss: 0.7065\n",
            " Training bag [7/11] bag loss: 0.6562\n",
            " Training bag [8/11] bag loss: 0.6478\n",
            " Training bag [9/11] bag loss: 0.6493\n",
            " Training bag [10/11] bag loss: 0.6494\n",
            " Testing bag [0/10] bag loss: 0.6989\n",
            " Testing bag [1/10] bag loss: 0.6568\n",
            " Testing bag [2/10] bag loss: 0.6507\n",
            " Testing bag [3/10] bag loss: 0.6553\n",
            " Testing bag [4/10] bag loss: 0.6555\n",
            " Testing bag [5/10] bag loss: 0.7044\n",
            " Testing bag [6/10] bag loss: 0.6481\n",
            " Testing bag [7/10] bag loss: 0.6453\n",
            " Testing bag [8/10] bag loss: 0.6571\n",
            " Testing bag [9/10] bag loss: 0.6532ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [104/300] train loss: 0.6640 test loss: 0.6625, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6486\n",
            " Training bag [1/11] bag loss: 0.7033\n",
            " Training bag [2/11] bag loss: 0.6479\n",
            " Training bag [3/11] bag loss: 0.6503\n",
            " Training bag [4/11] bag loss: 0.6988\n",
            " Training bag [5/11] bag loss: 0.6521\n",
            " Training bag [6/11] bag loss: 0.6438\n",
            " Training bag [7/11] bag loss: 0.6469\n",
            " Training bag [8/11] bag loss: 0.6464\n",
            " Training bag [9/11] bag loss: 0.6551\n",
            " Training bag [10/11] bag loss: 0.7079\n",
            " Testing bag [0/10] bag loss: 0.7014\n",
            " Testing bag [1/10] bag loss: 0.6574\n",
            " Testing bag [2/10] bag loss: 0.6519\n",
            " Testing bag [3/10] bag loss: 0.6551\n",
            " Testing bag [4/10] bag loss: 0.6562\n",
            " Testing bag [5/10] bag loss: 0.7036\n",
            " Testing bag [6/10] bag loss: 0.6471\n",
            " Testing bag [7/10] bag loss: 0.6457\n",
            " Testing bag [8/10] bag loss: 0.6557\n",
            " Testing bag [9/10] bag loss: 0.6519ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [105/300] train loss: 0.6637 test loss: 0.6626, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6425\n",
            " Training bag [1/11] bag loss: 0.6989\n",
            " Training bag [2/11] bag loss: 0.7064\n",
            " Training bag [3/11] bag loss: 0.6478\n",
            " Training bag [4/11] bag loss: 0.6533\n",
            " Training bag [5/11] bag loss: 0.6552\n",
            " Training bag [6/11] bag loss: 0.6453\n",
            " Training bag [7/11] bag loss: 0.6469\n",
            " Training bag [8/11] bag loss: 0.6487\n",
            " Training bag [9/11] bag loss: 0.7034\n",
            " Training bag [10/11] bag loss: 0.6471\n",
            " Testing bag [0/10] bag loss: 0.7000\n",
            " Testing bag [1/10] bag loss: 0.6569\n",
            " Testing bag [2/10] bag loss: 0.6508\n",
            " Testing bag [3/10] bag loss: 0.6551\n",
            " Testing bag [4/10] bag loss: 0.6558\n",
            " Testing bag [5/10] bag loss: 0.7037\n",
            " Testing bag [6/10] bag loss: 0.6460\n",
            " Testing bag [7/10] bag loss: 0.6454\n",
            " Testing bag [8/10] bag loss: 0.6560\n",
            " Testing bag [9/10] bag loss: 0.6525ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [106/300] train loss: 0.6632 test loss: 0.6622, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6529\n",
            " Training bag [1/11] bag loss: 0.6469\n",
            " Training bag [2/11] bag loss: 0.6423\n",
            " Training bag [3/11] bag loss: 0.6558\n",
            " Training bag [4/11] bag loss: 0.6988\n",
            " Training bag [5/11] bag loss: 0.6449\n",
            " Training bag [6/11] bag loss: 0.6475\n",
            " Training bag [7/11] bag loss: 0.6485\n",
            " Training bag [8/11] bag loss: 0.7077\n",
            " Training bag [9/11] bag loss: 0.7031\n",
            " Training bag [10/11] bag loss: 0.6467\n",
            " Testing bag [0/10] bag loss: 0.6997\n",
            " Testing bag [1/10] bag loss: 0.6567\n",
            " Testing bag [2/10] bag loss: 0.6522\n",
            " Testing bag [3/10] bag loss: 0.6542\n",
            " Testing bag [4/10] bag loss: 0.6556\n",
            " Testing bag [5/10] bag loss: 0.7038\n",
            " Testing bag [6/10] bag loss: 0.6461\n",
            " Testing bag [7/10] bag loss: 0.6445\n",
            " Testing bag [8/10] bag loss: 0.6549\n",
            " Testing bag [9/10] bag loss: 0.6511ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [107/300] train loss: 0.6632 test loss: 0.6619, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7031\n",
            " Training bag [1/11] bag loss: 0.6517\n",
            " Training bag [2/11] bag loss: 0.6467\n",
            " Training bag [3/11] bag loss: 0.6982\n",
            " Training bag [4/11] bag loss: 0.6478\n",
            " Training bag [5/11] bag loss: 0.7057\n",
            " Training bag [6/11] bag loss: 0.6480\n",
            " Training bag [7/11] bag loss: 0.6452\n",
            " Training bag [8/11] bag loss: 0.6422\n",
            " Training bag [9/11] bag loss: 0.6555\n",
            " Training bag [10/11] bag loss: 0.6471\n",
            " Testing bag [0/10] bag loss: 0.6988\n",
            " Testing bag [1/10] bag loss: 0.6563\n",
            " Testing bag [2/10] bag loss: 0.6517\n",
            " Testing bag [3/10] bag loss: 0.6540\n",
            " Testing bag [4/10] bag loss: 0.6545\n",
            " Testing bag [5/10] bag loss: 0.7043\n",
            " Testing bag [6/10] bag loss: 0.6459\n",
            " Testing bag [7/10] bag loss: 0.6431\n",
            " Testing bag [8/10] bag loss: 0.6561\n",
            " Testing bag [9/10] bag loss: 0.6534ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [108/300] train loss: 0.6628 test loss: 0.6618, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7030\n",
            " Training bag [1/11] bag loss: 0.6536\n",
            " Training bag [2/11] bag loss: 0.6992\n",
            " Training bag [3/11] bag loss: 0.7050\n",
            " Training bag [4/11] bag loss: 0.6508\n",
            " Training bag [5/11] bag loss: 0.6477\n",
            " Training bag [6/11] bag loss: 0.6477\n",
            " Training bag [7/11] bag loss: 0.6484\n",
            " Training bag [8/11] bag loss: 0.6434\n",
            " Training bag [9/11] bag loss: 0.6421\n",
            " Training bag [10/11] bag loss: 0.6464\n",
            " Testing bag [0/10] bag loss: 0.6998\n",
            " Testing bag [1/10] bag loss: 0.6559\n",
            " Testing bag [2/10] bag loss: 0.6506\n",
            " Testing bag [3/10] bag loss: 0.6543\n",
            " Testing bag [4/10] bag loss: 0.6544\n",
            " Testing bag [5/10] bag loss: 0.7047\n",
            " Testing bag [6/10] bag loss: 0.6466\n",
            " Testing bag [7/10] bag loss: 0.6432\n",
            " Testing bag [8/10] bag loss: 0.6550\n",
            " Testing bag [9/10] bag loss: 0.6522ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [109/300] train loss: 0.6625 test loss: 0.6617, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6981\n",
            " Training bag [1/11] bag loss: 0.6535\n",
            " Training bag [2/11] bag loss: 0.6471\n",
            " Training bag [3/11] bag loss: 0.6468\n",
            " Training bag [4/11] bag loss: 0.6476\n",
            " Training bag [5/11] bag loss: 0.7029\n",
            " Training bag [6/11] bag loss: 0.6413\n",
            " Training bag [7/11] bag loss: 0.6474\n",
            " Training bag [8/11] bag loss: 0.6448\n",
            " Training bag [9/11] bag loss: 0.7073\n",
            " Training bag [10/11] bag loss: 0.6508\n",
            " Testing bag [0/10] bag loss: 0.7000\n",
            " Testing bag [1/10] bag loss: 0.6562\n",
            " Testing bag [2/10] bag loss: 0.6508\n",
            " Testing bag [3/10] bag loss: 0.6540\n",
            " Testing bag [4/10] bag loss: 0.6535\n",
            " Testing bag [5/10] bag loss: 0.7037\n",
            " Testing bag [6/10] bag loss: 0.6451\n",
            " Testing bag [7/10] bag loss: 0.6436\n",
            " Testing bag [8/10] bag loss: 0.6542\n",
            " Testing bag [9/10] bag loss: 0.6526ROC AUC score: 0.75\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5416666666666666\n",
            "\n",
            " Epoch [110/300] train loss: 0.6625 test loss: 0.6614, average score: 0.4000, AUC: class-0>>0.75|class-1>>0.5|class-2>>0.5416666666666666\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6464\n",
            " Training bag [1/11] bag loss: 0.6412\n",
            " Training bag [2/11] bag loss: 0.6504\n",
            " Training bag [3/11] bag loss: 0.6537\n",
            " Training bag [4/11] bag loss: 0.7064\n",
            " Training bag [5/11] bag loss: 0.6461\n",
            " Training bag [6/11] bag loss: 0.6464\n",
            " Training bag [7/11] bag loss: 0.6986\n",
            " Training bag [8/11] bag loss: 0.7029\n",
            " Training bag [9/11] bag loss: 0.6432\n",
            " Training bag [10/11] bag loss: 0.6449\n",
            " Testing bag [0/10] bag loss: 0.7000\n",
            " Testing bag [1/10] bag loss: 0.6550\n",
            " Testing bag [2/10] bag loss: 0.6493\n",
            " Testing bag [3/10] bag loss: 0.6537\n",
            " Testing bag [4/10] bag loss: 0.6552\n",
            " Testing bag [5/10] bag loss: 0.7047\n",
            " Testing bag [6/10] bag loss: 0.6451\n",
            " Testing bag [7/10] bag loss: 0.6442\n",
            " Testing bag [8/10] bag loss: 0.6549\n",
            " Testing bag [9/10] bag loss: 0.6510ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [111/300] train loss: 0.6618 test loss: 0.6613, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6471\n",
            " Training bag [1/11] bag loss: 0.6432\n",
            " Training bag [2/11] bag loss: 0.6473\n",
            " Training bag [3/11] bag loss: 0.6408\n",
            " Training bag [4/11] bag loss: 0.7064\n",
            " Training bag [5/11] bag loss: 0.6983\n",
            " Training bag [6/11] bag loss: 0.7030\n",
            " Training bag [7/11] bag loss: 0.6499\n",
            " Training bag [8/11] bag loss: 0.6454\n",
            " Training bag [9/11] bag loss: 0.6552\n",
            " Training bag [10/11] bag loss: 0.6459\n",
            " Testing bag [0/10] bag loss: 0.6989\n",
            " Testing bag [1/10] bag loss: 0.6550\n",
            " Testing bag [2/10] bag loss: 0.6509\n",
            " Testing bag [3/10] bag loss: 0.6533\n",
            " Testing bag [4/10] bag loss: 0.6538\n",
            " Testing bag [5/10] bag loss: 0.7043\n",
            " Testing bag [6/10] bag loss: 0.6455\n",
            " Testing bag [7/10] bag loss: 0.6429\n",
            " Testing bag [8/10] bag loss: 0.6535\n",
            " Testing bag [9/10] bag loss: 0.6506ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [112/300] train loss: 0.6620 test loss: 0.6609, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7031\n",
            " Training bag [1/11] bag loss: 0.6452\n",
            " Training bag [2/11] bag loss: 0.6465\n",
            " Training bag [3/11] bag loss: 0.7061\n",
            " Training bag [4/11] bag loss: 0.6432\n",
            " Training bag [5/11] bag loss: 0.6506\n",
            " Training bag [6/11] bag loss: 0.6985\n",
            " Training bag [7/11] bag loss: 0.6531\n",
            " Training bag [8/11] bag loss: 0.6457\n",
            " Training bag [9/11] bag loss: 0.6411\n",
            " Training bag [10/11] bag loss: 0.6462\n",
            " Testing bag [0/10] bag loss: 0.7001\n",
            " Testing bag [1/10] bag loss: 0.6540\n",
            " Testing bag [2/10] bag loss: 0.6508\n",
            " Testing bag [3/10] bag loss: 0.6535\n",
            " Testing bag [4/10] bag loss: 0.6528\n",
            " Testing bag [5/10] bag loss: 0.7037\n",
            " Testing bag [6/10] bag loss: 0.6445\n",
            " Testing bag [7/10] bag loss: 0.6419\n",
            " Testing bag [8/10] bag loss: 0.6546\n",
            " Testing bag [9/10] bag loss: 0.6514ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5416666666666666\n",
            "\n",
            " Epoch [113/300] train loss: 0.6618 test loss: 0.6607, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5416666666666666\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6413\n",
            " Training bag [1/11] bag loss: 0.6477\n",
            " Training bag [2/11] bag loss: 0.6446\n",
            " Training bag [3/11] bag loss: 0.6504\n",
            " Training bag [4/11] bag loss: 0.6453\n",
            " Training bag [5/11] bag loss: 0.6432\n",
            " Training bag [6/11] bag loss: 0.6539\n",
            " Training bag [7/11] bag loss: 0.7067\n",
            " Training bag [8/11] bag loss: 0.6458\n",
            " Training bag [9/11] bag loss: 0.6988\n",
            " Training bag [10/11] bag loss: 0.7036\n",
            " Testing bag [0/10] bag loss: 0.7010\n",
            " Testing bag [1/10] bag loss: 0.6541\n",
            " Testing bag [2/10] bag loss: 0.6497\n",
            " Testing bag [3/10] bag loss: 0.6528\n",
            " Testing bag [4/10] bag loss: 0.6537\n",
            " Testing bag [5/10] bag loss: 0.7040\n",
            " Testing bag [6/10] bag loss: 0.6449\n",
            " Testing bag [7/10] bag loss: 0.6417\n",
            " Testing bag [8/10] bag loss: 0.6537\n",
            " Testing bag [9/10] bag loss: 0.6487ROC AUC score: 0.75\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [114/300] train loss: 0.6619 test loss: 0.6604, average score: 0.4000, AUC: class-0>>0.75|class-1>>0.5|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6446\n",
            " Training bag [1/11] bag loss: 0.6452\n",
            " Training bag [2/11] bag loss: 0.6435\n",
            " Training bag [3/11] bag loss: 0.6442\n",
            " Training bag [4/11] bag loss: 0.7062\n",
            " Training bag [5/11] bag loss: 0.6395\n",
            " Training bag [6/11] bag loss: 0.7029\n",
            " Training bag [7/11] bag loss: 0.6522\n",
            " Training bag [8/11] bag loss: 0.6985\n",
            " Training bag [9/11] bag loss: 0.6541\n",
            " Training bag [10/11] bag loss: 0.6465\n",
            " Testing bag [0/10] bag loss: 0.6994\n",
            " Testing bag [1/10] bag loss: 0.6553\n",
            " Testing bag [2/10] bag loss: 0.6481\n",
            " Testing bag [3/10] bag loss: 0.6526\n",
            " Testing bag [4/10] bag loss: 0.6540\n",
            " Testing bag [5/10] bag loss: 0.7037\n",
            " Testing bag [6/10] bag loss: 0.6450\n",
            " Testing bag [7/10] bag loss: 0.6433\n",
            " Testing bag [8/10] bag loss: 0.6548\n",
            " Testing bag [9/10] bag loss: 0.6515ROC AUC score: 0.7916666666666667\n",
            "ROC AUC score: 0.5\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [115/300] train loss: 0.6616 test loss: 0.6608, average score: 0.4000, AUC: class-0>>0.7916666666666667|class-1>>0.5|class-2>>0.5\n",
            "Final results: Mean Accuracy: 0.5227272727272727\n",
            "Class 0: Mean AUC = 0.8155\n",
            "Class 1: Mean AUC = 0.7500\n",
            "Class 2: Mean AUC = 0.6667\n",
            "\n",
            "\n",
            "  0%|          | 0/21 [00:00<?, ?it/s]\n",
            "  5%|â–         | 1/21 [00:14<04:50, 14.55s/it]\n",
            " 10%|â–‰         | 2/21 [00:16<02:16,  7.16s/it]\n",
            " 14%|â–ˆâ–        | 3/21 [00:19<01:30,  5.03s/it]\n",
            " 19%|â–ˆâ–‰        | 4/21 [00:25<01:32,  5.42s/it]\n",
            " 24%|â–ˆâ–ˆâ–       | 5/21 [00:28<01:12,  4.55s/it]\n",
            " 29%|â–ˆâ–ˆâ–Š       | 6/21 [00:30<00:56,  3.76s/it]\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 7/21 [00:31<00:41,  2.98s/it]\n",
            " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 8/21 [00:38<00:55,  4.23s/it]\n",
            " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 9/21 [00:41<00:46,  3.87s/it]\n",
            " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 10/21 [00:45<00:41,  3.78s/it]\n",
            " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 11/21 [00:45<00:26,  2.68s/it]\n",
            " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 12/21 [00:45<00:17,  1.94s/it]\n",
            " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 13/21 [00:46<00:12,  1.50s/it]\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 14/21 [00:47<00:10,  1.47s/it]\n",
            " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 15/21 [00:48<00:07,  1.31s/it]\n",
            " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 16/21 [00:50<00:06,  1.37s/it]\n",
            " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 17/21 [00:50<00:04,  1.17s/it]\n",
            " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 18/21 [00:52<00:04,  1.44s/it]\n",
            " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 19/21 [00:54<00:03,  1.54s/it]\n",
            " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 20/21 [00:54<00:01,  1.12s/it]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:56<00:00,  1.28s/it]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:56<00:00,  2.68s/it]\n",
            "/content/dsmil-wsi/train_tcga.py:63: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)\n",
            "  bag_label = Tensor(stacked_data[0, args.feats_size:]).unsqueeze(0)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## to train paste into train_tcga.py the content of train_MLiA.py\n",
        "%cd /content/dsmil-wsi\n",
        "!MPLBACKEND=Agg conda run -n dsmil python train_tcga.py --dataset=MLiA_dataset --num_classes=3 --feats_size=1024 --num_epochs=300  --dropout_patch=0.50 --lr=1e-5 --stop_epochs=100 --eval_scheme=5-fold-cv --split=0.2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlT1OcdPUe3B",
        "outputId": "9add4ec9-3135-42df-907d-2f3627a618f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5-fold-cv-custom\n",
            "Creating intermediate training files.\n",
            "5-fold-cv\n",
            "\n",
            "ðŸŒ€ Starting CV Fold 0\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7013\n",
            " Training bag [1/11] bag loss: 0.7129\n",
            " Training bag [2/11] bag loss: 0.6979\n",
            " Training bag [3/11] bag loss: 0.6956\n",
            " Training bag [4/11] bag loss: 0.7158\n",
            " Training bag [5/11] bag loss: 0.7027\n",
            " Training bag [6/11] bag loss: 0.7098\n",
            " Training bag [7/11] bag loss: 0.6995\n",
            " Training bag [8/11] bag loss: 0.7048\n",
            " Training bag [9/11] bag loss: 0.6924\n",
            " Training bag [10/11] bag loss: 0.6937\n",
            " Testing bag [0/5] bag loss: 0.7136\n",
            " Testing bag [1/5] bag loss: 0.6902\n",
            " Testing bag [2/5] bag loss: 0.6969\n",
            " Testing bag [3/5] bag loss: 0.6977\n",
            " Testing bag [4/5] bag loss: 0.6979ROC AUC score: 0.5\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [1/300] train loss: 0.7024 test loss: 0.6993, average score: 0.2000, AUC: class-0>>0.5|class-1>>0.75|class-2>>0.33333333333333337\n",
            "Best model saved at: weights/20250626/fold_0_19.pth\n",
            "Best thresholds ===>>> class-0>>0.5126194953918457|class-1>>0.4941782057285309|class-2>>0.4812300503253937\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7094\n",
            " Training bag [1/11] bag loss: 0.6939\n",
            " Training bag [2/11] bag loss: 0.6911\n",
            " Training bag [3/11] bag loss: 0.6936\n",
            " Training bag [4/11] bag loss: 0.7074\n",
            " Training bag [5/11] bag loss: 0.6859\n",
            " Training bag [6/11] bag loss: 0.6927\n",
            " Training bag [7/11] bag loss: 0.6828\n",
            " Training bag [8/11] bag loss: 0.7127\n",
            " Training bag [9/11] bag loss: 0.6990\n",
            " Training bag [10/11] bag loss: 0.6879\n",
            " Testing bag [0/5] bag loss: 0.7143\n",
            " Testing bag [1/5] bag loss: 0.6829\n",
            " Testing bag [2/5] bag loss: 0.6866\n",
            " Testing bag [3/5] bag loss: 0.6897\n",
            " Testing bag [4/5] bag loss: 0.6917ROC AUC score: 0.5\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [2/300] train loss: 0.6960 test loss: 0.6930, average score: 0.2000, AUC: class-0>>0.5|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7103\n",
            " Training bag [1/11] bag loss: 0.6920\n",
            " Training bag [2/11] bag loss: 0.6840\n",
            " Training bag [3/11] bag loss: 0.6824\n",
            " Training bag [4/11] bag loss: 0.6808\n",
            " Training bag [5/11] bag loss: 0.6872\n",
            " Training bag [6/11] bag loss: 0.6828\n",
            " Training bag [7/11] bag loss: 0.7096\n",
            " Training bag [8/11] bag loss: 0.6818\n",
            " Training bag [9/11] bag loss: 0.6766\n",
            " Training bag [10/11] bag loss: 0.7111\n",
            " Testing bag [0/5] bag loss: 0.7124\n",
            " Testing bag [1/5] bag loss: 0.6785\n",
            " Testing bag [2/5] bag loss: 0.6836\n",
            " Testing bag [3/5] bag loss: 0.6818\n",
            " Testing bag [4/5] bag loss: 0.6817ROC AUC score: 0.5\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.16666666666666669\n",
            "\n",
            " Epoch [3/300] train loss: 0.6908 test loss: 0.6876, average score: 0.4000, AUC: class-0>>0.5|class-1>>0.75|class-2>>0.16666666666666669\n",
            "Best model saved at: weights/20250626/fold_0_19.pth\n",
            "Best thresholds ===>>> class-0>>0.49463698267936707|class-1>>0.4625890851020813|class-2>>inf\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7060\n",
            " Training bag [1/11] bag loss: 0.6792\n",
            " Training bag [2/11] bag loss: 0.6790\n",
            " Training bag [3/11] bag loss: 0.6795\n",
            " Training bag [4/11] bag loss: 0.6721\n",
            " Training bag [5/11] bag loss: 0.6786\n",
            " Training bag [6/11] bag loss: 0.6785\n",
            " Training bag [7/11] bag loss: 0.6815\n",
            " Training bag [8/11] bag loss: 0.7141\n",
            " Training bag [9/11] bag loss: 0.7105\n",
            " Training bag [10/11] bag loss: 0.6751\n",
            " Testing bag [0/5] bag loss: 0.7114\n",
            " Testing bag [1/5] bag loss: 0.6744\n",
            " Testing bag [2/5] bag loss: 0.6775\n",
            " Testing bag [3/5] bag loss: 0.6747\n",
            " Testing bag [4/5] bag loss: 0.6767ROC AUC score: 0.5\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.16666666666666669\n",
            "\n",
            " Epoch [4/300] train loss: 0.6867 test loss: 0.6830, average score: 0.4000, AUC: class-0>>0.5|class-1>>0.75|class-2>>0.16666666666666669\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6679\n",
            " Training bag [1/11] bag loss: 0.6781\n",
            " Training bag [2/11] bag loss: 0.6762\n",
            " Training bag [3/11] bag loss: 0.6705\n",
            " Training bag [4/11] bag loss: 0.6690\n",
            " Training bag [5/11] bag loss: 0.7133\n",
            " Training bag [6/11] bag loss: 0.6668\n",
            " Training bag [7/11] bag loss: 0.7111\n",
            " Training bag [8/11] bag loss: 0.6758\n",
            " Training bag [9/11] bag loss: 0.7055\n",
            " Training bag [10/11] bag loss: 0.6700\n",
            " Testing bag [0/5] bag loss: 0.7103\n",
            " Testing bag [1/5] bag loss: 0.6678\n",
            " Testing bag [2/5] bag loss: 0.6739\n",
            " Testing bag [3/5] bag loss: 0.6743\n",
            " Testing bag [4/5] bag loss: 0.6743ROC AUC score: 0.5\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [5/300] train loss: 0.6822 test loss: 0.6801, average score: 0.2000, AUC: class-0>>0.5|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6689\n",
            " Training bag [1/11] bag loss: 0.6666\n",
            " Training bag [2/11] bag loss: 0.6621\n",
            " Training bag [3/11] bag loss: 0.6710\n",
            " Training bag [4/11] bag loss: 0.6588\n",
            " Training bag [5/11] bag loss: 0.6731\n",
            " Training bag [6/11] bag loss: 0.6744\n",
            " Training bag [7/11] bag loss: 0.6620\n",
            " Training bag [8/11] bag loss: 0.7165\n",
            " Training bag [9/11] bag loss: 0.7144\n",
            " Training bag [10/11] bag loss: 0.7100\n",
            " Testing bag [0/5] bag loss: 0.7090\n",
            " Testing bag [1/5] bag loss: 0.6646\n",
            " Testing bag [2/5] bag loss: 0.6692\n",
            " Testing bag [3/5] bag loss: 0.6649\n",
            " Testing bag [4/5] bag loss: 0.6651ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [6/300] train loss: 0.6798 test loss: 0.6745, average score: 0.2000, AUC: class-0>>0.33333333333333337|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6659\n",
            " Training bag [1/11] bag loss: 0.6610\n",
            " Training bag [2/11] bag loss: 0.6633\n",
            " Training bag [3/11] bag loss: 0.7089\n",
            " Training bag [4/11] bag loss: 0.6694\n",
            " Training bag [5/11] bag loss: 0.6647\n",
            " Training bag [6/11] bag loss: 0.7074\n",
            " Training bag [7/11] bag loss: 0.7038\n",
            " Training bag [8/11] bag loss: 0.6545\n",
            " Training bag [9/11] bag loss: 0.6651\n",
            " Training bag [10/11] bag loss: 0.6629\n",
            " Testing bag [0/5] bag loss: 0.7056\n",
            " Testing bag [1/5] bag loss: 0.6642\n",
            " Testing bag [2/5] bag loss: 0.6688\n",
            " Testing bag [3/5] bag loss: 0.6605\n",
            " Testing bag [4/5] bag loss: 0.6628ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [7/300] train loss: 0.6752 test loss: 0.6724, average score: 0.2000, AUC: class-0>>0.33333333333333337|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6998\n",
            " Training bag [1/11] bag loss: 0.7017\n",
            " Training bag [2/11] bag loss: 0.6640\n",
            " Training bag [3/11] bag loss: 0.6561\n",
            " Training bag [4/11] bag loss: 0.6982\n",
            " Training bag [5/11] bag loss: 0.6658\n",
            " Training bag [6/11] bag loss: 0.6659\n",
            " Training bag [7/11] bag loss: 0.6609\n",
            " Training bag [8/11] bag loss: 0.6658\n",
            " Training bag [9/11] bag loss: 0.6587\n",
            " Training bag [10/11] bag loss: 0.6519\n",
            " Testing bag [0/5] bag loss: 0.7061\n",
            " Testing bag [1/5] bag loss: 0.6589\n",
            " Testing bag [2/5] bag loss: 0.6618\n",
            " Testing bag [3/5] bag loss: 0.6599\n",
            " Testing bag [4/5] bag loss: 0.6611ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [8/300] train loss: 0.6717 test loss: 0.6696, average score: 0.2000, AUC: class-0>>0.33333333333333337|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6539\n",
            " Training bag [1/11] bag loss: 0.7032\n",
            " Training bag [2/11] bag loss: 0.6504\n",
            " Training bag [3/11] bag loss: 0.6561\n",
            " Training bag [4/11] bag loss: 0.7036\n",
            " Training bag [5/11] bag loss: 0.6543\n",
            " Training bag [6/11] bag loss: 0.6987\n",
            " Training bag [7/11] bag loss: 0.6597\n",
            " Training bag [8/11] bag loss: 0.6579\n",
            " Training bag [9/11] bag loss: 0.6556\n",
            " Training bag [10/11] bag loss: 0.6579\n",
            " Testing bag [0/5] bag loss: 0.7038\n",
            " Testing bag [1/5] bag loss: 0.6560\n",
            " Testing bag [2/5] bag loss: 0.6585\n",
            " Testing bag [3/5] bag loss: 0.6551\n",
            " Testing bag [4/5] bag loss: 0.6581ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [9/300] train loss: 0.6683 test loss: 0.6663, average score: 0.2000, AUC: class-0>>0.33333333333333337|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6992\n",
            " Training bag [1/11] bag loss: 0.7005\n",
            " Training bag [2/11] bag loss: 0.6480\n",
            " Training bag [3/11] bag loss: 0.6483\n",
            " Training bag [4/11] bag loss: 0.6549\n",
            " Training bag [5/11] bag loss: 0.6558\n",
            " Training bag [6/11] bag loss: 0.6541\n",
            " Training bag [7/11] bag loss: 0.7024\n",
            " Training bag [8/11] bag loss: 0.6518\n",
            " Training bag [9/11] bag loss: 0.6573\n",
            " Training bag [10/11] bag loss: 0.6575\n",
            " Testing bag [0/5] bag loss: 0.7031\n",
            " Testing bag [1/5] bag loss: 0.6498\n",
            " Testing bag [2/5] bag loss: 0.6546\n",
            " Testing bag [3/5] bag loss: 0.6531\n",
            " Testing bag [4/5] bag loss: 0.6547ROC AUC score: 0.5\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [10/300] train loss: 0.6663 test loss: 0.6631, average score: 0.4000, AUC: class-0>>0.5|class-1>>0.75|class-2>>0.33333333333333337\n",
            "Best model saved at: weights/20250626/fold_0_19.pth\n",
            "Best thresholds ===>>> class-0>>0.44869059324264526|class-1>>0.3896696865558624|class-2>>0.42685067653656006\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6545\n",
            " Training bag [1/11] bag loss: 0.6484\n",
            " Training bag [2/11] bag loss: 0.6395\n",
            " Training bag [3/11] bag loss: 0.6500\n",
            " Training bag [4/11] bag loss: 0.6480\n",
            " Training bag [5/11] bag loss: 0.6442\n",
            " Training bag [6/11] bag loss: 0.7116\n",
            " Training bag [7/11] bag loss: 0.6452\n",
            " Training bag [8/11] bag loss: 0.7106\n",
            " Training bag [9/11] bag loss: 0.7058\n",
            " Training bag [10/11] bag loss: 0.6424\n",
            " Testing bag [0/5] bag loss: 0.7068\n",
            " Testing bag [1/5] bag loss: 0.6481\n",
            " Testing bag [2/5] bag loss: 0.6515\n",
            " Testing bag [3/5] bag loss: 0.6490\n",
            " Testing bag [4/5] bag loss: 0.6511ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [11/300] train loss: 0.6637 test loss: 0.6613, average score: 0.2000, AUC: class-0>>0.33333333333333337|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7012\n",
            " Training bag [1/11] bag loss: 0.6390\n",
            " Training bag [2/11] bag loss: 0.6497\n",
            " Training bag [3/11] bag loss: 0.7033\n",
            " Training bag [4/11] bag loss: 0.6991\n",
            " Training bag [5/11] bag loss: 0.6390\n",
            " Training bag [6/11] bag loss: 0.6454\n",
            " Training bag [7/11] bag loss: 0.6492\n",
            " Training bag [8/11] bag loss: 0.6472\n",
            " Training bag [9/11] bag loss: 0.6499\n",
            " Training bag [10/11] bag loss: 0.6471\n",
            " Testing bag [0/5] bag loss: 0.7063\n",
            " Testing bag [1/5] bag loss: 0.6487\n",
            " Testing bag [2/5] bag loss: 0.6510\n",
            " Testing bag [3/5] bag loss: 0.6444\n",
            " Testing bag [4/5] bag loss: 0.6443ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [12/300] train loss: 0.6609 test loss: 0.6589, average score: 0.2000, AUC: class-0>>0.33333333333333337|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6471\n",
            " Training bag [1/11] bag loss: 0.6454\n",
            " Training bag [2/11] bag loss: 0.6324\n",
            " Training bag [3/11] bag loss: 0.7072\n",
            " Training bag [4/11] bag loss: 0.6418\n",
            " Training bag [5/11] bag loss: 0.7056\n",
            " Training bag [6/11] bag loss: 0.6427\n",
            " Training bag [7/11] bag loss: 0.6298\n",
            " Training bag [8/11] bag loss: 0.7000\n",
            " Training bag [9/11] bag loss: 0.6471\n",
            " Training bag [10/11] bag loss: 0.6449\n",
            " Testing bag [0/5] bag loss: 0.7069\n",
            " Testing bag [1/5] bag loss: 0.6456\n",
            " Testing bag [2/5] bag loss: 0.6494\n",
            " Testing bag [3/5] bag loss: 0.6403\n",
            " Testing bag [4/5] bag loss: 0.6419ROC AUC score: 0.5\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [13/300] train loss: 0.6585 test loss: 0.6568, average score: 0.4000, AUC: class-0>>0.5|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6277\n",
            " Training bag [1/11] bag loss: 0.7008\n",
            " Training bag [2/11] bag loss: 0.7031\n",
            " Training bag [3/11] bag loss: 0.6402\n",
            " Training bag [4/11] bag loss: 0.6460\n",
            " Training bag [5/11] bag loss: 0.6461\n",
            " Training bag [6/11] bag loss: 0.6414\n",
            " Training bag [7/11] bag loss: 0.6406\n",
            " Training bag [8/11] bag loss: 0.7029\n",
            " Training bag [9/11] bag loss: 0.6295\n",
            " Training bag [10/11] bag loss: 0.6367\n",
            " Testing bag [0/5] bag loss: 0.7085\n",
            " Testing bag [1/5] bag loss: 0.6430\n",
            " Testing bag [2/5] bag loss: 0.6459\n",
            " Testing bag [3/5] bag loss: 0.6392\n",
            " Testing bag [4/5] bag loss: 0.6405ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [14/300] train loss: 0.6559 test loss: 0.6554, average score: 0.2000, AUC: class-0>>0.33333333333333337|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6989\n",
            " Training bag [1/11] bag loss: 0.6281\n",
            " Training bag [2/11] bag loss: 0.6416\n",
            " Training bag [3/11] bag loss: 0.6273\n",
            " Training bag [4/11] bag loss: 0.6387\n",
            " Training bag [5/11] bag loss: 0.7033\n",
            " Training bag [6/11] bag loss: 0.7041\n",
            " Training bag [7/11] bag loss: 0.6399\n",
            " Training bag [8/11] bag loss: 0.6389\n",
            " Training bag [9/11] bag loss: 0.6380\n",
            " Training bag [10/11] bag loss: 0.6341\n",
            " Testing bag [0/5] bag loss: 0.7080\n",
            " Testing bag [1/5] bag loss: 0.6413\n",
            " Testing bag [2/5] bag loss: 0.6438\n",
            " Testing bag [3/5] bag loss: 0.6387\n",
            " Testing bag [4/5] bag loss: 0.6386ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [15/300] train loss: 0.6539 test loss: 0.6541, average score: 0.2000, AUC: class-0>>0.33333333333333337|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7045\n",
            " Training bag [1/11] bag loss: 0.6357\n",
            " Training bag [2/11] bag loss: 0.6353\n",
            " Training bag [3/11] bag loss: 0.6329\n",
            " Training bag [4/11] bag loss: 0.6312\n",
            " Training bag [5/11] bag loss: 0.6245\n",
            " Training bag [6/11] bag loss: 0.6279\n",
            " Training bag [7/11] bag loss: 0.6405\n",
            " Training bag [8/11] bag loss: 0.6370\n",
            " Training bag [9/11] bag loss: 0.7086\n",
            " Training bag [10/11] bag loss: 0.7100\n",
            " Testing bag [0/5] bag loss: 0.7124\n",
            " Testing bag [1/5] bag loss: 0.6356\n",
            " Testing bag [2/5] bag loss: 0.6392\n",
            " Testing bag [3/5] bag loss: 0.6352\n",
            " Testing bag [4/5] bag loss: 0.6351ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [16/300] train loss: 0.6535 test loss: 0.6515, average score: 0.2000, AUC: class-0>>0.33333333333333337|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6328\n",
            " Training bag [1/11] bag loss: 0.7066\n",
            " Training bag [2/11] bag loss: 0.6297\n",
            " Training bag [3/11] bag loss: 0.6215\n",
            " Training bag [4/11] bag loss: 0.6315\n",
            " Training bag [5/11] bag loss: 0.7024\n",
            " Training bag [6/11] bag loss: 0.6396\n",
            " Training bag [7/11] bag loss: 0.7046\n",
            " Training bag [8/11] bag loss: 0.6366\n",
            " Training bag [9/11] bag loss: 0.6190\n",
            " Training bag [10/11] bag loss: 0.6334\n",
            " Testing bag [0/5] bag loss: 0.7104\n",
            " Testing bag [1/5] bag loss: 0.6369\n",
            " Testing bag [2/5] bag loss: 0.6406\n",
            " Testing bag [3/5] bag loss: 0.6332\n",
            " Testing bag [4/5] bag loss: 0.6338ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [17/300] train loss: 0.6507 test loss: 0.6510, average score: 0.2000, AUC: class-0>>0.33333333333333337|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6271\n",
            " Training bag [1/11] bag loss: 0.7055\n",
            " Training bag [2/11] bag loss: 0.7014\n",
            " Training bag [3/11] bag loss: 0.6321\n",
            " Training bag [4/11] bag loss: 0.6245\n",
            " Training bag [5/11] bag loss: 0.7020\n",
            " Training bag [6/11] bag loss: 0.6370\n",
            " Training bag [7/11] bag loss: 0.6227\n",
            " Training bag [8/11] bag loss: 0.6340\n",
            " Training bag [9/11] bag loss: 0.6326\n",
            " Training bag [10/11] bag loss: 0.6331\n",
            " Testing bag [0/5] bag loss: 0.7102\n",
            " Testing bag [1/5] bag loss: 0.6351\n",
            " Testing bag [2/5] bag loss: 0.6393\n",
            " Testing bag [3/5] bag loss: 0.6328\n",
            " Testing bag [4/5] bag loss: 0.6325ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [18/300] train loss: 0.6502 test loss: 0.6500, average score: 0.2000, AUC: class-0>>0.33333333333333337|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6261\n",
            " Training bag [1/11] bag loss: 0.6305\n",
            " Training bag [2/11] bag loss: 0.6220\n",
            " Training bag [3/11] bag loss: 0.6330\n",
            " Training bag [4/11] bag loss: 0.7053\n",
            " Training bag [5/11] bag loss: 0.7077\n",
            " Training bag [6/11] bag loss: 0.7076\n",
            " Training bag [7/11] bag loss: 0.6269\n",
            " Training bag [8/11] bag loss: 0.6193\n",
            " Training bag [9/11] bag loss: 0.6293\n",
            " Training bag [10/11] bag loss: 0.6295\n",
            " Testing bag [0/5] bag loss: 0.7115\n",
            " Testing bag [1/5] bag loss: 0.6326\n",
            " Testing bag [2/5] bag loss: 0.6372\n",
            " Testing bag [3/5] bag loss: 0.6304\n",
            " Testing bag [4/5] bag loss: 0.6318ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [19/300] train loss: 0.6488 test loss: 0.6487, average score: 0.2000, AUC: class-0>>0.33333333333333337|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6293\n",
            " Training bag [1/11] bag loss: 0.7065\n",
            " Training bag [2/11] bag loss: 0.7042\n",
            " Training bag [3/11] bag loss: 0.6121\n",
            " Training bag [4/11] bag loss: 0.6246\n",
            " Training bag [5/11] bag loss: 0.6990\n",
            " Training bag [6/11] bag loss: 0.6091\n",
            " Training bag [7/11] bag loss: 0.6354\n",
            " Training bag [8/11] bag loss: 0.6361\n",
            " Training bag [9/11] bag loss: 0.6292\n",
            " Training bag [10/11] bag loss: 0.6336\n",
            " Testing bag [0/5] bag loss: 0.7109\n",
            " Testing bag [1/5] bag loss: 0.6332\n",
            " Testing bag [2/5] bag loss: 0.6379\n",
            " Testing bag [3/5] bag loss: 0.6262\n",
            " Testing bag [4/5] bag loss: 0.6276ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [20/300] train loss: 0.6472 test loss: 0.6472, average score: 0.2000, AUC: class-0>>0.33333333333333337|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6229\n",
            " Training bag [1/11] bag loss: 0.6275\n",
            " Training bag [2/11] bag loss: 0.6244\n",
            " Training bag [3/11] bag loss: 0.6268\n",
            " Training bag [4/11] bag loss: 0.6126\n",
            " Training bag [5/11] bag loss: 0.7089\n",
            " Training bag [6/11] bag loss: 0.7118\n",
            " Training bag [7/11] bag loss: 0.6264\n",
            " Training bag [8/11] bag loss: 0.6078\n",
            " Training bag [9/11] bag loss: 0.6244\n",
            " Training bag [10/11] bag loss: 0.7113\n",
            " Testing bag [0/5] bag loss: 0.7148\n",
            " Testing bag [1/5] bag loss: 0.6284\n",
            " Testing bag [2/5] bag loss: 0.6330\n",
            " Testing bag [3/5] bag loss: 0.6261\n",
            " Testing bag [4/5] bag loss: 0.6275ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [21/300] train loss: 0.6459 test loss: 0.6460, average score: 0.2000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6089\n",
            " Training bag [1/11] bag loss: 0.6205\n",
            " Training bag [2/11] bag loss: 0.6088\n",
            " Training bag [3/11] bag loss: 0.6201\n",
            " Training bag [4/11] bag loss: 0.7104\n",
            " Training bag [5/11] bag loss: 0.6279\n",
            " Training bag [6/11] bag loss: 0.6289\n",
            " Training bag [7/11] bag loss: 0.7103\n",
            " Training bag [8/11] bag loss: 0.7036\n",
            " Training bag [9/11] bag loss: 0.6305\n",
            " Training bag [10/11] bag loss: 0.6213\n",
            " Testing bag [0/5] bag loss: 0.7137\n",
            " Testing bag [1/5] bag loss: 0.6302\n",
            " Testing bag [2/5] bag loss: 0.6342\n",
            " Testing bag [3/5] bag loss: 0.6256\n",
            " Testing bag [4/5] bag loss: 0.6251ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [22/300] train loss: 0.6446 test loss: 0.6458, average score: 0.2000, AUC: class-0>>0.33333333333333337|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7001\n",
            " Training bag [1/11] bag loss: 0.6188\n",
            " Training bag [2/11] bag loss: 0.6211\n",
            " Training bag [3/11] bag loss: 0.6199\n",
            " Training bag [4/11] bag loss: 0.6296\n",
            " Training bag [5/11] bag loss: 0.6268\n",
            " Training bag [6/11] bag loss: 0.6141\n",
            " Training bag [7/11] bag loss: 0.7095\n",
            " Training bag [8/11] bag loss: 0.7089\n",
            " Training bag [9/11] bag loss: 0.6078\n",
            " Training bag [10/11] bag loss: 0.6197\n",
            " Testing bag [0/5] bag loss: 0.7138\n",
            " Testing bag [1/5] bag loss: 0.6265\n",
            " Testing bag [2/5] bag loss: 0.6315\n",
            " Testing bag [3/5] bag loss: 0.6268\n",
            " Testing bag [4/5] bag loss: 0.6266ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [23/300] train loss: 0.6433 test loss: 0.6450, average score: 0.2000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6221\n",
            " Training bag [1/11] bag loss: 0.7068\n",
            " Training bag [2/11] bag loss: 0.6085\n",
            " Training bag [3/11] bag loss: 0.6140\n",
            " Training bag [4/11] bag loss: 0.6189\n",
            " Training bag [5/11] bag loss: 0.7027\n",
            " Training bag [6/11] bag loss: 0.7064\n",
            " Training bag [7/11] bag loss: 0.6120\n",
            " Training bag [8/11] bag loss: 0.6161\n",
            " Training bag [9/11] bag loss: 0.6252\n",
            " Training bag [10/11] bag loss: 0.6262\n",
            " Testing bag [0/5] bag loss: 0.7128\n",
            " Testing bag [1/5] bag loss: 0.6233\n",
            " Testing bag [2/5] bag loss: 0.6289\n",
            " Testing bag [3/5] bag loss: 0.6270\n",
            " Testing bag [4/5] bag loss: 0.6286ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [24/300] train loss: 0.6417 test loss: 0.6441, average score: 0.2000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6994\n",
            " Training bag [1/11] bag loss: 0.6136\n",
            " Training bag [2/11] bag loss: 0.7042\n",
            " Training bag [3/11] bag loss: 0.6088\n",
            " Training bag [4/11] bag loss: 0.6078\n",
            " Training bag [5/11] bag loss: 0.6219\n",
            " Training bag [6/11] bag loss: 0.6249\n",
            " Training bag [7/11] bag loss: 0.6166\n",
            " Training bag [8/11] bag loss: 0.6212\n",
            " Training bag [9/11] bag loss: 0.7077\n",
            " Training bag [10/11] bag loss: 0.6209\n",
            " Testing bag [0/5] bag loss: 0.7149\n",
            " Testing bag [1/5] bag loss: 0.6262\n",
            " Testing bag [2/5] bag loss: 0.6309\n",
            " Testing bag [3/5] bag loss: 0.6230\n",
            " Testing bag [4/5] bag loss: 0.6229ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [25/300] train loss: 0.6406 test loss: 0.6436, average score: 0.2000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7065\n",
            " Training bag [1/11] bag loss: 0.6168\n",
            " Training bag [2/11] bag loss: 0.6021\n",
            " Training bag [3/11] bag loss: 0.7060\n",
            " Training bag [4/11] bag loss: 0.6031\n",
            " Training bag [5/11] bag loss: 0.6161\n",
            " Training bag [6/11] bag loss: 0.6226\n",
            " Training bag [7/11] bag loss: 0.6237\n",
            " Training bag [8/11] bag loss: 0.7025\n",
            " Training bag [9/11] bag loss: 0.6232\n",
            " Training bag [10/11] bag loss: 0.6165\n",
            " Testing bag [0/5] bag loss: 0.7143\n",
            " Testing bag [1/5] bag loss: 0.6262\n",
            " Testing bag [2/5] bag loss: 0.6307\n",
            " Testing bag [3/5] bag loss: 0.6214\n",
            " Testing bag [4/5] bag loss: 0.6209ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [26/300] train loss: 0.6399 test loss: 0.6427, average score: 0.2000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6175\n",
            " Training bag [1/11] bag loss: 0.6163\n",
            " Training bag [2/11] bag loss: 0.7038\n",
            " Training bag [3/11] bag loss: 0.6179\n",
            " Training bag [4/11] bag loss: 0.7064\n",
            " Training bag [5/11] bag loss: 0.6127\n",
            " Training bag [6/11] bag loss: 0.6033\n",
            " Training bag [7/11] bag loss: 0.7071\n",
            " Training bag [8/11] bag loss: 0.6099\n",
            " Training bag [9/11] bag loss: 0.6210\n",
            " Training bag [10/11] bag loss: 0.6106\n",
            " Testing bag [0/5] bag loss: 0.7146\n",
            " Testing bag [1/5] bag loss: 0.6230\n",
            " Testing bag [2/5] bag loss: 0.6274\n",
            " Testing bag [3/5] bag loss: 0.6231\n",
            " Testing bag [4/5] bag loss: 0.6230ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [27/300] train loss: 0.6388 test loss: 0.6422, average score: 0.2000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5991\n",
            " Training bag [1/11] bag loss: 0.7031\n",
            " Training bag [2/11] bag loss: 0.7065\n",
            " Training bag [3/11] bag loss: 0.6122\n",
            " Training bag [4/11] bag loss: 0.7043\n",
            " Training bag [5/11] bag loss: 0.6137\n",
            " Training bag [6/11] bag loss: 0.6180\n",
            " Training bag [7/11] bag loss: 0.6212\n",
            " Training bag [8/11] bag loss: 0.6226\n",
            " Training bag [9/11] bag loss: 0.6164\n",
            " Training bag [10/11] bag loss: 0.6006\n",
            " Testing bag [0/5] bag loss: 0.7138\n",
            " Testing bag [1/5] bag loss: 0.6203\n",
            " Testing bag [2/5] bag loss: 0.6258\n",
            " Testing bag [3/5] bag loss: 0.6228\n",
            " Testing bag [4/5] bag loss: 0.6242ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [28/300] train loss: 0.6380 test loss: 0.6414, average score: 0.2000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7069\n",
            " Training bag [1/11] bag loss: 0.6143\n",
            " Training bag [2/11] bag loss: 0.6081\n",
            " Training bag [3/11] bag loss: 0.6066\n",
            " Training bag [4/11] bag loss: 0.6203\n",
            " Training bag [5/11] bag loss: 0.7042\n",
            " Training bag [6/11] bag loss: 0.6164\n",
            " Training bag [7/11] bag loss: 0.6111\n",
            " Training bag [8/11] bag loss: 0.6168\n",
            " Training bag [9/11] bag loss: 0.5990\n",
            " Training bag [10/11] bag loss: 0.7091\n",
            " Testing bag [0/5] bag loss: 0.7170\n",
            " Testing bag [1/5] bag loss: 0.6185\n",
            " Testing bag [2/5] bag loss: 0.6248\n",
            " Testing bag [3/5] bag loss: 0.6194\n",
            " Testing bag [4/5] bag loss: 0.6206ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [29/300] train loss: 0.6375 test loss: 0.6401, average score: 0.2000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6121\n",
            " Training bag [1/11] bag loss: 0.6070\n",
            " Training bag [2/11] bag loss: 0.6105\n",
            " Training bag [3/11] bag loss: 0.7105\n",
            " Training bag [4/11] bag loss: 0.7095\n",
            " Training bag [5/11] bag loss: 0.6030\n",
            " Training bag [6/11] bag loss: 0.6190\n",
            " Training bag [7/11] bag loss: 0.7030\n",
            " Training bag [8/11] bag loss: 0.6202\n",
            " Training bag [9/11] bag loss: 0.6055\n",
            " Training bag [10/11] bag loss: 0.5971\n",
            " Testing bag [0/5] bag loss: 0.7160\n",
            " Testing bag [1/5] bag loss: 0.6195\n",
            " Testing bag [2/5] bag loss: 0.6251\n",
            " Testing bag [3/5] bag loss: 0.6194\n",
            " Testing bag [4/5] bag loss: 0.6220ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [30/300] train loss: 0.6361 test loss: 0.6404, average score: 0.2000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5984\n",
            " Training bag [1/11] bag loss: 0.7105\n",
            " Training bag [2/11] bag loss: 0.6131\n",
            " Training bag [3/11] bag loss: 0.6145\n",
            " Training bag [4/11] bag loss: 0.5910\n",
            " Training bag [5/11] bag loss: 0.7012\n",
            " Training bag [6/11] bag loss: 0.6064\n",
            " Training bag [7/11] bag loss: 0.6171\n",
            " Training bag [8/11] bag loss: 0.6170\n",
            " Training bag [9/11] bag loss: 0.7101\n",
            " Training bag [10/11] bag loss: 0.6082\n",
            " Testing bag [0/5] bag loss: 0.7162\n",
            " Testing bag [1/5] bag loss: 0.6205\n",
            " Testing bag [2/5] bag loss: 0.6258\n",
            " Testing bag [3/5] bag loss: 0.6169\n",
            " Testing bag [4/5] bag loss: 0.6183ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [31/300] train loss: 0.6352 test loss: 0.6395, average score: 0.2000, AUC: class-0>>0.33333333333333337|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6145\n",
            " Training bag [1/11] bag loss: 0.5952\n",
            " Training bag [2/11] bag loss: 0.5923\n",
            " Training bag [3/11] bag loss: 0.7135\n",
            " Training bag [4/11] bag loss: 0.7049\n",
            " Training bag [5/11] bag loss: 0.7073\n",
            " Training bag [6/11] bag loss: 0.6169\n",
            " Training bag [7/11] bag loss: 0.6083\n",
            " Training bag [8/11] bag loss: 0.6137\n",
            " Training bag [9/11] bag loss: 0.6053\n",
            " Training bag [10/11] bag loss: 0.6163\n",
            " Testing bag [0/5] bag loss: 0.7166\n",
            " Testing bag [1/5] bag loss: 0.6180\n",
            " Testing bag [2/5] bag loss: 0.6233\n",
            " Testing bag [3/5] bag loss: 0.6184\n",
            " Testing bag [4/5] bag loss: 0.6224ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [32/300] train loss: 0.6353 test loss: 0.6398, average score: 0.2000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6093\n",
            " Training bag [1/11] bag loss: 0.7093\n",
            " Training bag [2/11] bag loss: 0.7055\n",
            " Training bag [3/11] bag loss: 0.6137\n",
            " Training bag [4/11] bag loss: 0.6991\n",
            " Training bag [5/11] bag loss: 0.6090\n",
            " Training bag [6/11] bag loss: 0.6050\n",
            " Training bag [7/11] bag loss: 0.6099\n",
            " Training bag [8/11] bag loss: 0.5971\n",
            " Training bag [9/11] bag loss: 0.6192\n",
            " Training bag [10/11] bag loss: 0.6030\n",
            " Testing bag [0/5] bag loss: 0.7152\n",
            " Testing bag [1/5] bag loss: 0.6150\n",
            " Testing bag [2/5] bag loss: 0.6222\n",
            " Testing bag [3/5] bag loss: 0.6189\n",
            " Testing bag [4/5] bag loss: 0.6205ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [33/300] train loss: 0.6346 test loss: 0.6384, average score: 0.2000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6114\n",
            " Training bag [1/11] bag loss: 0.6028\n",
            " Training bag [2/11] bag loss: 0.6106\n",
            " Training bag [3/11] bag loss: 0.7136\n",
            " Training bag [4/11] bag loss: 0.7095\n",
            " Training bag [5/11] bag loss: 0.6099\n",
            " Training bag [6/11] bag loss: 0.5924\n",
            " Training bag [7/11] bag loss: 0.7029\n",
            " Training bag [8/11] bag loss: 0.6146\n",
            " Training bag [9/11] bag loss: 0.6055\n",
            " Training bag [10/11] bag loss: 0.5901\n",
            " Testing bag [0/5] bag loss: 0.7182\n",
            " Testing bag [1/5] bag loss: 0.6174\n",
            " Testing bag [2/5] bag loss: 0.6219\n",
            " Testing bag [3/5] bag loss: 0.6155\n",
            " Testing bag [4/5] bag loss: 0.6196ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [34/300] train loss: 0.6330 test loss: 0.6385, average score: 0.2000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6089\n",
            " Training bag [1/11] bag loss: 0.6109\n",
            " Training bag [2/11] bag loss: 0.7052\n",
            " Training bag [3/11] bag loss: 0.6132\n",
            " Training bag [4/11] bag loss: 0.6049\n",
            " Training bag [5/11] bag loss: 0.7084\n",
            " Training bag [6/11] bag loss: 0.5871\n",
            " Training bag [7/11] bag loss: 0.5885\n",
            " Training bag [8/11] bag loss: 0.6082\n",
            " Training bag [9/11] bag loss: 0.7105\n",
            " Training bag [10/11] bag loss: 0.6042\n",
            " Testing bag [0/5] bag loss: 0.7187\n",
            " Testing bag [1/5] bag loss: 0.6171\n",
            " Testing bag [2/5] bag loss: 0.6223\n",
            " Testing bag [3/5] bag loss: 0.6129\n",
            " Testing bag [4/5] bag loss: 0.6161ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [35/300] train loss: 0.6318 test loss: 0.6374, average score: 0.2000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7093\n",
            " Training bag [1/11] bag loss: 0.7085\n",
            " Training bag [2/11] bag loss: 0.6986\n",
            " Training bag [3/11] bag loss: 0.6105\n",
            " Training bag [4/11] bag loss: 0.6048\n",
            " Training bag [5/11] bag loss: 0.5888\n",
            " Training bag [6/11] bag loss: 0.5903\n",
            " Training bag [7/11] bag loss: 0.6096\n",
            " Training bag [8/11] bag loss: 0.6124\n",
            " Training bag [9/11] bag loss: 0.6144\n",
            " Training bag [10/11] bag loss: 0.6123\n",
            " Testing bag [0/5] bag loss: 0.7181\n",
            " Testing bag [1/5] bag loss: 0.6189\n",
            " Testing bag [2/5] bag loss: 0.6235\n",
            " Testing bag [3/5] bag loss: 0.6124\n",
            " Testing bag [4/5] bag loss: 0.6164ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [36/300] train loss: 0.6327 test loss: 0.6379, average score: 0.2000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6038\n",
            " Training bag [1/11] bag loss: 0.7092\n",
            " Training bag [2/11] bag loss: 0.6069\n",
            " Training bag [3/11] bag loss: 0.7094\n",
            " Training bag [4/11] bag loss: 0.5858\n",
            " Training bag [5/11] bag loss: 0.6044\n",
            " Training bag [6/11] bag loss: 0.5872\n",
            " Training bag [7/11] bag loss: 0.6084\n",
            " Training bag [8/11] bag loss: 0.6000\n",
            " Training bag [9/11] bag loss: 0.7068\n",
            " Training bag [10/11] bag loss: 0.6114\n",
            " Testing bag [0/5] bag loss: 0.7208\n",
            " Testing bag [1/5] bag loss: 0.6136\n",
            " Testing bag [2/5] bag loss: 0.6191\n",
            " Testing bag [3/5] bag loss: 0.6160\n",
            " Testing bag [4/5] bag loss: 0.6191ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [37/300] train loss: 0.6303 test loss: 0.6377, average score: 0.4000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.5\n",
            "Best model saved at: weights/20250626/fold_0_19.pth\n",
            "Best thresholds ===>>> class-0>>0.3767702877521515|class-1>>0.2820131778717041|class-2>>0.3700646758079529\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7104\n",
            " Training bag [1/11] bag loss: 0.5842\n",
            " Training bag [2/11] bag loss: 0.5997\n",
            " Training bag [3/11] bag loss: 0.6002\n",
            " Training bag [4/11] bag loss: 0.7010\n",
            " Training bag [5/11] bag loss: 0.6107\n",
            " Training bag [6/11] bag loss: 0.7070\n",
            " Training bag [7/11] bag loss: 0.5883\n",
            " Training bag [8/11] bag loss: 0.6058\n",
            " Training bag [9/11] bag loss: 0.6080\n",
            " Training bag [10/11] bag loss: 0.6093\n",
            " Testing bag [0/5] bag loss: 0.7191\n",
            " Testing bag [1/5] bag loss: 0.6157\n",
            " Testing bag [2/5] bag loss: 0.6199\n",
            " Testing bag [3/5] bag loss: 0.6116\n",
            " Testing bag [4/5] bag loss: 0.6158ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [38/300] train loss: 0.6295 test loss: 0.6364, average score: 0.2000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6050\n",
            " Training bag [1/11] bag loss: 0.5882\n",
            " Training bag [2/11] bag loss: 0.6074\n",
            " Training bag [3/11] bag loss: 0.5801\n",
            " Training bag [4/11] bag loss: 0.6064\n",
            " Training bag [5/11] bag loss: 0.6006\n",
            " Training bag [6/11] bag loss: 0.5996\n",
            " Training bag [7/11] bag loss: 0.7192\n",
            " Training bag [8/11] bag loss: 0.5952\n",
            " Training bag [9/11] bag loss: 0.7125\n",
            " Training bag [10/11] bag loss: 0.7169\n",
            " Testing bag [0/5] bag loss: 0.7248\n",
            " Testing bag [1/5] bag loss: 0.6123\n",
            " Testing bag [2/5] bag loss: 0.6170\n",
            " Testing bag [3/5] bag loss: 0.6103\n",
            " Testing bag [4/5] bag loss: 0.6142ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [39/300] train loss: 0.6301 test loss: 0.6357, average score: 0.2000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5805\n",
            " Training bag [1/11] bag loss: 0.6053\n",
            " Training bag [2/11] bag loss: 0.7136\n",
            " Training bag [3/11] bag loss: 0.6051\n",
            " Training bag [4/11] bag loss: 0.7120\n",
            " Training bag [5/11] bag loss: 0.6001\n",
            " Training bag [6/11] bag loss: 0.6029\n",
            " Training bag [7/11] bag loss: 0.6044\n",
            " Training bag [8/11] bag loss: 0.7044\n",
            " Training bag [9/11] bag loss: 0.5975\n",
            " Training bag [10/11] bag loss: 0.5852\n",
            " Testing bag [0/5] bag loss: 0.7203\n",
            " Testing bag [1/5] bag loss: 0.6111\n",
            " Testing bag [2/5] bag loss: 0.6182\n",
            " Testing bag [3/5] bag loss: 0.6120\n",
            " Testing bag [4/5] bag loss: 0.6163ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [40/300] train loss: 0.6283 test loss: 0.6356, average score: 0.4000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6013\n",
            " Training bag [1/11] bag loss: 0.5868\n",
            " Training bag [2/11] bag loss: 0.5940\n",
            " Training bag [3/11] bag loss: 0.6014\n",
            " Training bag [4/11] bag loss: 0.7140\n",
            " Training bag [5/11] bag loss: 0.5818\n",
            " Training bag [6/11] bag loss: 0.6090\n",
            " Training bag [7/11] bag loss: 0.6037\n",
            " Training bag [8/11] bag loss: 0.7163\n",
            " Training bag [9/11] bag loss: 0.5952\n",
            " Training bag [10/11] bag loss: 0.7087\n",
            " Testing bag [0/5] bag loss: 0.7234\n",
            " Testing bag [1/5] bag loss: 0.6110\n",
            " Testing bag [2/5] bag loss: 0.6177\n",
            " Testing bag [3/5] bag loss: 0.6106\n",
            " Testing bag [4/5] bag loss: 0.6151ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [41/300] train loss: 0.6284 test loss: 0.6356, average score: 0.2000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5769\n",
            " Training bag [1/11] bag loss: 0.6054\n",
            " Training bag [2/11] bag loss: 0.6019\n",
            " Training bag [3/11] bag loss: 0.7109\n",
            " Training bag [4/11] bag loss: 0.6019\n",
            " Training bag [5/11] bag loss: 0.7126\n",
            " Training bag [6/11] bag loss: 0.7055\n",
            " Training bag [7/11] bag loss: 0.5957\n",
            " Training bag [8/11] bag loss: 0.5967\n",
            " Training bag [9/11] bag loss: 0.6070\n",
            " Training bag [10/11] bag loss: 0.5902\n",
            " Testing bag [0/5] bag loss: 0.7192\n",
            " Testing bag [1/5] bag loss: 0.6098\n",
            " Testing bag [2/5] bag loss: 0.6181\n",
            " Testing bag [3/5] bag loss: 0.6133\n",
            " Testing bag [4/5] bag loss: 0.6179ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [42/300] train loss: 0.6277 test loss: 0.6356, average score: 0.4000, AUC: class-0>>0.33333333333333337|class-1>>0.75|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5996\n",
            " Training bag [1/11] bag loss: 0.5786\n",
            " Training bag [2/11] bag loss: 0.6015\n",
            " Training bag [3/11] bag loss: 0.7080\n",
            " Training bag [4/11] bag loss: 0.6032\n",
            " Training bag [5/11] bag loss: 0.6031\n",
            " Training bag [6/11] bag loss: 0.7116\n",
            " Training bag [7/11] bag loss: 0.5951\n",
            " Training bag [8/11] bag loss: 0.7120\n",
            " Training bag [9/11] bag loss: 0.5989\n",
            " Training bag [10/11] bag loss: 0.5851\n",
            " Testing bag [0/5] bag loss: 0.7216\n",
            " Testing bag [1/5] bag loss: 0.6105\n",
            " Testing bag [2/5] bag loss: 0.6174\n",
            " Testing bag [3/5] bag loss: 0.6077\n",
            " Testing bag [4/5] bag loss: 0.6169ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [43/300] train loss: 0.6270 test loss: 0.6348, average score: 0.2000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6022\n",
            " Training bag [1/11] bag loss: 0.5753\n",
            " Training bag [2/11] bag loss: 0.5759\n",
            " Training bag [3/11] bag loss: 0.6011\n",
            " Training bag [4/11] bag loss: 0.5996\n",
            " Training bag [5/11] bag loss: 0.5978\n",
            " Training bag [6/11] bag loss: 0.7163\n",
            " Training bag [7/11] bag loss: 0.5961\n",
            " Training bag [8/11] bag loss: 0.6039\n",
            " Training bag [9/11] bag loss: 0.7122\n",
            " Training bag [10/11] bag loss: 0.7180\n",
            " Testing bag [0/5] bag loss: 0.7250\n",
            " Testing bag [1/5] bag loss: 0.6099\n",
            " Testing bag [2/5] bag loss: 0.6147\n",
            " Testing bag [3/5] bag loss: 0.6073\n",
            " Testing bag [4/5] bag loss: 0.6140ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [44/300] train loss: 0.6271 test loss: 0.6342, average score: 0.2000, AUC: class-0>>0.33333333333333337|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5741\n",
            " Training bag [1/11] bag loss: 0.5994\n",
            " Training bag [2/11] bag loss: 0.7137\n",
            " Training bag [3/11] bag loss: 0.5922\n",
            " Training bag [4/11] bag loss: 0.5819\n",
            " Training bag [5/11] bag loss: 0.7104\n",
            " Training bag [6/11] bag loss: 0.6053\n",
            " Training bag [7/11] bag loss: 0.7015\n",
            " Training bag [8/11] bag loss: 0.6018\n",
            " Training bag [9/11] bag loss: 0.6002\n",
            " Training bag [10/11] bag loss: 0.5944\n",
            " Testing bag [0/5] bag loss: 0.7213\n",
            " Testing bag [1/5] bag loss: 0.6109\n",
            " Testing bag [2/5] bag loss: 0.6177\n",
            " Testing bag [3/5] bag loss: 0.6080\n",
            " Testing bag [4/5] bag loss: 0.6152ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [45/300] train loss: 0.6250 test loss: 0.6346, average score: 0.2000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7074\n",
            " Training bag [1/11] bag loss: 0.5997\n",
            " Training bag [2/11] bag loss: 0.6058\n",
            " Training bag [3/11] bag loss: 0.5926\n",
            " Training bag [4/11] bag loss: 0.7117\n",
            " Training bag [5/11] bag loss: 0.6988\n",
            " Training bag [6/11] bag loss: 0.5906\n",
            " Training bag [7/11] bag loss: 0.5966\n",
            " Training bag [8/11] bag loss: 0.5902\n",
            " Training bag [9/11] bag loss: 0.6065\n",
            " Training bag [10/11] bag loss: 0.5774\n",
            " Testing bag [0/5] bag loss: 0.7213\n",
            " Testing bag [1/5] bag loss: 0.6085\n",
            " Testing bag [2/5] bag loss: 0.6151\n",
            " Testing bag [3/5] bag loss: 0.6082\n",
            " Testing bag [4/5] bag loss: 0.6174ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [46/300] train loss: 0.6252 test loss: 0.6341, average score: 0.2000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5839\n",
            " Training bag [1/11] bag loss: 0.5904\n",
            " Training bag [2/11] bag loss: 0.5980\n",
            " Training bag [3/11] bag loss: 0.7141\n",
            " Training bag [4/11] bag loss: 0.7147\n",
            " Training bag [5/11] bag loss: 0.6008\n",
            " Training bag [6/11] bag loss: 0.7028\n",
            " Training bag [7/11] bag loss: 0.5959\n",
            " Training bag [8/11] bag loss: 0.5706\n",
            " Training bag [9/11] bag loss: 0.6046\n",
            " Training bag [10/11] bag loss: 0.6032\n",
            " Testing bag [0/5] bag loss: 0.7209\n",
            " Testing bag [1/5] bag loss: 0.6119\n",
            " Testing bag [2/5] bag loss: 0.6189\n",
            " Testing bag [3/5] bag loss: 0.6051\n",
            " Testing bag [4/5] bag loss: 0.6137ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [47/300] train loss: 0.6254 test loss: 0.6341, average score: 0.2000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5906\n",
            " Training bag [1/11] bag loss: 0.5904\n",
            " Training bag [2/11] bag loss: 0.5930\n",
            " Training bag [3/11] bag loss: 0.7148\n",
            " Training bag [4/11] bag loss: 0.7097\n",
            " Training bag [5/11] bag loss: 0.7005\n",
            " Training bag [6/11] bag loss: 0.6069\n",
            " Training bag [7/11] bag loss: 0.6097\n",
            " Training bag [8/11] bag loss: 0.5855\n",
            " Training bag [9/11] bag loss: 0.5733\n",
            " Training bag [10/11] bag loss: 0.6012\n",
            " Testing bag [0/5] bag loss: 0.7214\n",
            " Testing bag [1/5] bag loss: 0.6097\n",
            " Testing bag [2/5] bag loss: 0.6173\n",
            " Testing bag [3/5] bag loss: 0.6061\n",
            " Testing bag [4/5] bag loss: 0.6139ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.16666666666666669\n",
            "\n",
            " Epoch [48/300] train loss: 0.6250 test loss: 0.6337, average score: 0.2000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.16666666666666669\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7000\n",
            " Training bag [1/11] bag loss: 0.5714\n",
            " Training bag [2/11] bag loss: 0.5988\n",
            " Training bag [3/11] bag loss: 0.5748\n",
            " Training bag [4/11] bag loss: 0.5931\n",
            " Training bag [5/11] bag loss: 0.5902\n",
            " Training bag [6/11] bag loss: 0.5979\n",
            " Training bag [7/11] bag loss: 0.5990\n",
            " Training bag [8/11] bag loss: 0.7187\n",
            " Training bag [9/11] bag loss: 0.7136\n",
            " Training bag [10/11] bag loss: 0.5972\n",
            " Testing bag [0/5] bag loss: 0.7241\n",
            " Testing bag [1/5] bag loss: 0.6093\n",
            " Testing bag [2/5] bag loss: 0.6176\n",
            " Testing bag [3/5] bag loss: 0.6078\n",
            " Testing bag [4/5] bag loss: 0.6128ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.16666666666666669\n",
            "\n",
            " Epoch [49/300] train loss: 0.6231 test loss: 0.6343, average score: 0.2000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.16666666666666669\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5718\n",
            " Training bag [1/11] bag loss: 0.7022\n",
            " Training bag [2/11] bag loss: 0.5952\n",
            " Training bag [3/11] bag loss: 0.5996\n",
            " Training bag [4/11] bag loss: 0.7112\n",
            " Training bag [5/11] bag loss: 0.5926\n",
            " Training bag [6/11] bag loss: 0.7108\n",
            " Training bag [7/11] bag loss: 0.5703\n",
            " Training bag [8/11] bag loss: 0.6008\n",
            " Training bag [9/11] bag loss: 0.5988\n",
            " Training bag [10/11] bag loss: 0.5957\n",
            " Testing bag [0/5] bag loss: 0.7235\n",
            " Testing bag [1/5] bag loss: 0.6110\n",
            " Testing bag [2/5] bag loss: 0.6180\n",
            " Testing bag [3/5] bag loss: 0.6028\n",
            " Testing bag [4/5] bag loss: 0.6117ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.16666666666666669\n",
            "\n",
            " Epoch [50/300] train loss: 0.6226 test loss: 0.6334, average score: 0.2000, AUC: class-0>>0.33333333333333337|class-1>>0.75|class-2>>0.16666666666666669\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7133\n",
            " Training bag [1/11] bag loss: 0.5682\n",
            " Training bag [2/11] bag loss: 0.5990\n",
            " Training bag [3/11] bag loss: 0.5978\n",
            " Training bag [4/11] bag loss: 0.7036\n",
            " Training bag [5/11] bag loss: 0.7089\n",
            " Training bag [6/11] bag loss: 0.6005\n",
            " Training bag [7/11] bag loss: 0.5907\n",
            " Training bag [8/11] bag loss: 0.5933\n",
            " Training bag [9/11] bag loss: 0.5819\n",
            " Training bag [10/11] bag loss: 0.6006\n",
            " Testing bag [0/5] bag loss: 0.7225\n",
            " Testing bag [1/5] bag loss: 0.6051\n",
            " Testing bag [2/5] bag loss: 0.6114\n",
            " Testing bag [3/5] bag loss: 0.6059\n",
            " Testing bag [4/5] bag loss: 0.6147ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [51/300] train loss: 0.6234 test loss: 0.6319, average score: 0.2000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5875\n",
            " Training bag [1/11] bag loss: 0.7130\n",
            " Training bag [2/11] bag loss: 0.5690\n",
            " Training bag [3/11] bag loss: 0.6007\n",
            " Training bag [4/11] bag loss: 0.5867\n",
            " Training bag [5/11] bag loss: 0.5765\n",
            " Training bag [6/11] bag loss: 0.5983\n",
            " Training bag [7/11] bag loss: 0.7114\n",
            " Training bag [8/11] bag loss: 0.5925\n",
            " Training bag [9/11] bag loss: 0.5957\n",
            " Training bag [10/11] bag loss: 0.7043\n",
            " Testing bag [0/5] bag loss: 0.7265\n",
            " Testing bag [1/5] bag loss: 0.6063\n",
            " Testing bag [2/5] bag loss: 0.6116\n",
            " Testing bag [3/5] bag loss: 0.6059\n",
            " Testing bag [4/5] bag loss: 0.6114ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [52/300] train loss: 0.6214 test loss: 0.6323, average score: 0.2000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5955\n",
            " Training bag [1/11] bag loss: 0.5981\n",
            " Training bag [2/11] bag loss: 0.7115\n",
            " Training bag [3/11] bag loss: 0.5865\n",
            " Training bag [4/11] bag loss: 0.5893\n",
            " Training bag [5/11] bag loss: 0.5666\n",
            " Training bag [6/11] bag loss: 0.7163\n",
            " Training bag [7/11] bag loss: 0.7029\n",
            " Training bag [8/11] bag loss: 0.6017\n",
            " Training bag [9/11] bag loss: 0.5741\n",
            " Training bag [10/11] bag loss: 0.5885\n",
            " Testing bag [0/5] bag loss: 0.7232\n",
            " Testing bag [1/5] bag loss: 0.6070\n",
            " Testing bag [2/5] bag loss: 0.6160\n",
            " Testing bag [3/5] bag loss: 0.6042\n",
            " Testing bag [4/5] bag loss: 0.6131ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [53/300] train loss: 0.6210 test loss: 0.6327, average score: 0.4000, AUC: class-0>>0.33333333333333337|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5660\n",
            " Training bag [1/11] bag loss: 0.5727\n",
            " Training bag [2/11] bag loss: 0.7125\n",
            " Training bag [3/11] bag loss: 0.5882\n",
            " Training bag [4/11] bag loss: 0.5974\n",
            " Training bag [5/11] bag loss: 0.7050\n",
            " Training bag [6/11] bag loss: 0.7138\n",
            " Training bag [7/11] bag loss: 0.5937\n",
            " Training bag [8/11] bag loss: 0.5961\n",
            " Training bag [9/11] bag loss: 0.5960\n",
            " Training bag [10/11] bag loss: 0.5951\n",
            " Testing bag [0/5] bag loss: 0.7241\n",
            " Testing bag [1/5] bag loss: 0.6040\n",
            " Testing bag [2/5] bag loss: 0.6145\n",
            " Testing bag [3/5] bag loss: 0.6041\n",
            " Testing bag [4/5] bag loss: 0.6123ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [54/300] train loss: 0.6215 test loss: 0.6318, average score: 0.4000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7028\n",
            " Training bag [1/11] bag loss: 0.5643\n",
            " Training bag [2/11] bag loss: 0.5866\n",
            " Training bag [3/11] bag loss: 0.7115\n",
            " Training bag [4/11] bag loss: 0.5945\n",
            " Training bag [5/11] bag loss: 0.5970\n",
            " Training bag [6/11] bag loss: 0.5859\n",
            " Training bag [7/11] bag loss: 0.7054\n",
            " Training bag [8/11] bag loss: 0.5917\n",
            " Training bag [9/11] bag loss: 0.5778\n",
            " Training bag [10/11] bag loss: 0.6026\n",
            " Testing bag [0/5] bag loss: 0.7245\n",
            " Testing bag [1/5] bag loss: 0.6042\n",
            " Testing bag [2/5] bag loss: 0.6109\n",
            " Testing bag [3/5] bag loss: 0.6037\n",
            " Testing bag [4/5] bag loss: 0.6145ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [55/300] train loss: 0.6200 test loss: 0.6316, average score: 0.4000, AUC: class-0>>0.33333333333333337|class-1>>0.75|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5750\n",
            " Training bag [1/11] bag loss: 0.5941\n",
            " Training bag [2/11] bag loss: 0.5989\n",
            " Training bag [3/11] bag loss: 0.5825\n",
            " Training bag [4/11] bag loss: 0.7088\n",
            " Training bag [5/11] bag loss: 0.5609\n",
            " Training bag [6/11] bag loss: 0.5900\n",
            " Training bag [7/11] bag loss: 0.5919\n",
            " Training bag [8/11] bag loss: 0.5949\n",
            " Training bag [9/11] bag loss: 0.7159\n",
            " Training bag [10/11] bag loss: 0.7195\n",
            " Testing bag [0/5] bag loss: 0.7290\n",
            " Testing bag [1/5] bag loss: 0.6041\n",
            " Testing bag [2/5] bag loss: 0.6135\n",
            " Testing bag [3/5] bag loss: 0.6041\n",
            " Testing bag [4/5] bag loss: 0.6117ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [56/300] train loss: 0.6211 test loss: 0.6325, average score: 0.4000, AUC: class-0>>0.33333333333333337|class-1>>0.75|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7158\n",
            " Training bag [1/11] bag loss: 0.7048\n",
            " Training bag [2/11] bag loss: 0.5948\n",
            " Training bag [3/11] bag loss: 0.7051\n",
            " Training bag [4/11] bag loss: 0.5889\n",
            " Training bag [5/11] bag loss: 0.5634\n",
            " Training bag [6/11] bag loss: 0.5987\n",
            " Training bag [7/11] bag loss: 0.5973\n",
            " Training bag [8/11] bag loss: 0.5946\n",
            " Training bag [9/11] bag loss: 0.5899\n",
            " Training bag [10/11] bag loss: 0.5711\n",
            " Testing bag [0/5] bag loss: 0.7252\n",
            " Testing bag [1/5] bag loss: 0.6038\n",
            " Testing bag [2/5] bag loss: 0.6106\n",
            " Testing bag [3/5] bag loss: 0.6039\n",
            " Testing bag [4/5] bag loss: 0.6129ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [57/300] train loss: 0.6204 test loss: 0.6313, average score: 0.2000, AUC: class-0>>0.33333333333333337|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5830\n",
            " Training bag [1/11] bag loss: 0.5618\n",
            " Training bag [2/11] bag loss: 0.7073\n",
            " Training bag [3/11] bag loss: 0.5971\n",
            " Training bag [4/11] bag loss: 0.5896\n",
            " Training bag [5/11] bag loss: 0.5680\n",
            " Training bag [6/11] bag loss: 0.5839\n",
            " Training bag [7/11] bag loss: 0.7123\n",
            " Training bag [8/11] bag loss: 0.5909\n",
            " Training bag [9/11] bag loss: 0.5924\n",
            " Training bag [10/11] bag loss: 0.7189\n",
            " Testing bag [0/5] bag loss: 0.7280\n",
            " Testing bag [1/5] bag loss: 0.6035\n",
            " Testing bag [2/5] bag loss: 0.6096\n",
            " Testing bag [3/5] bag loss: 0.6007\n",
            " Testing bag [4/5] bag loss: 0.6120ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [58/300] train loss: 0.6187 test loss: 0.6308, average score: 0.4000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7181\n",
            " Training bag [1/11] bag loss: 0.5839\n",
            " Training bag [2/11] bag loss: 0.5620\n",
            " Training bag [3/11] bag loss: 0.5676\n",
            " Training bag [4/11] bag loss: 0.5956\n",
            " Training bag [5/11] bag loss: 0.7021\n",
            " Training bag [6/11] bag loss: 0.7069\n",
            " Training bag [7/11] bag loss: 0.5887\n",
            " Training bag [8/11] bag loss: 0.5976\n",
            " Training bag [9/11] bag loss: 0.5912\n",
            " Training bag [10/11] bag loss: 0.5933\n",
            " Testing bag [0/5] bag loss: 0.7252\n",
            " Testing bag [1/5] bag loss: 0.6069\n",
            " Testing bag [2/5] bag loss: 0.6138\n",
            " Testing bag [3/5] bag loss: 0.5994\n",
            " Testing bag [4/5] bag loss: 0.6109ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [59/300] train loss: 0.6188 test loss: 0.6312, average score: 0.4000, AUC: class-0>>0.33333333333333337|class-1>>0.75|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5848\n",
            " Training bag [1/11] bag loss: 0.7045\n",
            " Training bag [2/11] bag loss: 0.7129\n",
            " Training bag [3/11] bag loss: 0.5909\n",
            " Training bag [4/11] bag loss: 0.5610\n",
            " Training bag [5/11] bag loss: 0.5732\n",
            " Training bag [6/11] bag loss: 0.7078\n",
            " Training bag [7/11] bag loss: 0.5934\n",
            " Training bag [8/11] bag loss: 0.5946\n",
            " Training bag [9/11] bag loss: 0.5943\n",
            " Training bag [10/11] bag loss: 0.5872\n",
            " Testing bag [0/5] bag loss: 0.7254\n",
            " Testing bag [1/5] bag loss: 0.6048\n",
            " Testing bag [2/5] bag loss: 0.6155\n",
            " Testing bag [3/5] bag loss: 0.5999\n",
            " Testing bag [4/5] bag loss: 0.6094ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [60/300] train loss: 0.6186 test loss: 0.6310, average score: 0.4000, AUC: class-0>>0.33333333333333337|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5568\n",
            " Training bag [1/11] bag loss: 0.5631\n",
            " Training bag [2/11] bag loss: 0.7073\n",
            " Training bag [3/11] bag loss: 0.5873\n",
            " Training bag [4/11] bag loss: 0.5867\n",
            " Training bag [5/11] bag loss: 0.5945\n",
            " Training bag [6/11] bag loss: 0.7167\n",
            " Training bag [7/11] bag loss: 0.5939\n",
            " Training bag [8/11] bag loss: 0.7093\n",
            " Training bag [9/11] bag loss: 0.5935\n",
            " Training bag [10/11] bag loss: 0.5924\n",
            " Testing bag [0/5] bag loss: 0.7269\n",
            " Testing bag [1/5] bag loss: 0.6052\n",
            " Testing bag [2/5] bag loss: 0.6133\n",
            " Testing bag [3/5] bag loss: 0.6000\n",
            " Testing bag [4/5] bag loss: 0.6085ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.16666666666666669\n",
            "\n",
            " Epoch [61/300] train loss: 0.6183 test loss: 0.6308, average score: 0.2000, AUC: class-0>>0.33333333333333337|class-1>>0.75|class-2>>0.16666666666666669\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5932\n",
            " Training bag [1/11] bag loss: 0.5820\n",
            " Training bag [2/11] bag loss: 0.5920\n",
            " Training bag [3/11] bag loss: 0.7095\n",
            " Training bag [4/11] bag loss: 0.5883\n",
            " Training bag [5/11] bag loss: 0.5579\n",
            " Training bag [6/11] bag loss: 0.5691\n",
            " Training bag [7/11] bag loss: 0.7188\n",
            " Training bag [8/11] bag loss: 0.5834\n",
            " Training bag [9/11] bag loss: 0.7057\n",
            " Training bag [10/11] bag loss: 0.5977\n",
            " Testing bag [0/5] bag loss: 0.7265\n",
            " Testing bag [1/5] bag loss: 0.6023\n",
            " Testing bag [2/5] bag loss: 0.6119\n",
            " Testing bag [3/5] bag loss: 0.6030\n",
            " Testing bag [4/5] bag loss: 0.6120ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [62/300] train loss: 0.6180 test loss: 0.6312, average score: 0.4000, AUC: class-0>>0.33333333333333337|class-1>>0.75|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5886\n",
            " Training bag [1/11] bag loss: 0.5791\n",
            " Training bag [2/11] bag loss: 0.5937\n",
            " Training bag [3/11] bag loss: 0.5770\n",
            " Training bag [4/11] bag loss: 0.5665\n",
            " Training bag [5/11] bag loss: 0.7134\n",
            " Training bag [6/11] bag loss: 0.7205\n",
            " Training bag [7/11] bag loss: 0.5951\n",
            " Training bag [8/11] bag loss: 0.5559\n",
            " Training bag [9/11] bag loss: 0.7075\n",
            " Training bag [10/11] bag loss: 0.5889\n",
            " Testing bag [0/5] bag loss: 0.7277\n",
            " Testing bag [1/5] bag loss: 0.6046\n",
            " Testing bag [2/5] bag loss: 0.6145\n",
            " Testing bag [3/5] bag loss: 0.6013\n",
            " Testing bag [4/5] bag loss: 0.6100ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [63/300] train loss: 0.6169 test loss: 0.6316, average score: 0.4000, AUC: class-0>>0.33333333333333337|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5893\n",
            " Training bag [1/11] bag loss: 0.5922\n",
            " Training bag [2/11] bag loss: 0.5769\n",
            " Training bag [3/11] bag loss: 0.5940\n",
            " Training bag [4/11] bag loss: 0.7070\n",
            " Training bag [5/11] bag loss: 0.5593\n",
            " Training bag [6/11] bag loss: 0.5741\n",
            " Training bag [7/11] bag loss: 0.7187\n",
            " Training bag [8/11] bag loss: 0.7101\n",
            " Training bag [9/11] bag loss: 0.5983\n",
            " Training bag [10/11] bag loss: 0.5685\n",
            " Testing bag [0/5] bag loss: 0.7259\n",
            " Testing bag [1/5] bag loss: 0.6018\n",
            " Testing bag [2/5] bag loss: 0.6123\n",
            " Testing bag [3/5] bag loss: 0.5985\n",
            " Testing bag [4/5] bag loss: 0.6123ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [64/300] train loss: 0.6171 test loss: 0.6302, average score: 0.4000, AUC: class-0>>0.33333333333333337|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5843\n",
            " Training bag [1/11] bag loss: 0.5966\n",
            " Training bag [2/11] bag loss: 0.5539\n",
            " Training bag [3/11] bag loss: 0.5902\n",
            " Training bag [4/11] bag loss: 0.5780\n",
            " Training bag [5/11] bag loss: 0.5637\n",
            " Training bag [6/11] bag loss: 0.7112\n",
            " Training bag [7/11] bag loss: 0.7126\n",
            " Training bag [8/11] bag loss: 0.5763\n",
            " Training bag [9/11] bag loss: 0.7183\n",
            " Training bag [10/11] bag loss: 0.5910\n",
            " Testing bag [0/5] bag loss: 0.7275\n",
            " Testing bag [1/5] bag loss: 0.6017\n",
            " Testing bag [2/5] bag loss: 0.6124\n",
            " Testing bag [3/5] bag loss: 0.5982\n",
            " Testing bag [4/5] bag loss: 0.6117ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [65/300] train loss: 0.6160 test loss: 0.6303, average score: 0.4000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5540\n",
            " Training bag [1/11] bag loss: 0.5945\n",
            " Training bag [2/11] bag loss: 0.5832\n",
            " Training bag [3/11] bag loss: 0.5938\n",
            " Training bag [4/11] bag loss: 0.5765\n",
            " Training bag [5/11] bag loss: 0.7066\n",
            " Training bag [6/11] bag loss: 0.5844\n",
            " Training bag [7/11] bag loss: 0.5893\n",
            " Training bag [8/11] bag loss: 0.7203\n",
            " Training bag [9/11] bag loss: 0.5643\n",
            " Training bag [10/11] bag loss: 0.7106\n",
            " Testing bag [0/5] bag loss: 0.7301\n",
            " Testing bag [1/5] bag loss: 0.6009\n",
            " Testing bag [2/5] bag loss: 0.6120\n",
            " Testing bag [3/5] bag loss: 0.6015\n",
            " Testing bag [4/5] bag loss: 0.6119ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [66/300] train loss: 0.6161 test loss: 0.6313, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5781\n",
            " Training bag [1/11] bag loss: 0.5582\n",
            " Training bag [2/11] bag loss: 0.5887\n",
            " Training bag [3/11] bag loss: 0.7092\n",
            " Training bag [4/11] bag loss: 0.5865\n",
            " Training bag [5/11] bag loss: 0.5960\n",
            " Training bag [6/11] bag loss: 0.5534\n",
            " Training bag [7/11] bag loss: 0.7203\n",
            " Training bag [8/11] bag loss: 0.5781\n",
            " Training bag [9/11] bag loss: 0.7088\n",
            " Training bag [10/11] bag loss: 0.5890\n",
            " Testing bag [0/5] bag loss: 0.7279\n",
            " Testing bag [1/5] bag loss: 0.6019\n",
            " Testing bag [2/5] bag loss: 0.6119\n",
            " Testing bag [3/5] bag loss: 0.5997\n",
            " Testing bag [4/5] bag loss: 0.6115ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [67/300] train loss: 0.6151 test loss: 0.6306, average score: 0.4000, AUC: class-0>>0.33333333333333337|class-1>>0.75|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5930\n",
            " Training bag [1/11] bag loss: 0.7104\n",
            " Training bag [2/11] bag loss: 0.7140\n",
            " Training bag [3/11] bag loss: 0.5797\n",
            " Training bag [4/11] bag loss: 0.6991\n",
            " Training bag [5/11] bag loss: 0.5946\n",
            " Training bag [6/11] bag loss: 0.5810\n",
            " Training bag [7/11] bag loss: 0.5673\n",
            " Training bag [8/11] bag loss: 0.5929\n",
            " Training bag [9/11] bag loss: 0.5536\n",
            " Training bag [10/11] bag loss: 0.5867\n",
            " Testing bag [0/5] bag loss: 0.7280\n",
            " Testing bag [1/5] bag loss: 0.6033\n",
            " Testing bag [2/5] bag loss: 0.6107\n",
            " Testing bag [3/5] bag loss: 0.6005\n",
            " Testing bag [4/5] bag loss: 0.6092ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [68/300] train loss: 0.6157 test loss: 0.6303, average score: 0.4000, AUC: class-0>>0.33333333333333337|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5876\n",
            " Training bag [1/11] bag loss: 0.5923\n",
            " Training bag [2/11] bag loss: 0.5787\n",
            " Training bag [3/11] bag loss: 0.7104\n",
            " Training bag [4/11] bag loss: 0.5735\n",
            " Training bag [5/11] bag loss: 0.5640\n",
            " Training bag [6/11] bag loss: 0.5815\n",
            " Training bag [7/11] bag loss: 0.5941\n",
            " Training bag [8/11] bag loss: 0.5503\n",
            " Training bag [9/11] bag loss: 0.7232\n",
            " Training bag [10/11] bag loss: 0.7073\n",
            " Testing bag [0/5] bag loss: 0.7316\n",
            " Testing bag [1/5] bag loss: 0.6007\n",
            " Testing bag [2/5] bag loss: 0.6121\n",
            " Testing bag [3/5] bag loss: 0.5948\n",
            " Testing bag [4/5] bag loss: 0.6105ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [69/300] train loss: 0.6148 test loss: 0.6299, average score: 0.4000, AUC: class-0>>0.33333333333333337|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5491\n",
            " Training bag [1/11] bag loss: 0.5595\n",
            " Training bag [2/11] bag loss: 0.5820\n",
            " Training bag [3/11] bag loss: 0.5871\n",
            " Training bag [4/11] bag loss: 0.5911\n",
            " Training bag [5/11] bag loss: 0.5774\n",
            " Training bag [6/11] bag loss: 0.7240\n",
            " Training bag [7/11] bag loss: 0.7057\n",
            " Training bag [8/11] bag loss: 0.7106\n",
            " Training bag [9/11] bag loss: 0.5766\n",
            " Training bag [10/11] bag loss: 0.5937\n",
            " Testing bag [0/5] bag loss: 0.7294\n",
            " Testing bag [1/5] bag loss: 0.6009\n",
            " Testing bag [2/5] bag loss: 0.6105\n",
            " Testing bag [3/5] bag loss: 0.5963\n",
            " Testing bag [4/5] bag loss: 0.6110ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [70/300] train loss: 0.6143 test loss: 0.6296, average score: 0.4000, AUC: class-0>>0.33333333333333337|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5861\n",
            " Training bag [1/11] bag loss: 0.5880\n",
            " Training bag [2/11] bag loss: 0.7013\n",
            " Training bag [3/11] bag loss: 0.5774\n",
            " Training bag [4/11] bag loss: 0.7081\n",
            " Training bag [5/11] bag loss: 0.5561\n",
            " Training bag [6/11] bag loss: 0.5766\n",
            " Training bag [7/11] bag loss: 0.5486\n",
            " Training bag [8/11] bag loss: 0.7160\n",
            " Training bag [9/11] bag loss: 0.5905\n",
            " Training bag [10/11] bag loss: 0.5934\n",
            " Testing bag [0/5] bag loss: 0.7284\n",
            " Testing bag [1/5] bag loss: 0.5995\n",
            " Testing bag [2/5] bag loss: 0.6127\n",
            " Testing bag [3/5] bag loss: 0.5979\n",
            " Testing bag [4/5] bag loss: 0.6108ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [71/300] train loss: 0.6129 test loss: 0.6299, average score: 0.4000, AUC: class-0>>0.33333333333333337|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5482\n",
            " Training bag [1/11] bag loss: 0.5551\n",
            " Training bag [2/11] bag loss: 0.7061\n",
            " Training bag [3/11] bag loss: 0.5791\n",
            " Training bag [4/11] bag loss: 0.5808\n",
            " Training bag [5/11] bag loss: 0.5885\n",
            " Training bag [6/11] bag loss: 0.7176\n",
            " Training bag [7/11] bag loss: 0.7102\n",
            " Training bag [8/11] bag loss: 0.5861\n",
            " Training bag [9/11] bag loss: 0.5940\n",
            " Training bag [10/11] bag loss: 0.5870\n",
            " Testing bag [0/5] bag loss: 0.7274\n",
            " Testing bag [1/5] bag loss: 0.6016\n",
            " Testing bag [2/5] bag loss: 0.6124\n",
            " Testing bag [3/5] bag loss: 0.5962\n",
            " Testing bag [4/5] bag loss: 0.6116ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [72/300] train loss: 0.6139 test loss: 0.6299, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5914\n",
            " Training bag [1/11] bag loss: 0.5867\n",
            " Training bag [2/11] bag loss: 0.5771\n",
            " Training bag [3/11] bag loss: 0.5439\n",
            " Training bag [4/11] bag loss: 0.5480\n",
            " Training bag [5/11] bag loss: 0.5925\n",
            " Training bag [6/11] bag loss: 0.7113\n",
            " Training bag [7/11] bag loss: 0.7212\n",
            " Training bag [8/11] bag loss: 0.7095\n",
            " Training bag [9/11] bag loss: 0.5870\n",
            " Training bag [10/11] bag loss: 0.5850\n",
            " Testing bag [0/5] bag loss: 0.7277\n",
            " Testing bag [1/5] bag loss: 0.6014\n",
            " Testing bag [2/5] bag loss: 0.6130\n",
            " Testing bag [3/5] bag loss: 0.5948\n",
            " Testing bag [4/5] bag loss: 0.6092ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [73/300] train loss: 0.6140 test loss: 0.6292, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5781\n",
            " Training bag [1/11] bag loss: 0.5823\n",
            " Training bag [2/11] bag loss: 0.5787\n",
            " Training bag [3/11] bag loss: 0.7016\n",
            " Training bag [4/11] bag loss: 0.7069\n",
            " Training bag [5/11] bag loss: 0.5650\n",
            " Training bag [6/11] bag loss: 0.5523\n",
            " Training bag [7/11] bag loss: 0.5818\n",
            " Training bag [8/11] bag loss: 0.7163\n",
            " Training bag [9/11] bag loss: 0.5950\n",
            " Training bag [10/11] bag loss: 0.5898\n",
            " Testing bag [0/5] bag loss: 0.7292\n",
            " Testing bag [1/5] bag loss: 0.6012\n",
            " Testing bag [2/5] bag loss: 0.6073\n",
            " Testing bag [3/5] bag loss: 0.6000\n",
            " Testing bag [4/5] bag loss: 0.6127ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [74/300] train loss: 0.6134 test loss: 0.6301, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6980\n",
            " Training bag [1/11] bag loss: 0.5567\n",
            " Training bag [2/11] bag loss: 0.5922\n",
            " Training bag [3/11] bag loss: 0.5782\n",
            " Training bag [4/11] bag loss: 0.7097\n",
            " Training bag [5/11] bag loss: 0.5823\n",
            " Training bag [6/11] bag loss: 0.7162\n",
            " Training bag [7/11] bag loss: 0.5918\n",
            " Training bag [8/11] bag loss: 0.5467\n",
            " Training bag [9/11] bag loss: 0.5876\n",
            " Training bag [10/11] bag loss: 0.5874\n",
            " Testing bag [0/5] bag loss: 0.7294\n",
            " Testing bag [1/5] bag loss: 0.6011\n",
            " Testing bag [2/5] bag loss: 0.6100\n",
            " Testing bag [3/5] bag loss: 0.5963\n",
            " Testing bag [4/5] bag loss: 0.6118ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [75/300] train loss: 0.6134 test loss: 0.6297, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5724\n",
            " Training bag [1/11] bag loss: 0.5853\n",
            " Training bag [2/11] bag loss: 0.5706\n",
            " Training bag [3/11] bag loss: 0.5484\n",
            " Training bag [4/11] bag loss: 0.5757\n",
            " Training bag [5/11] bag loss: 0.7112\n",
            " Training bag [6/11] bag loss: 0.5966\n",
            " Training bag [7/11] bag loss: 0.5901\n",
            " Training bag [8/11] bag loss: 0.7208\n",
            " Training bag [9/11] bag loss: 0.5598\n",
            " Training bag [10/11] bag loss: 0.7055\n",
            " Testing bag [0/5] bag loss: 0.7317\n",
            " Testing bag [1/5] bag loss: 0.6001\n",
            " Testing bag [2/5] bag loss: 0.6070\n",
            " Testing bag [3/5] bag loss: 0.5987\n",
            " Testing bag [4/5] bag loss: 0.6079ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [76/300] train loss: 0.6124 test loss: 0.6291, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7058\n",
            " Training bag [1/11] bag loss: 0.7079\n",
            " Training bag [2/11] bag loss: 0.5846\n",
            " Training bag [3/11] bag loss: 0.5748\n",
            " Training bag [4/11] bag loss: 0.5602\n",
            " Training bag [5/11] bag loss: 0.5883\n",
            " Training bag [6/11] bag loss: 0.5807\n",
            " Training bag [7/11] bag loss: 0.5454\n",
            " Training bag [8/11] bag loss: 0.5897\n",
            " Training bag [9/11] bag loss: 0.5870\n",
            " Training bag [10/11] bag loss: 0.7183\n",
            " Testing bag [0/5] bag loss: 0.7297\n",
            " Testing bag [1/5] bag loss: 0.6009\n",
            " Testing bag [2/5] bag loss: 0.6089\n",
            " Testing bag [3/5] bag loss: 0.5957\n",
            " Testing bag [4/5] bag loss: 0.6072ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [77/300] train loss: 0.6130 test loss: 0.6285, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7101\n",
            " Training bag [1/11] bag loss: 0.7007\n",
            " Training bag [2/11] bag loss: 0.5725\n",
            " Training bag [3/11] bag loss: 0.5454\n",
            " Training bag [4/11] bag loss: 0.5823\n",
            " Training bag [5/11] bag loss: 0.7124\n",
            " Training bag [6/11] bag loss: 0.5552\n",
            " Training bag [7/11] bag loss: 0.5874\n",
            " Training bag [8/11] bag loss: 0.5871\n",
            " Training bag [9/11] bag loss: 0.5920\n",
            " Training bag [10/11] bag loss: 0.5751\n",
            " Testing bag [0/5] bag loss: 0.7291\n",
            " Testing bag [1/5] bag loss: 0.6003\n",
            " Testing bag [2/5] bag loss: 0.6120\n",
            " Testing bag [3/5] bag loss: 0.5975\n",
            " Testing bag [4/5] bag loss: 0.6106ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [78/300] train loss: 0.6109 test loss: 0.6299, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5835\n",
            " Training bag [1/11] bag loss: 0.5788\n",
            " Training bag [2/11] bag loss: 0.5471\n",
            " Training bag [3/11] bag loss: 0.5855\n",
            " Training bag [4/11] bag loss: 0.7222\n",
            " Training bag [5/11] bag loss: 0.5823\n",
            " Training bag [6/11] bag loss: 0.7042\n",
            " Training bag [7/11] bag loss: 0.5725\n",
            " Training bag [8/11] bag loss: 0.7066\n",
            " Training bag [9/11] bag loss: 0.5874\n",
            " Training bag [10/11] bag loss: 0.5435\n",
            " Testing bag [0/5] bag loss: 0.7306\n",
            " Testing bag [1/5] bag loss: 0.5991\n",
            " Testing bag [2/5] bag loss: 0.6124\n",
            " Testing bag [3/5] bag loss: 0.5927\n",
            " Testing bag [4/5] bag loss: 0.6098ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [79/300] train loss: 0.6103 test loss: 0.6289, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5718\n",
            " Training bag [1/11] bag loss: 0.7097\n",
            " Training bag [2/11] bag loss: 0.5929\n",
            " Training bag [3/11] bag loss: 0.5439\n",
            " Training bag [4/11] bag loss: 0.6982\n",
            " Training bag [5/11] bag loss: 0.7163\n",
            " Training bag [6/11] bag loss: 0.5500\n",
            " Training bag [7/11] bag loss: 0.5766\n",
            " Training bag [8/11] bag loss: 0.5852\n",
            " Training bag [9/11] bag loss: 0.5865\n",
            " Training bag [10/11] bag loss: 0.5850\n",
            " Testing bag [0/5] bag loss: 0.7305\n",
            " Testing bag [1/5] bag loss: 0.5983\n",
            " Testing bag [2/5] bag loss: 0.6080\n",
            " Testing bag [3/5] bag loss: 0.5947\n",
            " Testing bag [4/5] bag loss: 0.6104ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [80/300] train loss: 0.6106 test loss: 0.6284, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5825\n",
            " Training bag [1/11] bag loss: 0.5837\n",
            " Training bag [2/11] bag loss: 0.5733\n",
            " Training bag [3/11] bag loss: 0.7106\n",
            " Training bag [4/11] bag loss: 0.7019\n",
            " Training bag [5/11] bag loss: 0.5802\n",
            " Training bag [6/11] bag loss: 0.5682\n",
            " Training bag [7/11] bag loss: 0.5481\n",
            " Training bag [8/11] bag loss: 0.5965\n",
            " Training bag [9/11] bag loss: 0.7180\n",
            " Training bag [10/11] bag loss: 0.5572\n",
            " Testing bag [0/5] bag loss: 0.7291\n",
            " Testing bag [1/5] bag loss: 0.5980\n",
            " Testing bag [2/5] bag loss: 0.6064\n",
            " Testing bag [3/5] bag loss: 0.5941\n",
            " Testing bag [4/5] bag loss: 0.6094ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [81/300] train loss: 0.6109 test loss: 0.6274, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5412\n",
            " Training bag [1/11] bag loss: 0.5797\n",
            " Training bag [2/11] bag loss: 0.5889\n",
            " Training bag [3/11] bag loss: 0.5809\n",
            " Training bag [4/11] bag loss: 0.5694\n",
            " Training bag [5/11] bag loss: 0.5498\n",
            " Training bag [6/11] bag loss: 0.7104\n",
            " Training bag [7/11] bag loss: 0.7146\n",
            " Training bag [8/11] bag loss: 0.7222\n",
            " Training bag [9/11] bag loss: 0.5899\n",
            " Training bag [10/11] bag loss: 0.5743\n",
            " Testing bag [0/5] bag loss: 0.7320\n",
            " Testing bag [1/5] bag loss: 0.6006\n",
            " Testing bag [2/5] bag loss: 0.6102\n",
            " Testing bag [3/5] bag loss: 0.5915\n",
            " Testing bag [4/5] bag loss: 0.6067ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [82/300] train loss: 0.6110 test loss: 0.6282, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7011\n",
            " Training bag [1/11] bag loss: 0.5798\n",
            " Training bag [2/11] bag loss: 0.5704\n",
            " Training bag [3/11] bag loss: 0.7039\n",
            " Training bag [4/11] bag loss: 0.5828\n",
            " Training bag [5/11] bag loss: 0.5894\n",
            " Training bag [6/11] bag loss: 0.5531\n",
            " Training bag [7/11] bag loss: 0.7171\n",
            " Training bag [8/11] bag loss: 0.5734\n",
            " Training bag [9/11] bag loss: 0.5438\n",
            " Training bag [10/11] bag loss: 0.5930\n",
            " Testing bag [0/5] bag loss: 0.7306\n",
            " Testing bag [1/5] bag loss: 0.5975\n",
            " Testing bag [2/5] bag loss: 0.6090\n",
            " Testing bag [3/5] bag loss: 0.5961\n",
            " Testing bag [4/5] bag loss: 0.6118ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [83/300] train loss: 0.6098 test loss: 0.6290, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5498\n",
            " Training bag [1/11] bag loss: 0.5371\n",
            " Training bag [2/11] bag loss: 0.5749\n",
            " Training bag [3/11] bag loss: 0.5696\n",
            " Training bag [4/11] bag loss: 0.5880\n",
            " Training bag [5/11] bag loss: 0.5779\n",
            " Training bag [6/11] bag loss: 0.7055\n",
            " Training bag [7/11] bag loss: 0.7139\n",
            " Training bag [8/11] bag loss: 0.7197\n",
            " Training bag [9/11] bag loss: 0.5876\n",
            " Training bag [10/11] bag loss: 0.5919\n",
            " Testing bag [0/5] bag loss: 0.7326\n",
            " Testing bag [1/5] bag loss: 0.5962\n",
            " Testing bag [2/5] bag loss: 0.6082\n",
            " Testing bag [3/5] bag loss: 0.5950\n",
            " Testing bag [4/5] bag loss: 0.6130ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [84/300] train loss: 0.6105 test loss: 0.6290, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5838\n",
            " Training bag [1/11] bag loss: 0.7002\n",
            " Training bag [2/11] bag loss: 0.5918\n",
            " Training bag [3/11] bag loss: 0.5789\n",
            " Training bag [4/11] bag loss: 0.5675\n",
            " Training bag [5/11] bag loss: 0.5854\n",
            " Training bag [6/11] bag loss: 0.5741\n",
            " Training bag [7/11] bag loss: 0.5540\n",
            " Training bag [8/11] bag loss: 0.7130\n",
            " Training bag [9/11] bag loss: 0.5375\n",
            " Training bag [10/11] bag loss: 0.7217\n",
            " Testing bag [0/5] bag loss: 0.7343\n",
            " Testing bag [1/5] bag loss: 0.5986\n",
            " Testing bag [2/5] bag loss: 0.6096\n",
            " Testing bag [3/5] bag loss: 0.5944\n",
            " Testing bag [4/5] bag loss: 0.6091ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [85/300] train loss: 0.6098 test loss: 0.6292, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7069\n",
            " Training bag [1/11] bag loss: 0.5835\n",
            " Training bag [2/11] bag loss: 0.5882\n",
            " Training bag [3/11] bag loss: 0.5374\n",
            " Training bag [4/11] bag loss: 0.5481\n",
            " Training bag [5/11] bag loss: 0.5748\n",
            " Training bag [6/11] bag loss: 0.5835\n",
            " Training bag [7/11] bag loss: 0.7207\n",
            " Training bag [8/11] bag loss: 0.7020\n",
            " Training bag [9/11] bag loss: 0.5810\n",
            " Training bag [10/11] bag loss: 0.5726\n",
            " Testing bag [0/5] bag loss: 0.7326\n",
            " Testing bag [1/5] bag loss: 0.5992\n",
            " Testing bag [2/5] bag loss: 0.6108\n",
            " Testing bag [3/5] bag loss: 0.5908\n",
            " Testing bag [4/5] bag loss: 0.6093ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [86/300] train loss: 0.6090 test loss: 0.6285, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5844\n",
            " Training bag [1/11] bag loss: 0.5747\n",
            " Training bag [2/11] bag loss: 0.7178\n",
            " Training bag [3/11] bag loss: 0.7019\n",
            " Training bag [4/11] bag loss: 0.5861\n",
            " Training bag [5/11] bag loss: 0.5791\n",
            " Training bag [6/11] bag loss: 0.5390\n",
            " Training bag [7/11] bag loss: 0.5916\n",
            " Training bag [8/11] bag loss: 0.5678\n",
            " Training bag [9/11] bag loss: 0.7062\n",
            " Training bag [10/11] bag loss: 0.5495\n",
            " Testing bag [0/5] bag loss: 0.7326\n",
            " Testing bag [1/5] bag loss: 0.5980\n",
            " Testing bag [2/5] bag loss: 0.6068\n",
            " Testing bag [3/5] bag loss: 0.5946\n",
            " Testing bag [4/5] bag loss: 0.6121ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [87/300] train loss: 0.6089 test loss: 0.6288, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5784\n",
            " Training bag [1/11] bag loss: 0.7096\n",
            " Training bag [2/11] bag loss: 0.6976\n",
            " Training bag [3/11] bag loss: 0.5403\n",
            " Training bag [4/11] bag loss: 0.5883\n",
            " Training bag [5/11] bag loss: 0.5500\n",
            " Training bag [6/11] bag loss: 0.5899\n",
            " Training bag [7/11] bag loss: 0.5712\n",
            " Training bag [8/11] bag loss: 0.7185\n",
            " Training bag [9/11] bag loss: 0.5686\n",
            " Training bag [10/11] bag loss: 0.5830\n",
            " Testing bag [0/5] bag loss: 0.7296\n",
            " Testing bag [1/5] bag loss: 0.5959\n",
            " Testing bag [2/5] bag loss: 0.6076\n",
            " Testing bag [3/5] bag loss: 0.5922\n",
            " Testing bag [4/5] bag loss: 0.6087ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [88/300] train loss: 0.6087 test loss: 0.6268, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7171\n",
            " Training bag [1/11] bag loss: 0.5841\n",
            " Training bag [2/11] bag loss: 0.7062\n",
            " Training bag [3/11] bag loss: 0.5483\n",
            " Training bag [4/11] bag loss: 0.5815\n",
            " Training bag [5/11] bag loss: 0.5402\n",
            " Training bag [6/11] bag loss: 0.5909\n",
            " Training bag [7/11] bag loss: 0.5800\n",
            " Training bag [8/11] bag loss: 0.5716\n",
            " Training bag [9/11] bag loss: 0.5700\n",
            " Training bag [10/11] bag loss: 0.7043\n",
            " Testing bag [0/5] bag loss: 0.7333\n",
            " Testing bag [1/5] bag loss: 0.6009\n",
            " Testing bag [2/5] bag loss: 0.6103\n",
            " Testing bag [3/5] bag loss: 0.5908\n",
            " Testing bag [4/5] bag loss: 0.6073ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [89/300] train loss: 0.6086 test loss: 0.6285, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5793\n",
            " Training bag [1/11] bag loss: 0.7007\n",
            " Training bag [2/11] bag loss: 0.5482\n",
            " Training bag [3/11] bag loss: 0.5707\n",
            " Training bag [4/11] bag loss: 0.5723\n",
            " Training bag [5/11] bag loss: 0.7089\n",
            " Training bag [6/11] bag loss: 0.5783\n",
            " Training bag [7/11] bag loss: 0.5368\n",
            " Training bag [8/11] bag loss: 0.5812\n",
            " Training bag [9/11] bag loss: 0.7185\n",
            " Training bag [10/11] bag loss: 0.5912\n",
            " Testing bag [0/5] bag loss: 0.7320\n",
            " Testing bag [1/5] bag loss: 0.5962\n",
            " Testing bag [2/5] bag loss: 0.6088\n",
            " Testing bag [3/5] bag loss: 0.5960\n",
            " Testing bag [4/5] bag loss: 0.6115ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [90/300] train loss: 0.6078 test loss: 0.6289, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5826\n",
            " Training bag [1/11] bag loss: 0.5815\n",
            " Training bag [2/11] bag loss: 0.5432\n",
            " Training bag [3/11] bag loss: 0.5676\n",
            " Training bag [4/11] bag loss: 0.5321\n",
            " Training bag [5/11] bag loss: 0.5855\n",
            " Training bag [6/11] bag loss: 0.5714\n",
            " Training bag [7/11] bag loss: 0.7133\n",
            " Training bag [8/11] bag loss: 0.5732\n",
            " Training bag [9/11] bag loss: 0.7240\n",
            " Training bag [10/11] bag loss: 0.7047\n",
            " Testing bag [0/5] bag loss: 0.7362\n",
            " Testing bag [1/5] bag loss: 0.5977\n",
            " Testing bag [2/5] bag loss: 0.6071\n",
            " Testing bag [3/5] bag loss: 0.5889\n",
            " Testing bag [4/5] bag loss: 0.6112ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [91/300] train loss: 0.6072 test loss: 0.6282, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5668\n",
            " Training bag [1/11] bag loss: 0.5659\n",
            " Training bag [2/11] bag loss: 0.7065\n",
            " Training bag [3/11] bag loss: 0.6994\n",
            " Training bag [4/11] bag loss: 0.5862\n",
            " Training bag [5/11] bag loss: 0.5847\n",
            " Training bag [6/11] bag loss: 0.5715\n",
            " Training bag [7/11] bag loss: 0.5388\n",
            " Training bag [8/11] bag loss: 0.5923\n",
            " Training bag [9/11] bag loss: 0.5451\n",
            " Training bag [10/11] bag loss: 0.7201\n",
            " Testing bag [0/5] bag loss: 0.7342\n",
            " Testing bag [1/5] bag loss: 0.5949\n",
            " Testing bag [2/5] bag loss: 0.6092\n",
            " Testing bag [3/5] bag loss: 0.5917\n",
            " Testing bag [4/5] bag loss: 0.6106ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [92/300] train loss: 0.6070 test loss: 0.6281, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5707\n",
            " Training bag [1/11] bag loss: 0.5710\n",
            " Training bag [2/11] bag loss: 0.7067\n",
            " Training bag [3/11] bag loss: 0.7205\n",
            " Training bag [4/11] bag loss: 0.5512\n",
            " Training bag [5/11] bag loss: 0.5643\n",
            " Training bag [6/11] bag loss: 0.6961\n",
            " Training bag [7/11] bag loss: 0.5820\n",
            " Training bag [8/11] bag loss: 0.5930\n",
            " Training bag [9/11] bag loss: 0.5841\n",
            " Training bag [10/11] bag loss: 0.5375\n",
            " Testing bag [0/5] bag loss: 0.7329\n",
            " Testing bag [1/5] bag loss: 0.5942\n",
            " Testing bag [2/5] bag loss: 0.6077\n",
            " Testing bag [3/5] bag loss: 0.5937\n",
            " Testing bag [4/5] bag loss: 0.6094ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [93/300] train loss: 0.6070 test loss: 0.6276, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5819\n",
            " Training bag [1/11] bag loss: 0.7027\n",
            " Training bag [2/11] bag loss: 0.5639\n",
            " Training bag [3/11] bag loss: 0.5866\n",
            " Training bag [4/11] bag loss: 0.5420\n",
            " Training bag [5/11] bag loss: 0.7195\n",
            " Training bag [6/11] bag loss: 0.5788\n",
            " Training bag [7/11] bag loss: 0.5689\n",
            " Training bag [8/11] bag loss: 0.5318\n",
            " Training bag [9/11] bag loss: 0.5853\n",
            " Training bag [10/11] bag loss: 0.7065\n",
            " Testing bag [0/5] bag loss: 0.7356\n",
            " Testing bag [1/5] bag loss: 0.5971\n",
            " Testing bag [2/5] bag loss: 0.6096\n",
            " Testing bag [3/5] bag loss: 0.5904\n",
            " Testing bag [4/5] bag loss: 0.6094ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [94/300] train loss: 0.6062 test loss: 0.6284, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5785\n",
            " Training bag [1/11] bag loss: 0.5704\n",
            " Training bag [2/11] bag loss: 0.5658\n",
            " Training bag [3/11] bag loss: 0.7080\n",
            " Training bag [4/11] bag loss: 0.7054\n",
            " Training bag [5/11] bag loss: 0.5763\n",
            " Training bag [6/11] bag loss: 0.7171\n",
            " Training bag [7/11] bag loss: 0.5777\n",
            " Training bag [8/11] bag loss: 0.5921\n",
            " Training bag [9/11] bag loss: 0.5532\n",
            " Training bag [10/11] bag loss: 0.5353\n",
            " Testing bag [0/5] bag loss: 0.7336\n",
            " Testing bag [1/5] bag loss: 0.5960\n",
            " Testing bag [2/5] bag loss: 0.6059\n",
            " Testing bag [3/5] bag loss: 0.5955\n",
            " Testing bag [4/5] bag loss: 0.6134ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [95/300] train loss: 0.6072 test loss: 0.6289, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5723\n",
            " Training bag [1/11] bag loss: 0.5843\n",
            " Training bag [2/11] bag loss: 0.5883\n",
            " Training bag [3/11] bag loss: 0.5436\n",
            " Training bag [4/11] bag loss: 0.7089\n",
            " Training bag [5/11] bag loss: 0.5791\n",
            " Training bag [6/11] bag loss: 0.7212\n",
            " Training bag [7/11] bag loss: 0.5659\n",
            " Training bag [8/11] bag loss: 0.5277\n",
            " Training bag [9/11] bag loss: 0.5674\n",
            " Training bag [10/11] bag loss: 0.7060\n",
            " Testing bag [0/5] bag loss: 0.7348\n",
            " Testing bag [1/5] bag loss: 0.5952\n",
            " Testing bag [2/5] bag loss: 0.6097\n",
            " Testing bag [3/5] bag loss: 0.5937\n",
            " Testing bag [4/5] bag loss: 0.6095ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [96/300] train loss: 0.6059 test loss: 0.6286, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7101\n",
            " Training bag [1/11] bag loss: 0.7165\n",
            " Training bag [2/11] bag loss: 0.5740\n",
            " Training bag [3/11] bag loss: 0.5829\n",
            " Training bag [4/11] bag loss: 0.6958\n",
            " Training bag [5/11] bag loss: 0.5697\n",
            " Training bag [6/11] bag loss: 0.5334\n",
            " Training bag [7/11] bag loss: 0.5901\n",
            " Training bag [8/11] bag loss: 0.5822\n",
            " Training bag [9/11] bag loss: 0.5467\n",
            " Training bag [10/11] bag loss: 0.5674\n",
            " Testing bag [0/5] bag loss: 0.7349\n",
            " Testing bag [1/5] bag loss: 0.5980\n",
            " Testing bag [2/5] bag loss: 0.6084\n",
            " Testing bag [3/5] bag loss: 0.5945\n",
            " Testing bag [4/5] bag loss: 0.6107ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [97/300] train loss: 0.6062 test loss: 0.6293, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5447\n",
            " Training bag [1/11] bag loss: 0.5703\n",
            " Training bag [2/11] bag loss: 0.7091\n",
            " Training bag [3/11] bag loss: 0.5651\n",
            " Training bag [4/11] bag loss: 0.5284\n",
            " Training bag [5/11] bag loss: 0.5819\n",
            " Training bag [6/11] bag loss: 0.5909\n",
            " Training bag [7/11] bag loss: 0.5782\n",
            " Training bag [8/11] bag loss: 0.7247\n",
            " Training bag [9/11] bag loss: 0.5680\n",
            " Training bag [10/11] bag loss: 0.7020\n",
            " Testing bag [0/5] bag loss: 0.7356\n",
            " Testing bag [1/5] bag loss: 0.5960\n",
            " Testing bag [2/5] bag loss: 0.6068\n",
            " Testing bag [3/5] bag loss: 0.5943\n",
            " Testing bag [4/5] bag loss: 0.6101ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [98/300] train loss: 0.6058 test loss: 0.6286, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5279\n",
            " Training bag [1/11] bag loss: 0.7209\n",
            " Training bag [2/11] bag loss: 0.7077\n",
            " Training bag [3/11] bag loss: 0.5861\n",
            " Training bag [4/11] bag loss: 0.5880\n",
            " Training bag [5/11] bag loss: 0.5668\n",
            " Training bag [6/11] bag loss: 0.6951\n",
            " Training bag [7/11] bag loss: 0.5422\n",
            " Training bag [8/11] bag loss: 0.5769\n",
            " Training bag [9/11] bag loss: 0.5782\n",
            " Training bag [10/11] bag loss: 0.5642\n",
            " Testing bag [0/5] bag loss: 0.7345\n",
            " Testing bag [1/5] bag loss: 0.5965\n",
            " Testing bag [2/5] bag loss: 0.6110\n",
            " Testing bag [3/5] bag loss: 0.5908\n",
            " Testing bag [4/5] bag loss: 0.6099ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [99/300] train loss: 0.6049 test loss: 0.6285, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5627\n",
            " Training bag [1/11] bag loss: 0.7199\n",
            " Training bag [2/11] bag loss: 0.5441\n",
            " Training bag [3/11] bag loss: 0.5709\n",
            " Training bag [4/11] bag loss: 0.5778\n",
            " Training bag [5/11] bag loss: 0.5266\n",
            " Training bag [6/11] bag loss: 0.5834\n",
            " Training bag [7/11] bag loss: 0.7117\n",
            " Training bag [8/11] bag loss: 0.6995\n",
            " Training bag [9/11] bag loss: 0.5871\n",
            " Training bag [10/11] bag loss: 0.5711\n",
            " Testing bag [0/5] bag loss: 0.7342\n",
            " Testing bag [1/5] bag loss: 0.5978\n",
            " Testing bag [2/5] bag loss: 0.6076\n",
            " Testing bag [3/5] bag loss: 0.5886\n",
            " Testing bag [4/5] bag loss: 0.6103ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [100/300] train loss: 0.6050 test loss: 0.6277, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5776\n",
            " Training bag [1/11] bag loss: 0.5635\n",
            " Training bag [2/11] bag loss: 0.5816\n",
            " Training bag [3/11] bag loss: 0.5387\n",
            " Training bag [4/11] bag loss: 0.7229\n",
            " Training bag [5/11] bag loss: 0.5737\n",
            " Training bag [6/11] bag loss: 0.5616\n",
            " Training bag [7/11] bag loss: 0.7075\n",
            " Training bag [8/11] bag loss: 0.7046\n",
            " Training bag [9/11] bag loss: 0.5905\n",
            " Training bag [10/11] bag loss: 0.5302\n",
            " Testing bag [0/5] bag loss: 0.7358\n",
            " Testing bag [1/5] bag loss: 0.5947\n",
            " Testing bag [2/5] bag loss: 0.6063\n",
            " Testing bag [3/5] bag loss: 0.5899\n",
            " Testing bag [4/5] bag loss: 0.6101ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [101/300] train loss: 0.6048 test loss: 0.6274, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5776\n",
            " Training bag [1/11] bag loss: 0.5704\n",
            " Training bag [2/11] bag loss: 0.5604\n",
            " Training bag [3/11] bag loss: 0.5591\n",
            " Training bag [4/11] bag loss: 0.5904\n",
            " Training bag [5/11] bag loss: 0.7054\n",
            " Training bag [6/11] bag loss: 0.5815\n",
            " Training bag [7/11] bag loss: 0.7239\n",
            " Training bag [8/11] bag loss: 0.5401\n",
            " Training bag [9/11] bag loss: 0.7057\n",
            " Training bag [10/11] bag loss: 0.5288\n",
            " Testing bag [0/5] bag loss: 0.7349\n",
            " Testing bag [1/5] bag loss: 0.5955\n",
            " Testing bag [2/5] bag loss: 0.6086\n",
            " Testing bag [3/5] bag loss: 0.5929\n",
            " Testing bag [4/5] bag loss: 0.6094ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [102/300] train loss: 0.6039 test loss: 0.6283, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5623\n",
            " Training bag [1/11] bag loss: 0.5265\n",
            " Training bag [2/11] bag loss: 0.5714\n",
            " Training bag [3/11] bag loss: 0.7062\n",
            " Training bag [4/11] bag loss: 0.7209\n",
            " Training bag [5/11] bag loss: 0.5571\n",
            " Training bag [6/11] bag loss: 0.5902\n",
            " Training bag [7/11] bag loss: 0.5813\n",
            " Training bag [8/11] bag loss: 0.6984\n",
            " Training bag [9/11] bag loss: 0.5837\n",
            " Training bag [10/11] bag loss: 0.5431\n",
            " Testing bag [0/5] bag loss: 0.7356\n",
            " Testing bag [1/5] bag loss: 0.5952\n",
            " Testing bag [2/5] bag loss: 0.6082\n",
            " Testing bag [3/5] bag loss: 0.5908\n",
            " Testing bag [4/5] bag loss: 0.6111ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [103/300] train loss: 0.6037 test loss: 0.6282, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7175\n",
            " Training bag [1/11] bag loss: 0.5843\n",
            " Training bag [2/11] bag loss: 0.5356\n",
            " Training bag [3/11] bag loss: 0.7017\n",
            " Training bag [4/11] bag loss: 0.5623\n",
            " Training bag [5/11] bag loss: 0.6966\n",
            " Training bag [6/11] bag loss: 0.5731\n",
            " Training bag [7/11] bag loss: 0.5818\n",
            " Training bag [8/11] bag loss: 0.5779\n",
            " Training bag [9/11] bag loss: 0.5289\n",
            " Training bag [10/11] bag loss: 0.5648\n",
            " Testing bag [0/5] bag loss: 0.7351\n",
            " Testing bag [1/5] bag loss: 0.5961\n",
            " Testing bag [2/5] bag loss: 0.6077\n",
            " Testing bag [3/5] bag loss: 0.5915\n",
            " Testing bag [4/5] bag loss: 0.6102ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [104/300] train loss: 0.6022 test loss: 0.6281, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7022\n",
            " Training bag [1/11] bag loss: 0.5870\n",
            " Training bag [2/11] bag loss: 0.5771\n",
            " Training bag [3/11] bag loss: 0.5660\n",
            " Training bag [4/11] bag loss: 0.5354\n",
            " Training bag [5/11] bag loss: 0.6984\n",
            " Training bag [6/11] bag loss: 0.5615\n",
            " Training bag [7/11] bag loss: 0.5240\n",
            " Training bag [8/11] bag loss: 0.5853\n",
            " Training bag [9/11] bag loss: 0.7188\n",
            " Training bag [10/11] bag loss: 0.5755\n",
            " Testing bag [0/5] bag loss: 0.7361\n",
            " Testing bag [1/5] bag loss: 0.5974\n",
            " Testing bag [2/5] bag loss: 0.6108\n",
            " Testing bag [3/5] bag loss: 0.5918\n",
            " Testing bag [4/5] bag loss: 0.6089ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [105/300] train loss: 0.6028 test loss: 0.6290, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5741\n",
            " Training bag [1/11] bag loss: 0.5806\n",
            " Training bag [2/11] bag loss: 0.5792\n",
            " Training bag [3/11] bag loss: 0.5874\n",
            " Training bag [4/11] bag loss: 0.5580\n",
            " Training bag [5/11] bag loss: 0.7072\n",
            " Training bag [6/11] bag loss: 0.5586\n",
            " Training bag [7/11] bag loss: 0.5248\n",
            " Training bag [8/11] bag loss: 0.7063\n",
            " Training bag [9/11] bag loss: 0.7227\n",
            " Training bag [10/11] bag loss: 0.5367\n",
            " Testing bag [0/5] bag loss: 0.7373\n",
            " Testing bag [1/5] bag loss: 0.5958\n",
            " Testing bag [2/5] bag loss: 0.6099\n",
            " Testing bag [3/5] bag loss: 0.5930\n",
            " Testing bag [4/5] bag loss: 0.6073ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [106/300] train loss: 0.6032 test loss: 0.6287, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5619\n",
            " Training bag [1/11] bag loss: 0.7031\n",
            " Training bag [2/11] bag loss: 0.6968\n",
            " Training bag [3/11] bag loss: 0.7159\n",
            " Training bag [4/11] bag loss: 0.5259\n",
            " Training bag [5/11] bag loss: 0.5864\n",
            " Training bag [6/11] bag loss: 0.5806\n",
            " Training bag [7/11] bag loss: 0.5720\n",
            " Training bag [8/11] bag loss: 0.5893\n",
            " Training bag [9/11] bag loss: 0.5360\n",
            " Training bag [10/11] bag loss: 0.5624\n",
            " Testing bag [0/5] bag loss: 0.7362\n",
            " Testing bag [1/5] bag loss: 0.5969\n",
            " Testing bag [2/5] bag loss: 0.6102\n",
            " Testing bag [3/5] bag loss: 0.5894\n",
            " Testing bag [4/5] bag loss: 0.6071ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [107/300] train loss: 0.6028 test loss: 0.6279, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5768\n",
            " Training bag [1/11] bag loss: 0.5678\n",
            " Training bag [2/11] bag loss: 0.7032\n",
            " Training bag [3/11] bag loss: 0.7224\n",
            " Training bag [4/11] bag loss: 0.5840\n",
            " Training bag [5/11] bag loss: 0.5716\n",
            " Training bag [6/11] bag loss: 0.5628\n",
            " Training bag [7/11] bag loss: 0.5827\n",
            " Training bag [8/11] bag loss: 0.5352\n",
            " Training bag [9/11] bag loss: 0.5260\n",
            " Training bag [10/11] bag loss: 0.7094\n",
            " Testing bag [0/5] bag loss: 0.7385\n",
            " Testing bag [1/5] bag loss: 0.5954\n",
            " Testing bag [2/5] bag loss: 0.6051\n",
            " Testing bag [3/5] bag loss: 0.5914\n",
            " Testing bag [4/5] bag loss: 0.6106ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [108/300] train loss: 0.6038 test loss: 0.6282, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7055\n",
            " Training bag [1/11] bag loss: 0.5769\n",
            " Training bag [2/11] bag loss: 0.5580\n",
            " Training bag [3/11] bag loss: 0.5376\n",
            " Training bag [4/11] bag loss: 0.5696\n",
            " Training bag [5/11] bag loss: 0.5816\n",
            " Training bag [6/11] bag loss: 0.5866\n",
            " Training bag [7/11] bag loss: 0.5204\n",
            " Training bag [8/11] bag loss: 0.5612\n",
            " Training bag [9/11] bag loss: 0.7241\n",
            " Training bag [10/11] bag loss: 0.7034\n",
            " Testing bag [0/5] bag loss: 0.7395\n",
            " Testing bag [1/5] bag loss: 0.5954\n",
            " Testing bag [2/5] bag loss: 0.6071\n",
            " Testing bag [3/5] bag loss: 0.5865\n",
            " Testing bag [4/5] bag loss: 0.6075ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [109/300] train loss: 0.6023 test loss: 0.6272, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5836\n",
            " Training bag [1/11] bag loss: 0.5637\n",
            " Training bag [2/11] bag loss: 0.5771\n",
            " Training bag [3/11] bag loss: 0.5334\n",
            " Training bag [4/11] bag loss: 0.5644\n",
            " Training bag [5/11] bag loss: 0.5705\n",
            " Training bag [6/11] bag loss: 0.7104\n",
            " Training bag [7/11] bag loss: 0.5759\n",
            " Training bag [8/11] bag loss: 0.5233\n",
            " Training bag [9/11] bag loss: 0.7042\n",
            " Training bag [10/11] bag loss: 0.7249\n",
            " Testing bag [0/5] bag loss: 0.7378\n",
            " Testing bag [1/5] bag loss: 0.5940\n",
            " Testing bag [2/5] bag loss: 0.6082\n",
            " Testing bag [3/5] bag loss: 0.5911\n",
            " Testing bag [4/5] bag loss: 0.6097ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [110/300] train loss: 0.6029 test loss: 0.6282, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5857\n",
            " Training bag [1/11] bag loss: 0.7059\n",
            " Training bag [2/11] bag loss: 0.6962\n",
            " Training bag [3/11] bag loss: 0.5189\n",
            " Training bag [4/11] bag loss: 0.5853\n",
            " Training bag [5/11] bag loss: 0.5627\n",
            " Training bag [6/11] bag loss: 0.5639\n",
            " Training bag [7/11] bag loss: 0.5751\n",
            " Training bag [8/11] bag loss: 0.5381\n",
            " Training bag [9/11] bag loss: 0.7218\n",
            " Training bag [10/11] bag loss: 0.5700\n",
            " Testing bag [0/5] bag loss: 0.7359\n",
            " Testing bag [1/5] bag loss: 0.5966\n",
            " Testing bag [2/5] bag loss: 0.6106\n",
            " Testing bag [3/5] bag loss: 0.5910\n",
            " Testing bag [4/5] bag loss: 0.6071ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [111/300] train loss: 0.6021 test loss: 0.6282, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5692\n",
            " Training bag [1/11] bag loss: 0.5626\n",
            " Training bag [2/11] bag loss: 0.5598\n",
            " Training bag [3/11] bag loss: 0.7043\n",
            " Training bag [4/11] bag loss: 0.5788\n",
            " Training bag [5/11] bag loss: 0.5752\n",
            " Training bag [6/11] bag loss: 0.7057\n",
            " Training bag [7/11] bag loss: 0.5242\n",
            " Training bag [8/11] bag loss: 0.5885\n",
            " Training bag [9/11] bag loss: 0.5313\n",
            " Training bag [10/11] bag loss: 0.7217\n",
            " Testing bag [0/5] bag loss: 0.7396\n",
            " Testing bag [1/5] bag loss: 0.5949\n",
            " Testing bag [2/5] bag loss: 0.6080\n",
            " Testing bag [3/5] bag loss: 0.5861\n",
            " Testing bag [4/5] bag loss: 0.6079ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [112/300] train loss: 0.6019 test loss: 0.6273, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6963\n",
            " Training bag [1/11] bag loss: 0.7051\n",
            " Training bag [2/11] bag loss: 0.5844\n",
            " Training bag [3/11] bag loss: 0.5850\n",
            " Training bag [4/11] bag loss: 0.5203\n",
            " Training bag [5/11] bag loss: 0.5624\n",
            " Training bag [6/11] bag loss: 0.5737\n",
            " Training bag [7/11] bag loss: 0.5732\n",
            " Training bag [8/11] bag loss: 0.5589\n",
            " Training bag [9/11] bag loss: 0.5331\n",
            " Training bag [10/11] bag loss: 0.7241\n",
            " Testing bag [0/5] bag loss: 0.7393\n",
            " Testing bag [1/5] bag loss: 0.5940\n",
            " Testing bag [2/5] bag loss: 0.6094\n",
            " Testing bag [3/5] bag loss: 0.5912\n",
            " Testing bag [4/5] bag loss: 0.6079ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [113/300] train loss: 0.6015 test loss: 0.6283, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5804\n",
            " Training bag [1/11] bag loss: 0.5166\n",
            " Training bag [2/11] bag loss: 0.5277\n",
            " Training bag [3/11] bag loss: 0.5703\n",
            " Training bag [4/11] bag loss: 0.5633\n",
            " Training bag [5/11] bag loss: 0.7032\n",
            " Training bag [6/11] bag loss: 0.5693\n",
            " Training bag [7/11] bag loss: 0.5872\n",
            " Training bag [8/11] bag loss: 0.5557\n",
            " Training bag [9/11] bag loss: 0.7099\n",
            " Training bag [10/11] bag loss: 0.7230\n",
            " Testing bag [0/5] bag loss: 0.7383\n",
            " Testing bag [1/5] bag loss: 0.5934\n",
            " Testing bag [2/5] bag loss: 0.6095\n",
            " Testing bag [3/5] bag loss: 0.5904\n",
            " Testing bag [4/5] bag loss: 0.6106ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [114/300] train loss: 0.6006 test loss: 0.6284, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5698\n",
            " Training bag [1/11] bag loss: 0.7066\n",
            " Training bag [2/11] bag loss: 0.5828\n",
            " Training bag [3/11] bag loss: 0.5867\n",
            " Training bag [4/11] bag loss: 0.6961\n",
            " Training bag [5/11] bag loss: 0.5526\n",
            " Training bag [6/11] bag loss: 0.5237\n",
            " Training bag [7/11] bag loss: 0.5589\n",
            " Training bag [8/11] bag loss: 0.5382\n",
            " Training bag [9/11] bag loss: 0.7207\n",
            " Training bag [10/11] bag loss: 0.5782\n",
            " Testing bag [0/5] bag loss: 0.7383\n",
            " Testing bag [1/5] bag loss: 0.5942\n",
            " Testing bag [2/5] bag loss: 0.6101\n",
            " Testing bag [3/5] bag loss: 0.5880\n",
            " Testing bag [4/5] bag loss: 0.6147ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [115/300] train loss: 0.6013 test loss: 0.6291, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7215\n",
            " Training bag [1/11] bag loss: 0.6972\n",
            " Training bag [2/11] bag loss: 0.5842\n",
            " Training bag [3/11] bag loss: 0.5661\n",
            " Training bag [4/11] bag loss: 0.5295\n",
            " Training bag [5/11] bag loss: 0.5604\n",
            " Training bag [6/11] bag loss: 0.5812\n",
            " Training bag [7/11] bag loss: 0.6998\n",
            " Training bag [8/11] bag loss: 0.5768\n",
            " Training bag [9/11] bag loss: 0.5202\n",
            " Training bag [10/11] bag loss: 0.5602\n",
            " Testing bag [0/5] bag loss: 0.7367\n",
            " Testing bag [1/5] bag loss: 0.5961\n",
            " Testing bag [2/5] bag loss: 0.6075\n",
            " Testing bag [3/5] bag loss: 0.5859\n",
            " Testing bag [4/5] bag loss: 0.6107ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [116/300] train loss: 0.5997 test loss: 0.6274, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5599\n",
            " Training bag [1/11] bag loss: 0.7207\n",
            " Training bag [2/11] bag loss: 0.7044\n",
            " Training bag [3/11] bag loss: 0.5362\n",
            " Training bag [4/11] bag loss: 0.5193\n",
            " Training bag [5/11] bag loss: 0.5845\n",
            " Training bag [6/11] bag loss: 0.5686\n",
            " Training bag [7/11] bag loss: 0.5784\n",
            " Training bag [8/11] bag loss: 0.5716\n",
            " Training bag [9/11] bag loss: 0.6963\n",
            " Training bag [10/11] bag loss: 0.5767\n",
            " Testing bag [0/5] bag loss: 0.7379\n",
            " Testing bag [1/5] bag loss: 0.5947\n",
            " Testing bag [2/5] bag loss: 0.6087\n",
            " Testing bag [3/5] bag loss: 0.5855\n",
            " Testing bag [4/5] bag loss: 0.6123ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [117/300] train loss: 0.6015 test loss: 0.6278, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5193\n",
            " Training bag [1/11] bag loss: 0.7001\n",
            " Training bag [2/11] bag loss: 0.5731\n",
            " Training bag [3/11] bag loss: 0.5685\n",
            " Training bag [4/11] bag loss: 0.5792\n",
            " Training bag [5/11] bag loss: 0.5598\n",
            " Training bag [6/11] bag loss: 0.5808\n",
            " Training bag [7/11] bag loss: 0.5268\n",
            " Training bag [8/11] bag loss: 0.7046\n",
            " Training bag [9/11] bag loss: 0.7236\n",
            " Training bag [10/11] bag loss: 0.5586\n",
            " Testing bag [0/5] bag loss: 0.7383\n",
            " Testing bag [1/5] bag loss: 0.5974\n",
            " Testing bag [2/5] bag loss: 0.6113\n",
            " Testing bag [3/5] bag loss: 0.5839\n",
            " Testing bag [4/5] bag loss: 0.6076ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [118/300] train loss: 0.5995 test loss: 0.6277, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5665\n",
            " Training bag [1/11] bag loss: 0.6984\n",
            " Training bag [2/11] bag loss: 0.5330\n",
            " Training bag [3/11] bag loss: 0.7204\n",
            " Training bag [4/11] bag loss: 0.5596\n",
            " Training bag [5/11] bag loss: 0.5857\n",
            " Training bag [6/11] bag loss: 0.5192\n",
            " Training bag [7/11] bag loss: 0.5687\n",
            " Training bag [8/11] bag loss: 0.5799\n",
            " Training bag [9/11] bag loss: 0.7062\n",
            " Training bag [10/11] bag loss: 0.5763\n",
            " Testing bag [0/5] bag loss: 0.7373\n",
            " Testing bag [1/5] bag loss: 0.5943\n",
            " Testing bag [2/5] bag loss: 0.6079\n",
            " Testing bag [3/5] bag loss: 0.5923\n",
            " Testing bag [4/5] bag loss: 0.6116ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [119/300] train loss: 0.6013 test loss: 0.6286, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5580\n",
            " Training bag [1/11] bag loss: 0.5786\n",
            " Training bag [2/11] bag loss: 0.5341\n",
            " Training bag [3/11] bag loss: 0.5609\n",
            " Training bag [4/11] bag loss: 0.5760\n",
            " Training bag [5/11] bag loss: 0.7071\n",
            " Training bag [6/11] bag loss: 0.5497\n",
            " Training bag [7/11] bag loss: 0.5846\n",
            " Training bag [8/11] bag loss: 0.5166\n",
            " Training bag [9/11] bag loss: 0.7245\n",
            " Training bag [10/11] bag loss: 0.6996\n",
            " Testing bag [0/5] bag loss: 0.7407\n",
            " Testing bag [1/5] bag loss: 0.5936\n",
            " Testing bag [2/5] bag loss: 0.6095\n",
            " Testing bag [3/5] bag loss: 0.5848\n",
            " Testing bag [4/5] bag loss: 0.6110ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [120/300] train loss: 0.5991 test loss: 0.6279, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5149\n",
            " Training bag [1/11] bag loss: 0.5671\n",
            " Training bag [2/11] bag loss: 0.5570\n",
            " Training bag [3/11] bag loss: 0.7031\n",
            " Training bag [4/11] bag loss: 0.7235\n",
            " Training bag [5/11] bag loss: 0.5828\n",
            " Training bag [6/11] bag loss: 0.5801\n",
            " Training bag [7/11] bag loss: 0.5582\n",
            " Training bag [8/11] bag loss: 0.5763\n",
            " Training bag [9/11] bag loss: 0.6986\n",
            " Training bag [10/11] bag loss: 0.5319\n",
            " Testing bag [0/5] bag loss: 0.7381\n",
            " Testing bag [1/5] bag loss: 0.5959\n",
            " Testing bag [2/5] bag loss: 0.6063\n",
            " Testing bag [3/5] bag loss: 0.5873\n",
            " Testing bag [4/5] bag loss: 0.6127ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [121/300] train loss: 0.5994 test loss: 0.6281, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5659\n",
            " Training bag [1/11] bag loss: 0.5565\n",
            " Training bag [2/11] bag loss: 0.5559\n",
            " Training bag [3/11] bag loss: 0.5772\n",
            " Training bag [4/11] bag loss: 0.7029\n",
            " Training bag [5/11] bag loss: 0.5724\n",
            " Training bag [6/11] bag loss: 0.7023\n",
            " Training bag [7/11] bag loss: 0.7222\n",
            " Training bag [8/11] bag loss: 0.5344\n",
            " Training bag [9/11] bag loss: 0.5854\n",
            " Training bag [10/11] bag loss: 0.5175\n",
            " Testing bag [0/5] bag loss: 0.7379\n",
            " Testing bag [1/5] bag loss: 0.5939\n",
            " Testing bag [2/5] bag loss: 0.6086\n",
            " Testing bag [3/5] bag loss: 0.5925\n",
            " Testing bag [4/5] bag loss: 0.6121ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [122/300] train loss: 0.5993 test loss: 0.6290, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5172\n",
            " Training bag [1/11] bag loss: 0.5736\n",
            " Training bag [2/11] bag loss: 0.5530\n",
            " Training bag [3/11] bag loss: 0.6984\n",
            " Training bag [4/11] bag loss: 0.7220\n",
            " Training bag [5/11] bag loss: 0.5786\n",
            " Training bag [6/11] bag loss: 0.7011\n",
            " Training bag [7/11] bag loss: 0.5611\n",
            " Training bag [8/11] bag loss: 0.5862\n",
            " Training bag [9/11] bag loss: 0.5669\n",
            " Training bag [10/11] bag loss: 0.5270\n",
            " Testing bag [0/5] bag loss: 0.7387\n",
            " Testing bag [1/5] bag loss: 0.5966\n",
            " Testing bag [2/5] bag loss: 0.6091\n",
            " Testing bag [3/5] bag loss: 0.5884\n",
            " Testing bag [4/5] bag loss: 0.6117ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [123/300] train loss: 0.5986 test loss: 0.6289, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6928\n",
            " Training bag [1/11] bag loss: 0.7189\n",
            " Training bag [2/11] bag loss: 0.5637\n",
            " Training bag [3/11] bag loss: 0.6977\n",
            " Training bag [4/11] bag loss: 0.5170\n",
            " Training bag [5/11] bag loss: 0.5800\n",
            " Training bag [6/11] bag loss: 0.5672\n",
            " Training bag [7/11] bag loss: 0.5559\n",
            " Training bag [8/11] bag loss: 0.5353\n",
            " Training bag [9/11] bag loss: 0.5772\n",
            " Training bag [10/11] bag loss: 0.5847\n",
            " Testing bag [0/5] bag loss: 0.7390\n",
            " Testing bag [1/5] bag loss: 0.5946\n",
            " Testing bag [2/5] bag loss: 0.6055\n",
            " Testing bag [3/5] bag loss: 0.5891\n",
            " Testing bag [4/5] bag loss: 0.6135ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [124/300] train loss: 0.5991 test loss: 0.6283, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7033\n",
            " Training bag [1/11] bag loss: 0.5845\n",
            " Training bag [2/11] bag loss: 0.6995\n",
            " Training bag [3/11] bag loss: 0.5590\n",
            " Training bag [4/11] bag loss: 0.5742\n",
            " Training bag [5/11] bag loss: 0.5843\n",
            " Training bag [6/11] bag loss: 0.5285\n",
            " Training bag [7/11] bag loss: 0.7209\n",
            " Training bag [8/11] bag loss: 0.5584\n",
            " Training bag [9/11] bag loss: 0.5153\n",
            " Training bag [10/11] bag loss: 0.5656\n",
            " Testing bag [0/5] bag loss: 0.7383\n",
            " Testing bag [1/5] bag loss: 0.5952\n",
            " Testing bag [2/5] bag loss: 0.6092\n",
            " Testing bag [3/5] bag loss: 0.5848\n",
            " Testing bag [4/5] bag loss: 0.6114ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [125/300] train loss: 0.5994 test loss: 0.6278, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5148\n",
            " Training bag [1/11] bag loss: 0.5796\n",
            " Training bag [2/11] bag loss: 0.5713\n",
            " Training bag [3/11] bag loss: 0.5604\n",
            " Training bag [4/11] bag loss: 0.6971\n",
            " Training bag [5/11] bag loss: 0.7069\n",
            " Training bag [6/11] bag loss: 0.7205\n",
            " Training bag [7/11] bag loss: 0.5324\n",
            " Training bag [8/11] bag loss: 0.5710\n",
            " Training bag [9/11] bag loss: 0.5853\n",
            " Training bag [10/11] bag loss: 0.5587\n",
            " Testing bag [0/5] bag loss: 0.7394\n",
            " Testing bag [1/5] bag loss: 0.5946\n",
            " Testing bag [2/5] bag loss: 0.6106\n",
            " Testing bag [3/5] bag loss: 0.5837\n",
            " Testing bag [4/5] bag loss: 0.6113ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [126/300] train loss: 0.5998 test loss: 0.6279, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5552\n",
            " Training bag [1/11] bag loss: 0.5828\n",
            " Training bag [2/11] bag loss: 0.6958\n",
            " Training bag [3/11] bag loss: 0.7035\n",
            " Training bag [4/11] bag loss: 0.5137\n",
            " Training bag [5/11] bag loss: 0.7177\n",
            " Training bag [6/11] bag loss: 0.5687\n",
            " Training bag [7/11] bag loss: 0.5308\n",
            " Training bag [8/11] bag loss: 0.5579\n",
            " Training bag [9/11] bag loss: 0.5734\n",
            " Training bag [10/11] bag loss: 0.5814\n",
            " Testing bag [0/5] bag loss: 0.7386\n",
            " Testing bag [1/5] bag loss: 0.5948\n",
            " Testing bag [2/5] bag loss: 0.6107\n",
            " Testing bag [3/5] bag loss: 0.5884\n",
            " Testing bag [4/5] bag loss: 0.6101ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [127/300] train loss: 0.5983 test loss: 0.6285, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5719\n",
            " Training bag [1/11] bag loss: 0.6968\n",
            " Training bag [2/11] bag loss: 0.5293\n",
            " Training bag [3/11] bag loss: 0.5141\n",
            " Training bag [4/11] bag loss: 0.7196\n",
            " Training bag [5/11] bag loss: 0.7027\n",
            " Training bag [6/11] bag loss: 0.5784\n",
            " Training bag [7/11] bag loss: 0.5729\n",
            " Training bag [8/11] bag loss: 0.5617\n",
            " Training bag [9/11] bag loss: 0.5586\n",
            " Training bag [10/11] bag loss: 0.5792\n",
            " Testing bag [0/5] bag loss: 0.7379\n",
            " Testing bag [1/5] bag loss: 0.5976\n",
            " Testing bag [2/5] bag loss: 0.6125\n",
            " Testing bag [3/5] bag loss: 0.5890\n",
            " Testing bag [4/5] bag loss: 0.6096ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [128/300] train loss: 0.5986 test loss: 0.6293, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5567\n",
            " Training bag [1/11] bag loss: 0.5729\n",
            " Training bag [2/11] bag loss: 0.6948\n",
            " Training bag [3/11] bag loss: 0.5666\n",
            " Training bag [4/11] bag loss: 0.5800\n",
            " Training bag [5/11] bag loss: 0.5604\n",
            " Training bag [6/11] bag loss: 0.5254\n",
            " Training bag [7/11] bag loss: 0.5783\n",
            " Training bag [8/11] bag loss: 0.7032\n",
            " Training bag [9/11] bag loss: 0.7223\n",
            " Training bag [10/11] bag loss: 0.5134\n",
            " Testing bag [0/5] bag loss: 0.7402\n",
            " Testing bag [1/5] bag loss: 0.5932\n",
            " Testing bag [2/5] bag loss: 0.6075\n",
            " Testing bag [3/5] bag loss: 0.5853\n",
            " Testing bag [4/5] bag loss: 0.6095ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [129/300] train loss: 0.5976 test loss: 0.6272, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5546\n",
            " Training bag [1/11] bag loss: 0.5627\n",
            " Training bag [2/11] bag loss: 0.5822\n",
            " Training bag [3/11] bag loss: 0.6996\n",
            " Training bag [4/11] bag loss: 0.7028\n",
            " Training bag [5/11] bag loss: 0.5149\n",
            " Training bag [6/11] bag loss: 0.7212\n",
            " Training bag [7/11] bag loss: 0.5311\n",
            " Training bag [8/11] bag loss: 0.5801\n",
            " Training bag [9/11] bag loss: 0.5506\n",
            " Training bag [10/11] bag loss: 0.5718\n",
            " Testing bag [0/5] bag loss: 0.7372\n",
            " Testing bag [1/5] bag loss: 0.5948\n",
            " Testing bag [2/5] bag loss: 0.6079\n",
            " Testing bag [3/5] bag loss: 0.5884\n",
            " Testing bag [4/5] bag loss: 0.6122ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [130/300] train loss: 0.5974 test loss: 0.6281, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5577\n",
            " Training bag [1/11] bag loss: 0.5611\n",
            " Training bag [2/11] bag loss: 0.7207\n",
            " Training bag [3/11] bag loss: 0.5311\n",
            " Training bag [4/11] bag loss: 0.5142\n",
            " Training bag [5/11] bag loss: 0.5479\n",
            " Training bag [6/11] bag loss: 0.5734\n",
            " Training bag [7/11] bag loss: 0.6991\n",
            " Training bag [8/11] bag loss: 0.5848\n",
            " Training bag [9/11] bag loss: 0.5746\n",
            " Training bag [10/11] bag loss: 0.7048\n",
            " Testing bag [0/5] bag loss: 0.7400\n",
            " Testing bag [1/5] bag loss: 0.5940\n",
            " Testing bag [2/5] bag loss: 0.6104\n",
            " Testing bag [3/5] bag loss: 0.5889\n",
            " Testing bag [4/5] bag loss: 0.6080ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [131/300] train loss: 0.5972 test loss: 0.6283, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5568\n",
            " Training bag [1/11] bag loss: 0.5593\n",
            " Training bag [2/11] bag loss: 0.7222\n",
            " Training bag [3/11] bag loss: 0.5603\n",
            " Training bag [4/11] bag loss: 0.5171\n",
            " Training bag [5/11] bag loss: 0.6990\n",
            " Training bag [6/11] bag loss: 0.5752\n",
            " Training bag [7/11] bag loss: 0.5748\n",
            " Training bag [8/11] bag loss: 0.7033\n",
            " Training bag [9/11] bag loss: 0.5852\n",
            " Training bag [10/11] bag loss: 0.5304\n",
            " Testing bag [0/5] bag loss: 0.7373\n",
            " Testing bag [1/5] bag loss: 0.5932\n",
            " Testing bag [2/5] bag loss: 0.6095\n",
            " Testing bag [3/5] bag loss: 0.5850\n",
            " Testing bag [4/5] bag loss: 0.6144ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [132/300] train loss: 0.5985 test loss: 0.6279, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6926\n",
            " Training bag [1/11] bag loss: 0.5598\n",
            " Training bag [2/11] bag loss: 0.5574\n",
            " Training bag [3/11] bag loss: 0.5288\n",
            " Training bag [4/11] bag loss: 0.7006\n",
            " Training bag [5/11] bag loss: 0.5841\n",
            " Training bag [6/11] bag loss: 0.5124\n",
            " Training bag [7/11] bag loss: 0.5619\n",
            " Training bag [8/11] bag loss: 0.7205\n",
            " Training bag [9/11] bag loss: 0.5719\n",
            " Training bag [10/11] bag loss: 0.5812\n",
            " Testing bag [0/5] bag loss: 0.7395\n",
            " Testing bag [1/5] bag loss: 0.5967\n",
            " Testing bag [2/5] bag loss: 0.6131\n",
            " Testing bag [3/5] bag loss: 0.5864\n",
            " Testing bag [4/5] bag loss: 0.6099ROC AUC score: 0.0\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [133/300] train loss: 0.5974 test loss: 0.6291, average score: 0.4000, AUC: class-0>>0.0|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5706\n",
            " Training bag [1/11] bag loss: 0.6966\n",
            " Training bag [2/11] bag loss: 0.5773\n",
            " Training bag [3/11] bag loss: 0.7194\n",
            " Training bag [4/11] bag loss: 0.5581\n",
            " Training bag [5/11] bag loss: 0.5647\n",
            " Training bag [6/11] bag loss: 0.5610\n",
            " Training bag [7/11] bag loss: 0.5143\n",
            " Training bag [8/11] bag loss: 0.5255\n",
            " Training bag [9/11] bag loss: 0.5844\n",
            " Training bag [10/11] bag loss: 0.7003\n",
            " Testing bag [0/5] bag loss: 0.7390\n",
            " Testing bag [1/5] bag loss: 0.5930\n",
            " Testing bag [2/5] bag loss: 0.6105\n",
            " Testing bag [3/5] bag loss: 0.5844\n",
            " Testing bag [4/5] bag loss: 0.6095ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [134/300] train loss: 0.5975 test loss: 0.6273, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5590\n",
            " Training bag [1/11] bag loss: 0.5128\n",
            " Training bag [2/11] bag loss: 0.5632\n",
            " Training bag [3/11] bag loss: 0.5288\n",
            " Training bag [4/11] bag loss: 0.5798\n",
            " Training bag [5/11] bag loss: 0.7026\n",
            " Training bag [6/11] bag loss: 0.5697\n",
            " Training bag [7/11] bag loss: 0.5553\n",
            " Training bag [8/11] bag loss: 0.5791\n",
            " Training bag [9/11] bag loss: 0.7241\n",
            " Training bag [10/11] bag loss: 0.6990\n",
            " Testing bag [0/5] bag loss: 0.7419\n",
            " Testing bag [1/5] bag loss: 0.5931\n",
            " Testing bag [2/5] bag loss: 0.6081\n",
            " Testing bag [3/5] bag loss: 0.5847\n",
            " Testing bag [4/5] bag loss: 0.6110ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [135/300] train loss: 0.5976 test loss: 0.6278, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6946\n",
            " Training bag [1/11] bag loss: 0.5741\n",
            " Training bag [2/11] bag loss: 0.5660\n",
            " Training bag [3/11] bag loss: 0.5630\n",
            " Training bag [4/11] bag loss: 0.5772\n",
            " Training bag [5/11] bag loss: 0.7026\n",
            " Training bag [6/11] bag loss: 0.5806\n",
            " Training bag [7/11] bag loss: 0.5116\n",
            " Training bag [8/11] bag loss: 0.7225\n",
            " Training bag [9/11] bag loss: 0.5559\n",
            " Training bag [10/11] bag loss: 0.5232\n",
            " Testing bag [0/5] bag loss: 0.7383\n",
            " Testing bag [1/5] bag loss: 0.5952\n",
            " Testing bag [2/5] bag loss: 0.6082\n",
            " Testing bag [3/5] bag loss: 0.5885\n",
            " Testing bag [4/5] bag loss: 0.6109ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [136/300] train loss: 0.5974 test loss: 0.6282, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5824\n",
            " Training bag [1/11] bag loss: 0.5075\n",
            " Training bag [2/11] bag loss: 0.5178\n",
            " Training bag [3/11] bag loss: 0.7221\n",
            " Training bag [4/11] bag loss: 0.5673\n",
            " Training bag [5/11] bag loss: 0.5795\n",
            " Training bag [6/11] bag loss: 0.5590\n",
            " Training bag [7/11] bag loss: 0.5667\n",
            " Training bag [8/11] bag loss: 0.5544\n",
            " Training bag [9/11] bag loss: 0.6974\n",
            " Training bag [10/11] bag loss: 0.7015\n",
            " Testing bag [0/5] bag loss: 0.7425\n",
            " Testing bag [1/5] bag loss: 0.5936\n",
            " Testing bag [2/5] bag loss: 0.6094\n",
            " Testing bag [3/5] bag loss: 0.5866\n",
            " Testing bag [4/5] bag loss: 0.6110ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [137/300] train loss: 0.5960 test loss: 0.6286, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5093\n",
            " Training bag [1/11] bag loss: 0.6948\n",
            " Training bag [2/11] bag loss: 0.5767\n",
            " Training bag [3/11] bag loss: 0.5722\n",
            " Training bag [4/11] bag loss: 0.7204\n",
            " Training bag [5/11] bag loss: 0.5614\n",
            " Training bag [6/11] bag loss: 0.5577\n",
            " Training bag [7/11] bag loss: 0.5239\n",
            " Training bag [8/11] bag loss: 0.5650\n",
            " Training bag [9/11] bag loss: 0.5786\n",
            " Training bag [10/11] bag loss: 0.7011\n",
            " Testing bag [0/5] bag loss: 0.7407\n",
            " Testing bag [1/5] bag loss: 0.5950\n",
            " Testing bag [2/5] bag loss: 0.6132\n",
            " Testing bag [3/5] bag loss: 0.5835\n",
            " Testing bag [4/5] bag loss: 0.6098ROC AUC score: 0.16666666666666669\n",
            "ROC AUC score: 0.75\n",
            "ROC AUC score: 0.33333333333333337\n",
            "\n",
            " Epoch [138/300] train loss: 0.5965 test loss: 0.6285, average score: 0.4000, AUC: class-0>>0.16666666666666669|class-1>>0.75|class-2>>0.33333333333333337\n",
            "\n",
            " Testing bag [0/5] bag loss: 0.6128\n",
            " Testing bag [1/5] bag loss: 0.5961\n",
            " Testing bag [2/5] bag loss: 0.6057\n",
            " Testing bag [3/5] bag loss: 0.7124\n",
            " Testing bag [4/5] bag loss: 0.6058ROC AUC score: 0.8333333333333334\n",
            "ROC AUC score: 0.25\n",
            "ROC AUC score: 0.8333333333333334\n",
            "âœ… Fold 0 completed | Test Acc: 0.2000 | Test AUCs: [np.float64(0.833), np.float64(0.25), np.float64(0.833)]\n",
            "\n",
            "ðŸŒ€ Starting CV Fold 1\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7049\n",
            " Training bag [1/11] bag loss: 0.6894\n",
            " Training bag [2/11] bag loss: 0.6947\n",
            " Training bag [3/11] bag loss: 0.6902\n",
            " Training bag [4/11] bag loss: 0.6902\n",
            " Training bag [5/11] bag loss: 0.6937\n",
            " Training bag [6/11] bag loss: 0.6915\n",
            " Training bag [7/11] bag loss: 0.6920\n",
            " Training bag [8/11] bag loss: 0.6890\n",
            " Training bag [9/11] bag loss: 0.6935\n",
            " Training bag [10/11] bag loss: 0.6877\n",
            " Testing bag [0/6] bag loss: 0.6893\n",
            " Testing bag [1/6] bag loss: 0.6875\n",
            " Testing bag [2/6] bag loss: 0.6957\n",
            " Testing bag [3/6] bag loss: 0.6980\n",
            " Testing bag [4/6] bag loss: 0.6929\n",
            " Testing bag [5/6] bag loss: 0.6880ROC AUC score: 0.4444444444444444\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 1.0\n",
            "\n",
            " Epoch [1/300] train loss: 0.6924 test loss: 0.6919, average score: 0.5000, AUC: class-0>>0.4444444444444444|class-1>>0.8|class-2>>1.0\n",
            "Best model saved at: weights/20250626/fold_1_19.pth\n",
            "Best thresholds ===>>> class-0>>0.46489664912223816|class-1>>0.4539145231246948|class-2>>0.46822142601013184\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6893\n",
            " Training bag [1/11] bag loss: 0.6922\n",
            " Training bag [2/11] bag loss: 0.6958\n",
            " Training bag [3/11] bag loss: 0.6857\n",
            " Training bag [4/11] bag loss: 0.6880\n",
            " Training bag [5/11] bag loss: 0.6933\n",
            " Training bag [6/11] bag loss: 0.6861\n",
            " Training bag [7/11] bag loss: 0.6843\n",
            " Training bag [8/11] bag loss: 0.6906\n",
            " Training bag [9/11] bag loss: 0.6844\n",
            " Training bag [10/11] bag loss: 0.6832\n",
            " Testing bag [0/6] bag loss: 0.6885\n",
            " Testing bag [1/6] bag loss: 0.6834\n",
            " Testing bag [2/6] bag loss: 0.6909\n",
            " Testing bag [3/6] bag loss: 0.6926\n",
            " Testing bag [4/6] bag loss: 0.6852\n",
            " Testing bag [5/6] bag loss: 0.6848ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 1.0\n",
            "\n",
            " Epoch [2/300] train loss: 0.6884 test loss: 0.6876, average score: 0.5000, AUC: class-0>>0.5555555555555556|class-1>>0.8|class-2>>1.0\n",
            "Best model saved at: weights/20250626/fold_1_19.pth\n",
            "Best thresholds ===>>> class-0>>0.45837464928627014|class-1>>0.44208860397338867|class-2>>0.4605959951877594\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6808\n",
            " Training bag [1/11] bag loss: 0.6910\n",
            " Training bag [2/11] bag loss: 0.6752\n",
            " Training bag [3/11] bag loss: 0.6900\n",
            " Training bag [4/11] bag loss: 0.6907\n",
            " Training bag [5/11] bag loss: 0.6902\n",
            " Training bag [6/11] bag loss: 0.6902\n",
            " Training bag [7/11] bag loss: 0.6750\n",
            " Training bag [8/11] bag loss: 0.6916\n",
            " Training bag [9/11] bag loss: 0.6737\n",
            " Training bag [10/11] bag loss: 0.6852\n",
            " Testing bag [0/6] bag loss: 0.6892\n",
            " Testing bag [1/6] bag loss: 0.6759\n",
            " Testing bag [2/6] bag loss: 0.6883\n",
            " Testing bag [3/6] bag loss: 0.6902\n",
            " Testing bag [4/6] bag loss: 0.6847\n",
            " Testing bag [5/6] bag loss: 0.6744ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 1.0\n",
            "\n",
            " Epoch [3/300] train loss: 0.6849 test loss: 0.6838, average score: 0.5000, AUC: class-0>>0.5555555555555556|class-1>>0.8|class-2>>1.0\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6835\n",
            " Training bag [1/11] bag loss: 0.6810\n",
            " Training bag [2/11] bag loss: 0.6784\n",
            " Training bag [3/11] bag loss: 0.6757\n",
            " Training bag [4/11] bag loss: 0.6741\n",
            " Training bag [5/11] bag loss: 0.6976\n",
            " Training bag [6/11] bag loss: 0.6906\n",
            " Training bag [7/11] bag loss: 0.6923\n",
            " Training bag [8/11] bag loss: 0.6830\n",
            " Training bag [9/11] bag loss: 0.6707\n",
            " Training bag [10/11] bag loss: 0.6720\n",
            " Testing bag [0/6] bag loss: 0.6887\n",
            " Testing bag [1/6] bag loss: 0.6736\n",
            " Testing bag [2/6] bag loss: 0.6830\n",
            " Testing bag [3/6] bag loss: 0.6840\n",
            " Testing bag [4/6] bag loss: 0.6784\n",
            " Testing bag [5/6] bag loss: 0.6732ROC AUC score: 0.6666666666666666\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 1.0\n",
            "\n",
            " Epoch [4/300] train loss: 0.6817 test loss: 0.6801, average score: 0.6667, AUC: class-0>>0.6666666666666666|class-1>>0.8|class-2>>1.0\n",
            "Best model saved at: weights/20250626/fold_1_19.pth\n",
            "Best thresholds ===>>> class-0>>0.4445721209049225|class-1>>0.41982167959213257|class-2>>0.4483114182949066\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6820\n",
            " Training bag [1/11] bag loss: 0.6710\n",
            " Training bag [2/11] bag loss: 0.6779\n",
            " Training bag [3/11] bag loss: 0.6675\n",
            " Training bag [4/11] bag loss: 0.6644\n",
            " Training bag [5/11] bag loss: 0.6934\n",
            " Training bag [6/11] bag loss: 0.6940\n",
            " Training bag [7/11] bag loss: 0.6593\n",
            " Training bag [8/11] bag loss: 0.6791\n",
            " Training bag [9/11] bag loss: 0.6925\n",
            " Training bag [10/11] bag loss: 0.6783\n",
            " Testing bag [0/6] bag loss: 0.6898\n",
            " Testing bag [1/6] bag loss: 0.6620\n",
            " Testing bag [2/6] bag loss: 0.6828\n",
            " Testing bag [3/6] bag loss: 0.6825\n",
            " Testing bag [4/6] bag loss: 0.6786\n",
            " Testing bag [5/6] bag loss: 0.6669ROC AUC score: 0.6666666666666666\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 1.0\n",
            "\n",
            " Epoch [5/300] train loss: 0.6781 test loss: 0.6771, average score: 0.6667, AUC: class-0>>0.6666666666666666|class-1>>0.8|class-2>>1.0\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6755\n",
            " Training bag [1/11] bag loss: 0.6618\n",
            " Training bag [2/11] bag loss: 0.6720\n",
            " Training bag [3/11] bag loss: 0.6721\n",
            " Training bag [4/11] bag loss: 0.6710\n",
            " Training bag [5/11] bag loss: 0.6935\n",
            " Training bag [6/11] bag loss: 0.6664\n",
            " Training bag [7/11] bag loss: 0.6649\n",
            " Training bag [8/11] bag loss: 0.6957\n",
            " Training bag [9/11] bag loss: 0.6928\n",
            " Training bag [10/11] bag loss: 0.6634\n",
            " Testing bag [0/6] bag loss: 0.6900\n",
            " Testing bag [1/6] bag loss: 0.6640\n",
            " Testing bag [2/6] bag loss: 0.6751\n",
            " Testing bag [3/6] bag loss: 0.6750\n",
            " Testing bag [4/6] bag loss: 0.6703\n",
            " Testing bag [5/6] bag loss: 0.6657ROC AUC score: 0.6666666666666666\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 1.0\n",
            "\n",
            " Epoch [6/300] train loss: 0.6754 test loss: 0.6734, average score: 0.6667, AUC: class-0>>0.6666666666666666|class-1>>0.8|class-2>>1.0\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6698\n",
            " Training bag [1/11] bag loss: 0.6899\n",
            " Training bag [2/11] bag loss: 0.6682\n",
            " Training bag [3/11] bag loss: 0.6640\n",
            " Training bag [4/11] bag loss: 0.6870\n",
            " Training bag [5/11] bag loss: 0.6683\n",
            " Training bag [6/11] bag loss: 0.6638\n",
            " Training bag [7/11] bag loss: 0.6614\n",
            " Training bag [8/11] bag loss: 0.6899\n",
            " Training bag [9/11] bag loss: 0.6584\n",
            " Training bag [10/11] bag loss: 0.6753\n",
            " Testing bag [0/6] bag loss: 0.6882\n",
            " Testing bag [1/6] bag loss: 0.6566\n",
            " Testing bag [2/6] bag loss: 0.6749\n",
            " Testing bag [3/6] bag loss: 0.6750\n",
            " Testing bag [4/6] bag loss: 0.6712\n",
            " Testing bag [5/6] bag loss: 0.6588ROC AUC score: 0.6666666666666666\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 1.0\n",
            "\n",
            " Epoch [7/300] train loss: 0.6724 test loss: 0.6708, average score: 0.8333, AUC: class-0>>0.6666666666666666|class-1>>1.0|class-2>>1.0\n",
            "Best model saved at: weights/20250626/fold_1_19.pth\n",
            "Best thresholds ===>>> class-0>>0.4260711371898651|class-1>>0.39193233847618103|class-2>>0.4351091682910919\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6565\n",
            " Training bag [1/11] bag loss: 0.6885\n",
            " Training bag [2/11] bag loss: 0.6902\n",
            " Training bag [3/11] bag loss: 0.6752\n",
            " Training bag [4/11] bag loss: 0.6819\n",
            " Training bag [5/11] bag loss: 0.6554\n",
            " Training bag [6/11] bag loss: 0.6571\n",
            " Training bag [7/11] bag loss: 0.6731\n",
            " Training bag [8/11] bag loss: 0.6518\n",
            " Training bag [9/11] bag loss: 0.6759\n",
            " Training bag [10/11] bag loss: 0.6707\n",
            " Testing bag [0/6] bag loss: 0.6894\n",
            " Testing bag [1/6] bag loss: 0.6558\n",
            " Testing bag [2/6] bag loss: 0.6721\n",
            " Testing bag [3/6] bag loss: 0.6743\n",
            " Testing bag [4/6] bag loss: 0.6703\n",
            " Testing bag [5/6] bag loss: 0.6540ROC AUC score: 0.6666666666666666\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 1.0\n",
            "\n",
            " Epoch [8/300] train loss: 0.6706 test loss: 0.6693, average score: 0.8333, AUC: class-0>>0.6666666666666666|class-1>>1.0|class-2>>1.0\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6526\n",
            " Training bag [1/11] bag loss: 0.6668\n",
            " Training bag [2/11] bag loss: 0.6931\n",
            " Training bag [3/11] bag loss: 0.6902\n",
            " Training bag [4/11] bag loss: 0.6665\n",
            " Training bag [5/11] bag loss: 0.6678\n",
            " Training bag [6/11] bag loss: 0.6560\n",
            " Training bag [7/11] bag loss: 0.6536\n",
            " Training bag [8/11] bag loss: 0.6865\n",
            " Training bag [9/11] bag loss: 0.6613\n",
            " Training bag [10/11] bag loss: 0.6523\n",
            " Testing bag [0/6] bag loss: 0.6890\n",
            " Testing bag [1/6] bag loss: 0.6538\n",
            " Testing bag [2/6] bag loss: 0.6683\n",
            " Testing bag [3/6] bag loss: 0.6670\n",
            " Testing bag [4/6] bag loss: 0.6646\n",
            " Testing bag [5/6] bag loss: 0.6557ROC AUC score: 0.6666666666666666\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 1.0\n",
            "\n",
            " Epoch [9/300] train loss: 0.6679 test loss: 0.6664, average score: 0.8333, AUC: class-0>>0.6666666666666666|class-1>>1.0|class-2>>1.0\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6509\n",
            " Training bag [1/11] bag loss: 0.6490\n",
            " Training bag [2/11] bag loss: 0.6903\n",
            " Training bag [3/11] bag loss: 0.6433\n",
            " Training bag [4/11] bag loss: 0.6682\n",
            " Training bag [5/11] bag loss: 0.6436\n",
            " Training bag [6/11] bag loss: 0.6707\n",
            " Training bag [7/11] bag loss: 0.6944\n",
            " Training bag [8/11] bag loss: 0.6646\n",
            " Training bag [9/11] bag loss: 0.6951\n",
            " Training bag [10/11] bag loss: 0.6629\n",
            " Testing bag [0/6] bag loss: 0.6914\n",
            " Testing bag [1/6] bag loss: 0.6481\n",
            " Testing bag [2/6] bag loss: 0.6655\n",
            " Testing bag [3/6] bag loss: 0.6670\n",
            " Testing bag [4/6] bag loss: 0.6651\n",
            " Testing bag [5/6] bag loss: 0.6464ROC AUC score: 0.6666666666666666\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 1.0\n",
            "\n",
            " Epoch [10/300] train loss: 0.6666 test loss: 0.6639, average score: 0.6667, AUC: class-0>>0.6666666666666666|class-1>>0.8|class-2>>1.0\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6438\n",
            " Training bag [1/11] bag loss: 0.6461\n",
            " Training bag [2/11] bag loss: 0.6651\n",
            " Training bag [3/11] bag loss: 0.6956\n",
            " Training bag [4/11] bag loss: 0.6887\n",
            " Training bag [5/11] bag loss: 0.6620\n",
            " Training bag [6/11] bag loss: 0.6452\n",
            " Training bag [7/11] bag loss: 0.6598\n",
            " Training bag [8/11] bag loss: 0.6439\n",
            " Training bag [9/11] bag loss: 0.6914\n",
            " Training bag [10/11] bag loss: 0.6585\n",
            " Testing bag [0/6] bag loss: 0.6907\n",
            " Testing bag [1/6] bag loss: 0.6470\n",
            " Testing bag [2/6] bag loss: 0.6626\n",
            " Testing bag [3/6] bag loss: 0.6636\n",
            " Testing bag [4/6] bag loss: 0.6614\n",
            " Testing bag [5/6] bag loss: 0.6476ROC AUC score: 0.6666666666666666\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 1.0\n",
            "\n",
            " Epoch [11/300] train loss: 0.6636 test loss: 0.6622, average score: 0.6667, AUC: class-0>>0.6666666666666666|class-1>>0.8|class-2>>1.0\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6898\n",
            " Training bag [1/11] bag loss: 0.6576\n",
            " Training bag [2/11] bag loss: 0.6859\n",
            " Training bag [3/11] bag loss: 0.6552\n",
            " Training bag [4/11] bag loss: 0.6532\n",
            " Training bag [5/11] bag loss: 0.6509\n",
            " Training bag [6/11] bag loss: 0.6531\n",
            " Training bag [7/11] bag loss: 0.6926\n",
            " Training bag [8/11] bag loss: 0.6543\n",
            " Training bag [9/11] bag loss: 0.6501\n",
            " Training bag [10/11] bag loss: 0.6496\n",
            " Testing bag [0/6] bag loss: 0.6902\n",
            " Testing bag [1/6] bag loss: 0.6490\n",
            " Testing bag [2/6] bag loss: 0.6587\n",
            " Testing bag [3/6] bag loss: 0.6586\n",
            " Testing bag [4/6] bag loss: 0.6564\n",
            " Testing bag [5/6] bag loss: 0.6474ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 1.0\n",
            "\n",
            " Epoch [12/300] train loss: 0.6629 test loss: 0.6600, average score: 0.5000, AUC: class-0>>0.5555555555555556|class-1>>0.8|class-2>>1.0\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6445\n",
            " Training bag [1/11] bag loss: 0.6425\n",
            " Training bag [2/11] bag loss: 0.6562\n",
            " Training bag [3/11] bag loss: 0.6399\n",
            " Training bag [4/11] bag loss: 0.6556\n",
            " Training bag [5/11] bag loss: 0.6339\n",
            " Training bag [6/11] bag loss: 0.6570\n",
            " Training bag [7/11] bag loss: 0.6506\n",
            " Training bag [8/11] bag loss: 0.7008\n",
            " Training bag [9/11] bag loss: 0.7015\n",
            " Training bag [10/11] bag loss: 0.6991\n",
            " Testing bag [0/6] bag loss: 0.6958\n",
            " Testing bag [1/6] bag loss: 0.6387\n",
            " Testing bag [2/6] bag loss: 0.6581\n",
            " Testing bag [3/6] bag loss: 0.6565\n",
            " Testing bag [4/6] bag loss: 0.6545\n",
            " Testing bag [5/6] bag loss: 0.6406ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 1.0\n",
            "\n",
            " Epoch [13/300] train loss: 0.6620 test loss: 0.6574, average score: 0.5000, AUC: class-0>>0.5555555555555556|class-1>>0.8|class-2>>1.0\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6380\n",
            " Training bag [1/11] bag loss: 0.6941\n",
            " Training bag [2/11] bag loss: 0.6385\n",
            " Training bag [3/11] bag loss: 0.6543\n",
            " Training bag [4/11] bag loss: 0.6349\n",
            " Training bag [5/11] bag loss: 0.6534\n",
            " Training bag [6/11] bag loss: 0.6526\n",
            " Training bag [7/11] bag loss: 0.6955\n",
            " Training bag [8/11] bag loss: 0.6356\n",
            " Training bag [9/11] bag loss: 0.6932\n",
            " Training bag [10/11] bag loss: 0.6547\n",
            " Testing bag [0/6] bag loss: 0.6927\n",
            " Testing bag [1/6] bag loss: 0.6384\n",
            " Testing bag [2/6] bag loss: 0.6580\n",
            " Testing bag [3/6] bag loss: 0.6557\n",
            " Testing bag [4/6] bag loss: 0.6534\n",
            " Testing bag [5/6] bag loss: 0.6368ROC AUC score: 0.6666666666666667\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 1.0\n",
            "\n",
            " Epoch [14/300] train loss: 0.6586 test loss: 0.6558, average score: 0.6667, AUC: class-0>>0.6666666666666667|class-1>>1.0|class-2>>1.0\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6507\n",
            " Training bag [1/11] bag loss: 0.6370\n",
            " Training bag [2/11] bag loss: 0.6940\n",
            " Training bag [3/11] bag loss: 0.6401\n",
            " Training bag [4/11] bag loss: 0.6497\n",
            " Training bag [5/11] bag loss: 0.6511\n",
            " Training bag [6/11] bag loss: 0.6377\n",
            " Training bag [7/11] bag loss: 0.6353\n",
            " Training bag [8/11] bag loss: 0.6963\n",
            " Training bag [9/11] bag loss: 0.6489\n",
            " Training bag [10/11] bag loss: 0.6970\n",
            " Testing bag [0/6] bag loss: 0.6956\n",
            " Testing bag [1/6] bag loss: 0.6395\n",
            " Testing bag [2/6] bag loss: 0.6546\n",
            " Testing bag [3/6] bag loss: 0.6525\n",
            " Testing bag [4/6] bag loss: 0.6516\n",
            " Testing bag [5/6] bag loss: 0.6358ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 1.0\n",
            "\n",
            " Epoch [15/300] train loss: 0.6580 test loss: 0.6549, average score: 0.5000, AUC: class-0>>0.5555555555555556|class-1>>0.8|class-2>>1.0\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6952\n",
            " Training bag [1/11] bag loss: 0.6352\n",
            " Training bag [2/11] bag loss: 0.6520\n",
            " Training bag [3/11] bag loss: 0.6485\n",
            " Training bag [4/11] bag loss: 0.6351\n",
            " Training bag [5/11] bag loss: 0.6345\n",
            " Training bag [6/11] bag loss: 0.6467\n",
            " Training bag [7/11] bag loss: 0.6952\n",
            " Training bag [8/11] bag loss: 0.6950\n",
            " Training bag [9/11] bag loss: 0.6356\n",
            " Training bag [10/11] bag loss: 0.6477\n",
            " Testing bag [0/6] bag loss: 0.6924\n",
            " Testing bag [1/6] bag loss: 0.6362\n",
            " Testing bag [2/6] bag loss: 0.6550\n",
            " Testing bag [3/6] bag loss: 0.6519\n",
            " Testing bag [4/6] bag loss: 0.6511\n",
            " Testing bag [5/6] bag loss: 0.6358ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [16/300] train loss: 0.6564 test loss: 0.6537, average score: 0.3333, AUC: class-0>>0.5555555555555556|class-1>>0.8|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6353\n",
            " Training bag [1/11] bag loss: 0.6479\n",
            " Training bag [2/11] bag loss: 0.6317\n",
            " Training bag [3/11] bag loss: 0.6293\n",
            " Training bag [4/11] bag loss: 0.6992\n",
            " Training bag [5/11] bag loss: 0.6276\n",
            " Training bag [6/11] bag loss: 0.6969\n",
            " Training bag [7/11] bag loss: 0.6935\n",
            " Training bag [8/11] bag loss: 0.6529\n",
            " Training bag [9/11] bag loss: 0.6539\n",
            " Training bag [10/11] bag loss: 0.6497\n",
            " Testing bag [0/6] bag loss: 0.6929\n",
            " Testing bag [1/6] bag loss: 0.6333\n",
            " Testing bag [2/6] bag loss: 0.6552\n",
            " Testing bag [3/6] bag loss: 0.6517\n",
            " Testing bag [4/6] bag loss: 0.6514\n",
            " Testing bag [5/6] bag loss: 0.6325ROC AUC score: 0.6666666666666667\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [17/300] train loss: 0.6562 test loss: 0.6528, average score: 0.3333, AUC: class-0>>0.6666666666666667|class-1>>0.8|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6310\n",
            " Training bag [1/11] bag loss: 0.6458\n",
            " Training bag [2/11] bag loss: 0.6939\n",
            " Training bag [3/11] bag loss: 0.6946\n",
            " Training bag [4/11] bag loss: 0.6313\n",
            " Training bag [5/11] bag loss: 0.6458\n",
            " Training bag [6/11] bag loss: 0.6472\n",
            " Training bag [7/11] bag loss: 0.6427\n",
            " Training bag [8/11] bag loss: 0.6352\n",
            " Training bag [9/11] bag loss: 0.6947\n",
            " Training bag [10/11] bag loss: 0.6310\n",
            " Testing bag [0/6] bag loss: 0.6932\n",
            " Testing bag [1/6] bag loss: 0.6345\n",
            " Testing bag [2/6] bag loss: 0.6488\n",
            " Testing bag [3/6] bag loss: 0.6463\n",
            " Testing bag [4/6] bag loss: 0.6457\n",
            " Testing bag [5/6] bag loss: 0.6318ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [18/300] train loss: 0.6539 test loss: 0.6501, average score: 0.3333, AUC: class-0>>0.5555555555555556|class-1>>0.8|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6306\n",
            " Training bag [1/11] bag loss: 0.6919\n",
            " Training bag [2/11] bag loss: 0.6936\n",
            " Training bag [3/11] bag loss: 0.6303\n",
            " Training bag [4/11] bag loss: 0.6476\n",
            " Training bag [5/11] bag loss: 0.6290\n",
            " Training bag [6/11] bag loss: 0.6476\n",
            " Training bag [7/11] bag loss: 0.6248\n",
            " Training bag [8/11] bag loss: 0.6937\n",
            " Training bag [9/11] bag loss: 0.6494\n",
            " Training bag [10/11] bag loss: 0.6466\n",
            " Testing bag [0/6] bag loss: 0.6940\n",
            " Testing bag [1/6] bag loss: 0.6302\n",
            " Testing bag [2/6] bag loss: 0.6507\n",
            " Testing bag [3/6] bag loss: 0.6489\n",
            " Testing bag [4/6] bag loss: 0.6475\n",
            " Testing bag [5/6] bag loss: 0.6283ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [19/300] train loss: 0.6532 test loss: 0.6499, average score: 0.3333, AUC: class-0>>0.5555555555555556|class-1>>0.8|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6426\n",
            " Training bag [1/11] bag loss: 0.6957\n",
            " Training bag [2/11] bag loss: 0.6308\n",
            " Training bag [3/11] bag loss: 0.6410\n",
            " Training bag [4/11] bag loss: 0.6279\n",
            " Training bag [5/11] bag loss: 0.6411\n",
            " Training bag [6/11] bag loss: 0.6248\n",
            " Training bag [7/11] bag loss: 0.6281\n",
            " Training bag [8/11] bag loss: 0.6998\n",
            " Training bag [9/11] bag loss: 0.6980\n",
            " Training bag [10/11] bag loss: 0.6425\n",
            " Testing bag [0/6] bag loss: 0.6952\n",
            " Testing bag [1/6] bag loss: 0.6279\n",
            " Testing bag [2/6] bag loss: 0.6479\n",
            " Testing bag [3/6] bag loss: 0.6455\n",
            " Testing bag [4/6] bag loss: 0.6439\n",
            " Testing bag [5/6] bag loss: 0.6247ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [20/300] train loss: 0.6520 test loss: 0.6475, average score: 0.3333, AUC: class-0>>0.5555555555555556|class-1>>0.8|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6427\n",
            " Training bag [1/11] bag loss: 0.6966\n",
            " Training bag [2/11] bag loss: 0.6366\n",
            " Training bag [3/11] bag loss: 0.6293\n",
            " Training bag [4/11] bag loss: 0.6266\n",
            " Training bag [5/11] bag loss: 0.6360\n",
            " Training bag [6/11] bag loss: 0.6297\n",
            " Training bag [7/11] bag loss: 0.7002\n",
            " Training bag [8/11] bag loss: 0.6968\n",
            " Training bag [9/11] bag loss: 0.6277\n",
            " Training bag [10/11] bag loss: 0.6395\n",
            " Testing bag [0/6] bag loss: 0.6965\n",
            " Testing bag [1/6] bag loss: 0.6275\n",
            " Testing bag [2/6] bag loss: 0.6454\n",
            " Testing bag [3/6] bag loss: 0.6442\n",
            " Testing bag [4/6] bag loss: 0.6445\n",
            " Testing bag [5/6] bag loss: 0.6242ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [21/300] train loss: 0.6511 test loss: 0.6470, average score: 0.3333, AUC: class-0>>0.5555555555555556|class-1>>0.8|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6380\n",
            " Training bag [1/11] bag loss: 0.6284\n",
            " Training bag [2/11] bag loss: 0.6235\n",
            " Training bag [3/11] bag loss: 0.6248\n",
            " Training bag [4/11] bag loss: 0.6984\n",
            " Training bag [5/11] bag loss: 0.6405\n",
            " Training bag [6/11] bag loss: 0.6164\n",
            " Training bag [7/11] bag loss: 0.7006\n",
            " Training bag [8/11] bag loss: 0.6399\n",
            " Training bag [9/11] bag loss: 0.6403\n",
            " Training bag [10/11] bag loss: 0.7000\n",
            " Testing bag [0/6] bag loss: 0.6974\n",
            " Testing bag [1/6] bag loss: 0.6258\n",
            " Testing bag [2/6] bag loss: 0.6450\n",
            " Testing bag [3/6] bag loss: 0.6407\n",
            " Testing bag [4/6] bag loss: 0.6413\n",
            " Testing bag [5/6] bag loss: 0.6234ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [22/300] train loss: 0.6501 test loss: 0.6456, average score: 0.3333, AUC: class-0>>0.5555555555555556|class-1>>0.8|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6368\n",
            " Training bag [1/11] bag loss: 0.6339\n",
            " Training bag [2/11] bag loss: 0.6976\n",
            " Training bag [3/11] bag loss: 0.6972\n",
            " Training bag [4/11] bag loss: 0.6328\n",
            " Training bag [5/11] bag loss: 0.6339\n",
            " Training bag [6/11] bag loss: 0.6926\n",
            " Training bag [7/11] bag loss: 0.6328\n",
            " Training bag [8/11] bag loss: 0.6284\n",
            " Training bag [9/11] bag loss: 0.6336\n",
            " Training bag [10/11] bag loss: 0.6232\n",
            " Testing bag [0/6] bag loss: 0.6947\n",
            " Testing bag [1/6] bag loss: 0.6279\n",
            " Testing bag [2/6] bag loss: 0.6429\n",
            " Testing bag [3/6] bag loss: 0.6392\n",
            " Testing bag [4/6] bag loss: 0.6393\n",
            " Testing bag [5/6] bag loss: 0.6258ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [23/300] train loss: 0.6493 test loss: 0.6450, average score: 0.3333, AUC: class-0>>0.5555555555555556|class-1>>0.8|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6264\n",
            " Training bag [1/11] bag loss: 0.6350\n",
            " Training bag [2/11] bag loss: 0.6344\n",
            " Training bag [3/11] bag loss: 0.6329\n",
            " Training bag [4/11] bag loss: 0.6242\n",
            " Training bag [5/11] bag loss: 0.6204\n",
            " Training bag [6/11] bag loss: 0.6183\n",
            " Training bag [7/11] bag loss: 0.7069\n",
            " Training bag [8/11] bag loss: 0.7031\n",
            " Training bag [9/11] bag loss: 0.6353\n",
            " Training bag [10/11] bag loss: 0.7030\n",
            " Testing bag [0/6] bag loss: 0.6986\n",
            " Testing bag [1/6] bag loss: 0.6238\n",
            " Testing bag [2/6] bag loss: 0.6407\n",
            " Testing bag [3/6] bag loss: 0.6377\n",
            " Testing bag [4/6] bag loss: 0.6390\n",
            " Testing bag [5/6] bag loss: 0.6207ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [24/300] train loss: 0.6491 test loss: 0.6434, average score: 0.3333, AUC: class-0>>0.5555555555555556|class-1>>0.8|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6341\n",
            " Training bag [1/11] bag loss: 0.6229\n",
            " Training bag [2/11] bag loss: 0.7009\n",
            " Training bag [3/11] bag loss: 0.6190\n",
            " Training bag [4/11] bag loss: 0.6180\n",
            " Training bag [5/11] bag loss: 0.6186\n",
            " Training bag [6/11] bag loss: 0.7001\n",
            " Training bag [7/11] bag loss: 0.6389\n",
            " Training bag [8/11] bag loss: 0.6381\n",
            " Training bag [9/11] bag loss: 0.6977\n",
            " Training bag [10/11] bag loss: 0.6371\n",
            " Testing bag [0/6] bag loss: 0.6971\n",
            " Testing bag [1/6] bag loss: 0.6222\n",
            " Testing bag [2/6] bag loss: 0.6427\n",
            " Testing bag [3/6] bag loss: 0.6385\n",
            " Testing bag [4/6] bag loss: 0.6394\n",
            " Testing bag [5/6] bag loss: 0.6199ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [25/300] train loss: 0.6478 test loss: 0.6433, average score: 0.3333, AUC: class-0>>0.5555555555555556|class-1>>0.8|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6339\n",
            " Training bag [1/11] bag loss: 0.6333\n",
            " Training bag [2/11] bag loss: 0.6250\n",
            " Training bag [3/11] bag loss: 0.6205\n",
            " Training bag [4/11] bag loss: 0.6274\n",
            " Training bag [5/11] bag loss: 0.7041\n",
            " Training bag [6/11] bag loss: 0.6173\n",
            " Training bag [7/11] bag loss: 0.6181\n",
            " Training bag [8/11] bag loss: 0.6307\n",
            " Training bag [9/11] bag loss: 0.7056\n",
            " Training bag [10/11] bag loss: 0.7031\n",
            " Testing bag [0/6] bag loss: 0.7005\n",
            " Testing bag [1/6] bag loss: 0.6206\n",
            " Testing bag [2/6] bag loss: 0.6384\n",
            " Testing bag [3/6] bag loss: 0.6359\n",
            " Testing bag [4/6] bag loss: 0.6371\n",
            " Testing bag [5/6] bag loss: 0.6167ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [26/300] train loss: 0.6472 test loss: 0.6415, average score: 0.3333, AUC: class-0>>0.5555555555555556|class-1>>0.8|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7017\n",
            " Training bag [1/11] bag loss: 0.6322\n",
            " Training bag [2/11] bag loss: 0.6184\n",
            " Training bag [3/11] bag loss: 0.6192\n",
            " Training bag [4/11] bag loss: 0.6988\n",
            " Training bag [5/11] bag loss: 0.6328\n",
            " Training bag [6/11] bag loss: 0.6945\n",
            " Training bag [7/11] bag loss: 0.6340\n",
            " Training bag [8/11] bag loss: 0.6225\n",
            " Training bag [9/11] bag loss: 0.6216\n",
            " Training bag [10/11] bag loss: 0.6324\n",
            " Testing bag [0/6] bag loss: 0.6966\n",
            " Testing bag [1/6] bag loss: 0.6192\n",
            " Testing bag [2/6] bag loss: 0.6401\n",
            " Testing bag [3/6] bag loss: 0.6358\n",
            " Testing bag [4/6] bag loss: 0.6374\n",
            " Testing bag [5/6] bag loss: 0.6181ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [27/300] train loss: 0.6462 test loss: 0.6412, average score: 0.3333, AUC: class-0>>0.5555555555555556|class-1>>0.8|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6306\n",
            " Training bag [1/11] bag loss: 0.6987\n",
            " Training bag [2/11] bag loss: 0.6211\n",
            " Training bag [3/11] bag loss: 0.6299\n",
            " Training bag [4/11] bag loss: 0.6176\n",
            " Training bag [5/11] bag loss: 0.6275\n",
            " Training bag [6/11] bag loss: 0.7011\n",
            " Training bag [7/11] bag loss: 0.6265\n",
            " Training bag [8/11] bag loss: 0.6973\n",
            " Training bag [9/11] bag loss: 0.6254\n",
            " Training bag [10/11] bag loss: 0.6200\n",
            " Testing bag [0/6] bag loss: 0.6995\n",
            " Testing bag [1/6] bag loss: 0.6197\n",
            " Testing bag [2/6] bag loss: 0.6360\n",
            " Testing bag [3/6] bag loss: 0.6319\n",
            " Testing bag [4/6] bag loss: 0.6347\n",
            " Testing bag [5/6] bag loss: 0.6181ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [28/300] train loss: 0.6451 test loss: 0.6400, average score: 0.3333, AUC: class-0>>0.5555555555555556|class-1>>0.8|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6988\n",
            " Training bag [1/11] bag loss: 0.6134\n",
            " Training bag [2/11] bag loss: 0.6185\n",
            " Training bag [3/11] bag loss: 0.6342\n",
            " Training bag [4/11] bag loss: 0.6117\n",
            " Training bag [5/11] bag loss: 0.6330\n",
            " Training bag [6/11] bag loss: 0.6307\n",
            " Training bag [7/11] bag loss: 0.7025\n",
            " Training bag [8/11] bag loss: 0.6281\n",
            " Training bag [9/11] bag loss: 0.7007\n",
            " Training bag [10/11] bag loss: 0.6170\n",
            " Testing bag [0/6] bag loss: 0.6997\n",
            " Testing bag [1/6] bag loss: 0.6191\n",
            " Testing bag [2/6] bag loss: 0.6358\n",
            " Testing bag [3/6] bag loss: 0.6312\n",
            " Testing bag [4/6] bag loss: 0.6329\n",
            " Testing bag [5/6] bag loss: 0.6156ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [29/300] train loss: 0.6444 test loss: 0.6391, average score: 0.3333, AUC: class-0>>0.5555555555555556|class-1>>0.8|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7013\n",
            " Training bag [1/11] bag loss: 0.6280\n",
            " Training bag [2/11] bag loss: 0.6184\n",
            " Training bag [3/11] bag loss: 0.6278\n",
            " Training bag [4/11] bag loss: 0.6260\n",
            " Training bag [5/11] bag loss: 0.6990\n",
            " Training bag [6/11] bag loss: 0.6173\n",
            " Training bag [7/11] bag loss: 0.6154\n",
            " Training bag [8/11] bag loss: 0.6262\n",
            " Training bag [9/11] bag loss: 0.7028\n",
            " Training bag [10/11] bag loss: 0.6185\n",
            " Testing bag [0/6] bag loss: 0.6994\n",
            " Testing bag [1/6] bag loss: 0.6178\n",
            " Testing bag [2/6] bag loss: 0.6354\n",
            " Testing bag [3/6] bag loss: 0.6302\n",
            " Testing bag [4/6] bag loss: 0.6330\n",
            " Testing bag [5/6] bag loss: 0.6136ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [30/300] train loss: 0.6437 test loss: 0.6382, average score: 0.3333, AUC: class-0>>0.5555555555555556|class-1>>0.8|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6990\n",
            " Training bag [1/11] bag loss: 0.6278\n",
            " Training bag [2/11] bag loss: 0.6971\n",
            " Training bag [3/11] bag loss: 0.6262\n",
            " Training bag [4/11] bag loss: 0.6237\n",
            " Training bag [5/11] bag loss: 0.6243\n",
            " Training bag [6/11] bag loss: 0.6219\n",
            " Training bag [7/11] bag loss: 0.6146\n",
            " Training bag [8/11] bag loss: 0.6106\n",
            " Training bag [9/11] bag loss: 0.6996\n",
            " Training bag [10/11] bag loss: 0.6297\n",
            " Testing bag [0/6] bag loss: 0.6990\n",
            " Testing bag [1/6] bag loss: 0.6163\n",
            " Testing bag [2/6] bag loss: 0.6352\n",
            " Testing bag [3/6] bag loss: 0.6323\n",
            " Testing bag [4/6] bag loss: 0.6344\n",
            " Testing bag [5/6] bag loss: 0.6113ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [31/300] train loss: 0.6431 test loss: 0.6381, average score: 0.3333, AUC: class-0>>0.5555555555555556|class-1>>0.8|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6990\n",
            " Training bag [1/11] bag loss: 0.6284\n",
            " Training bag [2/11] bag loss: 0.6128\n",
            " Training bag [3/11] bag loss: 0.6150\n",
            " Training bag [4/11] bag loss: 0.6990\n",
            " Training bag [5/11] bag loss: 0.6975\n",
            " Training bag [6/11] bag loss: 0.6301\n",
            " Training bag [7/11] bag loss: 0.6283\n",
            " Training bag [8/11] bag loss: 0.6115\n",
            " Training bag [9/11] bag loss: 0.6269\n",
            " Training bag [10/11] bag loss: 0.6171\n",
            " Testing bag [0/6] bag loss: 0.6980\n",
            " Testing bag [1/6] bag loss: 0.6159\n",
            " Testing bag [2/6] bag loss: 0.6337\n",
            " Testing bag [3/6] bag loss: 0.6306\n",
            " Testing bag [4/6] bag loss: 0.6328\n",
            " Testing bag [5/6] bag loss: 0.6150ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [32/300] train loss: 0.6423 test loss: 0.6377, average score: 0.3333, AUC: class-0>>0.5555555555555556|class-1>>0.8|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6260\n",
            " Training bag [1/11] bag loss: 0.6107\n",
            " Training bag [2/11] bag loss: 0.7005\n",
            " Training bag [3/11] bag loss: 0.6145\n",
            " Training bag [4/11] bag loss: 0.6272\n",
            " Training bag [5/11] bag loss: 0.6073\n",
            " Training bag [6/11] bag loss: 0.6255\n",
            " Training bag [7/11] bag loss: 0.6093\n",
            " Training bag [8/11] bag loss: 0.7055\n",
            " Training bag [9/11] bag loss: 0.6262\n",
            " Training bag [10/11] bag loss: 0.7073\n",
            " Testing bag [0/6] bag loss: 0.7018\n",
            " Testing bag [1/6] bag loss: 0.6118\n",
            " Testing bag [2/6] bag loss: 0.6332\n",
            " Testing bag [3/6] bag loss: 0.6289\n",
            " Testing bag [4/6] bag loss: 0.6317\n",
            " Testing bag [5/6] bag loss: 0.6081ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [33/300] train loss: 0.6418 test loss: 0.6359, average score: 0.3333, AUC: class-0>>0.5555555555555556|class-1>>0.8|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6077\n",
            " Training bag [1/11] bag loss: 0.6095\n",
            " Training bag [2/11] bag loss: 0.7030\n",
            " Training bag [3/11] bag loss: 0.6280\n",
            " Training bag [4/11] bag loss: 0.7009\n",
            " Training bag [5/11] bag loss: 0.6993\n",
            " Training bag [6/11] bag loss: 0.6106\n",
            " Training bag [7/11] bag loss: 0.6297\n",
            " Training bag [8/11] bag loss: 0.6294\n",
            " Training bag [9/11] bag loss: 0.6268\n",
            " Training bag [10/11] bag loss: 0.6080\n",
            " Testing bag [0/6] bag loss: 0.6993\n",
            " Testing bag [1/6] bag loss: 0.6133\n",
            " Testing bag [2/6] bag loss: 0.6324\n",
            " Testing bag [3/6] bag loss: 0.6287\n",
            " Testing bag [4/6] bag loss: 0.6323\n",
            " Testing bag [5/6] bag loss: 0.6097ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [34/300] train loss: 0.6412 test loss: 0.6359, average score: 0.3333, AUC: class-0>>0.5555555555555556|class-1>>0.8|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6125\n",
            " Training bag [1/11] bag loss: 0.6107\n",
            " Training bag [2/11] bag loss: 0.7023\n",
            " Training bag [3/11] bag loss: 0.6280\n",
            " Training bag [4/11] bag loss: 0.6032\n",
            " Training bag [5/11] bag loss: 0.6282\n",
            " Training bag [6/11] bag loss: 0.6252\n",
            " Training bag [7/11] bag loss: 0.6226\n",
            " Training bag [8/11] bag loss: 0.7097\n",
            " Training bag [9/11] bag loss: 0.7062\n",
            " Training bag [10/11] bag loss: 0.6081\n",
            " Testing bag [0/6] bag loss: 0.7038\n",
            " Testing bag [1/6] bag loss: 0.6129\n",
            " Testing bag [2/6] bag loss: 0.6304\n",
            " Testing bag [3/6] bag loss: 0.6263\n",
            " Testing bag [4/6] bag loss: 0.6297\n",
            " Testing bag [5/6] bag loss: 0.6083ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [35/300] train loss: 0.6415 test loss: 0.6352, average score: 0.3333, AUC: class-0>>0.5555555555555556|class-1>>0.8|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7009\n",
            " Training bag [1/11] bag loss: 0.6992\n",
            " Training bag [2/11] bag loss: 0.6125\n",
            " Training bag [3/11] bag loss: 0.6251\n",
            " Training bag [4/11] bag loss: 0.6244\n",
            " Training bag [5/11] bag loss: 0.6252\n",
            " Training bag [6/11] bag loss: 0.6096\n",
            " Training bag [7/11] bag loss: 0.6178\n",
            " Training bag [8/11] bag loss: 0.6143\n",
            " Training bag [9/11] bag loss: 0.6081\n",
            " Training bag [10/11] bag loss: 0.7066\n",
            " Testing bag [0/6] bag loss: 0.7031\n",
            " Testing bag [1/6] bag loss: 0.6119\n",
            " Testing bag [2/6] bag loss: 0.6294\n",
            " Testing bag [3/6] bag loss: 0.6241\n",
            " Testing bag [4/6] bag loss: 0.6289\n",
            " Testing bag [5/6] bag loss: 0.6070ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [36/300] train loss: 0.6403 test loss: 0.6341, average score: 0.3333, AUC: class-0>>0.5555555555555556|class-1>>0.8|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7056\n",
            " Training bag [1/11] bag loss: 0.6995\n",
            " Training bag [2/11] bag loss: 0.6232\n",
            " Training bag [3/11] bag loss: 0.6151\n",
            " Training bag [4/11] bag loss: 0.6976\n",
            " Training bag [5/11] bag loss: 0.6239\n",
            " Training bag [6/11] bag loss: 0.6236\n",
            " Training bag [7/11] bag loss: 0.6144\n",
            " Training bag [8/11] bag loss: 0.6084\n",
            " Training bag [9/11] bag loss: 0.6194\n",
            " Training bag [10/11] bag loss: 0.6077\n",
            " Testing bag [0/6] bag loss: 0.7016\n",
            " Testing bag [1/6] bag loss: 0.6119\n",
            " Testing bag [2/6] bag loss: 0.6282\n",
            " Testing bag [3/6] bag loss: 0.6250\n",
            " Testing bag [4/6] bag loss: 0.6291\n",
            " Testing bag [5/6] bag loss: 0.6070ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [37/300] train loss: 0.6399 test loss: 0.6338, average score: 0.3333, AUC: class-0>>0.5555555555555556|class-1>>0.8|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6125\n",
            " Training bag [1/11] bag loss: 0.6217\n",
            " Training bag [2/11] bag loss: 0.6071\n",
            " Training bag [3/11] bag loss: 0.7095\n",
            " Training bag [4/11] bag loss: 0.6208\n",
            " Training bag [5/11] bag loss: 0.7062\n",
            " Training bag [6/11] bag loss: 0.6024\n",
            " Training bag [7/11] bag loss: 0.6245\n",
            " Training bag [8/11] bag loss: 0.6206\n",
            " Training bag [9/11] bag loss: 0.7033\n",
            " Training bag [10/11] bag loss: 0.6032\n",
            " Testing bag [0/6] bag loss: 0.7046\n",
            " Testing bag [1/6] bag loss: 0.6109\n",
            " Testing bag [2/6] bag loss: 0.6287\n",
            " Testing bag [3/6] bag loss: 0.6228\n",
            " Testing bag [4/6] bag loss: 0.6275\n",
            " Testing bag [5/6] bag loss: 0.6071ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [38/300] train loss: 0.6393 test loss: 0.6336, average score: 0.3333, AUC: class-0>>0.5555555555555556|class-1>>0.8|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7031\n",
            " Training bag [1/11] bag loss: 0.7008\n",
            " Training bag [2/11] bag loss: 0.6050\n",
            " Training bag [3/11] bag loss: 0.6237\n",
            " Training bag [4/11] bag loss: 0.6107\n",
            " Training bag [5/11] bag loss: 0.6217\n",
            " Training bag [6/11] bag loss: 0.6083\n",
            " Training bag [7/11] bag loss: 0.6213\n",
            " Training bag [8/11] bag loss: 0.5989\n",
            " Training bag [9/11] bag loss: 0.6227\n",
            " Training bag [10/11] bag loss: 0.7103\n",
            " Testing bag [0/6] bag loss: 0.7043\n",
            " Testing bag [1/6] bag loss: 0.6060\n",
            " Testing bag [2/6] bag loss: 0.6286\n",
            " Testing bag [3/6] bag loss: 0.6231\n",
            " Testing bag [4/6] bag loss: 0.6270\n",
            " Testing bag [5/6] bag loss: 0.6047ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [39/300] train loss: 0.6388 test loss: 0.6323, average score: 0.3333, AUC: class-0>>0.5555555555555556|class-1>>0.8|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6197\n",
            " Training bag [1/11] bag loss: 0.6007\n",
            " Training bag [2/11] bag loss: 0.6073\n",
            " Training bag [3/11] bag loss: 0.7076\n",
            " Training bag [4/11] bag loss: 0.6220\n",
            " Training bag [5/11] bag loss: 0.7042\n",
            " Training bag [6/11] bag loss: 0.6080\n",
            " Training bag [7/11] bag loss: 0.5990\n",
            " Training bag [8/11] bag loss: 0.6188\n",
            " Training bag [9/11] bag loss: 0.7075\n",
            " Training bag [10/11] bag loss: 0.6206\n",
            " Testing bag [0/6] bag loss: 0.7033\n",
            " Testing bag [1/6] bag loss: 0.6079\n",
            " Testing bag [2/6] bag loss: 0.6278\n",
            " Testing bag [3/6] bag loss: 0.6244\n",
            " Testing bag [4/6] bag loss: 0.6284\n",
            " Testing bag [5/6] bag loss: 0.6011ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [40/300] train loss: 0.6378 test loss: 0.6322, average score: 0.3333, AUC: class-0>>0.5555555555555556|class-1>>0.8|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6174\n",
            " Training bag [1/11] bag loss: 0.6021\n",
            " Training bag [2/11] bag loss: 0.7059\n",
            " Training bag [3/11] bag loss: 0.7039\n",
            " Training bag [4/11] bag loss: 0.6080\n",
            " Training bag [5/11] bag loss: 0.6202\n",
            " Training bag [6/11] bag loss: 0.7059\n",
            " Training bag [7/11] bag loss: 0.6207\n",
            " Training bag [8/11] bag loss: 0.6100\n",
            " Training bag [9/11] bag loss: 0.6193\n",
            " Training bag [10/11] bag loss: 0.6022\n",
            " Testing bag [0/6] bag loss: 0.7049\n",
            " Testing bag [1/6] bag loss: 0.6087\n",
            " Testing bag [2/6] bag loss: 0.6272\n",
            " Testing bag [3/6] bag loss: 0.6217\n",
            " Testing bag [4/6] bag loss: 0.6255\n",
            " Testing bag [5/6] bag loss: 0.6026ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [41/300] train loss: 0.6378 test loss: 0.6318, average score: 0.3333, AUC: class-0>>0.5555555555555556|class-1>>0.8|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6076\n",
            " Training bag [1/11] bag loss: 0.7061\n",
            " Training bag [2/11] bag loss: 0.6220\n",
            " Training bag [3/11] bag loss: 0.7012\n",
            " Training bag [4/11] bag loss: 0.6207\n",
            " Training bag [5/11] bag loss: 0.6066\n",
            " Training bag [6/11] bag loss: 0.7033\n",
            " Training bag [7/11] bag loss: 0.6018\n",
            " Training bag [8/11] bag loss: 0.6194\n",
            " Training bag [9/11] bag loss: 0.5978\n",
            " Training bag [10/11] bag loss: 0.6181\n",
            " Testing bag [0/6] bag loss: 0.7052\n",
            " Testing bag [1/6] bag loss: 0.6071\n",
            " Testing bag [2/6] bag loss: 0.6275\n",
            " Testing bag [3/6] bag loss: 0.6225\n",
            " Testing bag [4/6] bag loss: 0.6263\n",
            " Testing bag [5/6] bag loss: 0.5998ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [42/300] train loss: 0.6368 test loss: 0.6314, average score: 0.3333, AUC: class-0>>0.5555555555555556|class-1>>0.8|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6001\n",
            " Training bag [1/11] bag loss: 0.6168\n",
            " Training bag [2/11] bag loss: 0.7055\n",
            " Training bag [3/11] bag loss: 0.6198\n",
            " Training bag [4/11] bag loss: 0.6067\n",
            " Training bag [5/11] bag loss: 0.7104\n",
            " Training bag [6/11] bag loss: 0.6152\n",
            " Training bag [7/11] bag loss: 0.7044\n",
            " Training bag [8/11] bag loss: 0.6072\n",
            " Training bag [9/11] bag loss: 0.6175\n",
            " Training bag [10/11] bag loss: 0.6011\n",
            " Testing bag [0/6] bag loss: 0.7046\n",
            " Testing bag [1/6] bag loss: 0.6087\n",
            " Testing bag [2/6] bag loss: 0.6257\n",
            " Testing bag [3/6] bag loss: 0.6206\n",
            " Testing bag [4/6] bag loss: 0.6240\n",
            " Testing bag [5/6] bag loss: 0.6033ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [43/300] train loss: 0.6368 test loss: 0.6311, average score: 0.3333, AUC: class-0>>0.5555555555555556|class-1>>0.8|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6150\n",
            " Training bag [1/11] bag loss: 0.6065\n",
            " Training bag [2/11] bag loss: 0.7050\n",
            " Training bag [3/11] bag loss: 0.5977\n",
            " Training bag [4/11] bag loss: 0.6192\n",
            " Training bag [5/11] bag loss: 0.7074\n",
            " Training bag [6/11] bag loss: 0.6167\n",
            " Training bag [7/11] bag loss: 0.6048\n",
            " Training bag [8/11] bag loss: 0.5990\n",
            " Training bag [9/11] bag loss: 0.6136\n",
            " Training bag [10/11] bag loss: 0.7091\n",
            " Testing bag [0/6] bag loss: 0.7063\n",
            " Testing bag [1/6] bag loss: 0.6033\n",
            " Testing bag [2/6] bag loss: 0.6245\n",
            " Testing bag [3/6] bag loss: 0.6203\n",
            " Testing bag [4/6] bag loss: 0.6217\n",
            " Testing bag [5/6] bag loss: 0.6018ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [44/300] train loss: 0.6358 test loss: 0.6296, average score: 0.3333, AUC: class-0>>0.5555555555555556|class-1>>0.8|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5980\n",
            " Training bag [1/11] bag loss: 0.5945\n",
            " Training bag [2/11] bag loss: 0.7126\n",
            " Training bag [3/11] bag loss: 0.5983\n",
            " Training bag [4/11] bag loss: 0.6233\n",
            " Training bag [5/11] bag loss: 0.7074\n",
            " Training bag [6/11] bag loss: 0.6195\n",
            " Training bag [7/11] bag loss: 0.7022\n",
            " Training bag [8/11] bag loss: 0.6191\n",
            " Training bag [9/11] bag loss: 0.6035\n",
            " Training bag [10/11] bag loss: 0.6189\n",
            " Testing bag [0/6] bag loss: 0.7031\n",
            " Testing bag [1/6] bag loss: 0.6051\n",
            " Testing bag [2/6] bag loss: 0.6260\n",
            " Testing bag [3/6] bag loss: 0.6204\n",
            " Testing bag [4/6] bag loss: 0.6233\n",
            " Testing bag [5/6] bag loss: 0.5989ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [45/300] train loss: 0.6361 test loss: 0.6295, average score: 0.3333, AUC: class-0>>0.5555555555555556|class-1>>0.8|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6164\n",
            " Training bag [1/11] bag loss: 0.7060\n",
            " Training bag [2/11] bag loss: 0.6126\n",
            " Training bag [3/11] bag loss: 0.5982\n",
            " Training bag [4/11] bag loss: 0.7028\n",
            " Training bag [5/11] bag loss: 0.6018\n",
            " Training bag [6/11] bag loss: 0.6160\n",
            " Training bag [7/11] bag loss: 0.7083\n",
            " Training bag [8/11] bag loss: 0.6116\n",
            " Training bag [9/11] bag loss: 0.6062\n",
            " Training bag [10/11] bag loss: 0.6084\n",
            " Testing bag [0/6] bag loss: 0.7035\n",
            " Testing bag [1/6] bag loss: 0.6060\n",
            " Testing bag [2/6] bag loss: 0.6232\n",
            " Testing bag [3/6] bag loss: 0.6176\n",
            " Testing bag [4/6] bag loss: 0.6214\n",
            " Testing bag [5/6] bag loss: 0.6037ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [46/300] train loss: 0.6353 test loss: 0.6292, average score: 0.3333, AUC: class-0>>0.5555555555555556|class-1>>0.8|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6155\n",
            " Training bag [1/11] bag loss: 0.7093\n",
            " Training bag [2/11] bag loss: 0.6107\n",
            " Training bag [3/11] bag loss: 0.5975\n",
            " Training bag [4/11] bag loss: 0.6113\n",
            " Training bag [5/11] bag loss: 0.6045\n",
            " Training bag [6/11] bag loss: 0.7055\n",
            " Training bag [7/11] bag loss: 0.7070\n",
            " Training bag [8/11] bag loss: 0.6080\n",
            " Training bag [9/11] bag loss: 0.5996\n",
            " Training bag [10/11] bag loss: 0.6129\n",
            " Testing bag [0/6] bag loss: 0.7062\n",
            " Testing bag [1/6] bag loss: 0.6034\n",
            " Testing bag [2/6] bag loss: 0.6250\n",
            " Testing bag [3/6] bag loss: 0.6193\n",
            " Testing bag [4/6] bag loss: 0.6235\n",
            " Testing bag [5/6] bag loss: 0.5985ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [47/300] train loss: 0.6347 test loss: 0.6293, average score: 0.3333, AUC: class-0>>0.5555555555555556|class-1>>0.8|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6146\n",
            " Training bag [1/11] bag loss: 0.7082\n",
            " Training bag [2/11] bag loss: 0.5983\n",
            " Training bag [3/11] bag loss: 0.6012\n",
            " Training bag [4/11] bag loss: 0.7069\n",
            " Training bag [5/11] bag loss: 0.6136\n",
            " Training bag [6/11] bag loss: 0.7002\n",
            " Training bag [7/11] bag loss: 0.6043\n",
            " Training bag [8/11] bag loss: 0.5944\n",
            " Training bag [9/11] bag loss: 0.6174\n",
            " Training bag [10/11] bag loss: 0.6204\n",
            " Testing bag [0/6] bag loss: 0.7038\n",
            " Testing bag [1/6] bag loss: 0.6043\n",
            " Testing bag [2/6] bag loss: 0.6259\n",
            " Testing bag [3/6] bag loss: 0.6196\n",
            " Testing bag [4/6] bag loss: 0.6230\n",
            " Testing bag [5/6] bag loss: 0.5984ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [48/300] train loss: 0.6345 test loss: 0.6292, average score: 0.3333, AUC: class-0>>0.5555555555555556|class-1>>0.8|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6016\n",
            " Training bag [1/11] bag loss: 0.6145\n",
            " Training bag [2/11] bag loss: 0.6145\n",
            " Training bag [3/11] bag loss: 0.6127\n",
            " Training bag [4/11] bag loss: 0.7125\n",
            " Training bag [5/11] bag loss: 0.6020\n",
            " Training bag [6/11] bag loss: 0.6059\n",
            " Training bag [7/11] bag loss: 0.7149\n",
            " Training bag [8/11] bag loss: 0.7056\n",
            " Training bag [9/11] bag loss: 0.5964\n",
            " Training bag [10/11] bag loss: 0.5998\n",
            " Testing bag [0/6] bag loss: 0.7047\n",
            " Testing bag [1/6] bag loss: 0.6045\n",
            " Testing bag [2/6] bag loss: 0.6226\n",
            " Testing bag [3/6] bag loss: 0.6151\n",
            " Testing bag [4/6] bag loss: 0.6205\n",
            " Testing bag [5/6] bag loss: 0.5995ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [49/300] train loss: 0.6346 test loss: 0.6278, average score: 0.3333, AUC: class-0>>0.5555555555555556|class-1>>0.8|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6099\n",
            " Training bag [1/11] bag loss: 0.7081\n",
            " Training bag [2/11] bag loss: 0.6044\n",
            " Training bag [3/11] bag loss: 0.5937\n",
            " Training bag [4/11] bag loss: 0.6111\n",
            " Training bag [5/11] bag loss: 0.6151\n",
            " Training bag [6/11] bag loss: 0.7075\n",
            " Training bag [7/11] bag loss: 0.7093\n",
            " Training bag [8/11] bag loss: 0.6027\n",
            " Training bag [9/11] bag loss: 0.6120\n",
            " Training bag [10/11] bag loss: 0.5967\n",
            " Testing bag [0/6] bag loss: 0.7067\n",
            " Testing bag [1/6] bag loss: 0.6031\n",
            " Testing bag [2/6] bag loss: 0.6220\n",
            " Testing bag [3/6] bag loss: 0.6169\n",
            " Testing bag [4/6] bag loss: 0.6184\n",
            " Testing bag [5/6] bag loss: 0.6002ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [50/300] train loss: 0.6337 test loss: 0.6279, average score: 0.3333, AUC: class-0>>0.5555555555555556|class-1>>0.8|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7083\n",
            " Training bag [1/11] bag loss: 0.7013\n",
            " Training bag [2/11] bag loss: 0.6113\n",
            " Training bag [3/11] bag loss: 0.6048\n",
            " Training bag [4/11] bag loss: 0.5943\n",
            " Training bag [5/11] bag loss: 0.6122\n",
            " Training bag [6/11] bag loss: 0.6013\n",
            " Training bag [7/11] bag loss: 0.5924\n",
            " Training bag [8/11] bag loss: 0.6158\n",
            " Training bag [9/11] bag loss: 0.7114\n",
            " Training bag [10/11] bag loss: 0.6174\n",
            " Testing bag [0/6] bag loss: 0.7052\n",
            " Testing bag [1/6] bag loss: 0.5989\n",
            " Testing bag [2/6] bag loss: 0.6235\n",
            " Testing bag [3/6] bag loss: 0.6182\n",
            " Testing bag [4/6] bag loss: 0.6235\n",
            " Testing bag [5/6] bag loss: 0.5940ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [51/300] train loss: 0.6337 test loss: 0.6272, average score: 0.3333, AUC: class-0>>0.5555555555555556|class-1>>0.8|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6135\n",
            " Training bag [1/11] bag loss: 0.7097\n",
            " Training bag [2/11] bag loss: 0.6038\n",
            " Training bag [3/11] bag loss: 0.5949\n",
            " Training bag [4/11] bag loss: 0.5992\n",
            " Training bag [5/11] bag loss: 0.5855\n",
            " Training bag [6/11] bag loss: 0.7052\n",
            " Training bag [7/11] bag loss: 0.7087\n",
            " Training bag [8/11] bag loss: 0.6182\n",
            " Training bag [9/11] bag loss: 0.6201\n",
            " Training bag [10/11] bag loss: 0.6147\n",
            " Testing bag [0/6] bag loss: 0.7040\n",
            " Testing bag [1/6] bag loss: 0.6015\n",
            " Testing bag [2/6] bag loss: 0.6245\n",
            " Testing bag [3/6] bag loss: 0.6174\n",
            " Testing bag [4/6] bag loss: 0.6248\n",
            " Testing bag [5/6] bag loss: 0.5933ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [52/300] train loss: 0.6340 test loss: 0.6276, average score: 0.1667, AUC: class-0>>0.5555555555555556|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7023\n",
            " Training bag [1/11] bag loss: 0.5907\n",
            " Training bag [2/11] bag loss: 0.6164\n",
            " Training bag [3/11] bag loss: 0.6110\n",
            " Training bag [4/11] bag loss: 0.6110\n",
            " Training bag [5/11] bag loss: 0.5946\n",
            " Training bag [6/11] bag loss: 0.6059\n",
            " Training bag [7/11] bag loss: 0.7125\n",
            " Training bag [8/11] bag loss: 0.7120\n",
            " Training bag [9/11] bag loss: 0.6063\n",
            " Training bag [10/11] bag loss: 0.6040\n",
            " Testing bag [0/6] bag loss: 0.7071\n",
            " Testing bag [1/6] bag loss: 0.6022\n",
            " Testing bag [2/6] bag loss: 0.6202\n",
            " Testing bag [3/6] bag loss: 0.6128\n",
            " Testing bag [4/6] bag loss: 0.6185\n",
            " Testing bag [5/6] bag loss: 0.5969ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [53/300] train loss: 0.6333 test loss: 0.6263, average score: 0.3333, AUC: class-0>>0.5555555555555556|class-1>>0.8|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7080\n",
            " Training bag [1/11] bag loss: 0.5999\n",
            " Training bag [2/11] bag loss: 0.5927\n",
            " Training bag [3/11] bag loss: 0.6131\n",
            " Training bag [4/11] bag loss: 0.7017\n",
            " Training bag [5/11] bag loss: 0.5874\n",
            " Training bag [6/11] bag loss: 0.6155\n",
            " Training bag [7/11] bag loss: 0.6181\n",
            " Training bag [8/11] bag loss: 0.6092\n",
            " Training bag [9/11] bag loss: 0.5999\n",
            " Training bag [10/11] bag loss: 0.7125\n",
            " Testing bag [0/6] bag loss: 0.7080\n",
            " Testing bag [1/6] bag loss: 0.6004\n",
            " Testing bag [2/6] bag loss: 0.6208\n",
            " Testing bag [3/6] bag loss: 0.6141\n",
            " Testing bag [4/6] bag loss: 0.6212\n",
            " Testing bag [5/6] bag loss: 0.5945ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [54/300] train loss: 0.6325 test loss: 0.6265, average score: 0.3333, AUC: class-0>>0.5555555555555556|class-1>>0.8|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6081\n",
            " Training bag [1/11] bag loss: 0.6004\n",
            " Training bag [2/11] bag loss: 0.6082\n",
            " Training bag [3/11] bag loss: 0.7126\n",
            " Training bag [4/11] bag loss: 0.6078\n",
            " Training bag [5/11] bag loss: 0.6081\n",
            " Training bag [6/11] bag loss: 0.5937\n",
            " Training bag [7/11] bag loss: 0.6019\n",
            " Training bag [8/11] bag loss: 0.7097\n",
            " Training bag [9/11] bag loss: 0.5934\n",
            " Training bag [10/11] bag loss: 0.7163\n",
            " Testing bag [0/6] bag loss: 0.7074\n",
            " Testing bag [1/6] bag loss: 0.6009\n",
            " Testing bag [2/6] bag loss: 0.6196\n",
            " Testing bag [3/6] bag loss: 0.6131\n",
            " Testing bag [4/6] bag loss: 0.6189\n",
            " Testing bag [5/6] bag loss: 0.5961ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [55/300] train loss: 0.6327 test loss: 0.6260, average score: 0.3333, AUC: class-0>>0.5555555555555556|class-1>>0.8|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6076\n",
            " Training bag [1/11] bag loss: 0.7116\n",
            " Training bag [2/11] bag loss: 0.6015\n",
            " Training bag [3/11] bag loss: 0.7124\n",
            " Training bag [4/11] bag loss: 0.6108\n",
            " Training bag [5/11] bag loss: 0.5889\n",
            " Training bag [6/11] bag loss: 0.6115\n",
            " Training bag [7/11] bag loss: 0.6000\n",
            " Training bag [8/11] bag loss: 0.7035\n",
            " Training bag [9/11] bag loss: 0.6059\n",
            " Training bag [10/11] bag loss: 0.5936\n",
            " Testing bag [0/6] bag loss: 0.7071\n",
            " Testing bag [1/6] bag loss: 0.6017\n",
            " Testing bag [2/6] bag loss: 0.6197\n",
            " Testing bag [3/6] bag loss: 0.6135\n",
            " Testing bag [4/6] bag loss: 0.6213\n",
            " Testing bag [5/6] bag loss: 0.5938ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [56/300] train loss: 0.6316 test loss: 0.6262, average score: 0.3333, AUC: class-0>>0.5555555555555556|class-1>>0.8|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6122\n",
            " Training bag [1/11] bag loss: 0.5928\n",
            " Training bag [2/11] bag loss: 0.7111\n",
            " Training bag [3/11] bag loss: 0.6074\n",
            " Training bag [4/11] bag loss: 0.5867\n",
            " Training bag [5/11] bag loss: 0.6094\n",
            " Training bag [6/11] bag loss: 0.7153\n",
            " Training bag [7/11] bag loss: 0.6002\n",
            " Training bag [8/11] bag loss: 0.6042\n",
            " Training bag [9/11] bag loss: 0.7047\n",
            " Training bag [10/11] bag loss: 0.5984\n",
            " Testing bag [0/6] bag loss: 0.7070\n",
            " Testing bag [1/6] bag loss: 0.5992\n",
            " Testing bag [2/6] bag loss: 0.6187\n",
            " Testing bag [3/6] bag loss: 0.6132\n",
            " Testing bag [4/6] bag loss: 0.6180\n",
            " Testing bag [5/6] bag loss: 0.5933ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [57/300] train loss: 0.6311 test loss: 0.6249, average score: 0.1667, AUC: class-0>>0.5555555555555556|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7108\n",
            " Training bag [1/11] bag loss: 0.5906\n",
            " Training bag [2/11] bag loss: 0.6150\n",
            " Training bag [3/11] bag loss: 0.6114\n",
            " Training bag [4/11] bag loss: 0.7094\n",
            " Training bag [5/11] bag loss: 0.6067\n",
            " Training bag [6/11] bag loss: 0.6019\n",
            " Training bag [7/11] bag loss: 0.7003\n",
            " Training bag [8/11] bag loss: 0.5909\n",
            " Training bag [9/11] bag loss: 0.5997\n",
            " Training bag [10/11] bag loss: 0.6075\n",
            " Testing bag [0/6] bag loss: 0.7060\n",
            " Testing bag [1/6] bag loss: 0.5969\n",
            " Testing bag [2/6] bag loss: 0.6199\n",
            " Testing bag [3/6] bag loss: 0.6146\n",
            " Testing bag [4/6] bag loss: 0.6185\n",
            " Testing bag [5/6] bag loss: 0.5917ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [58/300] train loss: 0.6313 test loss: 0.6246, average score: 0.1667, AUC: class-0>>0.5555555555555556|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5976\n",
            " Training bag [1/11] bag loss: 0.6079\n",
            " Training bag [2/11] bag loss: 0.5852\n",
            " Training bag [3/11] bag loss: 0.5869\n",
            " Training bag [4/11] bag loss: 0.7132\n",
            " Training bag [5/11] bag loss: 0.6101\n",
            " Training bag [6/11] bag loss: 0.6106\n",
            " Training bag [7/11] bag loss: 0.7061\n",
            " Training bag [8/11] bag loss: 0.7137\n",
            " Training bag [9/11] bag loss: 0.5970\n",
            " Training bag [10/11] bag loss: 0.6129\n",
            " Testing bag [0/6] bag loss: 0.7065\n",
            " Testing bag [1/6] bag loss: 0.5989\n",
            " Testing bag [2/6] bag loss: 0.6199\n",
            " Testing bag [3/6] bag loss: 0.6138\n",
            " Testing bag [4/6] bag loss: 0.6169\n",
            " Testing bag [5/6] bag loss: 0.5908ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [59/300] train loss: 0.6310 test loss: 0.6245, average score: 0.3333, AUC: class-0>>0.5555555555555556|class-1>>0.8|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5895\n",
            " Training bag [1/11] bag loss: 0.5956\n",
            " Training bag [2/11] bag loss: 0.5917\n",
            " Training bag [3/11] bag loss: 0.7122\n",
            " Training bag [4/11] bag loss: 0.6170\n",
            " Training bag [5/11] bag loss: 0.6117\n",
            " Training bag [6/11] bag loss: 0.7124\n",
            " Training bag [7/11] bag loss: 0.6111\n",
            " Training bag [8/11] bag loss: 0.5843\n",
            " Training bag [9/11] bag loss: 0.7036\n",
            " Training bag [10/11] bag loss: 0.6086\n",
            " Testing bag [0/6] bag loss: 0.7083\n",
            " Testing bag [1/6] bag loss: 0.5975\n",
            " Testing bag [2/6] bag loss: 0.6209\n",
            " Testing bag [3/6] bag loss: 0.6136\n",
            " Testing bag [4/6] bag loss: 0.6175\n",
            " Testing bag [5/6] bag loss: 0.5900ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [60/300] train loss: 0.6307 test loss: 0.6246, average score: 0.1667, AUC: class-0>>0.5555555555555556|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7097\n",
            " Training bag [1/11] bag loss: 0.6070\n",
            " Training bag [2/11] bag loss: 0.6017\n",
            " Training bag [3/11] bag loss: 0.5869\n",
            " Training bag [4/11] bag loss: 0.7113\n",
            " Training bag [5/11] bag loss: 0.5946\n",
            " Training bag [6/11] bag loss: 0.5881\n",
            " Training bag [7/11] bag loss: 0.6155\n",
            " Training bag [8/11] bag loss: 0.7034\n",
            " Training bag [9/11] bag loss: 0.6137\n",
            " Training bag [10/11] bag loss: 0.6093\n",
            " Testing bag [0/6] bag loss: 0.7055\n",
            " Testing bag [1/6] bag loss: 0.5944\n",
            " Testing bag [2/6] bag loss: 0.6209\n",
            " Testing bag [3/6] bag loss: 0.6136\n",
            " Testing bag [4/6] bag loss: 0.6176\n",
            " Testing bag [5/6] bag loss: 0.5893ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [61/300] train loss: 0.6310 test loss: 0.6236, average score: 0.1667, AUC: class-0>>0.5555555555555556|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6107\n",
            " Training bag [1/11] bag loss: 0.7113\n",
            " Training bag [2/11] bag loss: 0.5847\n",
            " Training bag [3/11] bag loss: 0.6055\n",
            " Training bag [4/11] bag loss: 0.6063\n",
            " Training bag [5/11] bag loss: 0.6003\n",
            " Training bag [6/11] bag loss: 0.7038\n",
            " Training bag [7/11] bag loss: 0.7105\n",
            " Training bag [8/11] bag loss: 0.5920\n",
            " Training bag [9/11] bag loss: 0.6030\n",
            " Training bag [10/11] bag loss: 0.5967\n",
            " Testing bag [0/6] bag loss: 0.7050\n",
            " Testing bag [1/6] bag loss: 0.6005\n",
            " Testing bag [2/6] bag loss: 0.6182\n",
            " Testing bag [3/6] bag loss: 0.6112\n",
            " Testing bag [4/6] bag loss: 0.6188\n",
            " Testing bag [5/6] bag loss: 0.5918ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [62/300] train loss: 0.6295 test loss: 0.6242, average score: 0.1667, AUC: class-0>>0.5555555555555556|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6083\n",
            " Training bag [1/11] bag loss: 0.6036\n",
            " Training bag [2/11] bag loss: 0.5961\n",
            " Training bag [3/11] bag loss: 0.5860\n",
            " Training bag [4/11] bag loss: 0.5971\n",
            " Training bag [5/11] bag loss: 0.7189\n",
            " Training bag [6/11] bag loss: 0.7165\n",
            " Training bag [7/11] bag loss: 0.5852\n",
            " Training bag [8/11] bag loss: 0.7037\n",
            " Training bag [9/11] bag loss: 0.6117\n",
            " Training bag [10/11] bag loss: 0.6073\n",
            " Testing bag [0/6] bag loss: 0.7070\n",
            " Testing bag [1/6] bag loss: 0.5951\n",
            " Testing bag [2/6] bag loss: 0.6208\n",
            " Testing bag [3/6] bag loss: 0.6130\n",
            " Testing bag [4/6] bag loss: 0.6192\n",
            " Testing bag [5/6] bag loss: 0.5888ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [63/300] train loss: 0.6304 test loss: 0.6240, average score: 0.1667, AUC: class-0>>0.5555555555555556|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6070\n",
            " Training bag [1/11] bag loss: 0.5817\n",
            " Training bag [2/11] bag loss: 0.6062\n",
            " Training bag [3/11] bag loss: 0.7051\n",
            " Training bag [4/11] bag loss: 0.7135\n",
            " Training bag [5/11] bag loss: 0.7138\n",
            " Training bag [6/11] bag loss: 0.5963\n",
            " Training bag [7/11] bag loss: 0.5990\n",
            " Training bag [8/11] bag loss: 0.5905\n",
            " Training bag [9/11] bag loss: 0.6064\n",
            " Training bag [10/11] bag loss: 0.6151\n",
            " Testing bag [0/6] bag loss: 0.7053\n",
            " Testing bag [1/6] bag loss: 0.5967\n",
            " Testing bag [2/6] bag loss: 0.6185\n",
            " Testing bag [3/6] bag loss: 0.6119\n",
            " Testing bag [4/6] bag loss: 0.6196\n",
            " Testing bag [5/6] bag loss: 0.5863ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [64/300] train loss: 0.6304 test loss: 0.6231, average score: 0.1667, AUC: class-0>>0.5555555555555556|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6065\n",
            " Training bag [1/11] bag loss: 0.7112\n",
            " Training bag [2/11] bag loss: 0.5845\n",
            " Training bag [3/11] bag loss: 0.6079\n",
            " Training bag [4/11] bag loss: 0.5888\n",
            " Training bag [5/11] bag loss: 0.6058\n",
            " Training bag [6/11] bag loss: 0.7167\n",
            " Training bag [7/11] bag loss: 0.6004\n",
            " Training bag [8/11] bag loss: 0.5981\n",
            " Training bag [9/11] bag loss: 0.7031\n",
            " Training bag [10/11] bag loss: 0.5986\n",
            " Testing bag [0/6] bag loss: 0.7080\n",
            " Testing bag [1/6] bag loss: 0.5995\n",
            " Testing bag [2/6] bag loss: 0.6171\n",
            " Testing bag [3/6] bag loss: 0.6084\n",
            " Testing bag [4/6] bag loss: 0.6158\n",
            " Testing bag [5/6] bag loss: 0.5919ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [65/300] train loss: 0.6292 test loss: 0.6234, average score: 0.1667, AUC: class-0>>0.5555555555555556|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7113\n",
            " Training bag [1/11] bag loss: 0.5865\n",
            " Training bag [2/11] bag loss: 0.5913\n",
            " Training bag [3/11] bag loss: 0.7011\n",
            " Training bag [4/11] bag loss: 0.6095\n",
            " Training bag [5/11] bag loss: 0.5936\n",
            " Training bag [6/11] bag loss: 0.6136\n",
            " Training bag [7/11] bag loss: 0.5772\n",
            " Training bag [8/11] bag loss: 0.7090\n",
            " Training bag [9/11] bag loss: 0.6111\n",
            " Training bag [10/11] bag loss: 0.6057\n",
            " Testing bag [0/6] bag loss: 0.7061\n",
            " Testing bag [1/6] bag loss: 0.5949\n",
            " Testing bag [2/6] bag loss: 0.6184\n",
            " Testing bag [3/6] bag loss: 0.6126\n",
            " Testing bag [4/6] bag loss: 0.6188\n",
            " Testing bag [5/6] bag loss: 0.5870ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [66/300] train loss: 0.6282 test loss: 0.6230, average score: 0.1667, AUC: class-0>>0.5555555555555556|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6056\n",
            " Training bag [1/11] bag loss: 0.6015\n",
            " Training bag [2/11] bag loss: 0.6065\n",
            " Training bag [3/11] bag loss: 0.7155\n",
            " Training bag [4/11] bag loss: 0.6000\n",
            " Training bag [5/11] bag loss: 0.6014\n",
            " Training bag [6/11] bag loss: 0.5856\n",
            " Training bag [7/11] bag loss: 0.7149\n",
            " Training bag [8/11] bag loss: 0.7041\n",
            " Training bag [9/11] bag loss: 0.5914\n",
            " Training bag [10/11] bag loss: 0.5978\n",
            " Testing bag [0/6] bag loss: 0.7084\n",
            " Testing bag [1/6] bag loss: 0.5960\n",
            " Testing bag [2/6] bag loss: 0.6159\n",
            " Testing bag [3/6] bag loss: 0.6088\n",
            " Testing bag [4/6] bag loss: 0.6165\n",
            " Testing bag [5/6] bag loss: 0.5917ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [67/300] train loss: 0.6295 test loss: 0.6229, average score: 0.1667, AUC: class-0>>0.5555555555555556|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5994\n",
            " Training bag [1/11] bag loss: 0.6060\n",
            " Training bag [2/11] bag loss: 0.6017\n",
            " Training bag [3/11] bag loss: 0.5974\n",
            " Training bag [4/11] bag loss: 0.7077\n",
            " Training bag [5/11] bag loss: 0.5976\n",
            " Training bag [6/11] bag loss: 0.5990\n",
            " Training bag [7/11] bag loss: 0.7159\n",
            " Training bag [8/11] bag loss: 0.7120\n",
            " Training bag [9/11] bag loss: 0.5899\n",
            " Training bag [10/11] bag loss: 0.5823\n",
            " Testing bag [0/6] bag loss: 0.7089\n",
            " Testing bag [1/6] bag loss: 0.5973\n",
            " Testing bag [2/6] bag loss: 0.6162\n",
            " Testing bag [3/6] bag loss: 0.6090\n",
            " Testing bag [4/6] bag loss: 0.6160\n",
            " Testing bag [5/6] bag loss: 0.5886ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [68/300] train loss: 0.6281 test loss: 0.6227, average score: 0.1667, AUC: class-0>>0.5555555555555556|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5864\n",
            " Training bag [1/11] bag loss: 0.6081\n",
            " Training bag [2/11] bag loss: 0.6111\n",
            " Training bag [3/11] bag loss: 0.7158\n",
            " Training bag [4/11] bag loss: 0.5789\n",
            " Training bag [5/11] bag loss: 0.6000\n",
            " Training bag [6/11] bag loss: 0.6009\n",
            " Training bag [7/11] bag loss: 0.7157\n",
            " Training bag [8/11] bag loss: 0.5974\n",
            " Training bag [9/11] bag loss: 0.5926\n",
            " Training bag [10/11] bag loss: 0.7043\n",
            " Testing bag [0/6] bag loss: 0.7087\n",
            " Testing bag [1/6] bag loss: 0.5959\n",
            " Testing bag [2/6] bag loss: 0.6160\n",
            " Testing bag [3/6] bag loss: 0.6073\n",
            " Testing bag [4/6] bag loss: 0.6174\n",
            " Testing bag [5/6] bag loss: 0.5869ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [69/300] train loss: 0.6283 test loss: 0.6221, average score: 0.1667, AUC: class-0>>0.5555555555555556|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6017\n",
            " Training bag [1/11] bag loss: 0.7120\n",
            " Training bag [2/11] bag loss: 0.6057\n",
            " Training bag [3/11] bag loss: 0.5877\n",
            " Training bag [4/11] bag loss: 0.5989\n",
            " Training bag [5/11] bag loss: 0.5805\n",
            " Training bag [6/11] bag loss: 0.5961\n",
            " Training bag [7/11] bag loss: 0.5930\n",
            " Training bag [8/11] bag loss: 0.6040\n",
            " Training bag [9/11] bag loss: 0.7195\n",
            " Training bag [10/11] bag loss: 0.7073\n",
            " Testing bag [0/6] bag loss: 0.7082\n",
            " Testing bag [1/6] bag loss: 0.5943\n",
            " Testing bag [2/6] bag loss: 0.6147\n",
            " Testing bag [3/6] bag loss: 0.6078\n",
            " Testing bag [4/6] bag loss: 0.6163\n",
            " Testing bag [5/6] bag loss: 0.5850ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [70/300] train loss: 0.6279 test loss: 0.6211, average score: 0.1667, AUC: class-0>>0.5555555555555556|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5788\n",
            " Training bag [1/11] bag loss: 0.6062\n",
            " Training bag [2/11] bag loss: 0.6069\n",
            " Training bag [3/11] bag loss: 0.7159\n",
            " Training bag [4/11] bag loss: 0.5981\n",
            " Training bag [5/11] bag loss: 0.7029\n",
            " Training bag [6/11] bag loss: 0.7110\n",
            " Training bag [7/11] bag loss: 0.5997\n",
            " Training bag [8/11] bag loss: 0.5890\n",
            " Training bag [9/11] bag loss: 0.5939\n",
            " Training bag [10/11] bag loss: 0.6031\n",
            " Testing bag [0/6] bag loss: 0.7052\n",
            " Testing bag [1/6] bag loss: 0.5942\n",
            " Testing bag [2/6] bag loss: 0.6171\n",
            " Testing bag [3/6] bag loss: 0.6098\n",
            " Testing bag [4/6] bag loss: 0.6196\n",
            " Testing bag [5/6] bag loss: 0.5841ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [71/300] train loss: 0.6278 test loss: 0.6217, average score: 0.1667, AUC: class-0>>0.5555555555555556|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6035\n",
            " Training bag [1/11] bag loss: 0.5893\n",
            " Training bag [2/11] bag loss: 0.6049\n",
            " Training bag [3/11] bag loss: 0.5919\n",
            " Training bag [4/11] bag loss: 0.5816\n",
            " Training bag [5/11] bag loss: 0.7183\n",
            " Training bag [6/11] bag loss: 0.7049\n",
            " Training bag [7/11] bag loss: 0.6028\n",
            " Training bag [8/11] bag loss: 0.6080\n",
            " Training bag [9/11] bag loss: 0.5786\n",
            " Training bag [10/11] bag loss: 0.7154\n",
            " Testing bag [0/6] bag loss: 0.7107\n",
            " Testing bag [1/6] bag loss: 0.5924\n",
            " Testing bag [2/6] bag loss: 0.6164\n",
            " Testing bag [3/6] bag loss: 0.6074\n",
            " Testing bag [4/6] bag loss: 0.6139\n",
            " Testing bag [5/6] bag loss: 0.5844ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [72/300] train loss: 0.6272 test loss: 0.6209, average score: 0.3333, AUC: class-0>>0.5555555555555556|class-1>>0.8|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5997\n",
            " Training bag [1/11] bag loss: 0.5928\n",
            " Training bag [2/11] bag loss: 0.5914\n",
            " Training bag [3/11] bag loss: 0.6049\n",
            " Training bag [4/11] bag loss: 0.6086\n",
            " Training bag [5/11] bag loss: 0.7076\n",
            " Training bag [6/11] bag loss: 0.5975\n",
            " Training bag [7/11] bag loss: 0.7166\n",
            " Training bag [8/11] bag loss: 0.7163\n",
            " Training bag [9/11] bag loss: 0.5806\n",
            " Training bag [10/11] bag loss: 0.5887\n",
            " Testing bag [0/6] bag loss: 0.7081\n",
            " Testing bag [1/6] bag loss: 0.5942\n",
            " Testing bag [2/6] bag loss: 0.6151\n",
            " Testing bag [3/6] bag loss: 0.6063\n",
            " Testing bag [4/6] bag loss: 0.6162\n",
            " Testing bag [5/6] bag loss: 0.5878ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [73/300] train loss: 0.6277 test loss: 0.6213, average score: 0.1667, AUC: class-0>>0.5555555555555556|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5903\n",
            " Training bag [1/11] bag loss: 0.6063\n",
            " Training bag [2/11] bag loss: 0.5815\n",
            " Training bag [3/11] bag loss: 0.7167\n",
            " Training bag [4/11] bag loss: 0.6054\n",
            " Training bag [5/11] bag loss: 0.5909\n",
            " Training bag [6/11] bag loss: 0.5753\n",
            " Training bag [7/11] bag loss: 0.6028\n",
            " Training bag [8/11] bag loss: 0.7057\n",
            " Training bag [9/11] bag loss: 0.7122\n",
            " Training bag [10/11] bag loss: 0.6017\n",
            " Testing bag [0/6] bag loss: 0.7086\n",
            " Testing bag [1/6] bag loss: 0.5933\n",
            " Testing bag [2/6] bag loss: 0.6163\n",
            " Testing bag [3/6] bag loss: 0.6089\n",
            " Testing bag [4/6] bag loss: 0.6176\n",
            " Testing bag [5/6] bag loss: 0.5854ROC AUC score: 0.3333333333333333\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [74/300] train loss: 0.6263 test loss: 0.6217, average score: 0.5000, AUC: class-0>>0.3333333333333333|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7109\n",
            " Training bag [1/11] bag loss: 0.6055\n",
            " Training bag [2/11] bag loss: 0.6985\n",
            " Training bag [3/11] bag loss: 0.7092\n",
            " Training bag [4/11] bag loss: 0.5955\n",
            " Training bag [5/11] bag loss: 0.6077\n",
            " Training bag [6/11] bag loss: 0.6014\n",
            " Training bag [7/11] bag loss: 0.5992\n",
            " Training bag [8/11] bag loss: 0.5825\n",
            " Training bag [9/11] bag loss: 0.5922\n",
            " Training bag [10/11] bag loss: 0.5990\n",
            " Testing bag [0/6] bag loss: 0.7063\n",
            " Testing bag [1/6] bag loss: 0.5946\n",
            " Testing bag [2/6] bag loss: 0.6141\n",
            " Testing bag [3/6] bag loss: 0.6055\n",
            " Testing bag [4/6] bag loss: 0.6133\n",
            " Testing bag [5/6] bag loss: 0.5880ROC AUC score: 0.3333333333333333\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [75/300] train loss: 0.6274 test loss: 0.6203, average score: 0.5000, AUC: class-0>>0.3333333333333333|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7127\n",
            " Training bag [1/11] bag loss: 0.6003\n",
            " Training bag [2/11] bag loss: 0.5935\n",
            " Training bag [3/11] bag loss: 0.5895\n",
            " Training bag [4/11] bag loss: 0.5998\n",
            " Training bag [5/11] bag loss: 0.5807\n",
            " Training bag [6/11] bag loss: 0.6050\n",
            " Training bag [7/11] bag loss: 0.6050\n",
            " Training bag [8/11] bag loss: 0.5764\n",
            " Training bag [9/11] bag loss: 0.7087\n",
            " Training bag [10/11] bag loss: 0.7189\n",
            " Testing bag [0/6] bag loss: 0.7099\n",
            " Testing bag [1/6] bag loss: 0.5917\n",
            " Testing bag [2/6] bag loss: 0.6143\n",
            " Testing bag [3/6] bag loss: 0.6065\n",
            " Testing bag [4/6] bag loss: 0.6157\n",
            " Testing bag [5/6] bag loss: 0.5860ROC AUC score: 0.3333333333333333\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [76/300] train loss: 0.6264 test loss: 0.6207, average score: 0.5000, AUC: class-0>>0.3333333333333333|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5848\n",
            " Training bag [1/11] bag loss: 0.6038\n",
            " Training bag [2/11] bag loss: 0.6044\n",
            " Training bag [3/11] bag loss: 0.5968\n",
            " Training bag [4/11] bag loss: 0.5940\n",
            " Training bag [5/11] bag loss: 0.7196\n",
            " Training bag [6/11] bag loss: 0.5748\n",
            " Training bag [7/11] bag loss: 0.7169\n",
            " Training bag [8/11] bag loss: 0.5958\n",
            " Training bag [9/11] bag loss: 0.5825\n",
            " Training bag [10/11] bag loss: 0.7060\n",
            " Testing bag [0/6] bag loss: 0.7107\n",
            " Testing bag [1/6] bag loss: 0.5951\n",
            " Testing bag [2/6] bag loss: 0.6129\n",
            " Testing bag [3/6] bag loss: 0.6059\n",
            " Testing bag [4/6] bag loss: 0.6137\n",
            " Testing bag [5/6] bag loss: 0.5858ROC AUC score: 0.3333333333333333\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [77/300] train loss: 0.6254 test loss: 0.6207, average score: 0.5000, AUC: class-0>>0.3333333333333333|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5901\n",
            " Training bag [1/11] bag loss: 0.7163\n",
            " Training bag [2/11] bag loss: 0.5751\n",
            " Training bag [3/11] bag loss: 0.5782\n",
            " Training bag [4/11] bag loss: 0.6026\n",
            " Training bag [5/11] bag loss: 0.6111\n",
            " Training bag [6/11] bag loss: 0.5868\n",
            " Training bag [7/11] bag loss: 0.7043\n",
            " Training bag [8/11] bag loss: 0.6018\n",
            " Training bag [9/11] bag loss: 0.6055\n",
            " Training bag [10/11] bag loss: 0.7152\n",
            " Testing bag [0/6] bag loss: 0.7113\n",
            " Testing bag [1/6] bag loss: 0.5912\n",
            " Testing bag [2/6] bag loss: 0.6137\n",
            " Testing bag [3/6] bag loss: 0.6067\n",
            " Testing bag [4/6] bag loss: 0.6161\n",
            " Testing bag [5/6] bag loss: 0.5830ROC AUC score: 0.4444444444444444\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [78/300] train loss: 0.6261 test loss: 0.6203, average score: 0.5000, AUC: class-0>>0.4444444444444444|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5881\n",
            " Training bag [1/11] bag loss: 0.6040\n",
            " Training bag [2/11] bag loss: 0.5718\n",
            " Training bag [3/11] bag loss: 0.7134\n",
            " Training bag [4/11] bag loss: 0.5999\n",
            " Training bag [5/11] bag loss: 0.5886\n",
            " Training bag [6/11] bag loss: 0.7165\n",
            " Training bag [7/11] bag loss: 0.6069\n",
            " Training bag [8/11] bag loss: 0.7046\n",
            " Training bag [9/11] bag loss: 0.5799\n",
            " Training bag [10/11] bag loss: 0.6001\n",
            " Testing bag [0/6] bag loss: 0.7100\n",
            " Testing bag [1/6] bag loss: 0.5908\n",
            " Testing bag [2/6] bag loss: 0.6161\n",
            " Testing bag [3/6] bag loss: 0.6075\n",
            " Testing bag [4/6] bag loss: 0.6118\n",
            " Testing bag [5/6] bag loss: 0.5849ROC AUC score: 0.3333333333333333\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [79/300] train loss: 0.6249 test loss: 0.6202, average score: 0.5000, AUC: class-0>>0.3333333333333333|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7088\n",
            " Training bag [1/11] bag loss: 0.5907\n",
            " Training bag [2/11] bag loss: 0.7124\n",
            " Training bag [3/11] bag loss: 0.6016\n",
            " Training bag [4/11] bag loss: 0.5916\n",
            " Training bag [5/11] bag loss: 0.6971\n",
            " Training bag [6/11] bag loss: 0.6084\n",
            " Training bag [7/11] bag loss: 0.5737\n",
            " Training bag [8/11] bag loss: 0.6056\n",
            " Training bag [9/11] bag loss: 0.5813\n",
            " Training bag [10/11] bag loss: 0.6012\n",
            " Testing bag [0/6] bag loss: 0.7065\n",
            " Testing bag [1/6] bag loss: 0.5918\n",
            " Testing bag [2/6] bag loss: 0.6149\n",
            " Testing bag [3/6] bag loss: 0.6078\n",
            " Testing bag [4/6] bag loss: 0.6155\n",
            " Testing bag [5/6] bag loss: 0.5828ROC AUC score: 0.4444444444444444\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [80/300] train loss: 0.6247 test loss: 0.6199, average score: 0.5000, AUC: class-0>>0.4444444444444444|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6032\n",
            " Training bag [1/11] bag loss: 0.5902\n",
            " Training bag [2/11] bag loss: 0.5979\n",
            " Training bag [3/11] bag loss: 0.7186\n",
            " Training bag [4/11] bag loss: 0.7027\n",
            " Training bag [5/11] bag loss: 0.5815\n",
            " Training bag [6/11] bag loss: 0.5766\n",
            " Training bag [7/11] bag loss: 0.5972\n",
            " Training bag [8/11] bag loss: 0.5892\n",
            " Training bag [9/11] bag loss: 0.6042\n",
            " Training bag [10/11] bag loss: 0.7166\n",
            " Testing bag [0/6] bag loss: 0.7096\n",
            " Testing bag [1/6] bag loss: 0.5887\n",
            " Testing bag [2/6] bag loss: 0.6138\n",
            " Testing bag [3/6] bag loss: 0.6050\n",
            " Testing bag [4/6] bag loss: 0.6146\n",
            " Testing bag [5/6] bag loss: 0.5827ROC AUC score: 0.4444444444444444\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [81/300] train loss: 0.6253 test loss: 0.6191, average score: 0.5000, AUC: class-0>>0.4444444444444444|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5788\n",
            " Training bag [1/11] bag loss: 0.5867\n",
            " Training bag [2/11] bag loss: 0.5986\n",
            " Training bag [3/11] bag loss: 0.5699\n",
            " Training bag [4/11] bag loss: 0.7057\n",
            " Training bag [5/11] bag loss: 0.6024\n",
            " Training bag [6/11] bag loss: 0.5866\n",
            " Training bag [7/11] bag loss: 0.6076\n",
            " Training bag [8/11] bag loss: 0.7224\n",
            " Training bag [9/11] bag loss: 0.7132\n",
            " Training bag [10/11] bag loss: 0.6049\n",
            " Testing bag [0/6] bag loss: 0.7095\n",
            " Testing bag [1/6] bag loss: 0.5903\n",
            " Testing bag [2/6] bag loss: 0.6152\n",
            " Testing bag [3/6] bag loss: 0.6065\n",
            " Testing bag [4/6] bag loss: 0.6155\n",
            " Testing bag [5/6] bag loss: 0.5819ROC AUC score: 0.4444444444444444\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [82/300] train loss: 0.6252 test loss: 0.6198, average score: 0.5000, AUC: class-0>>0.4444444444444444|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6045\n",
            " Training bag [1/11] bag loss: 0.5960\n",
            " Training bag [2/11] bag loss: 0.7124\n",
            " Training bag [3/11] bag loss: 0.5919\n",
            " Training bag [4/11] bag loss: 0.5827\n",
            " Training bag [5/11] bag loss: 0.5965\n",
            " Training bag [6/11] bag loss: 0.5879\n",
            " Training bag [7/11] bag loss: 0.7037\n",
            " Training bag [8/11] bag loss: 0.7174\n",
            " Training bag [9/11] bag loss: 0.6014\n",
            " Training bag [10/11] bag loss: 0.5756\n",
            " Testing bag [0/6] bag loss: 0.7091\n",
            " Testing bag [1/6] bag loss: 0.5943\n",
            " Testing bag [2/6] bag loss: 0.6134\n",
            " Testing bag [3/6] bag loss: 0.6039\n",
            " Testing bag [4/6] bag loss: 0.6157\n",
            " Testing bag [5/6] bag loss: 0.5838ROC AUC score: 0.3333333333333333\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [83/300] train loss: 0.6246 test loss: 0.6200, average score: 0.5000, AUC: class-0>>0.3333333333333333|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5968\n",
            " Training bag [1/11] bag loss: 0.7013\n",
            " Training bag [2/11] bag loss: 0.7141\n",
            " Training bag [3/11] bag loss: 0.6038\n",
            " Training bag [4/11] bag loss: 0.5842\n",
            " Training bag [5/11] bag loss: 0.5749\n",
            " Training bag [6/11] bag loss: 0.5961\n",
            " Training bag [7/11] bag loss: 0.5942\n",
            " Training bag [8/11] bag loss: 0.6003\n",
            " Training bag [9/11] bag loss: 0.5891\n",
            " Training bag [10/11] bag loss: 0.7176\n",
            " Testing bag [0/6] bag loss: 0.7104\n",
            " Testing bag [1/6] bag loss: 0.5913\n",
            " Testing bag [2/6] bag loss: 0.6113\n",
            " Testing bag [3/6] bag loss: 0.6030\n",
            " Testing bag [4/6] bag loss: 0.6108\n",
            " Testing bag [5/6] bag loss: 0.5815ROC AUC score: 0.3333333333333333\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [84/300] train loss: 0.6248 test loss: 0.6181, average score: 0.5000, AUC: class-0>>0.3333333333333333|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6000\n",
            " Training bag [1/11] bag loss: 0.5860\n",
            " Training bag [2/11] bag loss: 0.7196\n",
            " Training bag [3/11] bag loss: 0.6037\n",
            " Training bag [4/11] bag loss: 0.5937\n",
            " Training bag [5/11] bag loss: 0.5822\n",
            " Training bag [6/11] bag loss: 0.5726\n",
            " Training bag [7/11] bag loss: 0.5937\n",
            " Training bag [8/11] bag loss: 0.7162\n",
            " Training bag [9/11] bag loss: 0.5901\n",
            " Training bag [10/11] bag loss: 0.7058\n",
            " Testing bag [0/6] bag loss: 0.7130\n",
            " Testing bag [1/6] bag loss: 0.5909\n",
            " Testing bag [2/6] bag loss: 0.6111\n",
            " Testing bag [3/6] bag loss: 0.6037\n",
            " Testing bag [4/6] bag loss: 0.6119\n",
            " Testing bag [5/6] bag loss: 0.5837ROC AUC score: 0.3333333333333333\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [85/300] train loss: 0.6240 test loss: 0.6190, average score: 0.5000, AUC: class-0>>0.3333333333333333|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7136\n",
            " Training bag [1/11] bag loss: 0.5980\n",
            " Training bag [2/11] bag loss: 0.6004\n",
            " Training bag [3/11] bag loss: 0.6998\n",
            " Training bag [4/11] bag loss: 0.6021\n",
            " Training bag [5/11] bag loss: 0.5969\n",
            " Training bag [6/11] bag loss: 0.5897\n",
            " Training bag [7/11] bag loss: 0.5938\n",
            " Training bag [8/11] bag loss: 0.5865\n",
            " Training bag [9/11] bag loss: 0.7167\n",
            " Training bag [10/11] bag loss: 0.5755\n",
            " Testing bag [0/6] bag loss: 0.7083\n",
            " Testing bag [1/6] bag loss: 0.5962\n",
            " Testing bag [2/6] bag loss: 0.6112\n",
            " Testing bag [3/6] bag loss: 0.6035\n",
            " Testing bag [4/6] bag loss: 0.6107\n",
            " Testing bag [5/6] bag loss: 0.5831ROC AUC score: 0.3333333333333333\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [86/300] train loss: 0.6248 test loss: 0.6188, average score: 0.5000, AUC: class-0>>0.3333333333333333|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5873\n",
            " Training bag [1/11] bag loss: 0.6002\n",
            " Training bag [2/11] bag loss: 0.5780\n",
            " Training bag [3/11] bag loss: 0.5978\n",
            " Training bag [4/11] bag loss: 0.7195\n",
            " Training bag [5/11] bag loss: 0.7166\n",
            " Training bag [6/11] bag loss: 0.7051\n",
            " Training bag [7/11] bag loss: 0.5950\n",
            " Training bag [8/11] bag loss: 0.6029\n",
            " Training bag [9/11] bag loss: 0.5738\n",
            " Training bag [10/11] bag loss: 0.5944\n",
            " Testing bag [0/6] bag loss: 0.7085\n",
            " Testing bag [1/6] bag loss: 0.5921\n",
            " Testing bag [2/6] bag loss: 0.6123\n",
            " Testing bag [3/6] bag loss: 0.6039\n",
            " Testing bag [4/6] bag loss: 0.6126\n",
            " Testing bag [5/6] bag loss: 0.5851ROC AUC score: 0.3333333333333333\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [87/300] train loss: 0.6246 test loss: 0.6191, average score: 0.5000, AUC: class-0>>0.3333333333333333|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5948\n",
            " Training bag [1/11] bag loss: 0.7012\n",
            " Training bag [2/11] bag loss: 0.5902\n",
            " Training bag [3/11] bag loss: 0.5882\n",
            " Training bag [4/11] bag loss: 0.5760\n",
            " Training bag [5/11] bag loss: 0.5965\n",
            " Training bag [6/11] bag loss: 0.6017\n",
            " Training bag [7/11] bag loss: 0.7204\n",
            " Training bag [8/11] bag loss: 0.6022\n",
            " Training bag [9/11] bag loss: 0.7136\n",
            " Training bag [10/11] bag loss: 0.5734\n",
            " Testing bag [0/6] bag loss: 0.7103\n",
            " Testing bag [1/6] bag loss: 0.5929\n",
            " Testing bag [2/6] bag loss: 0.6114\n",
            " Testing bag [3/6] bag loss: 0.6026\n",
            " Testing bag [4/6] bag loss: 0.6100\n",
            " Testing bag [5/6] bag loss: 0.5812ROC AUC score: 0.3333333333333333\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [88/300] train loss: 0.6235 test loss: 0.6181, average score: 0.5000, AUC: class-0>>0.3333333333333333|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5890\n",
            " Training bag [1/11] bag loss: 0.5710\n",
            " Training bag [2/11] bag loss: 0.5777\n",
            " Training bag [3/11] bag loss: 0.5788\n",
            " Training bag [4/11] bag loss: 0.6073\n",
            " Training bag [5/11] bag loss: 0.7054\n",
            " Training bag [6/11] bag loss: 0.6016\n",
            " Training bag [7/11] bag loss: 0.7205\n",
            " Training bag [8/11] bag loss: 0.7143\n",
            " Training bag [9/11] bag loss: 0.5984\n",
            " Training bag [10/11] bag loss: 0.6029\n",
            " Testing bag [0/6] bag loss: 0.7086\n",
            " Testing bag [1/6] bag loss: 0.5894\n",
            " Testing bag [2/6] bag loss: 0.6144\n",
            " Testing bag [3/6] bag loss: 0.6048\n",
            " Testing bag [4/6] bag loss: 0.6150\n",
            " Testing bag [5/6] bag loss: 0.5817ROC AUC score: 0.3333333333333333\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [89/300] train loss: 0.6243 test loss: 0.6190, average score: 0.5000, AUC: class-0>>0.3333333333333333|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5935\n",
            " Training bag [1/11] bag loss: 0.6006\n",
            " Training bag [2/11] bag loss: 0.5884\n",
            " Training bag [3/11] bag loss: 0.5915\n",
            " Training bag [4/11] bag loss: 0.5711\n",
            " Training bag [5/11] bag loss: 0.5933\n",
            " Training bag [6/11] bag loss: 0.5753\n",
            " Training bag [7/11] bag loss: 0.7253\n",
            " Training bag [8/11] bag loss: 0.7068\n",
            " Training bag [9/11] bag loss: 0.6020\n",
            " Training bag [10/11] bag loss: 0.7145\n",
            " Testing bag [0/6] bag loss: 0.7104\n",
            " Testing bag [1/6] bag loss: 0.5912\n",
            " Testing bag [2/6] bag loss: 0.6110\n",
            " Testing bag [3/6] bag loss: 0.6018\n",
            " Testing bag [4/6] bag loss: 0.6128\n",
            " Testing bag [5/6] bag loss: 0.5809ROC AUC score: 0.3333333333333333\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [90/300] train loss: 0.6238 test loss: 0.6180, average score: 0.5000, AUC: class-0>>0.3333333333333333|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7038\n",
            " Training bag [1/11] bag loss: 0.5710\n",
            " Training bag [2/11] bag loss: 0.7162\n",
            " Training bag [3/11] bag loss: 0.6059\n",
            " Training bag [4/11] bag loss: 0.5817\n",
            " Training bag [5/11] bag loss: 0.7112\n",
            " Training bag [6/11] bag loss: 0.5871\n",
            " Training bag [7/11] bag loss: 0.5998\n",
            " Training bag [8/11] bag loss: 0.6035\n",
            " Training bag [9/11] bag loss: 0.5911\n",
            " Training bag [10/11] bag loss: 0.5938\n",
            " Testing bag [0/6] bag loss: 0.7089\n",
            " Testing bag [1/6] bag loss: 0.5888\n",
            " Testing bag [2/6] bag loss: 0.6124\n",
            " Testing bag [3/6] bag loss: 0.6052\n",
            " Testing bag [4/6] bag loss: 0.6131\n",
            " Testing bag [5/6] bag loss: 0.5807ROC AUC score: 0.3333333333333333\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [91/300] train loss: 0.6241 test loss: 0.6182, average score: 0.5000, AUC: class-0>>0.3333333333333333|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5888\n",
            " Training bag [1/11] bag loss: 0.7005\n",
            " Training bag [2/11] bag loss: 0.5764\n",
            " Training bag [3/11] bag loss: 0.5680\n",
            " Training bag [4/11] bag loss: 0.7173\n",
            " Training bag [5/11] bag loss: 0.5811\n",
            " Training bag [6/11] bag loss: 0.6077\n",
            " Training bag [7/11] bag loss: 0.6078\n",
            " Training bag [8/11] bag loss: 0.7144\n",
            " Training bag [9/11] bag loss: 0.5992\n",
            " Training bag [10/11] bag loss: 0.5957\n",
            " Testing bag [0/6] bag loss: 0.7083\n",
            " Testing bag [1/6] bag loss: 0.5893\n",
            " Testing bag [2/6] bag loss: 0.6144\n",
            " Testing bag [3/6] bag loss: 0.6040\n",
            " Testing bag [4/6] bag loss: 0.6139\n",
            " Testing bag [5/6] bag loss: 0.5784ROC AUC score: 0.3333333333333333\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [92/300] train loss: 0.6233 test loss: 0.6180, average score: 0.5000, AUC: class-0>>0.3333333333333333|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7116\n",
            " Training bag [1/11] bag loss: 0.6991\n",
            " Training bag [2/11] bag loss: 0.5896\n",
            " Training bag [3/11] bag loss: 0.5972\n",
            " Training bag [4/11] bag loss: 0.5790\n",
            " Training bag [5/11] bag loss: 0.6031\n",
            " Training bag [6/11] bag loss: 0.6049\n",
            " Training bag [7/11] bag loss: 0.5699\n",
            " Training bag [8/11] bag loss: 0.5902\n",
            " Training bag [9/11] bag loss: 0.7182\n",
            " Training bag [10/11] bag loss: 0.5925\n",
            " Testing bag [0/6] bag loss: 0.7112\n",
            " Testing bag [1/6] bag loss: 0.5883\n",
            " Testing bag [2/6] bag loss: 0.6128\n",
            " Testing bag [3/6] bag loss: 0.6042\n",
            " Testing bag [4/6] bag loss: 0.6123\n",
            " Testing bag [5/6] bag loss: 0.5798ROC AUC score: 0.3333333333333333\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [93/300] train loss: 0.6232 test loss: 0.6181, average score: 0.5000, AUC: class-0>>0.3333333333333333|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7169\n",
            " Training bag [1/11] bag loss: 0.5876\n",
            " Training bag [2/11] bag loss: 0.5761\n",
            " Training bag [3/11] bag loss: 0.6990\n",
            " Training bag [4/11] bag loss: 0.5839\n",
            " Training bag [5/11] bag loss: 0.5995\n",
            " Training bag [6/11] bag loss: 0.7124\n",
            " Training bag [7/11] bag loss: 0.6055\n",
            " Training bag [8/11] bag loss: 0.5663\n",
            " Training bag [9/11] bag loss: 0.6081\n",
            " Training bag [10/11] bag loss: 0.5945\n",
            " Testing bag [0/6] bag loss: 0.7080\n",
            " Testing bag [1/6] bag loss: 0.5907\n",
            " Testing bag [2/6] bag loss: 0.6134\n",
            " Testing bag [3/6] bag loss: 0.6033\n",
            " Testing bag [4/6] bag loss: 0.6123\n",
            " Testing bag [5/6] bag loss: 0.5778ROC AUC score: 0.3333333333333333\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [94/300] train loss: 0.6227 test loss: 0.6176, average score: 0.5000, AUC: class-0>>0.3333333333333333|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5744\n",
            " Training bag [1/11] bag loss: 0.5861\n",
            " Training bag [2/11] bag loss: 0.5642\n",
            " Training bag [3/11] bag loss: 0.7210\n",
            " Training bag [4/11] bag loss: 0.7049\n",
            " Training bag [5/11] bag loss: 0.5994\n",
            " Training bag [6/11] bag loss: 0.5964\n",
            " Training bag [7/11] bag loss: 0.6059\n",
            " Training bag [8/11] bag loss: 0.7195\n",
            " Training bag [9/11] bag loss: 0.5809\n",
            " Training bag [10/11] bag loss: 0.6001\n",
            " Testing bag [0/6] bag loss: 0.7105\n",
            " Testing bag [1/6] bag loss: 0.5917\n",
            " Testing bag [2/6] bag loss: 0.6115\n",
            " Testing bag [3/6] bag loss: 0.6022\n",
            " Testing bag [4/6] bag loss: 0.6120\n",
            " Testing bag [5/6] bag loss: 0.5811ROC AUC score: 0.3333333333333333\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [95/300] train loss: 0.6230 test loss: 0.6182, average score: 0.5000, AUC: class-0>>0.3333333333333333|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6033\n",
            " Training bag [1/11] bag loss: 0.5973\n",
            " Training bag [2/11] bag loss: 0.7020\n",
            " Training bag [3/11] bag loss: 0.5886\n",
            " Training bag [4/11] bag loss: 0.7177\n",
            " Training bag [5/11] bag loss: 0.5855\n",
            " Training bag [6/11] bag loss: 0.5888\n",
            " Training bag [7/11] bag loss: 0.5931\n",
            " Training bag [8/11] bag loss: 0.5747\n",
            " Training bag [9/11] bag loss: 0.5880\n",
            " Training bag [10/11] bag loss: 0.7202\n",
            " Testing bag [0/6] bag loss: 0.7109\n",
            " Testing bag [1/6] bag loss: 0.5910\n",
            " Testing bag [2/6] bag loss: 0.6101\n",
            " Testing bag [3/6] bag loss: 0.6000\n",
            " Testing bag [4/6] bag loss: 0.6082\n",
            " Testing bag [5/6] bag loss: 0.5808ROC AUC score: 0.3333333333333333\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [96/300] train loss: 0.6236 test loss: 0.6168, average score: 0.5000, AUC: class-0>>0.3333333333333333|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5864\n",
            " Training bag [1/11] bag loss: 0.7043\n",
            " Training bag [2/11] bag loss: 0.5986\n",
            " Training bag [3/11] bag loss: 0.7210\n",
            " Training bag [4/11] bag loss: 0.5771\n",
            " Training bag [5/11] bag loss: 0.5925\n",
            " Training bag [6/11] bag loss: 0.5940\n",
            " Training bag [7/11] bag loss: 0.5687\n",
            " Training bag [8/11] bag loss: 0.7177\n",
            " Training bag [9/11] bag loss: 0.5875\n",
            " Training bag [10/11] bag loss: 0.6009\n",
            " Testing bag [0/6] bag loss: 0.7095\n",
            " Testing bag [1/6] bag loss: 0.5886\n",
            " Testing bag [2/6] bag loss: 0.6123\n",
            " Testing bag [3/6] bag loss: 0.6017\n",
            " Testing bag [4/6] bag loss: 0.6132\n",
            " Testing bag [5/6] bag loss: 0.5775ROC AUC score: 0.3333333333333333\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [97/300] train loss: 0.6226 test loss: 0.6171, average score: 0.5000, AUC: class-0>>0.3333333333333333|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7100\n",
            " Training bag [1/11] bag loss: 0.5786\n",
            " Training bag [2/11] bag loss: 0.5662\n",
            " Training bag [3/11] bag loss: 0.6029\n",
            " Training bag [4/11] bag loss: 0.7193\n",
            " Training bag [5/11] bag loss: 0.6035\n",
            " Training bag [6/11] bag loss: 0.6982\n",
            " Training bag [7/11] bag loss: 0.5913\n",
            " Training bag [8/11] bag loss: 0.5874\n",
            " Training bag [9/11] bag loss: 0.5946\n",
            " Training bag [10/11] bag loss: 0.5886\n",
            " Testing bag [0/6] bag loss: 0.7093\n",
            " Testing bag [1/6] bag loss: 0.5947\n",
            " Testing bag [2/6] bag loss: 0.6126\n",
            " Testing bag [3/6] bag loss: 0.6009\n",
            " Testing bag [4/6] bag loss: 0.6130\n",
            " Testing bag [5/6] bag loss: 0.5807ROC AUC score: 0.3333333333333333\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [98/300] train loss: 0.6219 test loss: 0.6185, average score: 0.5000, AUC: class-0>>0.3333333333333333|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5913\n",
            " Training bag [1/11] bag loss: 0.5677\n",
            " Training bag [2/11] bag loss: 0.5751\n",
            " Training bag [3/11] bag loss: 0.5825\n",
            " Training bag [4/11] bag loss: 0.7222\n",
            " Training bag [5/11] bag loss: 0.6042\n",
            " Training bag [6/11] bag loss: 0.7041\n",
            " Training bag [7/11] bag loss: 0.5820\n",
            " Training bag [8/11] bag loss: 0.7182\n",
            " Training bag [9/11] bag loss: 0.5960\n",
            " Training bag [10/11] bag loss: 0.6005\n",
            " Testing bag [0/6] bag loss: 0.7098\n",
            " Testing bag [1/6] bag loss: 0.5902\n",
            " Testing bag [2/6] bag loss: 0.6135\n",
            " Testing bag [3/6] bag loss: 0.6029\n",
            " Testing bag [4/6] bag loss: 0.6121\n",
            " Testing bag [5/6] bag loss: 0.5775ROC AUC score: 0.3333333333333333\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [99/300] train loss: 0.6222 test loss: 0.6176, average score: 0.5000, AUC: class-0>>0.3333333333333333|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6994\n",
            " Training bag [1/11] bag loss: 0.5926\n",
            " Training bag [2/11] bag loss: 0.7121\n",
            " Training bag [3/11] bag loss: 0.5869\n",
            " Training bag [4/11] bag loss: 0.5880\n",
            " Training bag [5/11] bag loss: 0.5767\n",
            " Training bag [6/11] bag loss: 0.6074\n",
            " Training bag [7/11] bag loss: 0.5671\n",
            " Training bag [8/11] bag loss: 0.5978\n",
            " Training bag [9/11] bag loss: 0.5985\n",
            " Training bag [10/11] bag loss: 0.7204\n",
            " Testing bag [0/6] bag loss: 0.7112\n",
            " Testing bag [1/6] bag loss: 0.5895\n",
            " Testing bag [2/6] bag loss: 0.6120\n",
            " Testing bag [3/6] bag loss: 0.6006\n",
            " Testing bag [4/6] bag loss: 0.6124\n",
            " Testing bag [5/6] bag loss: 0.5773ROC AUC score: 0.3333333333333333\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [100/300] train loss: 0.6225 test loss: 0.6172, average score: 0.5000, AUC: class-0>>0.3333333333333333|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7210\n",
            " Training bag [1/11] bag loss: 0.5741\n",
            " Training bag [2/11] bag loss: 0.5829\n",
            " Training bag [3/11] bag loss: 0.5663\n",
            " Training bag [4/11] bag loss: 0.5814\n",
            " Training bag [5/11] bag loss: 0.7199\n",
            " Training bag [6/11] bag loss: 0.6066\n",
            " Training bag [7/11] bag loss: 0.7016\n",
            " Training bag [8/11] bag loss: 0.6002\n",
            " Training bag [9/11] bag loss: 0.6028\n",
            " Training bag [10/11] bag loss: 0.5932\n",
            " Testing bag [0/6] bag loss: 0.7084\n",
            " Testing bag [1/6] bag loss: 0.5874\n",
            " Testing bag [2/6] bag loss: 0.6131\n",
            " Testing bag [3/6] bag loss: 0.6023\n",
            " Testing bag [4/6] bag loss: 0.6117\n",
            " Testing bag [5/6] bag loss: 0.5769ROC AUC score: 0.3333333333333333\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [101/300] train loss: 0.6227 test loss: 0.6166, average score: 0.5000, AUC: class-0>>0.3333333333333333|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7180\n",
            " Training bag [1/11] bag loss: 0.6975\n",
            " Training bag [2/11] bag loss: 0.5764\n",
            " Training bag [3/11] bag loss: 0.5988\n",
            " Training bag [4/11] bag loss: 0.6013\n",
            " Training bag [5/11] bag loss: 0.5926\n",
            " Training bag [6/11] bag loss: 0.7126\n",
            " Training bag [7/11] bag loss: 0.5918\n",
            " Training bag [8/11] bag loss: 0.5701\n",
            " Training bag [9/11] bag loss: 0.5830\n",
            " Training bag [10/11] bag loss: 0.5899\n",
            " Testing bag [0/6] bag loss: 0.7078\n",
            " Testing bag [1/6] bag loss: 0.5899\n",
            " Testing bag [2/6] bag loss: 0.6110\n",
            " Testing bag [3/6] bag loss: 0.6010\n",
            " Testing bag [4/6] bag loss: 0.6126\n",
            " Testing bag [5/6] bag loss: 0.5792ROC AUC score: 0.3333333333333333\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [102/300] train loss: 0.6211 test loss: 0.6169, average score: 0.5000, AUC: class-0>>0.3333333333333333|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5975\n",
            " Training bag [1/11] bag loss: 0.5901\n",
            " Training bag [2/11] bag loss: 0.5951\n",
            " Training bag [3/11] bag loss: 0.5882\n",
            " Training bag [4/11] bag loss: 0.7219\n",
            " Training bag [5/11] bag loss: 0.5831\n",
            " Training bag [6/11] bag loss: 0.5718\n",
            " Training bag [7/11] bag loss: 0.5785\n",
            " Training bag [8/11] bag loss: 0.7054\n",
            " Training bag [9/11] bag loss: 0.5863\n",
            " Training bag [10/11] bag loss: 0.7196\n",
            " Testing bag [0/6] bag loss: 0.7121\n",
            " Testing bag [1/6] bag loss: 0.5911\n",
            " Testing bag [2/6] bag loss: 0.6097\n",
            " Testing bag [3/6] bag loss: 0.5996\n",
            " Testing bag [4/6] bag loss: 0.6085\n",
            " Testing bag [5/6] bag loss: 0.5783ROC AUC score: 0.3333333333333333\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [103/300] train loss: 0.6216 test loss: 0.6166, average score: 0.5000, AUC: class-0>>0.3333333333333333|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5669\n",
            " Training bag [1/11] bag loss: 0.5860\n",
            " Training bag [2/11] bag loss: 0.5711\n",
            " Training bag [3/11] bag loss: 0.7013\n",
            " Training bag [4/11] bag loss: 0.7207\n",
            " Training bag [5/11] bag loss: 0.6072\n",
            " Training bag [6/11] bag loss: 0.5946\n",
            " Training bag [7/11] bag loss: 0.5963\n",
            " Training bag [8/11] bag loss: 0.5981\n",
            " Training bag [9/11] bag loss: 0.7145\n",
            " Training bag [10/11] bag loss: 0.5806\n",
            " Testing bag [0/6] bag loss: 0.7100\n",
            " Testing bag [1/6] bag loss: 0.5897\n",
            " Testing bag [2/6] bag loss: 0.6102\n",
            " Testing bag [3/6] bag loss: 0.6003\n",
            " Testing bag [4/6] bag loss: 0.6113\n",
            " Testing bag [5/6] bag loss: 0.5787ROC AUC score: 0.3333333333333333\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [104/300] train loss: 0.6216 test loss: 0.6167, average score: 0.5000, AUC: class-0>>0.3333333333333333|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5885\n",
            " Training bag [1/11] bag loss: 0.5771\n",
            " Training bag [2/11] bag loss: 0.5959\n",
            " Training bag [3/11] bag loss: 0.5671\n",
            " Training bag [4/11] bag loss: 0.5871\n",
            " Training bag [5/11] bag loss: 0.5780\n",
            " Training bag [6/11] bag loss: 0.7254\n",
            " Training bag [7/11] bag loss: 0.5924\n",
            " Training bag [8/11] bag loss: 0.7038\n",
            " Training bag [9/11] bag loss: 0.6015\n",
            " Training bag [10/11] bag loss: 0.7184\n",
            " Testing bag [0/6] bag loss: 0.7117\n",
            " Testing bag [1/6] bag loss: 0.5891\n",
            " Testing bag [2/6] bag loss: 0.6106\n",
            " Testing bag [3/6] bag loss: 0.5999\n",
            " Testing bag [4/6] bag loss: 0.6127\n",
            " Testing bag [5/6] bag loss: 0.5779ROC AUC score: 0.3333333333333333\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [105/300] train loss: 0.6214 test loss: 0.6170, average score: 0.5000, AUC: class-0>>0.3333333333333333|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5882\n",
            " Training bag [1/11] bag loss: 0.5856\n",
            " Training bag [2/11] bag loss: 0.5849\n",
            " Training bag [3/11] bag loss: 0.7214\n",
            " Training bag [4/11] bag loss: 0.6015\n",
            " Training bag [5/11] bag loss: 0.5912\n",
            " Training bag [6/11] bag loss: 0.7012\n",
            " Training bag [7/11] bag loss: 0.5767\n",
            " Training bag [8/11] bag loss: 0.7136\n",
            " Training bag [9/11] bag loss: 0.5986\n",
            " Training bag [10/11] bag loss: 0.5680\n",
            " Testing bag [0/6] bag loss: 0.7123\n",
            " Testing bag [1/6] bag loss: 0.5885\n",
            " Testing bag [2/6] bag loss: 0.6103\n",
            " Testing bag [3/6] bag loss: 0.6006\n",
            " Testing bag [4/6] bag loss: 0.6115\n",
            " Testing bag [5/6] bag loss: 0.5786ROC AUC score: 0.3333333333333333\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [106/300] train loss: 0.6210 test loss: 0.6170, average score: 0.5000, AUC: class-0>>0.3333333333333333|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7170\n",
            " Training bag [1/11] bag loss: 0.5791\n",
            " Training bag [2/11] bag loss: 0.5919\n",
            " Training bag [3/11] bag loss: 0.5975\n",
            " Training bag [4/11] bag loss: 0.6989\n",
            " Training bag [5/11] bag loss: 0.5890\n",
            " Training bag [6/11] bag loss: 0.5751\n",
            " Training bag [7/11] bag loss: 0.5995\n",
            " Training bag [8/11] bag loss: 0.5660\n",
            " Training bag [9/11] bag loss: 0.5916\n",
            " Training bag [10/11] bag loss: 0.7139\n",
            " Testing bag [0/6] bag loss: 0.7103\n",
            " Testing bag [1/6] bag loss: 0.5869\n",
            " Testing bag [2/6] bag loss: 0.6092\n",
            " Testing bag [3/6] bag loss: 0.6008\n",
            " Testing bag [4/6] bag loss: 0.6102\n",
            " Testing bag [5/6] bag loss: 0.5771ROC AUC score: 0.3333333333333333\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [107/300] train loss: 0.6200 test loss: 0.6158, average score: 0.5000, AUC: class-0>>0.3333333333333333|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5664\n",
            " Training bag [1/11] bag loss: 0.5889\n",
            " Training bag [2/11] bag loss: 0.7146\n",
            " Training bag [3/11] bag loss: 0.7198\n",
            " Training bag [4/11] bag loss: 0.5958\n",
            " Training bag [5/11] bag loss: 0.5807\n",
            " Training bag [6/11] bag loss: 0.5916\n",
            " Training bag [7/11] bag loss: 0.6970\n",
            " Training bag [8/11] bag loss: 0.5792\n",
            " Training bag [9/11] bag loss: 0.5893\n",
            " Training bag [10/11] bag loss: 0.6015\n",
            " Testing bag [0/6] bag loss: 0.7125\n",
            " Testing bag [1/6] bag loss: 0.5905\n",
            " Testing bag [2/6] bag loss: 0.6111\n",
            " Testing bag [3/6] bag loss: 0.6008\n",
            " Testing bag [4/6] bag loss: 0.6117\n",
            " Testing bag [5/6] bag loss: 0.5778ROC AUC score: 0.3333333333333333\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [108/300] train loss: 0.6204 test loss: 0.6174, average score: 0.5000, AUC: class-0>>0.3333333333333333|class-1>>0.6|class-2>>0.875\n",
            "\n",
            " Testing bag [0/4] bag loss: 0.6874\n",
            " Testing bag [1/4] bag loss: 0.6542\n",
            " Testing bag [2/4] bag loss: 0.6591\n",
            " Testing bag [3/4] bag loss: 0.6766ROC AUC score: 0.0\n",
            "ROC AUC score: 0.6666666666666667\n",
            "ROC AUC score: 1.0\n",
            "âœ… Fold 1 completed | Test Acc: 0.5000 | Test AUCs: [np.float64(0.0), np.float64(0.667), np.float64(1.0)]\n",
            "\n",
            "ðŸŒ€ Starting CV Fold 2\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7154\n",
            " Training bag [1/11] bag loss: 0.7118\n",
            " Training bag [2/11] bag loss: 0.6974\n",
            " Training bag [3/11] bag loss: 0.7129\n",
            " Training bag [4/11] bag loss: 0.6909\n",
            " Training bag [5/11] bag loss: 0.7075\n",
            " Training bag [6/11] bag loss: 0.7088\n",
            " Training bag [7/11] bag loss: 0.7055\n",
            " Training bag [8/11] bag loss: 0.6970\n",
            " Training bag [9/11] bag loss: 0.6985\n",
            " Training bag [10/11] bag loss: 0.6883\n",
            " Testing bag [0/6] bag loss: 0.6920\n",
            " Testing bag [1/6] bag loss: 0.7094\n",
            " Testing bag [2/6] bag loss: 0.6910\n",
            " Testing bag [3/6] bag loss: 0.7052\n",
            " Testing bag [4/6] bag loss: 0.6987\n",
            " Testing bag [5/6] bag loss: 0.6983ROC AUC score: 0.6666666666666667\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.375\n",
            "\n",
            " Epoch [1/300] train loss: 0.7031 test loss: 0.6991, average score: 0.1667, AUC: class-0>>0.6666666666666667|class-1>>0.6|class-2>>0.375\n",
            "Best model saved at: weights/20250626/fold_2_19.pth\n",
            "Best thresholds ===>>> class-0>>0.4948703646659851|class-1>>0.4737670123577118|class-2>>0.4829673767089844\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7098\n",
            " Training bag [1/11] bag loss: 0.7051\n",
            " Training bag [2/11] bag loss: 0.6859\n",
            " Training bag [3/11] bag loss: 0.6970\n",
            " Training bag [4/11] bag loss: 0.6905\n",
            " Training bag [5/11] bag loss: 0.7080\n",
            " Training bag [6/11] bag loss: 0.7093\n",
            " Training bag [7/11] bag loss: 0.7000\n",
            " Training bag [8/11] bag loss: 0.6993\n",
            " Training bag [9/11] bag loss: 0.6878\n",
            " Training bag [10/11] bag loss: 0.6840\n",
            " Testing bag [0/6] bag loss: 0.6896\n",
            " Testing bag [1/6] bag loss: 0.7081\n",
            " Testing bag [2/6] bag loss: 0.6845\n",
            " Testing bag [3/6] bag loss: 0.6984\n",
            " Testing bag [4/6] bag loss: 0.6920\n",
            " Testing bag [5/6] bag loss: 0.6943ROC AUC score: 0.6666666666666667\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.375\n",
            "\n",
            " Epoch [2/300] train loss: 0.6979 test loss: 0.6945, average score: 0.3333, AUC: class-0>>0.6666666666666667|class-1>>0.8|class-2>>0.375\n",
            "Best model saved at: weights/20250626/fold_2_19.pth\n",
            "Best thresholds ===>>> class-0>>0.4871692359447479|class-1>>0.46101248264312744|class-2>>0.4743713140487671\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6835\n",
            " Training bag [1/11] bag loss: 0.6982\n",
            " Training bag [2/11] bag loss: 0.7067\n",
            " Training bag [3/11] bag loss: 0.6949\n",
            " Training bag [4/11] bag loss: 0.6896\n",
            " Training bag [5/11] bag loss: 0.6831\n",
            " Training bag [6/11] bag loss: 0.6829\n",
            " Training bag [7/11] bag loss: 0.6904\n",
            " Training bag [8/11] bag loss: 0.7149\n",
            " Training bag [9/11] bag loss: 0.7111\n",
            " Training bag [10/11] bag loss: 0.6757\n",
            " Testing bag [0/6] bag loss: 0.6812\n",
            " Testing bag [1/6] bag loss: 0.7083\n",
            " Testing bag [2/6] bag loss: 0.6786\n",
            " Testing bag [3/6] bag loss: 0.6920\n",
            " Testing bag [4/6] bag loss: 0.6854\n",
            " Testing bag [5/6] bag loss: 0.6890ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.375\n",
            "\n",
            " Epoch [3/300] train loss: 0.6937 test loss: 0.6891, average score: 0.3333, AUC: class-0>>0.5555555555555556|class-1>>1.0|class-2>>0.375\n",
            "Best model saved at: weights/20250626/fold_2_19.pth\n",
            "Best thresholds ===>>> class-0>>0.47945719957351685|class-1>>0.44744837284088135|class-2>>0.4679984450340271\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6909\n",
            " Training bag [1/11] bag loss: 0.7077\n",
            " Training bag [2/11] bag loss: 0.7052\n",
            " Training bag [3/11] bag loss: 0.6770\n",
            " Training bag [4/11] bag loss: 0.6849\n",
            " Training bag [5/11] bag loss: 0.6806\n",
            " Training bag [6/11] bag loss: 0.6864\n",
            " Training bag [7/11] bag loss: 0.7072\n",
            " Training bag [8/11] bag loss: 0.6729\n",
            " Training bag [9/11] bag loss: 0.6750\n",
            " Training bag [10/11] bag loss: 0.6865\n",
            " Testing bag [0/6] bag loss: 0.6765\n",
            " Testing bag [1/6] bag loss: 0.7056\n",
            " Testing bag [2/6] bag loss: 0.6726\n",
            " Testing bag [3/6] bag loss: 0.6887\n",
            " Testing bag [4/6] bag loss: 0.6834\n",
            " Testing bag [5/6] bag loss: 0.6826ROC AUC score: 0.5555555555555556\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.375\n",
            "\n",
            " Epoch [4/300] train loss: 0.6886 test loss: 0.6849, average score: 0.3333, AUC: class-0>>0.5555555555555556|class-1>>1.0|class-2>>0.375\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6848\n",
            " Training bag [1/11] bag loss: 0.6688\n",
            " Training bag [2/11] bag loss: 0.7073\n",
            " Training bag [3/11] bag loss: 0.7085\n",
            " Training bag [4/11] bag loss: 0.6711\n",
            " Training bag [5/11] bag loss: 0.6659\n",
            " Training bag [6/11] bag loss: 0.6662\n",
            " Training bag [7/11] bag loss: 0.6905\n",
            " Training bag [8/11] bag loss: 0.7039\n",
            " Training bag [9/11] bag loss: 0.6865\n",
            " Training bag [10/11] bag loss: 0.6837\n",
            " Testing bag [0/6] bag loss: 0.6705\n",
            " Testing bag [1/6] bag loss: 0.7046\n",
            " Testing bag [2/6] bag loss: 0.6660\n",
            " Testing bag [3/6] bag loss: 0.6858\n",
            " Testing bag [4/6] bag loss: 0.6806\n",
            " Testing bag [5/6] bag loss: 0.6808ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [5/300] train loss: 0.6852 test loss: 0.6814, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.5\n",
            "Best model saved at: weights/20250626/fold_2_19.pth\n",
            "Best thresholds ===>>> class-0>>0.4600275456905365|class-1>>0.4274732172489166|class-2>>0.45727673172950745\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7047\n",
            " Training bag [1/11] bag loss: 0.6655\n",
            " Training bag [2/11] bag loss: 0.7050\n",
            " Training bag [3/11] bag loss: 0.6802\n",
            " Training bag [4/11] bag loss: 0.6807\n",
            " Training bag [5/11] bag loss: 0.6678\n",
            " Training bag [6/11] bag loss: 0.6771\n",
            " Training bag [7/11] bag loss: 0.6785\n",
            " Training bag [8/11] bag loss: 0.7052\n",
            " Training bag [9/11] bag loss: 0.6647\n",
            " Training bag [10/11] bag loss: 0.6686\n",
            " Testing bag [0/6] bag loss: 0.6694\n",
            " Testing bag [1/6] bag loss: 0.7048\n",
            " Testing bag [2/6] bag loss: 0.6661\n",
            " Testing bag [3/6] bag loss: 0.6768\n",
            " Testing bag [4/6] bag loss: 0.6709\n",
            " Testing bag [5/6] bag loss: 0.6719ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.25\n",
            "\n",
            " Epoch [6/300] train loss: 0.6816 test loss: 0.6766, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.25\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6665\n",
            " Training bag [1/11] bag loss: 0.6619\n",
            " Training bag [2/11] bag loss: 0.6762\n",
            " Training bag [3/11] bag loss: 0.6742\n",
            " Training bag [4/11] bag loss: 0.6754\n",
            " Training bag [5/11] bag loss: 0.7105\n",
            " Training bag [6/11] bag loss: 0.6571\n",
            " Training bag [7/11] bag loss: 0.6685\n",
            " Training bag [8/11] bag loss: 0.7119\n",
            " Training bag [9/11] bag loss: 0.7067\n",
            " Training bag [10/11] bag loss: 0.6600\n",
            " Testing bag [0/6] bag loss: 0.6646\n",
            " Testing bag [1/6] bag loss: 0.7062\n",
            " Testing bag [2/6] bag loss: 0.6599\n",
            " Testing bag [3/6] bag loss: 0.6722\n",
            " Testing bag [4/6] bag loss: 0.6679\n",
            " Testing bag [5/6] bag loss: 0.6662ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.375\n",
            "\n",
            " Epoch [7/300] train loss: 0.6790 test loss: 0.6728, average score: 0.3333, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.375\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6562\n",
            " Training bag [1/11] bag loss: 0.6545\n",
            " Training bag [2/11] bag loss: 0.6726\n",
            " Training bag [3/11] bag loss: 0.6525\n",
            " Training bag [4/11] bag loss: 0.6691\n",
            " Training bag [5/11] bag loss: 0.7101\n",
            " Training bag [6/11] bag loss: 0.6713\n",
            " Training bag [7/11] bag loss: 0.7123\n",
            " Training bag [8/11] bag loss: 0.7076\n",
            " Training bag [9/11] bag loss: 0.6683\n",
            " Training bag [10/11] bag loss: 0.6589\n",
            " Testing bag [0/6] bag loss: 0.6614\n",
            " Testing bag [1/6] bag loss: 0.7043\n",
            " Testing bag [2/6] bag loss: 0.6573\n",
            " Testing bag [3/6] bag loss: 0.6692\n",
            " Testing bag [4/6] bag loss: 0.6637\n",
            " Testing bag [5/6] bag loss: 0.6648ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.375\n",
            "\n",
            " Epoch [8/300] train loss: 0.6758 test loss: 0.6701, average score: 0.3333, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.375\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6649\n",
            " Training bag [1/11] bag loss: 0.7035\n",
            " Training bag [2/11] bag loss: 0.6568\n",
            " Training bag [3/11] bag loss: 0.7019\n",
            " Training bag [4/11] bag loss: 0.7034\n",
            " Training bag [5/11] bag loss: 0.6674\n",
            " Training bag [6/11] bag loss: 0.6553\n",
            " Training bag [7/11] bag loss: 0.6689\n",
            " Training bag [8/11] bag loss: 0.6539\n",
            " Training bag [9/11] bag loss: 0.6635\n",
            " Training bag [10/11] bag loss: 0.6570\n",
            " Testing bag [0/6] bag loss: 0.6598\n",
            " Testing bag [1/6] bag loss: 0.7039\n",
            " Testing bag [2/6] bag loss: 0.6543\n",
            " Testing bag [3/6] bag loss: 0.6661\n",
            " Testing bag [4/6] bag loss: 0.6621\n",
            " Testing bag [5/6] bag loss: 0.6611ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [9/300] train loss: 0.6724 test loss: 0.6679, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>0.8|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6622\n",
            " Training bag [1/11] bag loss: 0.7065\n",
            " Training bag [2/11] bag loss: 0.7002\n",
            " Training bag [3/11] bag loss: 0.6538\n",
            " Training bag [4/11] bag loss: 0.6518\n",
            " Training bag [5/11] bag loss: 0.6530\n",
            " Training bag [6/11] bag loss: 0.6653\n",
            " Training bag [7/11] bag loss: 0.7014\n",
            " Training bag [8/11] bag loss: 0.6456\n",
            " Training bag [9/11] bag loss: 0.6657\n",
            " Training bag [10/11] bag loss: 0.6669\n",
            " Testing bag [0/6] bag loss: 0.6523\n",
            " Testing bag [1/6] bag loss: 0.7031\n",
            " Testing bag [2/6] bag loss: 0.6485\n",
            " Testing bag [3/6] bag loss: 0.6649\n",
            " Testing bag [4/6] bag loss: 0.6616\n",
            " Testing bag [5/6] bag loss: 0.6607ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [10/300] train loss: 0.6702 test loss: 0.6652, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6643\n",
            " Training bag [1/11] bag loss: 0.6494\n",
            " Training bag [2/11] bag loss: 0.7031\n",
            " Training bag [3/11] bag loss: 0.7062\n",
            " Training bag [4/11] bag loss: 0.6582\n",
            " Training bag [5/11] bag loss: 0.6581\n",
            " Training bag [6/11] bag loss: 0.6548\n",
            " Training bag [7/11] bag loss: 0.6523\n",
            " Training bag [8/11] bag loss: 0.6483\n",
            " Training bag [9/11] bag loss: 0.7027\n",
            " Training bag [10/11] bag loss: 0.6494\n",
            " Testing bag [0/6] bag loss: 0.6538\n",
            " Testing bag [1/6] bag loss: 0.7040\n",
            " Testing bag [2/6] bag loss: 0.6484\n",
            " Testing bag [3/6] bag loss: 0.6578\n",
            " Testing bag [4/6] bag loss: 0.6546\n",
            " Testing bag [5/6] bag loss: 0.6530ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.375\n",
            "\n",
            " Epoch [11/300] train loss: 0.6679 test loss: 0.6619, average score: 0.3333, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.375\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6553\n",
            " Training bag [1/11] bag loss: 0.6484\n",
            " Training bag [2/11] bag loss: 0.7030\n",
            " Training bag [3/11] bag loss: 0.6535\n",
            " Training bag [4/11] bag loss: 0.7068\n",
            " Training bag [5/11] bag loss: 0.6530\n",
            " Training bag [6/11] bag loss: 0.6482\n",
            " Training bag [7/11] bag loss: 0.6991\n",
            " Training bag [8/11] bag loss: 0.6463\n",
            " Training bag [9/11] bag loss: 0.6528\n",
            " Training bag [10/11] bag loss: 0.6431\n",
            " Testing bag [0/6] bag loss: 0.6502\n",
            " Testing bag [1/6] bag loss: 0.7038\n",
            " Testing bag [2/6] bag loss: 0.6473\n",
            " Testing bag [3/6] bag loss: 0.6558\n",
            " Testing bag [4/6] bag loss: 0.6540\n",
            " Testing bag [5/6] bag loss: 0.6528ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.375\n",
            "\n",
            " Epoch [12/300] train loss: 0.6645 test loss: 0.6607, average score: 0.3333, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.375\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6441\n",
            " Training bag [1/11] bag loss: 0.6556\n",
            " Training bag [2/11] bag loss: 0.6421\n",
            " Training bag [3/11] bag loss: 0.6371\n",
            " Training bag [4/11] bag loss: 0.7108\n",
            " Training bag [5/11] bag loss: 0.6542\n",
            " Training bag [6/11] bag loss: 0.6548\n",
            " Training bag [7/11] bag loss: 0.6354\n",
            " Training bag [8/11] bag loss: 0.6500\n",
            " Training bag [9/11] bag loss: 0.7080\n",
            " Training bag [10/11] bag loss: 0.7075\n",
            " Testing bag [0/6] bag loss: 0.6455\n",
            " Testing bag [1/6] bag loss: 0.7071\n",
            " Testing bag [2/6] bag loss: 0.6408\n",
            " Testing bag [3/6] bag loss: 0.6523\n",
            " Testing bag [4/6] bag loss: 0.6500\n",
            " Testing bag [5/6] bag loss: 0.6499ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [13/300] train loss: 0.6636 test loss: 0.6576, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7029\n",
            " Training bag [1/11] bag loss: 0.6512\n",
            " Training bag [2/11] bag loss: 0.6429\n",
            " Training bag [3/11] bag loss: 0.6494\n",
            " Training bag [4/11] bag loss: 0.6387\n",
            " Training bag [5/11] bag loss: 0.7066\n",
            " Training bag [6/11] bag loss: 0.6497\n",
            " Training bag [7/11] bag loss: 0.6392\n",
            " Training bag [8/11] bag loss: 0.6466\n",
            " Training bag [9/11] bag loss: 0.6387\n",
            " Training bag [10/11] bag loss: 0.7072\n",
            " Testing bag [0/6] bag loss: 0.6449\n",
            " Testing bag [1/6] bag loss: 0.7055\n",
            " Testing bag [2/6] bag loss: 0.6401\n",
            " Testing bag [3/6] bag loss: 0.6499\n",
            " Testing bag [4/6] bag loss: 0.6486\n",
            " Testing bag [5/6] bag loss: 0.6480ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [14/300] train loss: 0.6612 test loss: 0.6562, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6366\n",
            " Training bag [1/11] bag loss: 0.6461\n",
            " Training bag [2/11] bag loss: 0.6464\n",
            " Training bag [3/11] bag loss: 0.7068\n",
            " Training bag [4/11] bag loss: 0.7078\n",
            " Training bag [5/11] bag loss: 0.6366\n",
            " Training bag [6/11] bag loss: 0.6458\n",
            " Training bag [7/11] bag loss: 0.6438\n",
            " Training bag [8/11] bag loss: 0.6406\n",
            " Training bag [9/11] bag loss: 0.6405\n",
            " Training bag [10/11] bag loss: 0.7053\n",
            " Testing bag [0/6] bag loss: 0.6429\n",
            " Testing bag [1/6] bag loss: 0.7069\n",
            " Testing bag [2/6] bag loss: 0.6393\n",
            " Testing bag [3/6] bag loss: 0.6473\n",
            " Testing bag [4/6] bag loss: 0.6451\n",
            " Testing bag [5/6] bag loss: 0.6449ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [15/300] train loss: 0.6597 test loss: 0.6544, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>0.8|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7067\n",
            " Training bag [1/11] bag loss: 0.7034\n",
            " Training bag [2/11] bag loss: 0.6362\n",
            " Training bag [3/11] bag loss: 0.6495\n",
            " Training bag [4/11] bag loss: 0.6357\n",
            " Training bag [5/11] bag loss: 0.6329\n",
            " Training bag [6/11] bag loss: 0.6485\n",
            " Training bag [7/11] bag loss: 0.6477\n",
            " Training bag [8/11] bag loss: 0.6996\n",
            " Training bag [9/11] bag loss: 0.6354\n",
            " Training bag [10/11] bag loss: 0.6456\n",
            " Testing bag [0/6] bag loss: 0.6409\n",
            " Testing bag [1/6] bag loss: 0.7044\n",
            " Testing bag [2/6] bag loss: 0.6378\n",
            " Testing bag [3/6] bag loss: 0.6476\n",
            " Testing bag [4/6] bag loss: 0.6459\n",
            " Testing bag [5/6] bag loss: 0.6441ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.625\n",
            "\n",
            " Epoch [16/300] train loss: 0.6583 test loss: 0.6535, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>0.8|class-2>>0.625\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6314\n",
            " Training bag [1/11] bag loss: 0.6433\n",
            " Training bag [2/11] bag loss: 0.6424\n",
            " Training bag [3/11] bag loss: 0.7089\n",
            " Training bag [4/11] bag loss: 0.6356\n",
            " Training bag [5/11] bag loss: 0.7031\n",
            " Training bag [6/11] bag loss: 0.6423\n",
            " Training bag [7/11] bag loss: 0.6406\n",
            " Training bag [8/11] bag loss: 0.6375\n",
            " Training bag [9/11] bag loss: 0.7055\n",
            " Training bag [10/11] bag loss: 0.6346\n",
            " Testing bag [0/6] bag loss: 0.6406\n",
            " Testing bag [1/6] bag loss: 0.7057\n",
            " Testing bag [2/6] bag loss: 0.6377\n",
            " Testing bag [3/6] bag loss: 0.6426\n",
            " Testing bag [4/6] bag loss: 0.6418\n",
            " Testing bag [5/6] bag loss: 0.6406ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [17/300] train loss: 0.6568 test loss: 0.6515, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>0.8|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6350\n",
            " Training bag [1/11] bag loss: 0.7060\n",
            " Training bag [2/11] bag loss: 0.6285\n",
            " Training bag [3/11] bag loss: 0.6455\n",
            " Training bag [4/11] bag loss: 0.6290\n",
            " Training bag [5/11] bag loss: 0.6452\n",
            " Training bag [6/11] bag loss: 0.6427\n",
            " Training bag [7/11] bag loss: 0.6402\n",
            " Training bag [8/11] bag loss: 0.6285\n",
            " Training bag [9/11] bag loss: 0.7127\n",
            " Training bag [10/11] bag loss: 0.7069\n",
            " Testing bag [0/6] bag loss: 0.6358\n",
            " Testing bag [1/6] bag loss: 0.7083\n",
            " Testing bag [2/6] bag loss: 0.6328\n",
            " Testing bag [3/6] bag loss: 0.6404\n",
            " Testing bag [4/6] bag loss: 0.6410\n",
            " Testing bag [5/6] bag loss: 0.6394ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.625\n",
            "\n",
            " Epoch [18/300] train loss: 0.6564 test loss: 0.6496, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.625\n",
            "Best model saved at: weights/20250626/fold_2_19.pth\n",
            "Best thresholds ===>>> class-0>>0.39962634444236755|class-1>>0.3373032212257385|class-2>>0.399140328168869\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6303\n",
            " Training bag [1/11] bag loss: 0.6388\n",
            " Training bag [2/11] bag loss: 0.7022\n",
            " Training bag [3/11] bag loss: 0.6394\n",
            " Training bag [4/11] bag loss: 0.6302\n",
            " Training bag [5/11] bag loss: 0.6279\n",
            " Training bag [6/11] bag loss: 0.6383\n",
            " Training bag [7/11] bag loss: 0.7087\n",
            " Training bag [8/11] bag loss: 0.6374\n",
            " Training bag [9/11] bag loss: 0.7080\n",
            " Training bag [10/11] bag loss: 0.6301\n",
            " Testing bag [0/6] bag loss: 0.6361\n",
            " Testing bag [1/6] bag loss: 0.7059\n",
            " Testing bag [2/6] bag loss: 0.6338\n",
            " Testing bag [3/6] bag loss: 0.6391\n",
            " Testing bag [4/6] bag loss: 0.6400\n",
            " Testing bag [5/6] bag loss: 0.6378ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.5\n",
            "\n",
            " Epoch [19/300] train loss: 0.6538 test loss: 0.6488, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.5\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7054\n",
            " Training bag [1/11] bag loss: 0.7008\n",
            " Training bag [2/11] bag loss: 0.6401\n",
            " Training bag [3/11] bag loss: 0.6367\n",
            " Training bag [4/11] bag loss: 0.6360\n",
            " Training bag [5/11] bag loss: 0.6324\n",
            " Training bag [6/11] bag loss: 0.7015\n",
            " Training bag [7/11] bag loss: 0.6284\n",
            " Training bag [8/11] bag loss: 0.6394\n",
            " Training bag [9/11] bag loss: 0.6275\n",
            " Training bag [10/11] bag loss: 0.6406\n",
            " Testing bag [0/6] bag loss: 0.6337\n",
            " Testing bag [1/6] bag loss: 0.7035\n",
            " Testing bag [2/6] bag loss: 0.6324\n",
            " Testing bag [3/6] bag loss: 0.6395\n",
            " Testing bag [4/6] bag loss: 0.6415\n",
            " Testing bag [5/6] bag loss: 0.6379ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.625\n",
            "\n",
            " Epoch [20/300] train loss: 0.6535 test loss: 0.6481, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.625\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6265\n",
            " Training bag [1/11] bag loss: 0.6373\n",
            " Training bag [2/11] bag loss: 0.6264\n",
            " Training bag [3/11] bag loss: 0.7074\n",
            " Training bag [4/11] bag loss: 0.6375\n",
            " Training bag [5/11] bag loss: 0.6364\n",
            " Training bag [6/11] bag loss: 0.6324\n",
            " Training bag [7/11] bag loss: 0.7043\n",
            " Training bag [8/11] bag loss: 0.6258\n",
            " Training bag [9/11] bag loss: 0.7077\n",
            " Training bag [10/11] bag loss: 0.6280\n",
            " Testing bag [0/6] bag loss: 0.6345\n",
            " Testing bag [1/6] bag loss: 0.7060\n",
            " Testing bag [2/6] bag loss: 0.6307\n",
            " Testing bag [3/6] bag loss: 0.6361\n",
            " Testing bag [4/6] bag loss: 0.6357\n",
            " Testing bag [5/6] bag loss: 0.6345ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [21/300] train loss: 0.6518 test loss: 0.6463, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>0.8|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6322\n",
            " Training bag [1/11] bag loss: 0.6280\n",
            " Training bag [2/11] bag loss: 0.6319\n",
            " Training bag [3/11] bag loss: 0.7029\n",
            " Training bag [4/11] bag loss: 0.7065\n",
            " Training bag [5/11] bag loss: 0.6276\n",
            " Training bag [6/11] bag loss: 0.6334\n",
            " Training bag [7/11] bag loss: 0.6250\n",
            " Training bag [8/11] bag loss: 0.6338\n",
            " Training bag [9/11] bag loss: 0.7063\n",
            " Training bag [10/11] bag loss: 0.6255\n",
            " Testing bag [0/6] bag loss: 0.6318\n",
            " Testing bag [1/6] bag loss: 0.7064\n",
            " Testing bag [2/6] bag loss: 0.6306\n",
            " Testing bag [3/6] bag loss: 0.6348\n",
            " Testing bag [4/6] bag loss: 0.6351\n",
            " Testing bag [5/6] bag loss: 0.6342ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [22/300] train loss: 0.6503 test loss: 0.6455, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>0.8|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6997\n",
            " Training bag [1/11] bag loss: 0.6238\n",
            " Training bag [2/11] bag loss: 0.6354\n",
            " Training bag [3/11] bag loss: 0.6351\n",
            " Training bag [4/11] bag loss: 0.6302\n",
            " Training bag [5/11] bag loss: 0.7047\n",
            " Training bag [6/11] bag loss: 0.6277\n",
            " Training bag [7/11] bag loss: 0.6286\n",
            " Training bag [8/11] bag loss: 0.6303\n",
            " Training bag [9/11] bag loss: 0.6248\n",
            " Training bag [10/11] bag loss: 0.7069\n",
            " Testing bag [0/6] bag loss: 0.6291\n",
            " Testing bag [1/6] bag loss: 0.7077\n",
            " Testing bag [2/6] bag loss: 0.6262\n",
            " Testing bag [3/6] bag loss: 0.6328\n",
            " Testing bag [4/6] bag loss: 0.6339\n",
            " Testing bag [5/6] bag loss: 0.6321ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.625\n",
            "\n",
            " Epoch [23/300] train loss: 0.6497 test loss: 0.6436, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>0.8|class-2>>0.625\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6248\n",
            " Training bag [1/11] bag loss: 0.6222\n",
            " Training bag [2/11] bag loss: 0.6181\n",
            " Training bag [3/11] bag loss: 0.6366\n",
            " Training bag [4/11] bag loss: 0.7090\n",
            " Training bag [5/11] bag loss: 0.6357\n",
            " Training bag [6/11] bag loss: 0.6334\n",
            " Training bag [7/11] bag loss: 0.6156\n",
            " Training bag [8/11] bag loss: 0.6328\n",
            " Training bag [9/11] bag loss: 0.7109\n",
            " Training bag [10/11] bag loss: 0.7082\n",
            " Testing bag [0/6] bag loss: 0.6267\n",
            " Testing bag [1/6] bag loss: 0.7096\n",
            " Testing bag [2/6] bag loss: 0.6242\n",
            " Testing bag [3/6] bag loss: 0.6327\n",
            " Testing bag [4/6] bag loss: 0.6334\n",
            " Testing bag [5/6] bag loss: 0.6316ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.625\n",
            "\n",
            " Epoch [24/300] train loss: 0.6498 test loss: 0.6430, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>0.8|class-2>>0.625\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6291\n",
            " Training bag [1/11] bag loss: 0.6284\n",
            " Training bag [2/11] bag loss: 0.6208\n",
            " Training bag [3/11] bag loss: 0.6277\n",
            " Training bag [4/11] bag loss: 0.7051\n",
            " Training bag [5/11] bag loss: 0.7084\n",
            " Training bag [6/11] bag loss: 0.6281\n",
            " Training bag [7/11] bag loss: 0.6248\n",
            " Training bag [8/11] bag loss: 0.6248\n",
            " Training bag [9/11] bag loss: 0.6284\n",
            " Training bag [10/11] bag loss: 0.7080\n",
            " Testing bag [0/6] bag loss: 0.6261\n",
            " Testing bag [1/6] bag loss: 0.7068\n",
            " Testing bag [2/6] bag loss: 0.6246\n",
            " Testing bag [3/6] bag loss: 0.6321\n",
            " Testing bag [4/6] bag loss: 0.6328\n",
            " Testing bag [5/6] bag loss: 0.6309ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.625\n",
            "\n",
            " Epoch [25/300] train loss: 0.6485 test loss: 0.6422, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>0.8|class-2>>0.625\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6282\n",
            " Training bag [1/11] bag loss: 0.7008\n",
            " Training bag [2/11] bag loss: 0.6230\n",
            " Training bag [3/11] bag loss: 0.6190\n",
            " Training bag [4/11] bag loss: 0.6317\n",
            " Training bag [5/11] bag loss: 0.7043\n",
            " Training bag [6/11] bag loss: 0.7044\n",
            " Training bag [7/11] bag loss: 0.6288\n",
            " Training bag [8/11] bag loss: 0.6229\n",
            " Training bag [9/11] bag loss: 0.6247\n",
            " Training bag [10/11] bag loss: 0.6308\n",
            " Testing bag [0/6] bag loss: 0.6259\n",
            " Testing bag [1/6] bag loss: 0.7044\n",
            " Testing bag [2/6] bag loss: 0.6253\n",
            " Testing bag [3/6] bag loss: 0.6319\n",
            " Testing bag [4/6] bag loss: 0.6330\n",
            " Testing bag [5/6] bag loss: 0.6300ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.625\n",
            "\n",
            " Epoch [26/300] train loss: 0.6471 test loss: 0.6417, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.625\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6194\n",
            " Training bag [1/11] bag loss: 0.7059\n",
            " Training bag [2/11] bag loss: 0.6303\n",
            " Training bag [3/11] bag loss: 0.6995\n",
            " Training bag [4/11] bag loss: 0.6288\n",
            " Training bag [5/11] bag loss: 0.6187\n",
            " Training bag [6/11] bag loss: 0.6200\n",
            " Training bag [7/11] bag loss: 0.7022\n",
            " Training bag [8/11] bag loss: 0.6312\n",
            " Training bag [9/11] bag loss: 0.6282\n",
            " Training bag [10/11] bag loss: 0.6237\n",
            " Testing bag [0/6] bag loss: 0.6261\n",
            " Testing bag [1/6] bag loss: 0.7062\n",
            " Testing bag [2/6] bag loss: 0.6250\n",
            " Testing bag [3/6] bag loss: 0.6298\n",
            " Testing bag [4/6] bag loss: 0.6314\n",
            " Testing bag [5/6] bag loss: 0.6292ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.625\n",
            "\n",
            " Epoch [27/300] train loss: 0.6462 test loss: 0.6413, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>0.8|class-2>>0.625\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6222\n",
            " Training bag [1/11] bag loss: 0.6144\n",
            " Training bag [2/11] bag loss: 0.6292\n",
            " Training bag [3/11] bag loss: 0.7071\n",
            " Training bag [4/11] bag loss: 0.6282\n",
            " Training bag [5/11] bag loss: 0.7023\n",
            " Training bag [6/11] bag loss: 0.7058\n",
            " Training bag [7/11] bag loss: 0.6214\n",
            " Training bag [8/11] bag loss: 0.6293\n",
            " Training bag [9/11] bag loss: 0.6178\n",
            " Training bag [10/11] bag loss: 0.6292\n",
            " Testing bag [0/6] bag loss: 0.6232\n",
            " Testing bag [1/6] bag loss: 0.7058\n",
            " Testing bag [2/6] bag loss: 0.6217\n",
            " Testing bag [3/6] bag loss: 0.6280\n",
            " Testing bag [4/6] bag loss: 0.6315\n",
            " Testing bag [5/6] bag loss: 0.6300ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.625\n",
            "\n",
            " Epoch [28/300] train loss: 0.6461 test loss: 0.6400, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.625\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6275\n",
            " Training bag [1/11] bag loss: 0.7038\n",
            " Training bag [2/11] bag loss: 0.7041\n",
            " Training bag [3/11] bag loss: 0.6250\n",
            " Training bag [4/11] bag loss: 0.6246\n",
            " Training bag [5/11] bag loss: 0.6239\n",
            " Training bag [6/11] bag loss: 0.6225\n",
            " Training bag [7/11] bag loss: 0.6971\n",
            " Training bag [8/11] bag loss: 0.6185\n",
            " Training bag [9/11] bag loss: 0.6249\n",
            " Training bag [10/11] bag loss: 0.6219\n",
            " Testing bag [0/6] bag loss: 0.6245\n",
            " Testing bag [1/6] bag loss: 0.7069\n",
            " Testing bag [2/6] bag loss: 0.6225\n",
            " Testing bag [3/6] bag loss: 0.6267\n",
            " Testing bag [4/6] bag loss: 0.6288\n",
            " Testing bag [5/6] bag loss: 0.6267ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [29/300] train loss: 0.6449 test loss: 0.6393, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.75\n",
            "Best model saved at: weights/20250626/fold_2_19.pth\n",
            "Best thresholds ===>>> class-0>>0.3734476864337921|class-1>>0.3099159896373749|class-2>>0.3896995186805725\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6239\n",
            " Training bag [1/11] bag loss: 0.6220\n",
            " Training bag [2/11] bag loss: 0.6189\n",
            " Training bag [3/11] bag loss: 0.7020\n",
            " Training bag [4/11] bag loss: 0.6179\n",
            " Training bag [5/11] bag loss: 0.6210\n",
            " Training bag [6/11] bag loss: 0.6242\n",
            " Training bag [7/11] bag loss: 0.7100\n",
            " Training bag [8/11] bag loss: 0.6175\n",
            " Training bag [9/11] bag loss: 0.7073\n",
            " Training bag [10/11] bag loss: 0.6200\n",
            " Testing bag [0/6] bag loss: 0.6228\n",
            " Testing bag [1/6] bag loss: 0.7080\n",
            " Testing bag [2/6] bag loss: 0.6216\n",
            " Testing bag [3/6] bag loss: 0.6246\n",
            " Testing bag [4/6] bag loss: 0.6262\n",
            " Testing bag [5/6] bag loss: 0.6251ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [30/300] train loss: 0.6441 test loss: 0.6380, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>0.8|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6228\n",
            " Training bag [1/11] bag loss: 0.6209\n",
            " Training bag [2/11] bag loss: 0.6208\n",
            " Training bag [3/11] bag loss: 0.6195\n",
            " Training bag [4/11] bag loss: 0.6168\n",
            " Training bag [5/11] bag loss: 0.6154\n",
            " Training bag [6/11] bag loss: 0.7119\n",
            " Training bag [7/11] bag loss: 0.6166\n",
            " Training bag [8/11] bag loss: 0.6188\n",
            " Training bag [9/11] bag loss: 0.7066\n",
            " Training bag [10/11] bag loss: 0.7119\n",
            " Testing bag [0/6] bag loss: 0.6198\n",
            " Testing bag [1/6] bag loss: 0.7109\n",
            " Testing bag [2/6] bag loss: 0.6188\n",
            " Testing bag [3/6] bag loss: 0.6227\n",
            " Testing bag [4/6] bag loss: 0.6268\n",
            " Testing bag [5/6] bag loss: 0.6234ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [31/300] train loss: 0.6438 test loss: 0.6371, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>0.8|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6236\n",
            " Training bag [1/11] bag loss: 0.6192\n",
            " Training bag [2/11] bag loss: 0.6157\n",
            " Training bag [3/11] bag loss: 0.6194\n",
            " Training bag [4/11] bag loss: 0.6159\n",
            " Training bag [5/11] bag loss: 0.6149\n",
            " Training bag [6/11] bag loss: 0.7115\n",
            " Training bag [7/11] bag loss: 0.6163\n",
            " Training bag [8/11] bag loss: 0.7132\n",
            " Training bag [9/11] bag loss: 0.7073\n",
            " Training bag [10/11] bag loss: 0.6176\n",
            " Testing bag [0/6] bag loss: 0.6200\n",
            " Testing bag [1/6] bag loss: 0.7092\n",
            " Testing bag [2/6] bag loss: 0.6185\n",
            " Testing bag [3/6] bag loss: 0.6226\n",
            " Testing bag [4/6] bag loss: 0.6261\n",
            " Testing bag [5/6] bag loss: 0.6222ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [32/300] train loss: 0.6431 test loss: 0.6364, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>0.8|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6991\n",
            " Training bag [1/11] bag loss: 0.6131\n",
            " Training bag [2/11] bag loss: 0.6088\n",
            " Training bag [3/11] bag loss: 0.6254\n",
            " Training bag [4/11] bag loss: 0.6271\n",
            " Training bag [5/11] bag loss: 0.7043\n",
            " Training bag [6/11] bag loss: 0.6141\n",
            " Training bag [7/11] bag loss: 0.7057\n",
            " Training bag [8/11] bag loss: 0.6247\n",
            " Training bag [9/11] bag loss: 0.6234\n",
            " Training bag [10/11] bag loss: 0.6155\n",
            " Testing bag [0/6] bag loss: 0.6193\n",
            " Testing bag [1/6] bag loss: 0.7076\n",
            " Testing bag [2/6] bag loss: 0.6162\n",
            " Testing bag [3/6] bag loss: 0.6249\n",
            " Testing bag [4/6] bag loss: 0.6274\n",
            " Testing bag [5/6] bag loss: 0.6233ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.625\n",
            "\n",
            " Epoch [33/300] train loss: 0.6419 test loss: 0.6365, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.625\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6122\n",
            " Training bag [1/11] bag loss: 0.6218\n",
            " Training bag [2/11] bag loss: 0.6227\n",
            " Training bag [3/11] bag loss: 0.6081\n",
            " Training bag [4/11] bag loss: 0.6126\n",
            " Training bag [5/11] bag loss: 0.6165\n",
            " Training bag [6/11] bag loss: 0.7100\n",
            " Training bag [7/11] bag loss: 0.6115\n",
            " Training bag [8/11] bag loss: 0.7110\n",
            " Training bag [9/11] bag loss: 0.6213\n",
            " Training bag [10/11] bag loss: 0.7114\n",
            " Testing bag [0/6] bag loss: 0.6173\n",
            " Testing bag [1/6] bag loss: 0.7119\n",
            " Testing bag [2/6] bag loss: 0.6128\n",
            " Testing bag [3/6] bag loss: 0.6236\n",
            " Testing bag [4/6] bag loss: 0.6260\n",
            " Testing bag [5/6] bag loss: 0.6238ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [34/300] train loss: 0.6417 test loss: 0.6359, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>0.8|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6060\n",
            " Training bag [1/11] bag loss: 0.6231\n",
            " Training bag [2/11] bag loss: 0.6190\n",
            " Training bag [3/11] bag loss: 0.6099\n",
            " Training bag [4/11] bag loss: 0.6121\n",
            " Training bag [5/11] bag loss: 0.7132\n",
            " Training bag [6/11] bag loss: 0.6205\n",
            " Training bag [7/11] bag loss: 0.6107\n",
            " Training bag [8/11] bag loss: 0.7047\n",
            " Training bag [9/11] bag loss: 0.7098\n",
            " Training bag [10/11] bag loss: 0.6206\n",
            " Testing bag [0/6] bag loss: 0.6150\n",
            " Testing bag [1/6] bag loss: 0.7097\n",
            " Testing bag [2/6] bag loss: 0.6118\n",
            " Testing bag [3/6] bag loss: 0.6240\n",
            " Testing bag [4/6] bag loss: 0.6263\n",
            " Testing bag [5/6] bag loss: 0.6233ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [35/300] train loss: 0.6409 test loss: 0.6350, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7020\n",
            " Training bag [1/11] bag loss: 0.6069\n",
            " Training bag [2/11] bag loss: 0.6226\n",
            " Training bag [3/11] bag loss: 0.6212\n",
            " Training bag [4/11] bag loss: 0.6135\n",
            " Training bag [5/11] bag loss: 0.6132\n",
            " Training bag [6/11] bag loss: 0.6083\n",
            " Training bag [7/11] bag loss: 0.7094\n",
            " Training bag [8/11] bag loss: 0.6217\n",
            " Training bag [9/11] bag loss: 0.6187\n",
            " Training bag [10/11] bag loss: 0.7094\n",
            " Testing bag [0/6] bag loss: 0.6148\n",
            " Testing bag [1/6] bag loss: 0.7108\n",
            " Testing bag [2/6] bag loss: 0.6130\n",
            " Testing bag [3/6] bag loss: 0.6215\n",
            " Testing bag [4/6] bag loss: 0.6251\n",
            " Testing bag [5/6] bag loss: 0.6204ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [36/300] train loss: 0.6406 test loss: 0.6343, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>0.8|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7048\n",
            " Training bag [1/11] bag loss: 0.6184\n",
            " Training bag [2/11] bag loss: 0.6141\n",
            " Training bag [3/11] bag loss: 0.6074\n",
            " Training bag [4/11] bag loss: 0.6120\n",
            " Training bag [5/11] bag loss: 0.6184\n",
            " Training bag [6/11] bag loss: 0.6056\n",
            " Training bag [7/11] bag loss: 0.6199\n",
            " Training bag [8/11] bag loss: 0.7125\n",
            " Training bag [9/11] bag loss: 0.7033\n",
            " Training bag [10/11] bag loss: 0.6225\n",
            " Testing bag [0/6] bag loss: 0.6138\n",
            " Testing bag [1/6] bag loss: 0.7092\n",
            " Testing bag [2/6] bag loss: 0.6115\n",
            " Testing bag [3/6] bag loss: 0.6210\n",
            " Testing bag [4/6] bag loss: 0.6250\n",
            " Testing bag [5/6] bag loss: 0.6219ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [37/300] train loss: 0.6399 test loss: 0.6338, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7067\n",
            " Training bag [1/11] bag loss: 0.6132\n",
            " Training bag [2/11] bag loss: 0.6958\n",
            " Training bag [3/11] bag loss: 0.6111\n",
            " Training bag [4/11] bag loss: 0.6221\n",
            " Training bag [5/11] bag loss: 0.6041\n",
            " Training bag [6/11] bag loss: 0.7019\n",
            " Training bag [7/11] bag loss: 0.6064\n",
            " Training bag [8/11] bag loss: 0.6211\n",
            " Training bag [9/11] bag loss: 0.6225\n",
            " Training bag [10/11] bag loss: 0.6246\n",
            " Testing bag [0/6] bag loss: 0.6126\n",
            " Testing bag [1/6] bag loss: 0.7092\n",
            " Testing bag [2/6] bag loss: 0.6130\n",
            " Testing bag [3/6] bag loss: 0.6218\n",
            " Testing bag [4/6] bag loss: 0.6253\n",
            " Testing bag [5/6] bag loss: 0.6236ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [38/300] train loss: 0.6391 test loss: 0.6342, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>0.8|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6180\n",
            " Training bag [1/11] bag loss: 0.7042\n",
            " Training bag [2/11] bag loss: 0.6180\n",
            " Training bag [3/11] bag loss: 0.6979\n",
            " Training bag [4/11] bag loss: 0.6105\n",
            " Training bag [5/11] bag loss: 0.7041\n",
            " Training bag [6/11] bag loss: 0.6115\n",
            " Training bag [7/11] bag loss: 0.6186\n",
            " Training bag [8/11] bag loss: 0.6222\n",
            " Training bag [9/11] bag loss: 0.6192\n",
            " Training bag [10/11] bag loss: 0.6105\n",
            " Testing bag [0/6] bag loss: 0.6162\n",
            " Testing bag [1/6] bag loss: 0.7080\n",
            " Testing bag [2/6] bag loss: 0.6140\n",
            " Testing bag [3/6] bag loss: 0.6174\n",
            " Testing bag [4/6] bag loss: 0.6208\n",
            " Testing bag [5/6] bag loss: 0.6178ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [39/300] train loss: 0.6395 test loss: 0.6324, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>0.8|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6150\n",
            " Training bag [1/11] bag loss: 0.6048\n",
            " Training bag [2/11] bag loss: 0.6201\n",
            " Training bag [3/11] bag loss: 0.6033\n",
            " Training bag [4/11] bag loss: 0.7073\n",
            " Training bag [5/11] bag loss: 0.6050\n",
            " Training bag [6/11] bag loss: 0.6188\n",
            " Training bag [7/11] bag loss: 0.7111\n",
            " Training bag [8/11] bag loss: 0.7064\n",
            " Training bag [9/11] bag loss: 0.6177\n",
            " Training bag [10/11] bag loss: 0.6197\n",
            " Testing bag [0/6] bag loss: 0.6121\n",
            " Testing bag [1/6] bag loss: 0.7101\n",
            " Testing bag [2/6] bag loss: 0.6095\n",
            " Testing bag [3/6] bag loss: 0.6189\n",
            " Testing bag [4/6] bag loss: 0.6239\n",
            " Testing bag [5/6] bag loss: 0.6217ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [40/300] train loss: 0.6390 test loss: 0.6327, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>0.8|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6995\n",
            " Training bag [1/11] bag loss: 0.6148\n",
            " Training bag [2/11] bag loss: 0.6142\n",
            " Training bag [3/11] bag loss: 0.6120\n",
            " Training bag [4/11] bag loss: 0.7072\n",
            " Training bag [5/11] bag loss: 0.6175\n",
            " Training bag [6/11] bag loss: 0.6134\n",
            " Training bag [7/11] bag loss: 0.6125\n",
            " Training bag [8/11] bag loss: 0.6150\n",
            " Training bag [9/11] bag loss: 0.7050\n",
            " Training bag [10/11] bag loss: 0.6061\n",
            " Testing bag [0/6] bag loss: 0.6136\n",
            " Testing bag [1/6] bag loss: 0.7101\n",
            " Testing bag [2/6] bag loss: 0.6122\n",
            " Testing bag [3/6] bag loss: 0.6151\n",
            " Testing bag [4/6] bag loss: 0.6187\n",
            " Testing bag [5/6] bag loss: 0.6169ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [41/300] train loss: 0.6379 test loss: 0.6311, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>0.8|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6111\n",
            " Training bag [1/11] bag loss: 0.6143\n",
            " Training bag [2/11] bag loss: 0.6992\n",
            " Training bag [3/11] bag loss: 0.6166\n",
            " Training bag [4/11] bag loss: 0.7049\n",
            " Training bag [5/11] bag loss: 0.6054\n",
            " Training bag [6/11] bag loss: 0.6117\n",
            " Training bag [7/11] bag loss: 0.6121\n",
            " Training bag [8/11] bag loss: 0.7064\n",
            " Training bag [9/11] bag loss: 0.6159\n",
            " Training bag [10/11] bag loss: 0.6102\n",
            " Testing bag [0/6] bag loss: 0.6136\n",
            " Testing bag [1/6] bag loss: 0.7093\n",
            " Testing bag [2/6] bag loss: 0.6134\n",
            " Testing bag [3/6] bag loss: 0.6153\n",
            " Testing bag [4/6] bag loss: 0.6192\n",
            " Testing bag [5/6] bag loss: 0.6177ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [42/300] train loss: 0.6371 test loss: 0.6314, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>0.8|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6098\n",
            " Training bag [1/11] bag loss: 0.7081\n",
            " Training bag [2/11] bag loss: 0.6973\n",
            " Training bag [3/11] bag loss: 0.6123\n",
            " Training bag [4/11] bag loss: 0.6103\n",
            " Training bag [5/11] bag loss: 0.6175\n",
            " Training bag [6/11] bag loss: 0.6994\n",
            " Training bag [7/11] bag loss: 0.6123\n",
            " Training bag [8/11] bag loss: 0.6148\n",
            " Training bag [9/11] bag loss: 0.6162\n",
            " Training bag [10/11] bag loss: 0.6073\n",
            " Testing bag [0/6] bag loss: 0.6126\n",
            " Testing bag [1/6] bag loss: 0.7091\n",
            " Testing bag [2/6] bag loss: 0.6141\n",
            " Testing bag [3/6] bag loss: 0.6133\n",
            " Testing bag [4/6] bag loss: 0.6191\n",
            " Testing bag [5/6] bag loss: 0.6171ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [43/300] train loss: 0.6368 test loss: 0.6309, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>0.8|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6083\n",
            " Training bag [1/11] bag loss: 0.6086\n",
            " Training bag [2/11] bag loss: 0.6992\n",
            " Training bag [3/11] bag loss: 0.7053\n",
            " Training bag [4/11] bag loss: 0.6153\n",
            " Training bag [5/11] bag loss: 0.6064\n",
            " Training bag [6/11] bag loss: 0.7044\n",
            " Training bag [7/11] bag loss: 0.6122\n",
            " Training bag [8/11] bag loss: 0.6152\n",
            " Training bag [9/11] bag loss: 0.6065\n",
            " Training bag [10/11] bag loss: 0.6178\n",
            " Testing bag [0/6] bag loss: 0.6092\n",
            " Testing bag [1/6] bag loss: 0.7099\n",
            " Testing bag [2/6] bag loss: 0.6091\n",
            " Testing bag [3/6] bag loss: 0.6175\n",
            " Testing bag [4/6] bag loss: 0.6214\n",
            " Testing bag [5/6] bag loss: 0.6192ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.625\n",
            "\n",
            " Epoch [44/300] train loss: 0.6363 test loss: 0.6311, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.625\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6001\n",
            " Training bag [1/11] bag loss: 0.7002\n",
            " Training bag [2/11] bag loss: 0.6165\n",
            " Training bag [3/11] bag loss: 0.7036\n",
            " Training bag [4/11] bag loss: 0.6092\n",
            " Training bag [5/11] bag loss: 0.6152\n",
            " Training bag [6/11] bag loss: 0.6074\n",
            " Training bag [7/11] bag loss: 0.6039\n",
            " Training bag [8/11] bag loss: 0.6148\n",
            " Training bag [9/11] bag loss: 0.7094\n",
            " Training bag [10/11] bag loss: 0.6124\n",
            " Testing bag [0/6] bag loss: 0.6087\n",
            " Testing bag [1/6] bag loss: 0.7117\n",
            " Testing bag [2/6] bag loss: 0.6063\n",
            " Testing bag [3/6] bag loss: 0.6148\n",
            " Testing bag [4/6] bag loss: 0.6211\n",
            " Testing bag [5/6] bag loss: 0.6186ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [45/300] train loss: 0.6357 test loss: 0.6302, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>0.8|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6982\n",
            " Training bag [1/11] bag loss: 0.6140\n",
            " Training bag [2/11] bag loss: 0.7004\n",
            " Training bag [3/11] bag loss: 0.6088\n",
            " Training bag [4/11] bag loss: 0.6093\n",
            " Training bag [5/11] bag loss: 0.6107\n",
            " Training bag [6/11] bag loss: 0.6062\n",
            " Training bag [7/11] bag loss: 0.6124\n",
            " Training bag [8/11] bag loss: 0.6094\n",
            " Training bag [9/11] bag loss: 0.6137\n",
            " Training bag [10/11] bag loss: 0.7102\n",
            " Testing bag [0/6] bag loss: 0.6074\n",
            " Testing bag [1/6] bag loss: 0.7129\n",
            " Testing bag [2/6] bag loss: 0.6055\n",
            " Testing bag [3/6] bag loss: 0.6140\n",
            " Testing bag [4/6] bag loss: 0.6184\n",
            " Testing bag [5/6] bag loss: 0.6149ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [46/300] train loss: 0.6358 test loss: 0.6289, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>0.8|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6126\n",
            " Training bag [1/11] bag loss: 0.6051\n",
            " Training bag [2/11] bag loss: 0.6074\n",
            " Training bag [3/11] bag loss: 0.7073\n",
            " Training bag [4/11] bag loss: 0.6084\n",
            " Training bag [5/11] bag loss: 0.7080\n",
            " Training bag [6/11] bag loss: 0.6035\n",
            " Training bag [7/11] bag loss: 0.7078\n",
            " Training bag [8/11] bag loss: 0.6112\n",
            " Training bag [9/11] bag loss: 0.6097\n",
            " Training bag [10/11] bag loss: 0.6101\n",
            " Testing bag [0/6] bag loss: 0.6085\n",
            " Testing bag [1/6] bag loss: 0.7105\n",
            " Testing bag [2/6] bag loss: 0.6067\n",
            " Testing bag [3/6] bag loss: 0.6126\n",
            " Testing bag [4/6] bag loss: 0.6195\n",
            " Testing bag [5/6] bag loss: 0.6175ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [47/300] train loss: 0.6356 test loss: 0.6292, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>0.8|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6069\n",
            " Training bag [1/11] bag loss: 0.6110\n",
            " Training bag [2/11] bag loss: 0.7081\n",
            " Training bag [3/11] bag loss: 0.5981\n",
            " Training bag [4/11] bag loss: 0.6099\n",
            " Training bag [5/11] bag loss: 0.6123\n",
            " Training bag [6/11] bag loss: 0.6107\n",
            " Training bag [7/11] bag loss: 0.6074\n",
            " Training bag [8/11] bag loss: 0.6038\n",
            " Training bag [9/11] bag loss: 0.7151\n",
            " Training bag [10/11] bag loss: 0.7043\n",
            " Testing bag [0/6] bag loss: 0.6059\n",
            " Testing bag [1/6] bag loss: 0.7171\n",
            " Testing bag [2/6] bag loss: 0.6061\n",
            " Testing bag [3/6] bag loss: 0.6092\n",
            " Testing bag [4/6] bag loss: 0.6173\n",
            " Testing bag [5/6] bag loss: 0.6148ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [48/300] train loss: 0.6352 test loss: 0.6284, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7017\n",
            " Training bag [1/11] bag loss: 0.6089\n",
            " Training bag [2/11] bag loss: 0.6112\n",
            " Training bag [3/11] bag loss: 0.7025\n",
            " Training bag [4/11] bag loss: 0.6070\n",
            " Training bag [5/11] bag loss: 0.6075\n",
            " Training bag [6/11] bag loss: 0.6098\n",
            " Training bag [7/11] bag loss: 0.6010\n",
            " Training bag [8/11] bag loss: 0.6079\n",
            " Training bag [9/11] bag loss: 0.7095\n",
            " Training bag [10/11] bag loss: 0.6093\n",
            " Testing bag [0/6] bag loss: 0.6057\n",
            " Testing bag [1/6] bag loss: 0.7129\n",
            " Testing bag [2/6] bag loss: 0.6039\n",
            " Testing bag [3/6] bag loss: 0.6144\n",
            " Testing bag [4/6] bag loss: 0.6191\n",
            " Testing bag [5/6] bag loss: 0.6171ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [49/300] train loss: 0.6342 test loss: 0.6288, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>0.8|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6094\n",
            " Training bag [1/11] bag loss: 0.7096\n",
            " Training bag [2/11] bag loss: 0.6078\n",
            " Training bag [3/11] bag loss: 0.6115\n",
            " Training bag [4/11] bag loss: 0.7052\n",
            " Training bag [5/11] bag loss: 0.6088\n",
            " Training bag [6/11] bag loss: 0.6037\n",
            " Training bag [7/11] bag loss: 0.6081\n",
            " Training bag [8/11] bag loss: 0.7030\n",
            " Training bag [9/11] bag loss: 0.5973\n",
            " Training bag [10/11] bag loss: 0.6125\n",
            " Testing bag [0/6] bag loss: 0.6050\n",
            " Testing bag [1/6] bag loss: 0.7119\n",
            " Testing bag [2/6] bag loss: 0.6042\n",
            " Testing bag [3/6] bag loss: 0.6123\n",
            " Testing bag [4/6] bag loss: 0.6191\n",
            " Testing bag [5/6] bag loss: 0.6166ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [50/300] train loss: 0.6343 test loss: 0.6282, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6109\n",
            " Training bag [1/11] bag loss: 0.7091\n",
            " Training bag [2/11] bag loss: 0.6066\n",
            " Training bag [3/11] bag loss: 0.6011\n",
            " Training bag [4/11] bag loss: 0.6083\n",
            " Training bag [5/11] bag loss: 0.6042\n",
            " Training bag [6/11] bag loss: 0.6075\n",
            " Training bag [7/11] bag loss: 0.6116\n",
            " Training bag [8/11] bag loss: 0.7035\n",
            " Training bag [9/11] bag loss: 0.5962\n",
            " Training bag [10/11] bag loss: 0.7096\n",
            " Testing bag [0/6] bag loss: 0.6052\n",
            " Testing bag [1/6] bag loss: 0.7168\n",
            " Testing bag [2/6] bag loss: 0.6040\n",
            " Testing bag [3/6] bag loss: 0.6112\n",
            " Testing bag [4/6] bag loss: 0.6159\n",
            " Testing bag [5/6] bag loss: 0.6117ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [51/300] train loss: 0.6335 test loss: 0.6275, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>0.8|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7053\n",
            " Training bag [1/11] bag loss: 0.5967\n",
            " Training bag [2/11] bag loss: 0.5991\n",
            " Training bag [3/11] bag loss: 0.6005\n",
            " Training bag [4/11] bag loss: 0.6127\n",
            " Training bag [5/11] bag loss: 0.5977\n",
            " Training bag [6/11] bag loss: 0.6163\n",
            " Training bag [7/11] bag loss: 0.6109\n",
            " Training bag [8/11] bag loss: 0.6105\n",
            " Training bag [9/11] bag loss: 0.7163\n",
            " Training bag [10/11] bag loss: 0.7106\n",
            " Testing bag [0/6] bag loss: 0.6018\n",
            " Testing bag [1/6] bag loss: 0.7164\n",
            " Testing bag [2/6] bag loss: 0.6012\n",
            " Testing bag [3/6] bag loss: 0.6099\n",
            " Testing bag [4/6] bag loss: 0.6167\n",
            " Testing bag [5/6] bag loss: 0.6144ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [52/300] train loss: 0.6342 test loss: 0.6267, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>0.8|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7114\n",
            " Training bag [1/11] bag loss: 0.6037\n",
            " Training bag [2/11] bag loss: 0.6112\n",
            " Training bag [3/11] bag loss: 0.6059\n",
            " Training bag [4/11] bag loss: 0.6998\n",
            " Training bag [5/11] bag loss: 0.6025\n",
            " Training bag [6/11] bag loss: 0.6051\n",
            " Training bag [7/11] bag loss: 0.6090\n",
            " Training bag [8/11] bag loss: 0.5987\n",
            " Training bag [9/11] bag loss: 0.7079\n",
            " Training bag [10/11] bag loss: 0.6072\n",
            " Testing bag [0/6] bag loss: 0.6053\n",
            " Testing bag [1/6] bag loss: 0.7145\n",
            " Testing bag [2/6] bag loss: 0.6037\n",
            " Testing bag [3/6] bag loss: 0.6094\n",
            " Testing bag [4/6] bag loss: 0.6150\n",
            " Testing bag [5/6] bag loss: 0.6119ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [53/300] train loss: 0.6329 test loss: 0.6266, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>0.8|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5959\n",
            " Training bag [1/11] bag loss: 0.7074\n",
            " Training bag [2/11] bag loss: 0.6999\n",
            " Training bag [3/11] bag loss: 0.7050\n",
            " Training bag [4/11] bag loss: 0.6039\n",
            " Training bag [5/11] bag loss: 0.6169\n",
            " Training bag [6/11] bag loss: 0.6133\n",
            " Training bag [7/11] bag loss: 0.6027\n",
            " Training bag [8/11] bag loss: 0.6075\n",
            " Training bag [9/11] bag loss: 0.6077\n",
            " Training bag [10/11] bag loss: 0.5996\n",
            " Testing bag [0/6] bag loss: 0.6045\n",
            " Testing bag [1/6] bag loss: 0.7149\n",
            " Testing bag [2/6] bag loss: 0.6023\n",
            " Testing bag [3/6] bag loss: 0.6102\n",
            " Testing bag [4/6] bag loss: 0.6163\n",
            " Testing bag [5/6] bag loss: 0.6142ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [54/300] train loss: 0.6327 test loss: 0.6271, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>0.8|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6074\n",
            " Training bag [1/11] bag loss: 0.6003\n",
            " Training bag [2/11] bag loss: 0.6026\n",
            " Training bag [3/11] bag loss: 0.6004\n",
            " Training bag [4/11] bag loss: 0.6106\n",
            " Training bag [5/11] bag loss: 0.7107\n",
            " Training bag [6/11] bag loss: 0.5893\n",
            " Training bag [7/11] bag loss: 0.7164\n",
            " Training bag [8/11] bag loss: 0.6075\n",
            " Training bag [9/11] bag loss: 0.7071\n",
            " Training bag [10/11] bag loss: 0.6076\n",
            " Testing bag [0/6] bag loss: 0.6006\n",
            " Testing bag [1/6] bag loss: 0.7157\n",
            " Testing bag [2/6] bag loss: 0.5998\n",
            " Testing bag [3/6] bag loss: 0.6109\n",
            " Testing bag [4/6] bag loss: 0.6170\n",
            " Testing bag [5/6] bag loss: 0.6132ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [55/300] train loss: 0.6327 test loss: 0.6262, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>0.8|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6094\n",
            " Training bag [1/11] bag loss: 0.7107\n",
            " Training bag [2/11] bag loss: 0.6025\n",
            " Training bag [3/11] bag loss: 0.6040\n",
            " Training bag [4/11] bag loss: 0.6031\n",
            " Training bag [5/11] bag loss: 0.7052\n",
            " Training bag [6/11] bag loss: 0.6011\n",
            " Training bag [7/11] bag loss: 0.6068\n",
            " Training bag [8/11] bag loss: 0.5973\n",
            " Training bag [9/11] bag loss: 0.6051\n",
            " Training bag [10/11] bag loss: 0.7027\n",
            " Testing bag [0/6] bag loss: 0.6019\n",
            " Testing bag [1/6] bag loss: 0.7178\n",
            " Testing bag [2/6] bag loss: 0.6019\n",
            " Testing bag [3/6] bag loss: 0.6065\n",
            " Testing bag [4/6] bag loss: 0.6150\n",
            " Testing bag [5/6] bag loss: 0.6101ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [56/300] train loss: 0.6316 test loss: 0.6255, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6030\n",
            " Training bag [1/11] bag loss: 0.6089\n",
            " Training bag [2/11] bag loss: 0.6017\n",
            " Training bag [3/11] bag loss: 0.6014\n",
            " Training bag [4/11] bag loss: 0.7062\n",
            " Training bag [5/11] bag loss: 0.7090\n",
            " Training bag [6/11] bag loss: 0.5983\n",
            " Training bag [7/11] bag loss: 0.5916\n",
            " Training bag [8/11] bag loss: 0.7110\n",
            " Training bag [9/11] bag loss: 0.6105\n",
            " Training bag [10/11] bag loss: 0.6076\n",
            " Testing bag [0/6] bag loss: 0.6004\n",
            " Testing bag [1/6] bag loss: 0.7152\n",
            " Testing bag [2/6] bag loss: 0.5999\n",
            " Testing bag [3/6] bag loss: 0.6091\n",
            " Testing bag [4/6] bag loss: 0.6170\n",
            " Testing bag [5/6] bag loss: 0.6131ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [57/300] train loss: 0.6317 test loss: 0.6258, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>0.8|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6003\n",
            " Training bag [1/11] bag loss: 0.6101\n",
            " Training bag [2/11] bag loss: 0.6036\n",
            " Training bag [3/11] bag loss: 0.5998\n",
            " Training bag [4/11] bag loss: 0.7086\n",
            " Training bag [5/11] bag loss: 0.5914\n",
            " Training bag [6/11] bag loss: 0.7137\n",
            " Training bag [7/11] bag loss: 0.5942\n",
            " Training bag [8/11] bag loss: 0.6044\n",
            " Training bag [9/11] bag loss: 0.7017\n",
            " Training bag [10/11] bag loss: 0.6108\n",
            " Testing bag [0/6] bag loss: 0.6000\n",
            " Testing bag [1/6] bag loss: 0.7172\n",
            " Testing bag [2/6] bag loss: 0.5999\n",
            " Testing bag [3/6] bag loss: 0.6072\n",
            " Testing bag [4/6] bag loss: 0.6168\n",
            " Testing bag [5/6] bag loss: 0.6125ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [58/300] train loss: 0.6308 test loss: 0.6256, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6037\n",
            " Training bag [1/11] bag loss: 0.6012\n",
            " Training bag [2/11] bag loss: 0.6056\n",
            " Training bag [3/11] bag loss: 0.7136\n",
            " Training bag [4/11] bag loss: 0.5930\n",
            " Training bag [5/11] bag loss: 0.6070\n",
            " Training bag [6/11] bag loss: 0.5984\n",
            " Training bag [7/11] bag loss: 0.7087\n",
            " Training bag [8/11] bag loss: 0.7094\n",
            " Training bag [9/11] bag loss: 0.6061\n",
            " Training bag [10/11] bag loss: 0.6013\n",
            " Testing bag [0/6] bag loss: 0.6018\n",
            " Testing bag [1/6] bag loss: 0.7163\n",
            " Testing bag [2/6] bag loss: 0.6029\n",
            " Testing bag [3/6] bag loss: 0.6058\n",
            " Testing bag [4/6] bag loss: 0.6137\n",
            " Testing bag [5/6] bag loss: 0.6096ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [59/300] train loss: 0.6316 test loss: 0.6250, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6067\n",
            " Training bag [1/11] bag loss: 0.5990\n",
            " Training bag [2/11] bag loss: 0.6014\n",
            " Training bag [3/11] bag loss: 0.5988\n",
            " Training bag [4/11] bag loss: 0.5872\n",
            " Training bag [5/11] bag loss: 0.7065\n",
            " Training bag [6/11] bag loss: 0.7149\n",
            " Training bag [7/11] bag loss: 0.6083\n",
            " Training bag [8/11] bag loss: 0.6068\n",
            " Training bag [9/11] bag loss: 0.7055\n",
            " Training bag [10/11] bag loss: 0.6098\n",
            " Testing bag [0/6] bag loss: 0.5987\n",
            " Testing bag [1/6] bag loss: 0.7172\n",
            " Testing bag [2/6] bag loss: 0.5973\n",
            " Testing bag [3/6] bag loss: 0.6090\n",
            " Testing bag [4/6] bag loss: 0.6166\n",
            " Testing bag [5/6] bag loss: 0.6121ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [60/300] train loss: 0.6313 test loss: 0.6251, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6018\n",
            " Training bag [1/11] bag loss: 0.6009\n",
            " Training bag [2/11] bag loss: 0.7048\n",
            " Training bag [3/11] bag loss: 0.6059\n",
            " Training bag [4/11] bag loss: 0.7112\n",
            " Training bag [5/11] bag loss: 0.5927\n",
            " Training bag [6/11] bag loss: 0.6082\n",
            " Training bag [7/11] bag loss: 0.6032\n",
            " Training bag [8/11] bag loss: 0.6020\n",
            " Training bag [9/11] bag loss: 0.5983\n",
            " Training bag [10/11] bag loss: 0.7035\n",
            " Testing bag [0/6] bag loss: 0.6000\n",
            " Testing bag [1/6] bag loss: 0.7180\n",
            " Testing bag [2/6] bag loss: 0.6002\n",
            " Testing bag [3/6] bag loss: 0.6065\n",
            " Testing bag [4/6] bag loss: 0.6139\n",
            " Testing bag [5/6] bag loss: 0.6097ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [61/300] train loss: 0.6302 test loss: 0.6247, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>0.8|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7028\n",
            " Training bag [1/11] bag loss: 0.7096\n",
            " Training bag [2/11] bag loss: 0.6083\n",
            " Training bag [3/11] bag loss: 0.6017\n",
            " Training bag [4/11] bag loss: 0.6998\n",
            " Training bag [5/11] bag loss: 0.6022\n",
            " Training bag [6/11] bag loss: 0.5937\n",
            " Training bag [7/11] bag loss: 0.6076\n",
            " Training bag [8/11] bag loss: 0.6004\n",
            " Training bag [9/11] bag loss: 0.6019\n",
            " Training bag [10/11] bag loss: 0.6028\n",
            " Testing bag [0/6] bag loss: 0.5990\n",
            " Testing bag [1/6] bag loss: 0.7152\n",
            " Testing bag [2/6] bag loss: 0.5997\n",
            " Testing bag [3/6] bag loss: 0.6072\n",
            " Testing bag [4/6] bag loss: 0.6154\n",
            " Testing bag [5/6] bag loss: 0.6112ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [62/300] train loss: 0.6301 test loss: 0.6246, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>0.8|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7096\n",
            " Training bag [1/11] bag loss: 0.6006\n",
            " Training bag [2/11] bag loss: 0.7037\n",
            " Training bag [3/11] bag loss: 0.6044\n",
            " Training bag [4/11] bag loss: 0.6040\n",
            " Training bag [5/11] bag loss: 0.6068\n",
            " Training bag [6/11] bag loss: 0.5932\n",
            " Training bag [7/11] bag loss: 0.5991\n",
            " Training bag [8/11] bag loss: 0.7017\n",
            " Training bag [9/11] bag loss: 0.6070\n",
            " Training bag [10/11] bag loss: 0.6025\n",
            " Testing bag [0/6] bag loss: 0.6005\n",
            " Testing bag [1/6] bag loss: 0.7174\n",
            " Testing bag [2/6] bag loss: 0.5992\n",
            " Testing bag [3/6] bag loss: 0.6047\n",
            " Testing bag [4/6] bag loss: 0.6138\n",
            " Testing bag [5/6] bag loss: 0.6087ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [63/300] train loss: 0.6302 test loss: 0.6241, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5966\n",
            " Training bag [1/11] bag loss: 0.6076\n",
            " Training bag [2/11] bag loss: 0.6061\n",
            " Training bag [3/11] bag loss: 0.5891\n",
            " Training bag [4/11] bag loss: 0.5986\n",
            " Training bag [5/11] bag loss: 0.5952\n",
            " Training bag [6/11] bag loss: 0.5990\n",
            " Training bag [7/11] bag loss: 0.7210\n",
            " Training bag [8/11] bag loss: 0.7081\n",
            " Training bag [9/11] bag loss: 0.7125\n",
            " Training bag [10/11] bag loss: 0.5983\n",
            " Testing bag [0/6] bag loss: 0.5988\n",
            " Testing bag [1/6] bag loss: 0.7199\n",
            " Testing bag [2/6] bag loss: 0.5977\n",
            " Testing bag [3/6] bag loss: 0.6043\n",
            " Testing bag [4/6] bag loss: 0.6118\n",
            " Testing bag [5/6] bag loss: 0.6081ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [64/300] train loss: 0.6302 test loss: 0.6234, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5979\n",
            " Training bag [1/11] bag loss: 0.5999\n",
            " Training bag [2/11] bag loss: 0.5966\n",
            " Training bag [3/11] bag loss: 0.5903\n",
            " Training bag [4/11] bag loss: 0.5850\n",
            " Training bag [5/11] bag loss: 0.6081\n",
            " Training bag [6/11] bag loss: 0.7205\n",
            " Training bag [7/11] bag loss: 0.7111\n",
            " Training bag [8/11] bag loss: 0.7082\n",
            " Training bag [9/11] bag loss: 0.6108\n",
            " Training bag [10/11] bag loss: 0.6040\n",
            " Testing bag [0/6] bag loss: 0.5962\n",
            " Testing bag [1/6] bag loss: 0.7185\n",
            " Testing bag [2/6] bag loss: 0.5949\n",
            " Testing bag [3/6] bag loss: 0.6071\n",
            " Testing bag [4/6] bag loss: 0.6155\n",
            " Testing bag [5/6] bag loss: 0.6122ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [65/300] train loss: 0.6302 test loss: 0.6241, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>0.8|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7049\n",
            " Training bag [1/11] bag loss: 0.6982\n",
            " Training bag [2/11] bag loss: 0.7082\n",
            " Training bag [3/11] bag loss: 0.6018\n",
            " Training bag [4/11] bag loss: 0.6032\n",
            " Training bag [5/11] bag loss: 0.6075\n",
            " Training bag [6/11] bag loss: 0.5934\n",
            " Training bag [7/11] bag loss: 0.6070\n",
            " Training bag [8/11] bag loss: 0.5998\n",
            " Training bag [9/11] bag loss: 0.5991\n",
            " Training bag [10/11] bag loss: 0.6013\n",
            " Testing bag [0/6] bag loss: 0.5996\n",
            " Testing bag [1/6] bag loss: 0.7202\n",
            " Testing bag [2/6] bag loss: 0.6009\n",
            " Testing bag [3/6] bag loss: 0.6062\n",
            " Testing bag [4/6] bag loss: 0.6137\n",
            " Testing bag [5/6] bag loss: 0.6092ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [66/300] train loss: 0.6295 test loss: 0.6250, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7044\n",
            " Training bag [1/11] bag loss: 0.7099\n",
            " Training bag [2/11] bag loss: 0.5941\n",
            " Training bag [3/11] bag loss: 0.5985\n",
            " Training bag [4/11] bag loss: 0.6087\n",
            " Training bag [5/11] bag loss: 0.5869\n",
            " Training bag [6/11] bag loss: 0.6023\n",
            " Training bag [7/11] bag loss: 0.6084\n",
            " Training bag [8/11] bag loss: 0.7000\n",
            " Training bag [9/11] bag loss: 0.5998\n",
            " Training bag [10/11] bag loss: 0.5973\n",
            " Testing bag [0/6] bag loss: 0.5988\n",
            " Testing bag [1/6] bag loss: 0.7190\n",
            " Testing bag [2/6] bag loss: 0.5972\n",
            " Testing bag [3/6] bag loss: 0.6041\n",
            " Testing bag [4/6] bag loss: 0.6128\n",
            " Testing bag [5/6] bag loss: 0.6087ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [67/300] train loss: 0.6282 test loss: 0.6234, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5981\n",
            " Training bag [1/11] bag loss: 0.5911\n",
            " Training bag [2/11] bag loss: 0.6048\n",
            " Training bag [3/11] bag loss: 0.6058\n",
            " Training bag [4/11] bag loss: 0.7103\n",
            " Training bag [5/11] bag loss: 0.5954\n",
            " Training bag [6/11] bag loss: 0.7169\n",
            " Training bag [7/11] bag loss: 0.5980\n",
            " Training bag [8/11] bag loss: 0.7020\n",
            " Training bag [9/11] bag loss: 0.5869\n",
            " Training bag [10/11] bag loss: 0.5992\n",
            " Testing bag [0/6] bag loss: 0.5965\n",
            " Testing bag [1/6] bag loss: 0.7198\n",
            " Testing bag [2/6] bag loss: 0.5948\n",
            " Testing bag [3/6] bag loss: 0.6052\n",
            " Testing bag [4/6] bag loss: 0.6137\n",
            " Testing bag [5/6] bag loss: 0.6072ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [68/300] train loss: 0.6280 test loss: 0.6229, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6023\n",
            " Training bag [1/11] bag loss: 0.5962\n",
            " Training bag [2/11] bag loss: 0.5958\n",
            " Training bag [3/11] bag loss: 0.7087\n",
            " Training bag [4/11] bag loss: 0.6021\n",
            " Training bag [5/11] bag loss: 0.7165\n",
            " Training bag [6/11] bag loss: 0.6012\n",
            " Training bag [7/11] bag loss: 0.7007\n",
            " Training bag [8/11] bag loss: 0.5968\n",
            " Training bag [9/11] bag loss: 0.6033\n",
            " Training bag [10/11] bag loss: 0.5897\n",
            " Testing bag [0/6] bag loss: 0.5967\n",
            " Testing bag [1/6] bag loss: 0.7186\n",
            " Testing bag [2/6] bag loss: 0.5964\n",
            " Testing bag [3/6] bag loss: 0.6042\n",
            " Testing bag [4/6] bag loss: 0.6123\n",
            " Testing bag [5/6] bag loss: 0.6085ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [69/300] train loss: 0.6285 test loss: 0.6228, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6026\n",
            " Training bag [1/11] bag loss: 0.5949\n",
            " Training bag [2/11] bag loss: 0.6000\n",
            " Training bag [3/11] bag loss: 0.7117\n",
            " Training bag [4/11] bag loss: 0.5972\n",
            " Training bag [5/11] bag loss: 0.6037\n",
            " Training bag [6/11] bag loss: 0.5870\n",
            " Training bag [7/11] bag loss: 0.7053\n",
            " Training bag [8/11] bag loss: 0.5908\n",
            " Training bag [9/11] bag loss: 0.7153\n",
            " Training bag [10/11] bag loss: 0.5998\n",
            " Testing bag [0/6] bag loss: 0.5947\n",
            " Testing bag [1/6] bag loss: 0.7208\n",
            " Testing bag [2/6] bag loss: 0.5947\n",
            " Testing bag [3/6] bag loss: 0.6043\n",
            " Testing bag [4/6] bag loss: 0.6137\n",
            " Testing bag [5/6] bag loss: 0.6077ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [70/300] train loss: 0.6280 test loss: 0.6227, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7061\n",
            " Training bag [1/11] bag loss: 0.5992\n",
            " Training bag [2/11] bag loss: 0.7000\n",
            " Training bag [3/11] bag loss: 0.6042\n",
            " Training bag [4/11] bag loss: 0.7086\n",
            " Training bag [5/11] bag loss: 0.5964\n",
            " Training bag [6/11] bag loss: 0.5935\n",
            " Training bag [7/11] bag loss: 0.6032\n",
            " Training bag [8/11] bag loss: 0.6015\n",
            " Training bag [9/11] bag loss: 0.5984\n",
            " Training bag [10/11] bag loss: 0.6011\n",
            " Testing bag [0/6] bag loss: 0.5981\n",
            " Testing bag [1/6] bag loss: 0.7199\n",
            " Testing bag [2/6] bag loss: 0.5977\n",
            " Testing bag [3/6] bag loss: 0.6002\n",
            " Testing bag [4/6] bag loss: 0.6107\n",
            " Testing bag [5/6] bag loss: 0.6064ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [71/300] train loss: 0.6284 test loss: 0.6222, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6991\n",
            " Training bag [1/11] bag loss: 0.6027\n",
            " Training bag [2/11] bag loss: 0.5949\n",
            " Training bag [3/11] bag loss: 0.7121\n",
            " Training bag [4/11] bag loss: 0.6004\n",
            " Training bag [5/11] bag loss: 0.5996\n",
            " Training bag [6/11] bag loss: 0.7028\n",
            " Training bag [7/11] bag loss: 0.5923\n",
            " Training bag [8/11] bag loss: 0.6080\n",
            " Training bag [9/11] bag loss: 0.5983\n",
            " Training bag [10/11] bag loss: 0.5871\n",
            " Testing bag [0/6] bag loss: 0.5964\n",
            " Testing bag [1/6] bag loss: 0.7190\n",
            " Testing bag [2/6] bag loss: 0.5966\n",
            " Testing bag [3/6] bag loss: 0.6039\n",
            " Testing bag [4/6] bag loss: 0.6124\n",
            " Testing bag [5/6] bag loss: 0.6065ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [72/300] train loss: 0.6270 test loss: 0.6225, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5988\n",
            " Training bag [1/11] bag loss: 0.7017\n",
            " Training bag [2/11] bag loss: 0.7119\n",
            " Training bag [3/11] bag loss: 0.7022\n",
            " Training bag [4/11] bag loss: 0.5969\n",
            " Training bag [5/11] bag loss: 0.5982\n",
            " Training bag [6/11] bag loss: 0.5958\n",
            " Training bag [7/11] bag loss: 0.6028\n",
            " Training bag [8/11] bag loss: 0.6094\n",
            " Training bag [9/11] bag loss: 0.6057\n",
            " Training bag [10/11] bag loss: 0.5864\n",
            " Testing bag [0/6] bag loss: 0.5960\n",
            " Testing bag [1/6] bag loss: 0.7225\n",
            " Testing bag [2/6] bag loss: 0.5919\n",
            " Testing bag [3/6] bag loss: 0.6023\n",
            " Testing bag [4/6] bag loss: 0.6133\n",
            " Testing bag [5/6] bag loss: 0.6089ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [73/300] train loss: 0.6282 test loss: 0.6225, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7127\n",
            " Training bag [1/11] bag loss: 0.5855\n",
            " Training bag [2/11] bag loss: 0.5951\n",
            " Training bag [3/11] bag loss: 0.6074\n",
            " Training bag [4/11] bag loss: 0.7008\n",
            " Training bag [5/11] bag loss: 0.5997\n",
            " Training bag [6/11] bag loss: 0.6041\n",
            " Training bag [7/11] bag loss: 0.5951\n",
            " Training bag [8/11] bag loss: 0.5963\n",
            " Training bag [9/11] bag loss: 0.7069\n",
            " Training bag [10/11] bag loss: 0.5912\n",
            " Testing bag [0/6] bag loss: 0.5952\n",
            " Testing bag [1/6] bag loss: 0.7218\n",
            " Testing bag [2/6] bag loss: 0.5954\n",
            " Testing bag [3/6] bag loss: 0.6020\n",
            " Testing bag [4/6] bag loss: 0.6119\n",
            " Testing bag [5/6] bag loss: 0.6056ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [74/300] train loss: 0.6268 test loss: 0.6220, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5853\n",
            " Training bag [1/11] bag loss: 0.7094\n",
            " Training bag [2/11] bag loss: 0.5984\n",
            " Training bag [3/11] bag loss: 0.6987\n",
            " Training bag [4/11] bag loss: 0.5946\n",
            " Training bag [5/11] bag loss: 0.5907\n",
            " Training bag [6/11] bag loss: 0.6043\n",
            " Training bag [7/11] bag loss: 0.5977\n",
            " Training bag [8/11] bag loss: 0.5921\n",
            " Training bag [9/11] bag loss: 0.6064\n",
            " Training bag [10/11] bag loss: 0.7174\n",
            " Testing bag [0/6] bag loss: 0.5930\n",
            " Testing bag [1/6] bag loss: 0.7222\n",
            " Testing bag [2/6] bag loss: 0.5939\n",
            " Testing bag [3/6] bag loss: 0.6037\n",
            " Testing bag [4/6] bag loss: 0.6131\n",
            " Testing bag [5/6] bag loss: 0.6066ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [75/300] train loss: 0.6268 test loss: 0.6221, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5829\n",
            " Training bag [1/11] bag loss: 0.5968\n",
            " Training bag [2/11] bag loss: 0.7018\n",
            " Training bag [3/11] bag loss: 0.7166\n",
            " Training bag [4/11] bag loss: 0.6034\n",
            " Training bag [5/11] bag loss: 0.5948\n",
            " Training bag [6/11] bag loss: 0.5914\n",
            " Training bag [7/11] bag loss: 0.6012\n",
            " Training bag [8/11] bag loss: 0.5921\n",
            " Training bag [9/11] bag loss: 0.7082\n",
            " Training bag [10/11] bag loss: 0.5963\n",
            " Testing bag [0/6] bag loss: 0.5931\n",
            " Testing bag [1/6] bag loss: 0.7224\n",
            " Testing bag [2/6] bag loss: 0.5933\n",
            " Testing bag [3/6] bag loss: 0.6023\n",
            " Testing bag [4/6] bag loss: 0.6134\n",
            " Testing bag [5/6] bag loss: 0.6068ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [76/300] train loss: 0.6260 test loss: 0.6219, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>0.8|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7144\n",
            " Training bag [1/11] bag loss: 0.5959\n",
            " Training bag [2/11] bag loss: 0.5995\n",
            " Training bag [3/11] bag loss: 0.5969\n",
            " Training bag [4/11] bag loss: 0.7048\n",
            " Training bag [5/11] bag loss: 0.5975\n",
            " Training bag [6/11] bag loss: 0.5862\n",
            " Training bag [7/11] bag loss: 0.6047\n",
            " Training bag [8/11] bag loss: 0.5946\n",
            " Training bag [9/11] bag loss: 0.5896\n",
            " Training bag [10/11] bag loss: 0.7027\n",
            " Testing bag [0/6] bag loss: 0.5949\n",
            " Testing bag [1/6] bag loss: 0.7239\n",
            " Testing bag [2/6] bag loss: 0.5935\n",
            " Testing bag [3/6] bag loss: 0.6015\n",
            " Testing bag [4/6] bag loss: 0.6111\n",
            " Testing bag [5/6] bag loss: 0.6066ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [77/300] train loss: 0.6261 test loss: 0.6219, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5929\n",
            " Training bag [1/11] bag loss: 0.7042\n",
            " Training bag [2/11] bag loss: 0.7052\n",
            " Training bag [3/11] bag loss: 0.5887\n",
            " Training bag [4/11] bag loss: 0.6081\n",
            " Training bag [5/11] bag loss: 0.5986\n",
            " Training bag [6/11] bag loss: 0.7120\n",
            " Training bag [7/11] bag loss: 0.6017\n",
            " Training bag [8/11] bag loss: 0.5983\n",
            " Training bag [9/11] bag loss: 0.5981\n",
            " Training bag [10/11] bag loss: 0.5868\n",
            " Testing bag [0/6] bag loss: 0.5950\n",
            " Testing bag [1/6] bag loss: 0.7217\n",
            " Testing bag [2/6] bag loss: 0.5951\n",
            " Testing bag [3/6] bag loss: 0.6000\n",
            " Testing bag [4/6] bag loss: 0.6109\n",
            " Testing bag [5/6] bag loss: 0.6069ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [78/300] train loss: 0.6268 test loss: 0.6216, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7137\n",
            " Training bag [1/11] bag loss: 0.5951\n",
            " Training bag [2/11] bag loss: 0.5870\n",
            " Training bag [3/11] bag loss: 0.7013\n",
            " Training bag [4/11] bag loss: 0.6025\n",
            " Training bag [5/11] bag loss: 0.5984\n",
            " Training bag [6/11] bag loss: 0.7026\n",
            " Training bag [7/11] bag loss: 0.5985\n",
            " Training bag [8/11] bag loss: 0.5951\n",
            " Training bag [9/11] bag loss: 0.5954\n",
            " Training bag [10/11] bag loss: 0.5946\n",
            " Testing bag [0/6] bag loss: 0.5933\n",
            " Testing bag [1/6] bag loss: 0.7214\n",
            " Testing bag [2/6] bag loss: 0.5936\n",
            " Testing bag [3/6] bag loss: 0.6025\n",
            " Testing bag [4/6] bag loss: 0.6127\n",
            " Testing bag [5/6] bag loss: 0.6056ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [79/300] train loss: 0.6258 test loss: 0.6215, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5950\n",
            " Training bag [1/11] bag loss: 0.5937\n",
            " Training bag [2/11] bag loss: 0.5988\n",
            " Training bag [3/11] bag loss: 0.7181\n",
            " Training bag [4/11] bag loss: 0.5844\n",
            " Training bag [5/11] bag loss: 0.5881\n",
            " Training bag [6/11] bag loss: 0.7075\n",
            " Training bag [7/11] bag loss: 0.6046\n",
            " Training bag [8/11] bag loss: 0.5923\n",
            " Training bag [9/11] bag loss: 0.5921\n",
            " Training bag [10/11] bag loss: 0.7060\n",
            " Testing bag [0/6] bag loss: 0.5931\n",
            " Testing bag [1/6] bag loss: 0.7256\n",
            " Testing bag [2/6] bag loss: 0.5933\n",
            " Testing bag [3/6] bag loss: 0.5993\n",
            " Testing bag [4/6] bag loss: 0.6105\n",
            " Testing bag [5/6] bag loss: 0.6048ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [80/300] train loss: 0.6255 test loss: 0.6211, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>0.8|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5987\n",
            " Training bag [1/11] bag loss: 0.5930\n",
            " Training bag [2/11] bag loss: 0.5836\n",
            " Training bag [3/11] bag loss: 0.7178\n",
            " Training bag [4/11] bag loss: 0.7038\n",
            " Training bag [5/11] bag loss: 0.5952\n",
            " Training bag [6/11] bag loss: 0.5891\n",
            " Training bag [7/11] bag loss: 0.7040\n",
            " Training bag [8/11] bag loss: 0.5911\n",
            " Training bag [9/11] bag loss: 0.5993\n",
            " Training bag [10/11] bag loss: 0.6059\n",
            " Testing bag [0/6] bag loss: 0.5904\n",
            " Testing bag [1/6] bag loss: 0.7222\n",
            " Testing bag [2/6] bag loss: 0.5902\n",
            " Testing bag [3/6] bag loss: 0.6029\n",
            " Testing bag [4/6] bag loss: 0.6134\n",
            " Testing bag [5/6] bag loss: 0.6078ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [81/300] train loss: 0.6256 test loss: 0.6211, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5916\n",
            " Training bag [1/11] bag loss: 0.5964\n",
            " Training bag [2/11] bag loss: 0.5950\n",
            " Training bag [3/11] bag loss: 0.5970\n",
            " Training bag [4/11] bag loss: 0.5821\n",
            " Training bag [5/11] bag loss: 0.5983\n",
            " Training bag [6/11] bag loss: 0.5881\n",
            " Training bag [7/11] bag loss: 0.7085\n",
            " Training bag [8/11] bag loss: 0.7156\n",
            " Training bag [9/11] bag loss: 0.5917\n",
            " Training bag [10/11] bag loss: 0.7192\n",
            " Testing bag [0/6] bag loss: 0.5913\n",
            " Testing bag [1/6] bag loss: 0.7261\n",
            " Testing bag [2/6] bag loss: 0.5913\n",
            " Testing bag [3/6] bag loss: 0.5981\n",
            " Testing bag [4/6] bag loss: 0.6106\n",
            " Testing bag [5/6] bag loss: 0.6036ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [82/300] train loss: 0.6258 test loss: 0.6202, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>0.8|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7015\n",
            " Training bag [1/11] bag loss: 0.5875\n",
            " Training bag [2/11] bag loss: 0.5810\n",
            " Training bag [3/11] bag loss: 0.5965\n",
            " Training bag [4/11] bag loss: 0.6051\n",
            " Training bag [5/11] bag loss: 0.5890\n",
            " Training bag [6/11] bag loss: 0.7071\n",
            " Training bag [7/11] bag loss: 0.7164\n",
            " Training bag [8/11] bag loss: 0.5973\n",
            " Training bag [9/11] bag loss: 0.6018\n",
            " Training bag [10/11] bag loss: 0.5921\n",
            " Testing bag [0/6] bag loss: 0.5929\n",
            " Testing bag [1/6] bag loss: 0.7236\n",
            " Testing bag [2/6] bag loss: 0.5904\n",
            " Testing bag [3/6] bag loss: 0.5982\n",
            " Testing bag [4/6] bag loss: 0.6110\n",
            " Testing bag [5/6] bag loss: 0.6069ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [83/300] train loss: 0.6250 test loss: 0.6205, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>0.8|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5880\n",
            " Training bag [1/11] bag loss: 0.5905\n",
            " Training bag [2/11] bag loss: 0.5872\n",
            " Training bag [3/11] bag loss: 0.5756\n",
            " Training bag [4/11] bag loss: 0.7089\n",
            " Training bag [5/11] bag loss: 0.7108\n",
            " Training bag [6/11] bag loss: 0.6006\n",
            " Training bag [7/11] bag loss: 0.6059\n",
            " Training bag [8/11] bag loss: 0.5992\n",
            " Training bag [9/11] bag loss: 0.6062\n",
            " Training bag [10/11] bag loss: 0.7180\n",
            " Testing bag [0/6] bag loss: 0.5908\n",
            " Testing bag [1/6] bag loss: 0.7254\n",
            " Testing bag [2/6] bag loss: 0.5920\n",
            " Testing bag [3/6] bag loss: 0.6006\n",
            " Testing bag [4/6] bag loss: 0.6120\n",
            " Testing bag [5/6] bag loss: 0.6058ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [84/300] train loss: 0.6264 test loss: 0.6211, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5911\n",
            " Training bag [1/11] bag loss: 0.5950\n",
            " Training bag [2/11] bag loss: 0.6026\n",
            " Training bag [3/11] bag loss: 0.7120\n",
            " Training bag [4/11] bag loss: 0.5968\n",
            " Training bag [5/11] bag loss: 0.7011\n",
            " Training bag [6/11] bag loss: 0.5842\n",
            " Training bag [7/11] bag loss: 0.5911\n",
            " Training bag [8/11] bag loss: 0.5915\n",
            " Training bag [9/11] bag loss: 0.5940\n",
            " Training bag [10/11] bag loss: 0.7175\n",
            " Testing bag [0/6] bag loss: 0.5918\n",
            " Testing bag [1/6] bag loss: 0.7237\n",
            " Testing bag [2/6] bag loss: 0.5913\n",
            " Testing bag [3/6] bag loss: 0.6007\n",
            " Testing bag [4/6] bag loss: 0.6115\n",
            " Testing bag [5/6] bag loss: 0.6050ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [85/300] train loss: 0.6252 test loss: 0.6207, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5924\n",
            " Training bag [1/11] bag loss: 0.5882\n",
            " Training bag [2/11] bag loss: 0.7037\n",
            " Training bag [3/11] bag loss: 0.5926\n",
            " Training bag [4/11] bag loss: 0.5974\n",
            " Training bag [5/11] bag loss: 0.5988\n",
            " Training bag [6/11] bag loss: 0.7059\n",
            " Training bag [7/11] bag loss: 0.7157\n",
            " Training bag [8/11] bag loss: 0.5883\n",
            " Training bag [9/11] bag loss: 0.5975\n",
            " Training bag [10/11] bag loss: 0.5963\n",
            " Testing bag [0/6] bag loss: 0.5947\n",
            " Testing bag [1/6] bag loss: 0.7234\n",
            " Testing bag [2/6] bag loss: 0.5940\n",
            " Testing bag [3/6] bag loss: 0.5974\n",
            " Testing bag [4/6] bag loss: 0.6105\n",
            " Testing bag [5/6] bag loss: 0.6046ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [86/300] train loss: 0.6252 test loss: 0.6208, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5943\n",
            " Training bag [1/11] bag loss: 0.5798\n",
            " Training bag [2/11] bag loss: 0.7165\n",
            " Training bag [3/11] bag loss: 0.5954\n",
            " Training bag [4/11] bag loss: 0.6037\n",
            " Training bag [5/11] bag loss: 0.7090\n",
            " Training bag [6/11] bag loss: 0.5945\n",
            " Training bag [7/11] bag loss: 0.5878\n",
            " Training bag [8/11] bag loss: 0.5985\n",
            " Training bag [9/11] bag loss: 0.7082\n",
            " Training bag [10/11] bag loss: 0.5931\n",
            " Testing bag [0/6] bag loss: 0.5921\n",
            " Testing bag [1/6] bag loss: 0.7236\n",
            " Testing bag [2/6] bag loss: 0.5919\n",
            " Testing bag [3/6] bag loss: 0.5974\n",
            " Testing bag [4/6] bag loss: 0.6109\n",
            " Testing bag [5/6] bag loss: 0.6036ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [87/300] train loss: 0.6255 test loss: 0.6199, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7145\n",
            " Training bag [1/11] bag loss: 0.6016\n",
            " Training bag [2/11] bag loss: 0.5933\n",
            " Training bag [3/11] bag loss: 0.5930\n",
            " Training bag [4/11] bag loss: 0.5931\n",
            " Training bag [5/11] bag loss: 0.5974\n",
            " Training bag [6/11] bag loss: 0.7058\n",
            " Training bag [7/11] bag loss: 0.7026\n",
            " Training bag [8/11] bag loss: 0.5821\n",
            " Training bag [9/11] bag loss: 0.5875\n",
            " Training bag [10/11] bag loss: 0.5944\n",
            " Testing bag [0/6] bag loss: 0.5903\n",
            " Testing bag [1/6] bag loss: 0.7244\n",
            " Testing bag [2/6] bag loss: 0.5916\n",
            " Testing bag [3/6] bag loss: 0.6002\n",
            " Testing bag [4/6] bag loss: 0.6124\n",
            " Testing bag [5/6] bag loss: 0.6072ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [88/300] train loss: 0.6241 test loss: 0.6210, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5800\n",
            " Training bag [1/11] bag loss: 0.5939\n",
            " Training bag [2/11] bag loss: 0.7164\n",
            " Training bag [3/11] bag loss: 0.5917\n",
            " Training bag [4/11] bag loss: 0.5976\n",
            " Training bag [5/11] bag loss: 0.5986\n",
            " Training bag [6/11] bag loss: 0.7027\n",
            " Training bag [7/11] bag loss: 0.5962\n",
            " Training bag [8/11] bag loss: 0.5952\n",
            " Training bag [9/11] bag loss: 0.7093\n",
            " Training bag [10/11] bag loss: 0.5903\n",
            " Testing bag [0/6] bag loss: 0.5912\n",
            " Testing bag [1/6] bag loss: 0.7243\n",
            " Testing bag [2/6] bag loss: 0.5914\n",
            " Testing bag [3/6] bag loss: 0.5975\n",
            " Testing bag [4/6] bag loss: 0.6104\n",
            " Testing bag [5/6] bag loss: 0.6042ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [89/300] train loss: 0.6247 test loss: 0.6198, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5903\n",
            " Training bag [1/11] bag loss: 0.6993\n",
            " Training bag [2/11] bag loss: 0.6011\n",
            " Training bag [3/11] bag loss: 0.7032\n",
            " Training bag [4/11] bag loss: 0.5811\n",
            " Training bag [5/11] bag loss: 0.5943\n",
            " Training bag [6/11] bag loss: 0.6019\n",
            " Training bag [7/11] bag loss: 0.7129\n",
            " Training bag [8/11] bag loss: 0.5927\n",
            " Training bag [9/11] bag loss: 0.5875\n",
            " Training bag [10/11] bag loss: 0.5936\n",
            " Testing bag [0/6] bag loss: 0.5908\n",
            " Testing bag [1/6] bag loss: 0.7228\n",
            " Testing bag [2/6] bag loss: 0.5908\n",
            " Testing bag [3/6] bag loss: 0.6023\n",
            " Testing bag [4/6] bag loss: 0.6120\n",
            " Testing bag [5/6] bag loss: 0.6070ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [90/300] train loss: 0.6234 test loss: 0.6210, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5942\n",
            " Training bag [1/11] bag loss: 0.5892\n",
            " Training bag [2/11] bag loss: 0.7134\n",
            " Training bag [3/11] bag loss: 0.5798\n",
            " Training bag [4/11] bag loss: 0.7145\n",
            " Training bag [5/11] bag loss: 0.5889\n",
            " Training bag [6/11] bag loss: 0.5951\n",
            " Training bag [7/11] bag loss: 0.6030\n",
            " Training bag [8/11] bag loss: 0.7053\n",
            " Training bag [9/11] bag loss: 0.5848\n",
            " Training bag [10/11] bag loss: 0.6030\n",
            " Testing bag [0/6] bag loss: 0.5893\n",
            " Testing bag [1/6] bag loss: 0.7239\n",
            " Testing bag [2/6] bag loss: 0.5908\n",
            " Testing bag [3/6] bag loss: 0.6018\n",
            " Testing bag [4/6] bag loss: 0.6128\n",
            " Testing bag [5/6] bag loss: 0.6058ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [91/300] train loss: 0.6247 test loss: 0.6207, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5988\n",
            " Training bag [1/11] bag loss: 0.5906\n",
            " Training bag [2/11] bag loss: 0.7049\n",
            " Training bag [3/11] bag loss: 0.6017\n",
            " Training bag [4/11] bag loss: 0.7154\n",
            " Training bag [5/11] bag loss: 0.5904\n",
            " Training bag [6/11] bag loss: 0.6967\n",
            " Training bag [7/11] bag loss: 0.5957\n",
            " Training bag [8/11] bag loss: 0.5889\n",
            " Training bag [9/11] bag loss: 0.5918\n",
            " Training bag [10/11] bag loss: 0.5819\n",
            " Testing bag [0/6] bag loss: 0.5910\n",
            " Testing bag [1/6] bag loss: 0.7243\n",
            " Testing bag [2/6] bag loss: 0.5907\n",
            " Testing bag [3/6] bag loss: 0.5984\n",
            " Testing bag [4/6] bag loss: 0.6109\n",
            " Testing bag [5/6] bag loss: 0.6043ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [92/300] train loss: 0.6233 test loss: 0.6199, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5896\n",
            " Training bag [1/11] bag loss: 0.5907\n",
            " Training bag [2/11] bag loss: 0.5902\n",
            " Training bag [3/11] bag loss: 0.7082\n",
            " Training bag [4/11] bag loss: 0.5963\n",
            " Training bag [5/11] bag loss: 0.5811\n",
            " Training bag [6/11] bag loss: 0.7008\n",
            " Training bag [7/11] bag loss: 0.5866\n",
            " Training bag [8/11] bag loss: 0.7160\n",
            " Training bag [9/11] bag loss: 0.5915\n",
            " Training bag [10/11] bag loss: 0.6023\n",
            " Testing bag [0/6] bag loss: 0.5903\n",
            " Testing bag [1/6] bag loss: 0.7241\n",
            " Testing bag [2/6] bag loss: 0.5899\n",
            " Testing bag [3/6] bag loss: 0.6002\n",
            " Testing bag [4/6] bag loss: 0.6126\n",
            " Testing bag [5/6] bag loss: 0.6066ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [93/300] train loss: 0.6230 test loss: 0.6206, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7045\n",
            " Training bag [1/11] bag loss: 0.7137\n",
            " Training bag [2/11] bag loss: 0.5910\n",
            " Training bag [3/11] bag loss: 0.5846\n",
            " Training bag [4/11] bag loss: 0.5888\n",
            " Training bag [5/11] bag loss: 0.5764\n",
            " Training bag [6/11] bag loss: 0.5979\n",
            " Training bag [7/11] bag loss: 0.6962\n",
            " Training bag [8/11] bag loss: 0.6066\n",
            " Training bag [9/11] bag loss: 0.5980\n",
            " Training bag [10/11] bag loss: 0.6047\n",
            " Testing bag [0/6] bag loss: 0.5894\n",
            " Testing bag [1/6] bag loss: 0.7232\n",
            " Testing bag [2/6] bag loss: 0.5869\n",
            " Testing bag [3/6] bag loss: 0.6021\n",
            " Testing bag [4/6] bag loss: 0.6142\n",
            " Testing bag [5/6] bag loss: 0.6072ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [94/300] train loss: 0.6239 test loss: 0.6205, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5928\n",
            " Training bag [1/11] bag loss: 0.5892\n",
            " Training bag [2/11] bag loss: 0.6991\n",
            " Training bag [3/11] bag loss: 0.7161\n",
            " Training bag [4/11] bag loss: 0.5790\n",
            " Training bag [5/11] bag loss: 0.6027\n",
            " Training bag [6/11] bag loss: 0.5983\n",
            " Training bag [7/11] bag loss: 0.7023\n",
            " Training bag [8/11] bag loss: 0.5864\n",
            " Training bag [9/11] bag loss: 0.5923\n",
            " Training bag [10/11] bag loss: 0.5911\n",
            " Testing bag [0/6] bag loss: 0.5900\n",
            " Testing bag [1/6] bag loss: 0.7226\n",
            " Testing bag [2/6] bag loss: 0.5883\n",
            " Testing bag [3/6] bag loss: 0.5995\n",
            " Testing bag [4/6] bag loss: 0.6122\n",
            " Testing bag [5/6] bag loss: 0.6064ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [95/300] train loss: 0.6227 test loss: 0.6198, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7001\n",
            " Training bag [1/11] bag loss: 0.5850\n",
            " Training bag [2/11] bag loss: 0.6000\n",
            " Training bag [3/11] bag loss: 0.7017\n",
            " Training bag [4/11] bag loss: 0.5915\n",
            " Training bag [5/11] bag loss: 0.5793\n",
            " Training bag [6/11] bag loss: 0.7131\n",
            " Training bag [7/11] bag loss: 0.5918\n",
            " Training bag [8/11] bag loss: 0.5898\n",
            " Training bag [9/11] bag loss: 0.6046\n",
            " Training bag [10/11] bag loss: 0.5949\n",
            " Testing bag [0/6] bag loss: 0.5892\n",
            " Testing bag [1/6] bag loss: 0.7246\n",
            " Testing bag [2/6] bag loss: 0.5886\n",
            " Testing bag [3/6] bag loss: 0.5995\n",
            " Testing bag [4/6] bag loss: 0.6135\n",
            " Testing bag [5/6] bag loss: 0.6059ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [96/300] train loss: 0.6229 test loss: 0.6202, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5915\n",
            " Training bag [1/11] bag loss: 0.5881\n",
            " Training bag [2/11] bag loss: 0.5924\n",
            " Training bag [3/11] bag loss: 0.7179\n",
            " Training bag [4/11] bag loss: 0.6997\n",
            " Training bag [5/11] bag loss: 0.5989\n",
            " Training bag [6/11] bag loss: 0.5809\n",
            " Training bag [7/11] bag loss: 0.7029\n",
            " Training bag [8/11] bag loss: 0.5929\n",
            " Training bag [9/11] bag loss: 0.5966\n",
            " Training bag [10/11] bag loss: 0.5857\n",
            " Testing bag [0/6] bag loss: 0.5911\n",
            " Testing bag [1/6] bag loss: 0.7249\n",
            " Testing bag [2/6] bag loss: 0.5895\n",
            " Testing bag [3/6] bag loss: 0.5993\n",
            " Testing bag [4/6] bag loss: 0.6110\n",
            " Testing bag [5/6] bag loss: 0.6054ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [97/300] train loss: 0.6225 test loss: 0.6202, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5972\n",
            " Training bag [1/11] bag loss: 0.7154\n",
            " Training bag [2/11] bag loss: 0.5884\n",
            " Training bag [3/11] bag loss: 0.5906\n",
            " Training bag [4/11] bag loss: 0.5859\n",
            " Training bag [5/11] bag loss: 0.7063\n",
            " Training bag [6/11] bag loss: 0.7048\n",
            " Training bag [7/11] bag loss: 0.5907\n",
            " Training bag [8/11] bag loss: 0.6026\n",
            " Training bag [9/11] bag loss: 0.5902\n",
            " Training bag [10/11] bag loss: 0.5779\n",
            " Testing bag [0/6] bag loss: 0.5903\n",
            " Testing bag [1/6] bag loss: 0.7259\n",
            " Testing bag [2/6] bag loss: 0.5888\n",
            " Testing bag [3/6] bag loss: 0.5981\n",
            " Testing bag [4/6] bag loss: 0.6111\n",
            " Testing bag [5/6] bag loss: 0.6057ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [98/300] train loss: 0.6227 test loss: 0.6200, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6966\n",
            " Training bag [1/11] bag loss: 0.5841\n",
            " Training bag [2/11] bag loss: 0.7015\n",
            " Training bag [3/11] bag loss: 0.5760\n",
            " Training bag [4/11] bag loss: 0.7117\n",
            " Training bag [5/11] bag loss: 0.5853\n",
            " Training bag [6/11] bag loss: 0.5982\n",
            " Training bag [7/11] bag loss: 0.6043\n",
            " Training bag [8/11] bag loss: 0.6064\n",
            " Training bag [9/11] bag loss: 0.5883\n",
            " Training bag [10/11] bag loss: 0.5911\n",
            " Testing bag [0/6] bag loss: 0.5891\n",
            " Testing bag [1/6] bag loss: 0.7243\n",
            " Testing bag [2/6] bag loss: 0.5855\n",
            " Testing bag [3/6] bag loss: 0.5977\n",
            " Testing bag [4/6] bag loss: 0.6125\n",
            " Testing bag [5/6] bag loss: 0.6053ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [99/300] train loss: 0.6221 test loss: 0.6191, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5906\n",
            " Training bag [1/11] bag loss: 0.6006\n",
            " Training bag [2/11] bag loss: 0.5864\n",
            " Training bag [3/11] bag loss: 0.5941\n",
            " Training bag [4/11] bag loss: 0.5897\n",
            " Training bag [5/11] bag loss: 0.5874\n",
            " Training bag [6/11] bag loss: 0.5857\n",
            " Training bag [7/11] bag loss: 0.7240\n",
            " Training bag [8/11] bag loss: 0.7145\n",
            " Training bag [9/11] bag loss: 0.5766\n",
            " Training bag [10/11] bag loss: 0.7021\n",
            " Testing bag [0/6] bag loss: 0.5880\n",
            " Testing bag [1/6] bag loss: 0.7288\n",
            " Testing bag [2/6] bag loss: 0.5860\n",
            " Testing bag [3/6] bag loss: 0.5981\n",
            " Testing bag [4/6] bag loss: 0.6107\n",
            " Testing bag [5/6] bag loss: 0.6042ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [100/300] train loss: 0.6229 test loss: 0.6193, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5899\n",
            " Training bag [1/11] bag loss: 0.5969\n",
            " Training bag [2/11] bag loss: 0.5863\n",
            " Training bag [3/11] bag loss: 0.7101\n",
            " Training bag [4/11] bag loss: 0.7183\n",
            " Training bag [5/11] bag loss: 0.5792\n",
            " Training bag [6/11] bag loss: 0.5902\n",
            " Training bag [7/11] bag loss: 0.5897\n",
            " Training bag [8/11] bag loss: 0.5884\n",
            " Training bag [9/11] bag loss: 0.7090\n",
            " Training bag [10/11] bag loss: 0.6021\n",
            " Testing bag [0/6] bag loss: 0.5858\n",
            " Testing bag [1/6] bag loss: 0.7269\n",
            " Testing bag [2/6] bag loss: 0.5872\n",
            " Testing bag [3/6] bag loss: 0.5974\n",
            " Testing bag [4/6] bag loss: 0.6122\n",
            " Testing bag [5/6] bag loss: 0.6046ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [101/300] train loss: 0.6236 test loss: 0.6190, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5826\n",
            " Training bag [1/11] bag loss: 0.5849\n",
            " Training bag [2/11] bag loss: 0.7086\n",
            " Training bag [3/11] bag loss: 0.7162\n",
            " Training bag [4/11] bag loss: 0.6047\n",
            " Training bag [5/11] bag loss: 0.5921\n",
            " Training bag [6/11] bag loss: 0.5880\n",
            " Training bag [7/11] bag loss: 0.6000\n",
            " Training bag [8/11] bag loss: 0.7056\n",
            " Training bag [9/11] bag loss: 0.5758\n",
            " Training bag [10/11] bag loss: 0.5914\n",
            " Testing bag [0/6] bag loss: 0.5882\n",
            " Testing bag [1/6] bag loss: 0.7266\n",
            " Testing bag [2/6] bag loss: 0.5856\n",
            " Testing bag [3/6] bag loss: 0.5995\n",
            " Testing bag [4/6] bag loss: 0.6119\n",
            " Testing bag [5/6] bag loss: 0.6047ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [102/300] train loss: 0.6227 test loss: 0.6194, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6031\n",
            " Training bag [1/11] bag loss: 0.5973\n",
            " Training bag [2/11] bag loss: 0.5855\n",
            " Training bag [3/11] bag loss: 0.7006\n",
            " Training bag [4/11] bag loss: 0.5804\n",
            " Training bag [5/11] bag loss: 0.7067\n",
            " Training bag [6/11] bag loss: 0.5917\n",
            " Training bag [7/11] bag loss: 0.5873\n",
            " Training bag [8/11] bag loss: 0.5913\n",
            " Training bag [9/11] bag loss: 0.5867\n",
            " Training bag [10/11] bag loss: 0.7180\n",
            " Testing bag [0/6] bag loss: 0.5884\n",
            " Testing bag [1/6] bag loss: 0.7266\n",
            " Testing bag [2/6] bag loss: 0.5871\n",
            " Testing bag [3/6] bag loss: 0.5975\n",
            " Testing bag [4/6] bag loss: 0.6085\n",
            " Testing bag [5/6] bag loss: 0.6039ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [103/300] train loss: 0.6226 test loss: 0.6187, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5888\n",
            " Training bag [1/11] bag loss: 0.5881\n",
            " Training bag [2/11] bag loss: 0.5761\n",
            " Training bag [3/11] bag loss: 0.5796\n",
            " Training bag [4/11] bag loss: 0.6004\n",
            " Training bag [5/11] bag loss: 0.5815\n",
            " Training bag [6/11] bag loss: 0.6015\n",
            " Training bag [7/11] bag loss: 0.7078\n",
            " Training bag [8/11] bag loss: 0.7120\n",
            " Training bag [9/11] bag loss: 0.5891\n",
            " Training bag [10/11] bag loss: 0.7214\n",
            " Testing bag [0/6] bag loss: 0.5856\n",
            " Testing bag [1/6] bag loss: 0.7291\n",
            " Testing bag [2/6] bag loss: 0.5840\n",
            " Testing bag [3/6] bag loss: 0.5965\n",
            " Testing bag [4/6] bag loss: 0.6117\n",
            " Testing bag [5/6] bag loss: 0.6049ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [104/300] train loss: 0.6224 test loss: 0.6186, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.75\n",
            "Best model saved at: weights/20250626/fold_2_19.pth\n",
            "Best thresholds ===>>> class-0>>0.3398062288761139|class-1>>0.27407386898994446|class-2>>0.3809547424316406\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5857\n",
            " Training bag [1/11] bag loss: 0.5838\n",
            " Training bag [2/11] bag loss: 0.7073\n",
            " Training bag [3/11] bag loss: 0.5706\n",
            " Training bag [4/11] bag loss: 0.5767\n",
            " Training bag [5/11] bag loss: 0.7014\n",
            " Training bag [6/11] bag loss: 0.6031\n",
            " Training bag [7/11] bag loss: 0.6071\n",
            " Training bag [8/11] bag loss: 0.5952\n",
            " Training bag [9/11] bag loss: 0.7178\n",
            " Training bag [10/11] bag loss: 0.5917\n",
            " Testing bag [0/6] bag loss: 0.5851\n",
            " Testing bag [1/6] bag loss: 0.7273\n",
            " Testing bag [2/6] bag loss: 0.5862\n",
            " Testing bag [3/6] bag loss: 0.5967\n",
            " Testing bag [4/6] bag loss: 0.6125\n",
            " Testing bag [5/6] bag loss: 0.6054ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [105/300] train loss: 0.6219 test loss: 0.6189, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5853\n",
            " Training bag [1/11] bag loss: 0.5847\n",
            " Training bag [2/11] bag loss: 0.5976\n",
            " Training bag [3/11] bag loss: 0.7190\n",
            " Training bag [4/11] bag loss: 0.7013\n",
            " Training bag [5/11] bag loss: 0.5904\n",
            " Training bag [6/11] bag loss: 0.5823\n",
            " Training bag [7/11] bag loss: 0.6004\n",
            " Training bag [8/11] bag loss: 0.5730\n",
            " Training bag [9/11] bag loss: 0.7049\n",
            " Training bag [10/11] bag loss: 0.5920\n",
            " Testing bag [0/6] bag loss: 0.5869\n",
            " Testing bag [1/6] bag loss: 0.7286\n",
            " Testing bag [2/6] bag loss: 0.5864\n",
            " Testing bag [3/6] bag loss: 0.5992\n",
            " Testing bag [4/6] bag loss: 0.6121\n",
            " Testing bag [5/6] bag loss: 0.6049ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [106/300] train loss: 0.6210 test loss: 0.6197, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6974\n",
            " Training bag [1/11] bag loss: 0.5743\n",
            " Training bag [2/11] bag loss: 0.5867\n",
            " Training bag [3/11] bag loss: 0.7144\n",
            " Training bag [4/11] bag loss: 0.5930\n",
            " Training bag [5/11] bag loss: 0.5801\n",
            " Training bag [6/11] bag loss: 0.5827\n",
            " Training bag [7/11] bag loss: 0.5925\n",
            " Training bag [8/11] bag loss: 0.6003\n",
            " Training bag [9/11] bag loss: 0.6021\n",
            " Training bag [10/11] bag loss: 0.7092\n",
            " Testing bag [0/6] bag loss: 0.5869\n",
            " Testing bag [1/6] bag loss: 0.7287\n",
            " Testing bag [2/6] bag loss: 0.5867\n",
            " Testing bag [3/6] bag loss: 0.5963\n",
            " Testing bag [4/6] bag loss: 0.6114\n",
            " Testing bag [5/6] bag loss: 0.6046ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [107/300] train loss: 0.6212 test loss: 0.6191, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7062\n",
            " Training bag [1/11] bag loss: 0.5873\n",
            " Training bag [2/11] bag loss: 0.5727\n",
            " Training bag [3/11] bag loss: 0.5851\n",
            " Training bag [4/11] bag loss: 0.5997\n",
            " Training bag [5/11] bag loss: 0.6978\n",
            " Training bag [6/11] bag loss: 0.5786\n",
            " Training bag [7/11] bag loss: 0.5921\n",
            " Training bag [8/11] bag loss: 0.6034\n",
            " Training bag [9/11] bag loss: 0.5916\n",
            " Training bag [10/11] bag loss: 0.7184\n",
            " Testing bag [0/6] bag loss: 0.5849\n",
            " Testing bag [1/6] bag loss: 0.7283\n",
            " Testing bag [2/6] bag loss: 0.5848\n",
            " Testing bag [3/6] bag loss: 0.5987\n",
            " Testing bag [4/6] bag loss: 0.6110\n",
            " Testing bag [5/6] bag loss: 0.6036ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [108/300] train loss: 0.6212 test loss: 0.6186, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5863\n",
            " Training bag [1/11] bag loss: 0.5727\n",
            " Training bag [2/11] bag loss: 0.7181\n",
            " Training bag [3/11] bag loss: 0.5910\n",
            " Training bag [4/11] bag loss: 0.7087\n",
            " Training bag [5/11] bag loss: 0.6033\n",
            " Training bag [6/11] bag loss: 0.5819\n",
            " Training bag [7/11] bag loss: 0.5856\n",
            " Training bag [8/11] bag loss: 0.5913\n",
            " Training bag [9/11] bag loss: 0.5981\n",
            " Training bag [10/11] bag loss: 0.7012\n",
            " Testing bag [0/6] bag loss: 0.5868\n",
            " Testing bag [1/6] bag loss: 0.7296\n",
            " Testing bag [2/6] bag loss: 0.5845\n",
            " Testing bag [3/6] bag loss: 0.5959\n",
            " Testing bag [4/6] bag loss: 0.6107\n",
            " Testing bag [5/6] bag loss: 0.6037ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [109/300] train loss: 0.6217 test loss: 0.6185, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5893\n",
            " Training bag [1/11] bag loss: 0.5868\n",
            " Training bag [2/11] bag loss: 0.7177\n",
            " Training bag [3/11] bag loss: 0.5903\n",
            " Training bag [4/11] bag loss: 0.5882\n",
            " Training bag [5/11] bag loss: 0.5748\n",
            " Training bag [6/11] bag loss: 0.7012\n",
            " Training bag [7/11] bag loss: 0.7073\n",
            " Training bag [8/11] bag loss: 0.6002\n",
            " Training bag [9/11] bag loss: 0.5975\n",
            " Training bag [10/11] bag loss: 0.5820\n",
            " Testing bag [0/6] bag loss: 0.5868\n",
            " Testing bag [1/6] bag loss: 0.7292\n",
            " Testing bag [2/6] bag loss: 0.5886\n",
            " Testing bag [3/6] bag loss: 0.5946\n",
            " Testing bag [4/6] bag loss: 0.6109\n",
            " Testing bag [5/6] bag loss: 0.6022ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [110/300] train loss: 0.6214 test loss: 0.6187, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5963\n",
            " Training bag [1/11] bag loss: 0.5869\n",
            " Training bag [2/11] bag loss: 0.6984\n",
            " Training bag [3/11] bag loss: 0.5877\n",
            " Training bag [4/11] bag loss: 0.5754\n",
            " Training bag [5/11] bag loss: 0.5863\n",
            " Training bag [6/11] bag loss: 0.5974\n",
            " Training bag [7/11] bag loss: 0.5847\n",
            " Training bag [8/11] bag loss: 0.7088\n",
            " Training bag [9/11] bag loss: 0.5883\n",
            " Training bag [10/11] bag loss: 0.7191\n",
            " Testing bag [0/6] bag loss: 0.5855\n",
            " Testing bag [1/6] bag loss: 0.7284\n",
            " Testing bag [2/6] bag loss: 0.5853\n",
            " Testing bag [3/6] bag loss: 0.5940\n",
            " Testing bag [4/6] bag loss: 0.6096\n",
            " Testing bag [5/6] bag loss: 0.6023ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [111/300] train loss: 0.6209 test loss: 0.6175, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "Best model saved at: weights/20250626/fold_2_19.pth\n",
            "Best thresholds ===>>> class-0>>0.34066203236579895|class-1>>0.27541840076446533|class-2>>0.3642522990703583\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7046\n",
            " Training bag [1/11] bag loss: 0.5814\n",
            " Training bag [2/11] bag loss: 0.5878\n",
            " Training bag [3/11] bag loss: 0.5732\n",
            " Training bag [4/11] bag loss: 0.7161\n",
            " Training bag [5/11] bag loss: 0.5969\n",
            " Training bag [6/11] bag loss: 0.5856\n",
            " Training bag [7/11] bag loss: 0.5856\n",
            " Training bag [8/11] bag loss: 0.6015\n",
            " Training bag [9/11] bag loss: 0.5885\n",
            " Training bag [10/11] bag loss: 0.7009\n",
            " Testing bag [0/6] bag loss: 0.5851\n",
            " Testing bag [1/6] bag loss: 0.7309\n",
            " Testing bag [2/6] bag loss: 0.5867\n",
            " Testing bag [3/6] bag loss: 0.5974\n",
            " Testing bag [4/6] bag loss: 0.6104\n",
            " Testing bag [5/6] bag loss: 0.6030ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [112/300] train loss: 0.6202 test loss: 0.6189, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7168\n",
            " Training bag [1/11] bag loss: 0.5860\n",
            " Training bag [2/11] bag loss: 0.6957\n",
            " Training bag [3/11] bag loss: 0.5900\n",
            " Training bag [4/11] bag loss: 0.5740\n",
            " Training bag [5/11] bag loss: 0.5866\n",
            " Training bag [6/11] bag loss: 0.7027\n",
            " Training bag [7/11] bag loss: 0.5926\n",
            " Training bag [8/11] bag loss: 0.6014\n",
            " Training bag [9/11] bag loss: 0.5810\n",
            " Training bag [10/11] bag loss: 0.5978\n",
            " Testing bag [0/6] bag loss: 0.5851\n",
            " Testing bag [1/6] bag loss: 0.7260\n",
            " Testing bag [2/6] bag loss: 0.5864\n",
            " Testing bag [3/6] bag loss: 0.5953\n",
            " Testing bag [4/6] bag loss: 0.6109\n",
            " Testing bag [5/6] bag loss: 0.6049ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [113/300] train loss: 0.6204 test loss: 0.6181, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5952\n",
            " Training bag [1/11] bag loss: 0.5830\n",
            " Training bag [2/11] bag loss: 0.5855\n",
            " Training bag [3/11] bag loss: 0.5874\n",
            " Training bag [4/11] bag loss: 0.5730\n",
            " Training bag [5/11] bag loss: 0.5839\n",
            " Training bag [6/11] bag loss: 0.5835\n",
            " Training bag [7/11] bag loss: 0.5961\n",
            " Training bag [8/11] bag loss: 0.7069\n",
            " Training bag [9/11] bag loss: 0.7128\n",
            " Training bag [10/11] bag loss: 0.7223\n",
            " Testing bag [0/6] bag loss: 0.5841\n",
            " Testing bag [1/6] bag loss: 0.7302\n",
            " Testing bag [2/6] bag loss: 0.5841\n",
            " Testing bag [3/6] bag loss: 0.5934\n",
            " Testing bag [4/6] bag loss: 0.6092\n",
            " Testing bag [5/6] bag loss: 0.6022ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [114/300] train loss: 0.6209 test loss: 0.6172, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5844\n",
            " Training bag [1/11] bag loss: 0.5878\n",
            " Training bag [2/11] bag loss: 0.5944\n",
            " Training bag [3/11] bag loss: 0.5723\n",
            " Training bag [4/11] bag loss: 0.7074\n",
            " Training bag [5/11] bag loss: 0.5981\n",
            " Training bag [6/11] bag loss: 0.5816\n",
            " Training bag [7/11] bag loss: 0.7202\n",
            " Training bag [8/11] bag loss: 0.5847\n",
            " Training bag [9/11] bag loss: 0.7091\n",
            " Training bag [10/11] bag loss: 0.5856\n",
            " Testing bag [0/6] bag loss: 0.5870\n",
            " Testing bag [1/6] bag loss: 0.7288\n",
            " Testing bag [2/6] bag loss: 0.5853\n",
            " Testing bag [3/6] bag loss: 0.5942\n",
            " Testing bag [4/6] bag loss: 0.6101\n",
            " Testing bag [5/6] bag loss: 0.6021ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [115/300] train loss: 0.6205 test loss: 0.6179, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7085\n",
            " Training bag [1/11] bag loss: 0.5811\n",
            " Training bag [2/11] bag loss: 0.5731\n",
            " Training bag [3/11] bag loss: 0.5974\n",
            " Training bag [4/11] bag loss: 0.5823\n",
            " Training bag [5/11] bag loss: 0.6008\n",
            " Training bag [6/11] bag loss: 0.5872\n",
            " Training bag [7/11] bag loss: 0.7207\n",
            " Training bag [8/11] bag loss: 0.5863\n",
            " Training bag [9/11] bag loss: 0.5863\n",
            " Training bag [10/11] bag loss: 0.7009\n",
            " Testing bag [0/6] bag loss: 0.5854\n",
            " Testing bag [1/6] bag loss: 0.7313\n",
            " Testing bag [2/6] bag loss: 0.5847\n",
            " Testing bag [3/6] bag loss: 0.5947\n",
            " Testing bag [4/6] bag loss: 0.6099\n",
            " Testing bag [5/6] bag loss: 0.6028ROC AUC score: 0.33333333333333337\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [116/300] train loss: 0.6204 test loss: 0.6181, average score: 0.5000, AUC: class-0>>0.33333333333333337|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5866\n",
            " Training bag [1/11] bag loss: 0.5856\n",
            " Training bag [2/11] bag loss: 0.5845\n",
            " Training bag [3/11] bag loss: 0.5823\n",
            " Training bag [4/11] bag loss: 0.5923\n",
            " Training bag [5/11] bag loss: 0.7236\n",
            " Training bag [6/11] bag loss: 0.5861\n",
            " Training bag [7/11] bag loss: 0.7077\n",
            " Training bag [8/11] bag loss: 0.5712\n",
            " Training bag [9/11] bag loss: 0.6003\n",
            " Training bag [10/11] bag loss: 0.7079\n",
            " Testing bag [0/6] bag loss: 0.5851\n",
            " Testing bag [1/6] bag loss: 0.7293\n",
            " Testing bag [2/6] bag loss: 0.5851\n",
            " Testing bag [3/6] bag loss: 0.5960\n",
            " Testing bag [4/6] bag loss: 0.6100\n",
            " Testing bag [5/6] bag loss: 0.6029ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [117/300] train loss: 0.6207 test loss: 0.6181, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5861\n",
            " Training bag [1/11] bag loss: 0.7071\n",
            " Training bag [2/11] bag loss: 0.5928\n",
            " Training bag [3/11] bag loss: 0.5892\n",
            " Training bag [4/11] bag loss: 0.5822\n",
            " Training bag [5/11] bag loss: 0.7184\n",
            " Training bag [6/11] bag loss: 0.7072\n",
            " Training bag [7/11] bag loss: 0.5772\n",
            " Training bag [8/11] bag loss: 0.5905\n",
            " Training bag [9/11] bag loss: 0.5977\n",
            " Training bag [10/11] bag loss: 0.5831\n",
            " Testing bag [0/6] bag loss: 0.5863\n",
            " Testing bag [1/6] bag loss: 0.7302\n",
            " Testing bag [2/6] bag loss: 0.5856\n",
            " Testing bag [3/6] bag loss: 0.5937\n",
            " Testing bag [4/6] bag loss: 0.6108\n",
            " Testing bag [5/6] bag loss: 0.6027ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [118/300] train loss: 0.6210 test loss: 0.6182, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7027\n",
            " Training bag [1/11] bag loss: 0.6946\n",
            " Training bag [2/11] bag loss: 0.5991\n",
            " Training bag [3/11] bag loss: 0.5865\n",
            " Training bag [4/11] bag loss: 0.5872\n",
            " Training bag [5/11] bag loss: 0.7145\n",
            " Training bag [6/11] bag loss: 0.5959\n",
            " Training bag [7/11] bag loss: 0.5802\n",
            " Training bag [8/11] bag loss: 0.5723\n",
            " Training bag [9/11] bag loss: 0.5909\n",
            " Training bag [10/11] bag loss: 0.5880\n",
            " Testing bag [0/6] bag loss: 0.5846\n",
            " Testing bag [1/6] bag loss: 0.7313\n",
            " Testing bag [2/6] bag loss: 0.5853\n",
            " Testing bag [3/6] bag loss: 0.5932\n",
            " Testing bag [4/6] bag loss: 0.6116\n",
            " Testing bag [5/6] bag loss: 0.6039ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [119/300] train loss: 0.6193 test loss: 0.6183, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5864\n",
            " Training bag [1/11] bag loss: 0.7035\n",
            " Training bag [2/11] bag loss: 0.5869\n",
            " Training bag [3/11] bag loss: 0.7166\n",
            " Training bag [4/11] bag loss: 0.5879\n",
            " Training bag [5/11] bag loss: 0.5824\n",
            " Training bag [6/11] bag loss: 0.5720\n",
            " Training bag [7/11] bag loss: 0.5946\n",
            " Training bag [8/11] bag loss: 0.5983\n",
            " Training bag [9/11] bag loss: 0.5860\n",
            " Training bag [10/11] bag loss: 0.7076\n",
            " Testing bag [0/6] bag loss: 0.5851\n",
            " Testing bag [1/6] bag loss: 0.7304\n",
            " Testing bag [2/6] bag loss: 0.5837\n",
            " Testing bag [3/6] bag loss: 0.5949\n",
            " Testing bag [4/6] bag loss: 0.6093\n",
            " Testing bag [5/6] bag loss: 0.6027ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [120/300] train loss: 0.6202 test loss: 0.6177, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5840\n",
            " Training bag [1/11] bag loss: 0.7045\n",
            " Training bag [2/11] bag loss: 0.5845\n",
            " Training bag [3/11] bag loss: 0.7075\n",
            " Training bag [4/11] bag loss: 0.5745\n",
            " Training bag [5/11] bag loss: 0.5996\n",
            " Training bag [6/11] bag loss: 0.5941\n",
            " Training bag [7/11] bag loss: 0.5812\n",
            " Training bag [8/11] bag loss: 0.5844\n",
            " Training bag [9/11] bag loss: 0.7183\n",
            " Training bag [10/11] bag loss: 0.5867\n",
            " Testing bag [0/6] bag loss: 0.5849\n",
            " Testing bag [1/6] bag loss: 0.7298\n",
            " Testing bag [2/6] bag loss: 0.5858\n",
            " Testing bag [3/6] bag loss: 0.5932\n",
            " Testing bag [4/6] bag loss: 0.6102\n",
            " Testing bag [5/6] bag loss: 0.6027ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [121/300] train loss: 0.6199 test loss: 0.6178, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5824\n",
            " Training bag [1/11] bag loss: 0.5930\n",
            " Training bag [2/11] bag loss: 0.5965\n",
            " Training bag [3/11] bag loss: 0.7199\n",
            " Training bag [4/11] bag loss: 0.5833\n",
            " Training bag [5/11] bag loss: 0.5829\n",
            " Training bag [6/11] bag loss: 0.5887\n",
            " Training bag [7/11] bag loss: 0.5736\n",
            " Training bag [8/11] bag loss: 0.5882\n",
            " Training bag [9/11] bag loss: 0.7080\n",
            " Training bag [10/11] bag loss: 0.7118\n",
            " Testing bag [0/6] bag loss: 0.5843\n",
            " Testing bag [1/6] bag loss: 0.7314\n",
            " Testing bag [2/6] bag loss: 0.5834\n",
            " Testing bag [3/6] bag loss: 0.5927\n",
            " Testing bag [4/6] bag loss: 0.6089\n",
            " Testing bag [5/6] bag loss: 0.6017ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [122/300] train loss: 0.6208 test loss: 0.6170, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5825\n",
            " Training bag [1/11] bag loss: 0.5829\n",
            " Training bag [2/11] bag loss: 0.5933\n",
            " Training bag [3/11] bag loss: 0.5824\n",
            " Training bag [4/11] bag loss: 0.7113\n",
            " Training bag [5/11] bag loss: 0.5912\n",
            " Training bag [6/11] bag loss: 0.5894\n",
            " Training bag [7/11] bag loss: 0.7015\n",
            " Training bag [8/11] bag loss: 0.5763\n",
            " Training bag [9/11] bag loss: 0.5883\n",
            " Training bag [10/11] bag loss: 0.7198\n",
            " Testing bag [0/6] bag loss: 0.5857\n",
            " Testing bag [1/6] bag loss: 0.7294\n",
            " Testing bag [2/6] bag loss: 0.5831\n",
            " Testing bag [3/6] bag loss: 0.5944\n",
            " Testing bag [4/6] bag loss: 0.6096\n",
            " Testing bag [5/6] bag loss: 0.6015ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [123/300] train loss: 0.6199 test loss: 0.6173, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5846\n",
            " Training bag [1/11] bag loss: 0.5836\n",
            " Training bag [2/11] bag loss: 0.5776\n",
            " Training bag [3/11] bag loss: 0.5677\n",
            " Training bag [4/11] bag loss: 0.5903\n",
            " Training bag [5/11] bag loss: 0.6038\n",
            " Training bag [6/11] bag loss: 0.5865\n",
            " Training bag [7/11] bag loss: 0.7118\n",
            " Training bag [8/11] bag loss: 0.7105\n",
            " Training bag [9/11] bag loss: 0.5932\n",
            " Training bag [10/11] bag loss: 0.7210\n",
            " Testing bag [0/6] bag loss: 0.5845\n",
            " Testing bag [1/6] bag loss: 0.7319\n",
            " Testing bag [2/6] bag loss: 0.5842\n",
            " Testing bag [3/6] bag loss: 0.5950\n",
            " Testing bag [4/6] bag loss: 0.6098\n",
            " Testing bag [5/6] bag loss: 0.6035ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [124/300] train loss: 0.6210 test loss: 0.6182, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5836\n",
            " Training bag [1/11] bag loss: 0.5998\n",
            " Training bag [2/11] bag loss: 0.5824\n",
            " Training bag [3/11] bag loss: 0.7196\n",
            " Training bag [4/11] bag loss: 0.7083\n",
            " Training bag [5/11] bag loss: 0.5856\n",
            " Training bag [6/11] bag loss: 0.6973\n",
            " Training bag [7/11] bag loss: 0.5718\n",
            " Training bag [8/11] bag loss: 0.5800\n",
            " Training bag [9/11] bag loss: 0.5891\n",
            " Training bag [10/11] bag loss: 0.5948\n",
            " Testing bag [0/6] bag loss: 0.5833\n",
            " Testing bag [1/6] bag loss: 0.7307\n",
            " Testing bag [2/6] bag loss: 0.5851\n",
            " Testing bag [3/6] bag loss: 0.5944\n",
            " Testing bag [4/6] bag loss: 0.6109\n",
            " Testing bag [5/6] bag loss: 0.6045ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [125/300] train loss: 0.6193 test loss: 0.6182, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7021\n",
            " Training bag [1/11] bag loss: 0.5842\n",
            " Training bag [2/11] bag loss: 0.7156\n",
            " Training bag [3/11] bag loss: 0.5722\n",
            " Training bag [4/11] bag loss: 0.6925\n",
            " Training bag [5/11] bag loss: 0.5898\n",
            " Training bag [6/11] bag loss: 0.5978\n",
            " Training bag [7/11] bag loss: 0.5792\n",
            " Training bag [8/11] bag loss: 0.5825\n",
            " Training bag [9/11] bag loss: 0.5868\n",
            " Training bag [10/11] bag loss: 0.6001\n",
            " Testing bag [0/6] bag loss: 0.5850\n",
            " Testing bag [1/6] bag loss: 0.7282\n",
            " Testing bag [2/6] bag loss: 0.5842\n",
            " Testing bag [3/6] bag loss: 0.5943\n",
            " Testing bag [4/6] bag loss: 0.6111\n",
            " Testing bag [5/6] bag loss: 0.6030ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [126/300] train loss: 0.6184 test loss: 0.6176, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5857\n",
            " Training bag [1/11] bag loss: 0.5964\n",
            " Training bag [2/11] bag loss: 0.5732\n",
            " Training bag [3/11] bag loss: 0.5894\n",
            " Training bag [4/11] bag loss: 0.5854\n",
            " Training bag [5/11] bag loss: 0.7220\n",
            " Training bag [6/11] bag loss: 0.7093\n",
            " Training bag [7/11] bag loss: 0.7068\n",
            " Training bag [8/11] bag loss: 0.5847\n",
            " Training bag [9/11] bag loss: 0.5824\n",
            " Training bag [10/11] bag loss: 0.5868\n",
            " Testing bag [0/6] bag loss: 0.5864\n",
            " Testing bag [1/6] bag loss: 0.7317\n",
            " Testing bag [2/6] bag loss: 0.5866\n",
            " Testing bag [3/6] bag loss: 0.5937\n",
            " Testing bag [4/6] bag loss: 0.6090\n",
            " Testing bag [5/6] bag loss: 0.6015ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [127/300] train loss: 0.6202 test loss: 0.6182, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7168\n",
            " Training bag [1/11] bag loss: 0.5964\n",
            " Training bag [2/11] bag loss: 0.6940\n",
            " Training bag [3/11] bag loss: 0.5864\n",
            " Training bag [4/11] bag loss: 0.5833\n",
            " Training bag [5/11] bag loss: 0.5878\n",
            " Training bag [6/11] bag loss: 0.7017\n",
            " Training bag [7/11] bag loss: 0.5765\n",
            " Training bag [8/11] bag loss: 0.5819\n",
            " Training bag [9/11] bag loss: 0.5920\n",
            " Training bag [10/11] bag loss: 0.5865\n",
            " Testing bag [0/6] bag loss: 0.5852\n",
            " Testing bag [1/6] bag loss: 0.7282\n",
            " Testing bag [2/6] bag loss: 0.5846\n",
            " Testing bag [3/6] bag loss: 0.5945\n",
            " Testing bag [4/6] bag loss: 0.6094\n",
            " Testing bag [5/6] bag loss: 0.6009ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.75\n",
            "\n",
            " Epoch [128/300] train loss: 0.6185 test loss: 0.6171, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.75\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6940\n",
            " Training bag [1/11] bag loss: 0.7159\n",
            " Training bag [2/11] bag loss: 0.5859\n",
            " Training bag [3/11] bag loss: 0.5942\n",
            " Training bag [4/11] bag loss: 0.5864\n",
            " Training bag [5/11] bag loss: 0.5728\n",
            " Training bag [6/11] bag loss: 0.7051\n",
            " Training bag [7/11] bag loss: 0.5793\n",
            " Training bag [8/11] bag loss: 0.5857\n",
            " Training bag [9/11] bag loss: 0.5864\n",
            " Training bag [10/11] bag loss: 0.6018\n",
            " Testing bag [0/6] bag loss: 0.5836\n",
            " Testing bag [1/6] bag loss: 0.7289\n",
            " Testing bag [2/6] bag loss: 0.5831\n",
            " Testing bag [3/6] bag loss: 0.5911\n",
            " Testing bag [4/6] bag loss: 0.6117\n",
            " Testing bag [5/6] bag loss: 0.6046ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [129/300] train loss: 0.6189 test loss: 0.6172, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5829\n",
            " Training bag [1/11] bag loss: 0.5835\n",
            " Training bag [2/11] bag loss: 0.5938\n",
            " Training bag [3/11] bag loss: 0.7118\n",
            " Training bag [4/11] bag loss: 0.7042\n",
            " Training bag [5/11] bag loss: 0.7176\n",
            " Training bag [6/11] bag loss: 0.5860\n",
            " Training bag [7/11] bag loss: 0.5809\n",
            " Training bag [8/11] bag loss: 0.6000\n",
            " Training bag [9/11] bag loss: 0.5851\n",
            " Training bag [10/11] bag loss: 0.5718\n",
            " Testing bag [0/6] bag loss: 0.5850\n",
            " Testing bag [1/6] bag loss: 0.7315\n",
            " Testing bag [2/6] bag loss: 0.5835\n",
            " Testing bag [3/6] bag loss: 0.5952\n",
            " Testing bag [4/6] bag loss: 0.6097\n",
            " Testing bag [5/6] bag loss: 0.6021ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [130/300] train loss: 0.6198 test loss: 0.6178, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5846\n",
            " Training bag [1/11] bag loss: 0.5691\n",
            " Training bag [2/11] bag loss: 0.5839\n",
            " Training bag [3/11] bag loss: 0.5760\n",
            " Training bag [4/11] bag loss: 0.5996\n",
            " Training bag [5/11] bag loss: 0.5834\n",
            " Training bag [6/11] bag loss: 0.7029\n",
            " Training bag [7/11] bag loss: 0.5905\n",
            " Training bag [8/11] bag loss: 0.7127\n",
            " Training bag [9/11] bag loss: 0.5850\n",
            " Training bag [10/11] bag loss: 0.7207\n",
            " Testing bag [0/6] bag loss: 0.5841\n",
            " Testing bag [1/6] bag loss: 0.7341\n",
            " Testing bag [2/6] bag loss: 0.5840\n",
            " Testing bag [3/6] bag loss: 0.5907\n",
            " Testing bag [4/6] bag loss: 0.6089\n",
            " Testing bag [5/6] bag loss: 0.6018ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [131/300] train loss: 0.6189 test loss: 0.6173, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5708\n",
            " Training bag [1/11] bag loss: 0.5854\n",
            " Training bag [2/11] bag loss: 0.5851\n",
            " Training bag [3/11] bag loss: 0.5950\n",
            " Training bag [4/11] bag loss: 0.5843\n",
            " Training bag [5/11] bag loss: 0.5803\n",
            " Training bag [6/11] bag loss: 0.5827\n",
            " Training bag [7/11] bag loss: 0.7100\n",
            " Training bag [8/11] bag loss: 0.7238\n",
            " Training bag [9/11] bag loss: 0.7064\n",
            " Training bag [10/11] bag loss: 0.5930\n",
            " Testing bag [0/6] bag loss: 0.5832\n",
            " Testing bag [1/6] bag loss: 0.7312\n",
            " Testing bag [2/6] bag loss: 0.5816\n",
            " Testing bag [3/6] bag loss: 0.5920\n",
            " Testing bag [4/6] bag loss: 0.6098\n",
            " Testing bag [5/6] bag loss: 0.6023ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [132/300] train loss: 0.6197 test loss: 0.6167, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6994\n",
            " Training bag [1/11] bag loss: 0.5786\n",
            " Training bag [2/11] bag loss: 0.5834\n",
            " Training bag [3/11] bag loss: 0.5993\n",
            " Training bag [4/11] bag loss: 0.7036\n",
            " Training bag [5/11] bag loss: 0.5819\n",
            " Training bag [6/11] bag loss: 0.7170\n",
            " Training bag [7/11] bag loss: 0.5860\n",
            " Training bag [8/11] bag loss: 0.5674\n",
            " Training bag [9/11] bag loss: 0.5854\n",
            " Training bag [10/11] bag loss: 0.5958\n",
            " Testing bag [0/6] bag loss: 0.5836\n",
            " Testing bag [1/6] bag loss: 0.7327\n",
            " Testing bag [2/6] bag loss: 0.5817\n",
            " Testing bag [3/6] bag loss: 0.5932\n",
            " Testing bag [4/6] bag loss: 0.6118\n",
            " Testing bag [5/6] bag loss: 0.6032ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [133/300] train loss: 0.6180 test loss: 0.6177, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7048\n",
            " Training bag [1/11] bag loss: 0.5832\n",
            " Training bag [2/11] bag loss: 0.5932\n",
            " Training bag [3/11] bag loss: 0.7176\n",
            " Training bag [4/11] bag loss: 0.5866\n",
            " Training bag [5/11] bag loss: 0.5796\n",
            " Training bag [6/11] bag loss: 0.5868\n",
            " Training bag [7/11] bag loss: 0.5846\n",
            " Training bag [8/11] bag loss: 0.5682\n",
            " Training bag [9/11] bag loss: 0.5975\n",
            " Training bag [10/11] bag loss: 0.6995\n",
            " Testing bag [0/6] bag loss: 0.5837\n",
            " Testing bag [1/6] bag loss: 0.7336\n",
            " Testing bag [2/6] bag loss: 0.5832\n",
            " Testing bag [3/6] bag loss: 0.5928\n",
            " Testing bag [4/6] bag loss: 0.6097\n",
            " Testing bag [5/6] bag loss: 0.6011ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [134/300] train loss: 0.6183 test loss: 0.6174, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7064\n",
            " Training bag [1/11] bag loss: 0.5839\n",
            " Training bag [2/11] bag loss: 0.5925\n",
            " Training bag [3/11] bag loss: 0.6947\n",
            " Training bag [4/11] bag loss: 0.5844\n",
            " Training bag [5/11] bag loss: 0.5840\n",
            " Training bag [6/11] bag loss: 0.5688\n",
            " Training bag [7/11] bag loss: 0.5845\n",
            " Training bag [8/11] bag loss: 0.7182\n",
            " Training bag [9/11] bag loss: 0.5770\n",
            " Training bag [10/11] bag loss: 0.5969\n",
            " Testing bag [0/6] bag loss: 0.5835\n",
            " Testing bag [1/6] bag loss: 0.7326\n",
            " Testing bag [2/6] bag loss: 0.5833\n",
            " Testing bag [3/6] bag loss: 0.5910\n",
            " Testing bag [4/6] bag loss: 0.6103\n",
            " Testing bag [5/6] bag loss: 0.6027ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [135/300] train loss: 0.6174 test loss: 0.6172, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5835\n",
            " Training bag [1/11] bag loss: 0.5823\n",
            " Training bag [2/11] bag loss: 0.7068\n",
            " Training bag [3/11] bag loss: 0.7205\n",
            " Training bag [4/11] bag loss: 0.5989\n",
            " Training bag [5/11] bag loss: 0.5691\n",
            " Training bag [6/11] bag loss: 0.5847\n",
            " Training bag [7/11] bag loss: 0.5870\n",
            " Training bag [8/11] bag loss: 0.5924\n",
            " Training bag [9/11] bag loss: 0.5797\n",
            " Training bag [10/11] bag loss: 0.7142\n",
            " Testing bag [0/6] bag loss: 0.5823\n",
            " Testing bag [1/6] bag loss: 0.7324\n",
            " Testing bag [2/6] bag loss: 0.5828\n",
            " Testing bag [3/6] bag loss: 0.5938\n",
            " Testing bag [4/6] bag loss: 0.6089\n",
            " Testing bag [5/6] bag loss: 0.6009ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [136/300] train loss: 0.6199 test loss: 0.6169, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5823\n",
            " Training bag [1/11] bag loss: 0.5909\n",
            " Training bag [2/11] bag loss: 0.5936\n",
            " Training bag [3/11] bag loss: 0.7201\n",
            " Training bag [4/11] bag loss: 0.5716\n",
            " Training bag [5/11] bag loss: 0.5776\n",
            " Training bag [6/11] bag loss: 0.6975\n",
            " Training bag [7/11] bag loss: 0.5813\n",
            " Training bag [8/11] bag loss: 0.7089\n",
            " Training bag [9/11] bag loss: 0.5863\n",
            " Training bag [10/11] bag loss: 0.5856\n",
            " Testing bag [0/6] bag loss: 0.5844\n",
            " Testing bag [1/6] bag loss: 0.7310\n",
            " Testing bag [2/6] bag loss: 0.5841\n",
            " Testing bag [3/6] bag loss: 0.5894\n",
            " Testing bag [4/6] bag loss: 0.6093\n",
            " Testing bag [5/6] bag loss: 0.6009ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [137/300] train loss: 0.6178 test loss: 0.6165, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7054\n",
            " Training bag [1/11] bag loss: 0.5816\n",
            " Training bag [2/11] bag loss: 0.5720\n",
            " Training bag [3/11] bag loss: 0.6966\n",
            " Training bag [4/11] bag loss: 0.5989\n",
            " Training bag [5/11] bag loss: 0.5912\n",
            " Training bag [6/11] bag loss: 0.7172\n",
            " Training bag [7/11] bag loss: 0.5800\n",
            " Training bag [8/11] bag loss: 0.5882\n",
            " Training bag [9/11] bag loss: 0.5840\n",
            " Training bag [10/11] bag loss: 0.5859\n",
            " Testing bag [0/6] bag loss: 0.5839\n",
            " Testing bag [1/6] bag loss: 0.7316\n",
            " Testing bag [2/6] bag loss: 0.5839\n",
            " Testing bag [3/6] bag loss: 0.5925\n",
            " Testing bag [4/6] bag loss: 0.6083\n",
            " Testing bag [5/6] bag loss: 0.6006ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [138/300] train loss: 0.6183 test loss: 0.6168, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6963\n",
            " Training bag [1/11] bag loss: 0.5906\n",
            " Training bag [2/11] bag loss: 0.5693\n",
            " Training bag [3/11] bag loss: 0.5830\n",
            " Training bag [4/11] bag loss: 0.5844\n",
            " Training bag [5/11] bag loss: 0.5812\n",
            " Training bag [6/11] bag loss: 0.5947\n",
            " Training bag [7/11] bag loss: 0.7204\n",
            " Training bag [8/11] bag loss: 0.7107\n",
            " Training bag [9/11] bag loss: 0.5816\n",
            " Training bag [10/11] bag loss: 0.5868\n",
            " Testing bag [0/6] bag loss: 0.5834\n",
            " Testing bag [1/6] bag loss: 0.7342\n",
            " Testing bag [2/6] bag loss: 0.5845\n",
            " Testing bag [3/6] bag loss: 0.5899\n",
            " Testing bag [4/6] bag loss: 0.6089\n",
            " Testing bag [5/6] bag loss: 0.6007ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [139/300] train loss: 0.6181 test loss: 0.6169, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7189\n",
            " Training bag [1/11] bag loss: 0.5816\n",
            " Training bag [2/11] bag loss: 0.7064\n",
            " Training bag [3/11] bag loss: 0.6947\n",
            " Training bag [4/11] bag loss: 0.5794\n",
            " Training bag [5/11] bag loss: 0.5971\n",
            " Training bag [6/11] bag loss: 0.5856\n",
            " Training bag [7/11] bag loss: 0.5941\n",
            " Training bag [8/11] bag loss: 0.5821\n",
            " Training bag [9/11] bag loss: 0.5853\n",
            " Training bag [10/11] bag loss: 0.5698\n",
            " Testing bag [0/6] bag loss: 0.5831\n",
            " Testing bag [1/6] bag loss: 0.7328\n",
            " Testing bag [2/6] bag loss: 0.5829\n",
            " Testing bag [3/6] bag loss: 0.5900\n",
            " Testing bag [4/6] bag loss: 0.6088\n",
            " Testing bag [5/6] bag loss: 0.6010ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [140/300] train loss: 0.6177 test loss: 0.6164, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7174\n",
            " Training bag [1/11] bag loss: 0.5938\n",
            " Training bag [2/11] bag loss: 0.5703\n",
            " Training bag [3/11] bag loss: 0.5832\n",
            " Training bag [4/11] bag loss: 0.6969\n",
            " Training bag [5/11] bag loss: 0.5844\n",
            " Training bag [6/11] bag loss: 0.5811\n",
            " Training bag [7/11] bag loss: 0.5946\n",
            " Training bag [8/11] bag loss: 0.7078\n",
            " Training bag [9/11] bag loss: 0.5860\n",
            " Training bag [10/11] bag loss: 0.5813\n",
            " Testing bag [0/6] bag loss: 0.5827\n",
            " Testing bag [1/6] bag loss: 0.7339\n",
            " Testing bag [2/6] bag loss: 0.5832\n",
            " Testing bag [3/6] bag loss: 0.5924\n",
            " Testing bag [4/6] bag loss: 0.6084\n",
            " Testing bag [5/6] bag loss: 0.6018ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [141/300] train loss: 0.6179 test loss: 0.6171, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6966\n",
            " Training bag [1/11] bag loss: 0.5846\n",
            " Training bag [2/11] bag loss: 0.5912\n",
            " Training bag [3/11] bag loss: 0.5842\n",
            " Training bag [4/11] bag loss: 0.5820\n",
            " Training bag [5/11] bag loss: 0.7060\n",
            " Training bag [6/11] bag loss: 0.5864\n",
            " Training bag [7/11] bag loss: 0.5939\n",
            " Training bag [8/11] bag loss: 0.7197\n",
            " Training bag [9/11] bag loss: 0.5808\n",
            " Training bag [10/11] bag loss: 0.5704\n",
            " Testing bag [0/6] bag loss: 0.5836\n",
            " Testing bag [1/6] bag loss: 0.7315\n",
            " Testing bag [2/6] bag loss: 0.5832\n",
            " Testing bag [3/6] bag loss: 0.5867\n",
            " Testing bag [4/6] bag loss: 0.6089\n",
            " Testing bag [5/6] bag loss: 0.6014ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [142/300] train loss: 0.6178 test loss: 0.6159, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5849\n",
            " Training bag [1/11] bag loss: 0.7189\n",
            " Training bag [2/11] bag loss: 0.5763\n",
            " Training bag [3/11] bag loss: 0.5807\n",
            " Training bag [4/11] bag loss: 0.7079\n",
            " Training bag [5/11] bag loss: 0.5856\n",
            " Training bag [6/11] bag loss: 0.5851\n",
            " Training bag [7/11] bag loss: 0.5987\n",
            " Training bag [8/11] bag loss: 0.5683\n",
            " Training bag [9/11] bag loss: 0.5928\n",
            " Training bag [10/11] bag loss: 0.6996\n",
            " Testing bag [0/6] bag loss: 0.5825\n",
            " Testing bag [1/6] bag loss: 0.7323\n",
            " Testing bag [2/6] bag loss: 0.5820\n",
            " Testing bag [3/6] bag loss: 0.5944\n",
            " Testing bag [4/6] bag loss: 0.6091\n",
            " Testing bag [5/6] bag loss: 0.6020ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [143/300] train loss: 0.6181 test loss: 0.6171, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5836\n",
            " Training bag [1/11] bag loss: 0.5819\n",
            " Training bag [2/11] bag loss: 0.5837\n",
            " Training bag [3/11] bag loss: 0.5889\n",
            " Training bag [4/11] bag loss: 0.7114\n",
            " Training bag [5/11] bag loss: 0.5696\n",
            " Training bag [6/11] bag loss: 0.5930\n",
            " Training bag [7/11] bag loss: 0.7204\n",
            " Training bag [8/11] bag loss: 0.5849\n",
            " Training bag [9/11] bag loss: 0.5785\n",
            " Training bag [10/11] bag loss: 0.6968\n",
            " Testing bag [0/6] bag loss: 0.5836\n",
            " Testing bag [1/6] bag loss: 0.7326\n",
            " Testing bag [2/6] bag loss: 0.5827\n",
            " Testing bag [3/6] bag loss: 0.5892\n",
            " Testing bag [4/6] bag loss: 0.6092\n",
            " Testing bag [5/6] bag loss: 0.6009ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [144/300] train loss: 0.6175 test loss: 0.6164, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7040\n",
            " Training bag [1/11] bag loss: 0.5822\n",
            " Training bag [2/11] bag loss: 0.7168\n",
            " Training bag [3/11] bag loss: 0.5936\n",
            " Training bag [4/11] bag loss: 0.5968\n",
            " Training bag [5/11] bag loss: 0.5794\n",
            " Training bag [6/11] bag loss: 0.5688\n",
            " Training bag [7/11] bag loss: 0.5860\n",
            " Training bag [8/11] bag loss: 0.5818\n",
            " Training bag [9/11] bag loss: 0.6950\n",
            " Training bag [10/11] bag loss: 0.5834\n",
            " Testing bag [0/6] bag loss: 0.5813\n",
            " Testing bag [1/6] bag loss: 0.7337\n",
            " Testing bag [2/6] bag loss: 0.5807\n",
            " Testing bag [3/6] bag loss: 0.5910\n",
            " Testing bag [4/6] bag loss: 0.6111\n",
            " Testing bag [5/6] bag loss: 0.6021ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [145/300] train loss: 0.6171 test loss: 0.6166, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5837\n",
            " Training bag [1/11] bag loss: 0.5776\n",
            " Training bag [2/11] bag loss: 0.6956\n",
            " Training bag [3/11] bag loss: 0.5660\n",
            " Training bag [4/11] bag loss: 0.5826\n",
            " Training bag [5/11] bag loss: 0.5938\n",
            " Training bag [6/11] bag loss: 0.5814\n",
            " Training bag [7/11] bag loss: 0.7209\n",
            " Training bag [8/11] bag loss: 0.5829\n",
            " Training bag [9/11] bag loss: 0.5966\n",
            " Training bag [10/11] bag loss: 0.7053\n",
            " Testing bag [0/6] bag loss: 0.5830\n",
            " Testing bag [1/6] bag loss: 0.7338\n",
            " Testing bag [2/6] bag loss: 0.5802\n",
            " Testing bag [3/6] bag loss: 0.5897\n",
            " Testing bag [4/6] bag loss: 0.6094\n",
            " Testing bag [5/6] bag loss: 0.6024ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [146/300] train loss: 0.6170 test loss: 0.6164, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7027\n",
            " Training bag [1/11] bag loss: 0.5662\n",
            " Training bag [2/11] bag loss: 0.5836\n",
            " Training bag [3/11] bag loss: 0.5840\n",
            " Training bag [4/11] bag loss: 0.5966\n",
            " Training bag [5/11] bag loss: 0.5944\n",
            " Training bag [6/11] bag loss: 0.7196\n",
            " Training bag [7/11] bag loss: 0.5823\n",
            " Training bag [8/11] bag loss: 0.7092\n",
            " Training bag [9/11] bag loss: 0.5780\n",
            " Training bag [10/11] bag loss: 0.5834\n",
            " Testing bag [0/6] bag loss: 0.5833\n",
            " Testing bag [1/6] bag loss: 0.7333\n",
            " Testing bag [2/6] bag loss: 0.5795\n",
            " Testing bag [3/6] bag loss: 0.5909\n",
            " Testing bag [4/6] bag loss: 0.6103\n",
            " Testing bag [5/6] bag loss: 0.6030ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [147/300] train loss: 0.6182 test loss: 0.6167, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5814\n",
            " Training bag [1/11] bag loss: 0.6938\n",
            " Training bag [2/11] bag loss: 0.5817\n",
            " Training bag [3/11] bag loss: 0.5753\n",
            " Training bag [4/11] bag loss: 0.5853\n",
            " Training bag [5/11] bag loss: 0.7184\n",
            " Training bag [6/11] bag loss: 0.7080\n",
            " Training bag [7/11] bag loss: 0.5816\n",
            " Training bag [8/11] bag loss: 0.5939\n",
            " Training bag [9/11] bag loss: 0.5703\n",
            " Training bag [10/11] bag loss: 0.5974\n",
            " Testing bag [0/6] bag loss: 0.5831\n",
            " Testing bag [1/6] bag loss: 0.7314\n",
            " Testing bag [2/6] bag loss: 0.5826\n",
            " Testing bag [3/6] bag loss: 0.5934\n",
            " Testing bag [4/6] bag loss: 0.6109\n",
            " Testing bag [5/6] bag loss: 0.6026ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [148/300] train loss: 0.6170 test loss: 0.6174, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5912\n",
            " Training bag [1/11] bag loss: 0.5802\n",
            " Training bag [2/11] bag loss: 0.6951\n",
            " Training bag [3/11] bag loss: 0.5806\n",
            " Training bag [4/11] bag loss: 0.7038\n",
            " Training bag [5/11] bag loss: 0.7170\n",
            " Training bag [6/11] bag loss: 0.5883\n",
            " Training bag [7/11] bag loss: 0.5724\n",
            " Training bag [8/11] bag loss: 0.5805\n",
            " Training bag [9/11] bag loss: 0.5842\n",
            " Training bag [10/11] bag loss: 0.5966\n",
            " Testing bag [0/6] bag loss: 0.5836\n",
            " Testing bag [1/6] bag loss: 0.7323\n",
            " Testing bag [2/6] bag loss: 0.5807\n",
            " Testing bag [3/6] bag loss: 0.5924\n",
            " Testing bag [4/6] bag loss: 0.6097\n",
            " Testing bag [5/6] bag loss: 0.6016ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [149/300] train loss: 0.6173 test loss: 0.6167, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5831\n",
            " Training bag [1/11] bag loss: 0.5908\n",
            " Training bag [2/11] bag loss: 0.5816\n",
            " Training bag [3/11] bag loss: 0.5793\n",
            " Training bag [4/11] bag loss: 0.7057\n",
            " Training bag [5/11] bag loss: 0.5835\n",
            " Training bag [6/11] bag loss: 0.5685\n",
            " Training bag [7/11] bag loss: 0.5774\n",
            " Training bag [8/11] bag loss: 0.5956\n",
            " Training bag [9/11] bag loss: 0.7219\n",
            " Training bag [10/11] bag loss: 0.6976\n",
            " Testing bag [0/6] bag loss: 0.5817\n",
            " Testing bag [1/6] bag loss: 0.7349\n",
            " Testing bag [2/6] bag loss: 0.5805\n",
            " Testing bag [3/6] bag loss: 0.5909\n",
            " Testing bag [4/6] bag loss: 0.6086\n",
            " Testing bag [5/6] bag loss: 0.6008ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [150/300] train loss: 0.6168 test loss: 0.6162, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5903\n",
            " Training bag [1/11] bag loss: 0.5818\n",
            " Training bag [2/11] bag loss: 0.6955\n",
            " Training bag [3/11] bag loss: 0.5825\n",
            " Training bag [4/11] bag loss: 0.5758\n",
            " Training bag [5/11] bag loss: 0.7186\n",
            " Training bag [6/11] bag loss: 0.5646\n",
            " Training bag [7/11] bag loss: 0.5989\n",
            " Training bag [8/11] bag loss: 0.5834\n",
            " Training bag [9/11] bag loss: 0.7057\n",
            " Training bag [10/11] bag loss: 0.5816\n",
            " Testing bag [0/6] bag loss: 0.5812\n",
            " Testing bag [1/6] bag loss: 0.7323\n",
            " Testing bag [2/6] bag loss: 0.5798\n",
            " Testing bag [3/6] bag loss: 0.5939\n",
            " Testing bag [4/6] bag loss: 0.6107\n",
            " Testing bag [5/6] bag loss: 0.6015ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [151/300] train loss: 0.6163 test loss: 0.6165, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7011\n",
            " Training bag [1/11] bag loss: 0.7174\n",
            " Training bag [2/11] bag loss: 0.5821\n",
            " Training bag [3/11] bag loss: 0.5821\n",
            " Training bag [4/11] bag loss: 0.5669\n",
            " Training bag [5/11] bag loss: 0.5743\n",
            " Training bag [6/11] bag loss: 0.5952\n",
            " Training bag [7/11] bag loss: 0.5853\n",
            " Training bag [8/11] bag loss: 0.5819\n",
            " Training bag [9/11] bag loss: 0.5967\n",
            " Training bag [10/11] bag loss: 0.7086\n",
            " Testing bag [0/6] bag loss: 0.5814\n",
            " Testing bag [1/6] bag loss: 0.7341\n",
            " Testing bag [2/6] bag loss: 0.5795\n",
            " Testing bag [3/6] bag loss: 0.5901\n",
            " Testing bag [4/6] bag loss: 0.6096\n",
            " Testing bag [5/6] bag loss: 0.6016ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [152/300] train loss: 0.6174 test loss: 0.6160, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5745\n",
            " Training bag [1/11] bag loss: 0.5917\n",
            " Training bag [2/11] bag loss: 0.6949\n",
            " Training bag [3/11] bag loss: 0.5823\n",
            " Training bag [4/11] bag loss: 0.7185\n",
            " Training bag [5/11] bag loss: 0.5808\n",
            " Training bag [6/11] bag loss: 0.5657\n",
            " Training bag [7/11] bag loss: 0.5823\n",
            " Training bag [8/11] bag loss: 0.5963\n",
            " Training bag [9/11] bag loss: 0.7081\n",
            " Training bag [10/11] bag loss: 0.5849\n",
            " Testing bag [0/6] bag loss: 0.5830\n",
            " Testing bag [1/6] bag loss: 0.7332\n",
            " Testing bag [2/6] bag loss: 0.5808\n",
            " Testing bag [3/6] bag loss: 0.5908\n",
            " Testing bag [4/6] bag loss: 0.6091\n",
            " Testing bag [5/6] bag loss: 0.6008ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [153/300] train loss: 0.6164 test loss: 0.6163, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5701\n",
            " Training bag [1/11] bag loss: 0.5957\n",
            " Training bag [2/11] bag loss: 0.5799\n",
            " Training bag [3/11] bag loss: 0.7204\n",
            " Training bag [4/11] bag loss: 0.5810\n",
            " Training bag [5/11] bag loss: 0.6963\n",
            " Training bag [6/11] bag loss: 0.5819\n",
            " Training bag [7/11] bag loss: 0.5829\n",
            " Training bag [8/11] bag loss: 0.5751\n",
            " Training bag [9/11] bag loss: 0.7078\n",
            " Training bag [10/11] bag loss: 0.5924\n",
            " Testing bag [0/6] bag loss: 0.5830\n",
            " Testing bag [1/6] bag loss: 0.7343\n",
            " Testing bag [2/6] bag loss: 0.5810\n",
            " Testing bag [3/6] bag loss: 0.5927\n",
            " Testing bag [4/6] bag loss: 0.6111\n",
            " Testing bag [5/6] bag loss: 0.6025ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [154/300] train loss: 0.6167 test loss: 0.6174, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7175\n",
            " Training bag [1/11] bag loss: 0.5657\n",
            " Training bag [2/11] bag loss: 0.5923\n",
            " Training bag [3/11] bag loss: 0.6927\n",
            " Training bag [4/11] bag loss: 0.7009\n",
            " Training bag [5/11] bag loss: 0.5963\n",
            " Training bag [6/11] bag loss: 0.5762\n",
            " Training bag [7/11] bag loss: 0.5804\n",
            " Training bag [8/11] bag loss: 0.5850\n",
            " Training bag [9/11] bag loss: 0.5802\n",
            " Training bag [10/11] bag loss: 0.5856\n",
            " Testing bag [0/6] bag loss: 0.5817\n",
            " Testing bag [1/6] bag loss: 0.7323\n",
            " Testing bag [2/6] bag loss: 0.5805\n",
            " Testing bag [3/6] bag loss: 0.5885\n",
            " Testing bag [4/6] bag loss: 0.6095\n",
            " Testing bag [5/6] bag loss: 0.6010ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [155/300] train loss: 0.6157 test loss: 0.6156, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5822\n",
            " Training bag [1/11] bag loss: 0.5964\n",
            " Training bag [2/11] bag loss: 0.5877\n",
            " Training bag [3/11] bag loss: 0.5678\n",
            " Training bag [4/11] bag loss: 0.7205\n",
            " Training bag [5/11] bag loss: 0.7095\n",
            " Training bag [6/11] bag loss: 0.5833\n",
            " Training bag [7/11] bag loss: 0.6936\n",
            " Training bag [8/11] bag loss: 0.5835\n",
            " Training bag [9/11] bag loss: 0.5800\n",
            " Training bag [10/11] bag loss: 0.5782\n",
            " Testing bag [0/6] bag loss: 0.5828\n",
            " Testing bag [1/6] bag loss: 0.7338\n",
            " Testing bag [2/6] bag loss: 0.5810\n",
            " Testing bag [3/6] bag loss: 0.5920\n",
            " Testing bag [4/6] bag loss: 0.6086\n",
            " Testing bag [5/6] bag loss: 0.6017ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [156/300] train loss: 0.6166 test loss: 0.6167, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7190\n",
            " Training bag [1/11] bag loss: 0.5800\n",
            " Training bag [2/11] bag loss: 0.5903\n",
            " Training bag [3/11] bag loss: 0.5935\n",
            " Training bag [4/11] bag loss: 0.7031\n",
            " Training bag [5/11] bag loss: 0.5794\n",
            " Training bag [6/11] bag loss: 0.6927\n",
            " Training bag [7/11] bag loss: 0.5804\n",
            " Training bag [8/11] bag loss: 0.5859\n",
            " Training bag [9/11] bag loss: 0.5874\n",
            " Training bag [10/11] bag loss: 0.5692\n",
            " Testing bag [0/6] bag loss: 0.5846\n",
            " Testing bag [1/6] bag loss: 0.7329\n",
            " Testing bag [2/6] bag loss: 0.5841\n",
            " Testing bag [3/6] bag loss: 0.5899\n",
            " Testing bag [4/6] bag loss: 0.6083\n",
            " Testing bag [5/6] bag loss: 0.6000ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [157/300] train loss: 0.6165 test loss: 0.6167, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5788\n",
            " Training bag [1/11] bag loss: 0.5693\n",
            " Training bag [2/11] bag loss: 0.6957\n",
            " Training bag [3/11] bag loss: 0.5941\n",
            " Training bag [4/11] bag loss: 0.5823\n",
            " Training bag [5/11] bag loss: 0.7191\n",
            " Training bag [6/11] bag loss: 0.5835\n",
            " Training bag [7/11] bag loss: 0.5905\n",
            " Training bag [8/11] bag loss: 0.5797\n",
            " Training bag [9/11] bag loss: 0.7078\n",
            " Training bag [10/11] bag loss: 0.5754\n",
            " Testing bag [0/6] bag loss: 0.5822\n",
            " Testing bag [1/6] bag loss: 0.7331\n",
            " Testing bag [2/6] bag loss: 0.5806\n",
            " Testing bag [3/6] bag loss: 0.5869\n",
            " Testing bag [4/6] bag loss: 0.6092\n",
            " Testing bag [5/6] bag loss: 0.6013ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [158/300] train loss: 0.6160 test loss: 0.6156, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7067\n",
            " Training bag [1/11] bag loss: 0.5820\n",
            " Training bag [2/11] bag loss: 0.5780\n",
            " Training bag [3/11] bag loss: 0.6997\n",
            " Training bag [4/11] bag loss: 0.5808\n",
            " Training bag [5/11] bag loss: 0.5636\n",
            " Training bag [6/11] bag loss: 0.5838\n",
            " Training bag [7/11] bag loss: 0.7182\n",
            " Training bag [8/11] bag loss: 0.5951\n",
            " Training bag [9/11] bag loss: 0.5991\n",
            " Training bag [10/11] bag loss: 0.5828\n",
            " Testing bag [0/6] bag loss: 0.5810\n",
            " Testing bag [1/6] bag loss: 0.7336\n",
            " Testing bag [2/6] bag loss: 0.5787\n",
            " Testing bag [3/6] bag loss: 0.5908\n",
            " Testing bag [4/6] bag loss: 0.6112\n",
            " Testing bag [5/6] bag loss: 0.6036ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [159/300] train loss: 0.6172 test loss: 0.6165, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7038\n",
            " Training bag [1/11] bag loss: 0.5824\n",
            " Training bag [2/11] bag loss: 0.5644\n",
            " Training bag [3/11] bag loss: 0.7016\n",
            " Training bag [4/11] bag loss: 0.5848\n",
            " Training bag [5/11] bag loss: 0.7154\n",
            " Training bag [6/11] bag loss: 0.5839\n",
            " Training bag [7/11] bag loss: 0.5984\n",
            " Training bag [8/11] bag loss: 0.5946\n",
            " Training bag [9/11] bag loss: 0.5817\n",
            " Training bag [10/11] bag loss: 0.5752\n",
            " Testing bag [0/6] bag loss: 0.5815\n",
            " Testing bag [1/6] bag loss: 0.7333\n",
            " Testing bag [2/6] bag loss: 0.5815\n",
            " Testing bag [3/6] bag loss: 0.5896\n",
            " Testing bag [4/6] bag loss: 0.6102\n",
            " Testing bag [5/6] bag loss: 0.6026ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [160/300] train loss: 0.6169 test loss: 0.6164, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5811\n",
            " Training bag [1/11] bag loss: 0.7176\n",
            " Training bag [2/11] bag loss: 0.5663\n",
            " Training bag [3/11] bag loss: 0.5911\n",
            " Training bag [4/11] bag loss: 0.5752\n",
            " Training bag [5/11] bag loss: 0.7028\n",
            " Training bag [6/11] bag loss: 0.5826\n",
            " Training bag [7/11] bag loss: 0.5792\n",
            " Training bag [8/11] bag loss: 0.6930\n",
            " Training bag [9/11] bag loss: 0.5818\n",
            " Training bag [10/11] bag loss: 0.5960\n",
            " Testing bag [0/6] bag loss: 0.5807\n",
            " Testing bag [1/6] bag loss: 0.7327\n",
            " Testing bag [2/6] bag loss: 0.5804\n",
            " Testing bag [3/6] bag loss: 0.5897\n",
            " Testing bag [4/6] bag loss: 0.6099\n",
            " Testing bag [5/6] bag loss: 0.6010ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [161/300] train loss: 0.6152 test loss: 0.6157, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7179\n",
            " Training bag [1/11] bag loss: 0.6933\n",
            " Training bag [2/11] bag loss: 0.5841\n",
            " Training bag [3/11] bag loss: 0.5806\n",
            " Training bag [4/11] bag loss: 0.7036\n",
            " Training bag [5/11] bag loss: 0.5942\n",
            " Training bag [6/11] bag loss: 0.5759\n",
            " Training bag [7/11] bag loss: 0.5994\n",
            " Training bag [8/11] bag loss: 0.5641\n",
            " Training bag [9/11] bag loss: 0.5813\n",
            " Training bag [10/11] bag loss: 0.5809\n",
            " Testing bag [0/6] bag loss: 0.5798\n",
            " Testing bag [1/6] bag loss: 0.7334\n",
            " Testing bag [2/6] bag loss: 0.5784\n",
            " Testing bag [3/6] bag loss: 0.5932\n",
            " Testing bag [4/6] bag loss: 0.6106\n",
            " Testing bag [5/6] bag loss: 0.6033ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [162/300] train loss: 0.6159 test loss: 0.6164, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5952\n",
            " Training bag [1/11] bag loss: 0.7185\n",
            " Training bag [2/11] bag loss: 0.5839\n",
            " Training bag [3/11] bag loss: 0.5806\n",
            " Training bag [4/11] bag loss: 0.5827\n",
            " Training bag [5/11] bag loss: 0.6938\n",
            " Training bag [6/11] bag loss: 0.5661\n",
            " Training bag [7/11] bag loss: 0.5973\n",
            " Training bag [8/11] bag loss: 0.7025\n",
            " Training bag [9/11] bag loss: 0.5823\n",
            " Training bag [10/11] bag loss: 0.5751\n",
            " Testing bag [0/6] bag loss: 0.5825\n",
            " Testing bag [1/6] bag loss: 0.7340\n",
            " Testing bag [2/6] bag loss: 0.5813\n",
            " Testing bag [3/6] bag loss: 0.5920\n",
            " Testing bag [4/6] bag loss: 0.6100\n",
            " Testing bag [5/6] bag loss: 0.6010ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [163/300] train loss: 0.6162 test loss: 0.6168, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7057\n",
            " Training bag [1/11] bag loss: 0.5785\n",
            " Training bag [2/11] bag loss: 0.5949\n",
            " Training bag [3/11] bag loss: 0.5663\n",
            " Training bag [4/11] bag loss: 0.5842\n",
            " Training bag [5/11] bag loss: 0.6933\n",
            " Training bag [6/11] bag loss: 0.5817\n",
            " Training bag [7/11] bag loss: 0.5738\n",
            " Training bag [8/11] bag loss: 0.5930\n",
            " Training bag [9/11] bag loss: 0.5803\n",
            " Training bag [10/11] bag loss: 0.7205\n",
            " Testing bag [0/6] bag loss: 0.5804\n",
            " Testing bag [1/6] bag loss: 0.7349\n",
            " Testing bag [2/6] bag loss: 0.5784\n",
            " Testing bag [3/6] bag loss: 0.5862\n",
            " Testing bag [4/6] bag loss: 0.6103\n",
            " Testing bag [5/6] bag loss: 0.6012ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [164/300] train loss: 0.6157 test loss: 0.6152, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5733\n",
            " Training bag [1/11] bag loss: 0.5810\n",
            " Training bag [2/11] bag loss: 0.5830\n",
            " Training bag [3/11] bag loss: 0.7214\n",
            " Training bag [4/11] bag loss: 0.5932\n",
            " Training bag [5/11] bag loss: 0.7030\n",
            " Training bag [6/11] bag loss: 0.6998\n",
            " Training bag [7/11] bag loss: 0.5841\n",
            " Training bag [8/11] bag loss: 0.5656\n",
            " Training bag [9/11] bag loss: 0.5890\n",
            " Training bag [10/11] bag loss: 0.5824\n",
            " Testing bag [0/6] bag loss: 0.5820\n",
            " Testing bag [1/6] bag loss: 0.7334\n",
            " Testing bag [2/6] bag loss: 0.5820\n",
            " Testing bag [3/6] bag loss: 0.5893\n",
            " Testing bag [4/6] bag loss: 0.6102\n",
            " Testing bag [5/6] bag loss: 0.6016ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [165/300] train loss: 0.6160 test loss: 0.6164, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5766\n",
            " Training bag [1/11] bag loss: 0.5783\n",
            " Training bag [2/11] bag loss: 0.5899\n",
            " Training bag [3/11] bag loss: 0.5797\n",
            " Training bag [4/11] bag loss: 0.5818\n",
            " Training bag [5/11] bag loss: 0.5780\n",
            " Training bag [6/11] bag loss: 0.7063\n",
            " Training bag [7/11] bag loss: 0.5942\n",
            " Training bag [8/11] bag loss: 0.7217\n",
            " Training bag [9/11] bag loss: 0.6950\n",
            " Training bag [10/11] bag loss: 0.5670\n",
            " Testing bag [0/6] bag loss: 0.5808\n",
            " Testing bag [1/6] bag loss: 0.7349\n",
            " Testing bag [2/6] bag loss: 0.5799\n",
            " Testing bag [3/6] bag loss: 0.5907\n",
            " Testing bag [4/6] bag loss: 0.6099\n",
            " Testing bag [5/6] bag loss: 0.6005ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [166/300] train loss: 0.6153 test loss: 0.6161, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5832\n",
            " Training bag [1/11] bag loss: 0.7196\n",
            " Training bag [2/11] bag loss: 0.5831\n",
            " Training bag [3/11] bag loss: 0.7023\n",
            " Training bag [4/11] bag loss: 0.5741\n",
            " Training bag [5/11] bag loss: 0.5615\n",
            " Training bag [6/11] bag loss: 0.7016\n",
            " Training bag [7/11] bag loss: 0.5859\n",
            " Training bag [8/11] bag loss: 0.5860\n",
            " Training bag [9/11] bag loss: 0.5929\n",
            " Training bag [10/11] bag loss: 0.5997\n",
            " Testing bag [0/6] bag loss: 0.5792\n",
            " Testing bag [1/6] bag loss: 0.7349\n",
            " Testing bag [2/6] bag loss: 0.5803\n",
            " Testing bag [3/6] bag loss: 0.5929\n",
            " Testing bag [4/6] bag loss: 0.6122\n",
            " Testing bag [5/6] bag loss: 0.6031ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [167/300] train loss: 0.6173 test loss: 0.6171, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7178\n",
            " Training bag [1/11] bag loss: 0.5965\n",
            " Training bag [2/11] bag loss: 0.5784\n",
            " Training bag [3/11] bag loss: 0.6946\n",
            " Training bag [4/11] bag loss: 0.7025\n",
            " Training bag [5/11] bag loss: 0.5806\n",
            " Training bag [6/11] bag loss: 0.5884\n",
            " Training bag [7/11] bag loss: 0.5874\n",
            " Training bag [8/11] bag loss: 0.5688\n",
            " Training bag [9/11] bag loss: 0.5776\n",
            " Training bag [10/11] bag loss: 0.5833\n",
            " Testing bag [0/6] bag loss: 0.5819\n",
            " Testing bag [1/6] bag loss: 0.7336\n",
            " Testing bag [2/6] bag loss: 0.5811\n",
            " Testing bag [3/6] bag loss: 0.5908\n",
            " Testing bag [4/6] bag loss: 0.6089\n",
            " Testing bag [5/6] bag loss: 0.6002ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [168/300] train loss: 0.6160 test loss: 0.6161, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5790\n",
            " Training bag [1/11] bag loss: 0.5676\n",
            " Training bag [2/11] bag loss: 0.5913\n",
            " Training bag [3/11] bag loss: 0.5810\n",
            " Training bag [4/11] bag loss: 0.7090\n",
            " Training bag [5/11] bag loss: 0.7194\n",
            " Training bag [6/11] bag loss: 0.5781\n",
            " Training bag [7/11] bag loss: 0.6938\n",
            " Training bag [8/11] bag loss: 0.5951\n",
            " Training bag [9/11] bag loss: 0.5833\n",
            " Training bag [10/11] bag loss: 0.5786\n",
            " Testing bag [0/6] bag loss: 0.5811\n",
            " Testing bag [1/6] bag loss: 0.7323\n",
            " Testing bag [2/6] bag loss: 0.5789\n",
            " Testing bag [3/6] bag loss: 0.5883\n",
            " Testing bag [4/6] bag loss: 0.6097\n",
            " Testing bag [5/6] bag loss: 0.6006ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [169/300] train loss: 0.6160 test loss: 0.6151, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7172\n",
            " Training bag [1/11] bag loss: 0.5819\n",
            " Training bag [2/11] bag loss: 0.5819\n",
            " Training bag [3/11] bag loss: 0.5660\n",
            " Training bag [4/11] bag loss: 0.5898\n",
            " Training bag [5/11] bag loss: 0.5796\n",
            " Training bag [6/11] bag loss: 0.5727\n",
            " Training bag [7/11] bag loss: 0.7084\n",
            " Training bag [8/11] bag loss: 0.6933\n",
            " Training bag [9/11] bag loss: 0.5961\n",
            " Training bag [10/11] bag loss: 0.5806\n",
            " Testing bag [0/6] bag loss: 0.5802\n",
            " Testing bag [1/6] bag loss: 0.7326\n",
            " Testing bag [2/6] bag loss: 0.5797\n",
            " Testing bag [3/6] bag loss: 0.5889\n",
            " Testing bag [4/6] bag loss: 0.6110\n",
            " Testing bag [5/6] bag loss: 0.6025ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [170/300] train loss: 0.6152 test loss: 0.6158, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5806\n",
            " Training bag [1/11] bag loss: 0.5936\n",
            " Training bag [2/11] bag loss: 0.5644\n",
            " Training bag [3/11] bag loss: 0.5906\n",
            " Training bag [4/11] bag loss: 0.7199\n",
            " Training bag [5/11] bag loss: 0.5835\n",
            " Training bag [6/11] bag loss: 0.7087\n",
            " Training bag [7/11] bag loss: 0.6944\n",
            " Training bag [8/11] bag loss: 0.5768\n",
            " Training bag [9/11] bag loss: 0.5828\n",
            " Training bag [10/11] bag loss: 0.5778\n",
            " Testing bag [0/6] bag loss: 0.5813\n",
            " Testing bag [1/6] bag loss: 0.7340\n",
            " Testing bag [2/6] bag loss: 0.5771\n",
            " Testing bag [3/6] bag loss: 0.5916\n",
            " Testing bag [4/6] bag loss: 0.6099\n",
            " Testing bag [5/6] bag loss: 0.6017ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [171/300] train loss: 0.6157 test loss: 0.6159, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5954\n",
            " Training bag [1/11] bag loss: 0.6924\n",
            " Training bag [2/11] bag loss: 0.5828\n",
            " Training bag [3/11] bag loss: 0.5824\n",
            " Training bag [4/11] bag loss: 0.7020\n",
            " Training bag [5/11] bag loss: 0.5898\n",
            " Training bag [6/11] bag loss: 0.5797\n",
            " Training bag [7/11] bag loss: 0.5759\n",
            " Training bag [8/11] bag loss: 0.5801\n",
            " Training bag [9/11] bag loss: 0.5675\n",
            " Training bag [10/11] bag loss: 0.7204\n",
            " Testing bag [0/6] bag loss: 0.5800\n",
            " Testing bag [1/6] bag loss: 0.7346\n",
            " Testing bag [2/6] bag loss: 0.5816\n",
            " Testing bag [3/6] bag loss: 0.5888\n",
            " Testing bag [4/6] bag loss: 0.6096\n",
            " Testing bag [5/6] bag loss: 0.6014ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [172/300] train loss: 0.6153 test loss: 0.6160, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5787\n",
            " Training bag [1/11] bag loss: 0.5829\n",
            " Training bag [2/11] bag loss: 0.5748\n",
            " Training bag [3/11] bag loss: 0.6934\n",
            " Training bag [4/11] bag loss: 0.7030\n",
            " Training bag [5/11] bag loss: 0.5787\n",
            " Training bag [6/11] bag loss: 0.5917\n",
            " Training bag [7/11] bag loss: 0.5953\n",
            " Training bag [8/11] bag loss: 0.5647\n",
            " Training bag [9/11] bag loss: 0.7194\n",
            " Training bag [10/11] bag loss: 0.5810\n",
            " Testing bag [0/6] bag loss: 0.5797\n",
            " Testing bag [1/6] bag loss: 0.7344\n",
            " Testing bag [2/6] bag loss: 0.5807\n",
            " Testing bag [3/6] bag loss: 0.5865\n",
            " Testing bag [4/6] bag loss: 0.6111\n",
            " Testing bag [5/6] bag loss: 0.6025ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [173/300] train loss: 0.6149 test loss: 0.6158, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7020\n",
            " Training bag [1/11] bag loss: 0.7175\n",
            " Training bag [2/11] bag loss: 0.5815\n",
            " Training bag [3/11] bag loss: 0.5742\n",
            " Training bag [4/11] bag loss: 0.5849\n",
            " Training bag [5/11] bag loss: 0.6962\n",
            " Training bag [6/11] bag loss: 0.5625\n",
            " Training bag [7/11] bag loss: 0.5926\n",
            " Training bag [8/11] bag loss: 0.5973\n",
            " Training bag [9/11] bag loss: 0.5800\n",
            " Training bag [10/11] bag loss: 0.5811\n",
            " Testing bag [0/6] bag loss: 0.5803\n",
            " Testing bag [1/6] bag loss: 0.7328\n",
            " Testing bag [2/6] bag loss: 0.5795\n",
            " Testing bag [3/6] bag loss: 0.5890\n",
            " Testing bag [4/6] bag loss: 0.6110\n",
            " Testing bag [5/6] bag loss: 0.6026ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [174/300] train loss: 0.6154 test loss: 0.6159, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5659\n",
            " Training bag [1/11] bag loss: 0.5800\n",
            " Training bag [2/11] bag loss: 0.5716\n",
            " Training bag [3/11] bag loss: 0.5900\n",
            " Training bag [4/11] bag loss: 0.7048\n",
            " Training bag [5/11] bag loss: 0.6934\n",
            " Training bag [6/11] bag loss: 0.5826\n",
            " Training bag [7/11] bag loss: 0.7181\n",
            " Training bag [8/11] bag loss: 0.5961\n",
            " Training bag [9/11] bag loss: 0.5807\n",
            " Training bag [10/11] bag loss: 0.5792\n",
            " Testing bag [0/6] bag loss: 0.5803\n",
            " Testing bag [1/6] bag loss: 0.7351\n",
            " Testing bag [2/6] bag loss: 0.5819\n",
            " Testing bag [3/6] bag loss: 0.5883\n",
            " Testing bag [4/6] bag loss: 0.6117\n",
            " Testing bag [5/6] bag loss: 0.6026ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [175/300] train loss: 0.6148 test loss: 0.6167, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5800\n",
            " Training bag [1/11] bag loss: 0.5639\n",
            " Training bag [2/11] bag loss: 0.5708\n",
            " Training bag [3/11] bag loss: 0.5799\n",
            " Training bag [4/11] bag loss: 0.5954\n",
            " Training bag [5/11] bag loss: 0.7057\n",
            " Training bag [6/11] bag loss: 0.5780\n",
            " Training bag [7/11] bag loss: 0.5812\n",
            " Training bag [8/11] bag loss: 0.6980\n",
            " Training bag [9/11] bag loss: 0.5886\n",
            " Training bag [10/11] bag loss: 0.7199\n",
            " Testing bag [0/6] bag loss: 0.5801\n",
            " Testing bag [1/6] bag loss: 0.7351\n",
            " Testing bag [2/6] bag loss: 0.5797\n",
            " Testing bag [3/6] bag loss: 0.5872\n",
            " Testing bag [4/6] bag loss: 0.6092\n",
            " Testing bag [5/6] bag loss: 0.6016ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [176/300] train loss: 0.6147 test loss: 0.6155, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6942\n",
            " Training bag [1/11] bag loss: 0.5814\n",
            " Training bag [2/11] bag loss: 0.5729\n",
            " Training bag [3/11] bag loss: 0.7013\n",
            " Training bag [4/11] bag loss: 0.5792\n",
            " Training bag [5/11] bag loss: 0.5908\n",
            " Training bag [6/11] bag loss: 0.5642\n",
            " Training bag [7/11] bag loss: 0.5785\n",
            " Training bag [8/11] bag loss: 0.5969\n",
            " Training bag [9/11] bag loss: 0.5824\n",
            " Training bag [10/11] bag loss: 0.7196\n",
            " Testing bag [0/6] bag loss: 0.5803\n",
            " Testing bag [1/6] bag loss: 0.7361\n",
            " Testing bag [2/6] bag loss: 0.5797\n",
            " Testing bag [3/6] bag loss: 0.5904\n",
            " Testing bag [4/6] bag loss: 0.6099\n",
            " Testing bag [5/6] bag loss: 0.6005ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [177/300] train loss: 0.6147 test loss: 0.6162, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7189\n",
            " Training bag [1/11] bag loss: 0.5940\n",
            " Training bag [2/11] bag loss: 0.6910\n",
            " Training bag [3/11] bag loss: 0.7015\n",
            " Training bag [4/11] bag loss: 0.5819\n",
            " Training bag [5/11] bag loss: 0.5838\n",
            " Training bag [6/11] bag loss: 0.5813\n",
            " Training bag [7/11] bag loss: 0.5888\n",
            " Training bag [8/11] bag loss: 0.5744\n",
            " Training bag [9/11] bag loss: 0.5636\n",
            " Training bag [10/11] bag loss: 0.5804\n",
            " Testing bag [0/6] bag loss: 0.5801\n",
            " Testing bag [1/6] bag loss: 0.7350\n",
            " Testing bag [2/6] bag loss: 0.5781\n",
            " Testing bag [3/6] bag loss: 0.5866\n",
            " Testing bag [4/6] bag loss: 0.6101\n",
            " Testing bag [5/6] bag loss: 0.6009ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [178/300] train loss: 0.6145 test loss: 0.6151, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5655\n",
            " Training bag [1/11] bag loss: 0.5795\n",
            " Training bag [2/11] bag loss: 0.5723\n",
            " Training bag [3/11] bag loss: 0.5975\n",
            " Training bag [4/11] bag loss: 0.5786\n",
            " Training bag [5/11] bag loss: 0.7218\n",
            " Training bag [6/11] bag loss: 0.7048\n",
            " Training bag [7/11] bag loss: 0.5794\n",
            " Training bag [8/11] bag loss: 0.5905\n",
            " Training bag [9/11] bag loss: 0.5797\n",
            " Training bag [10/11] bag loss: 0.7006\n",
            " Testing bag [0/6] bag loss: 0.5797\n",
            " Testing bag [1/6] bag loss: 0.7355\n",
            " Testing bag [2/6] bag loss: 0.5780\n",
            " Testing bag [3/6] bag loss: 0.5873\n",
            " Testing bag [4/6] bag loss: 0.6101\n",
            " Testing bag [5/6] bag loss: 0.6020ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [179/300] train loss: 0.6155 test loss: 0.6154, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5935\n",
            " Training bag [1/11] bag loss: 0.7073\n",
            " Training bag [2/11] bag loss: 0.5757\n",
            " Training bag [3/11] bag loss: 0.5747\n",
            " Training bag [4/11] bag loss: 0.5866\n",
            " Training bag [5/11] bag loss: 0.5772\n",
            " Training bag [6/11] bag loss: 0.5821\n",
            " Training bag [7/11] bag loss: 0.5664\n",
            " Training bag [8/11] bag loss: 0.7214\n",
            " Training bag [9/11] bag loss: 0.5830\n",
            " Training bag [10/11] bag loss: 0.6954\n",
            " Testing bag [0/6] bag loss: 0.5806\n",
            " Testing bag [1/6] bag loss: 0.7366\n",
            " Testing bag [2/6] bag loss: 0.5794\n",
            " Testing bag [3/6] bag loss: 0.5894\n",
            " Testing bag [4/6] bag loss: 0.6092\n",
            " Testing bag [5/6] bag loss: 0.6006ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [180/300] train loss: 0.6149 test loss: 0.6160, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5765\n",
            " Training bag [1/11] bag loss: 0.7103\n",
            " Training bag [2/11] bag loss: 0.5746\n",
            " Training bag [3/11] bag loss: 0.7062\n",
            " Training bag [4/11] bag loss: 0.5937\n",
            " Training bag [5/11] bag loss: 0.5777\n",
            " Training bag [6/11] bag loss: 0.5661\n",
            " Training bag [7/11] bag loss: 0.5841\n",
            " Training bag [8/11] bag loss: 0.7188\n",
            " Training bag [9/11] bag loss: 0.5914\n",
            " Training bag [10/11] bag loss: 0.5830\n",
            " Testing bag [0/6] bag loss: 0.5796\n",
            " Testing bag [1/6] bag loss: 0.7351\n",
            " Testing bag [2/6] bag loss: 0.5793\n",
            " Testing bag [3/6] bag loss: 0.5900\n",
            " Testing bag [4/6] bag loss: 0.6095\n",
            " Testing bag [5/6] bag loss: 0.6012ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [181/300] train loss: 0.6166 test loss: 0.6158, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7064\n",
            " Training bag [1/11] bag loss: 0.5766\n",
            " Training bag [2/11] bag loss: 0.5825\n",
            " Training bag [3/11] bag loss: 0.5671\n",
            " Training bag [4/11] bag loss: 0.5790\n",
            " Training bag [5/11] bag loss: 0.5875\n",
            " Training bag [6/11] bag loss: 0.5950\n",
            " Training bag [7/11] bag loss: 0.7217\n",
            " Training bag [8/11] bag loss: 0.6962\n",
            " Training bag [9/11] bag loss: 0.5817\n",
            " Training bag [10/11] bag loss: 0.5745\n",
            " Testing bag [0/6] bag loss: 0.5811\n",
            " Testing bag [1/6] bag loss: 0.7346\n",
            " Testing bag [2/6] bag loss: 0.5792\n",
            " Testing bag [3/6] bag loss: 0.5838\n",
            " Testing bag [4/6] bag loss: 0.6097\n",
            " Testing bag [5/6] bag loss: 0.5990ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [182/300] train loss: 0.6153 test loss: 0.6146, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5929\n",
            " Training bag [1/11] bag loss: 0.7087\n",
            " Training bag [2/11] bag loss: 0.5757\n",
            " Training bag [3/11] bag loss: 0.5827\n",
            " Training bag [4/11] bag loss: 0.7015\n",
            " Training bag [5/11] bag loss: 0.5758\n",
            " Training bag [6/11] bag loss: 0.7186\n",
            " Training bag [7/11] bag loss: 0.5651\n",
            " Training bag [8/11] bag loss: 0.5748\n",
            " Training bag [9/11] bag loss: 0.5886\n",
            " Training bag [10/11] bag loss: 0.5805\n",
            " Testing bag [0/6] bag loss: 0.5799\n",
            " Testing bag [1/6] bag loss: 0.7342\n",
            " Testing bag [2/6] bag loss: 0.5788\n",
            " Testing bag [3/6] bag loss: 0.5908\n",
            " Testing bag [4/6] bag loss: 0.6092\n",
            " Testing bag [5/6] bag loss: 0.5997ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [183/300] train loss: 0.6150 test loss: 0.6154, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6928\n",
            " Training bag [1/11] bag loss: 0.5770\n",
            " Training bag [2/11] bag loss: 0.7190\n",
            " Training bag [3/11] bag loss: 0.5948\n",
            " Training bag [4/11] bag loss: 0.5762\n",
            " Training bag [5/11] bag loss: 0.5771\n",
            " Training bag [6/11] bag loss: 0.5832\n",
            " Training bag [7/11] bag loss: 0.5635\n",
            " Training bag [8/11] bag loss: 0.5876\n",
            " Training bag [9/11] bag loss: 0.5802\n",
            " Training bag [10/11] bag loss: 0.7034\n",
            " Testing bag [0/6] bag loss: 0.5809\n",
            " Testing bag [1/6] bag loss: 0.7374\n",
            " Testing bag [2/6] bag loss: 0.5781\n",
            " Testing bag [3/6] bag loss: 0.5900\n",
            " Testing bag [4/6] bag loss: 0.6100\n",
            " Testing bag [5/6] bag loss: 0.6012ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [184/300] train loss: 0.6141 test loss: 0.6162, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5756\n",
            " Training bag [1/11] bag loss: 0.7097\n",
            " Training bag [2/11] bag loss: 0.5813\n",
            " Training bag [3/11] bag loss: 0.5806\n",
            " Training bag [4/11] bag loss: 0.5874\n",
            " Training bag [5/11] bag loss: 0.7050\n",
            " Training bag [6/11] bag loss: 0.5723\n",
            " Training bag [7/11] bag loss: 0.5769\n",
            " Training bag [8/11] bag loss: 0.5932\n",
            " Training bag [9/11] bag loss: 0.5657\n",
            " Training bag [10/11] bag loss: 0.7210\n",
            " Testing bag [0/6] bag loss: 0.5810\n",
            " Testing bag [1/6] bag loss: 0.7382\n",
            " Testing bag [2/6] bag loss: 0.5785\n",
            " Testing bag [3/6] bag loss: 0.5864\n",
            " Testing bag [4/6] bag loss: 0.6087\n",
            " Testing bag [5/6] bag loss: 0.6014ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [185/300] train loss: 0.6153 test loss: 0.6157, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7193\n",
            " Training bag [1/11] bag loss: 0.7086\n",
            " Training bag [2/11] bag loss: 0.5817\n",
            " Training bag [3/11] bag loss: 0.5724\n",
            " Training bag [4/11] bag loss: 0.5784\n",
            " Training bag [5/11] bag loss: 0.5798\n",
            " Training bag [6/11] bag loss: 0.5955\n",
            " Training bag [7/11] bag loss: 0.5918\n",
            " Training bag [8/11] bag loss: 0.6920\n",
            " Training bag [9/11] bag loss: 0.5755\n",
            " Training bag [10/11] bag loss: 0.5618\n",
            " Testing bag [0/6] bag loss: 0.5802\n",
            " Testing bag [1/6] bag loss: 0.7357\n",
            " Testing bag [2/6] bag loss: 0.5787\n",
            " Testing bag [3/6] bag loss: 0.5842\n",
            " Testing bag [4/6] bag loss: 0.6104\n",
            " Testing bag [5/6] bag loss: 0.6008ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [186/300] train loss: 0.6143 test loss: 0.6150, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5822\n",
            " Training bag [1/11] bag loss: 0.5771\n",
            " Training bag [2/11] bag loss: 0.5873\n",
            " Training bag [3/11] bag loss: 0.5786\n",
            " Training bag [4/11] bag loss: 0.5811\n",
            " Training bag [5/11] bag loss: 0.6950\n",
            " Training bag [6/11] bag loss: 0.7043\n",
            " Training bag [7/11] bag loss: 0.5653\n",
            " Training bag [8/11] bag loss: 0.7197\n",
            " Training bag [9/11] bag loss: 0.5937\n",
            " Training bag [10/11] bag loss: 0.5748\n",
            " Testing bag [0/6] bag loss: 0.5810\n",
            " Testing bag [1/6] bag loss: 0.7347\n",
            " Testing bag [2/6] bag loss: 0.5790\n",
            " Testing bag [3/6] bag loss: 0.5856\n",
            " Testing bag [4/6] bag loss: 0.6091\n",
            " Testing bag [5/6] bag loss: 0.6012ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [187/300] train loss: 0.6145 test loss: 0.6151, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5826\n",
            " Training bag [1/11] bag loss: 0.7188\n",
            " Training bag [2/11] bag loss: 0.5808\n",
            " Training bag [3/11] bag loss: 0.5722\n",
            " Training bag [4/11] bag loss: 0.5893\n",
            " Training bag [5/11] bag loss: 0.5786\n",
            " Training bag [6/11] bag loss: 0.6928\n",
            " Training bag [7/11] bag loss: 0.5604\n",
            " Training bag [8/11] bag loss: 0.7048\n",
            " Training bag [9/11] bag loss: 0.5787\n",
            " Training bag [10/11] bag loss: 0.5952\n",
            " Testing bag [0/6] bag loss: 0.5793\n",
            " Testing bag [1/6] bag loss: 0.7356\n",
            " Testing bag [2/6] bag loss: 0.5777\n",
            " Testing bag [3/6] bag loss: 0.5899\n",
            " Testing bag [4/6] bag loss: 0.6104\n",
            " Testing bag [5/6] bag loss: 0.6016ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [188/300] train loss: 0.6140 test loss: 0.6157, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7020\n",
            " Training bag [1/11] bag loss: 0.5624\n",
            " Training bag [2/11] bag loss: 0.7181\n",
            " Training bag [3/11] bag loss: 0.5781\n",
            " Training bag [4/11] bag loss: 0.5969\n",
            " Training bag [5/11] bag loss: 0.5804\n",
            " Training bag [6/11] bag loss: 0.5764\n",
            " Training bag [7/11] bag loss: 0.5796\n",
            " Training bag [8/11] bag loss: 0.5889\n",
            " Training bag [9/11] bag loss: 0.5724\n",
            " Training bag [10/11] bag loss: 0.6925\n",
            " Testing bag [0/6] bag loss: 0.5794\n",
            " Testing bag [1/6] bag loss: 0.7370\n",
            " Testing bag [2/6] bag loss: 0.5781\n",
            " Testing bag [3/6] bag loss: 0.5896\n",
            " Testing bag [4/6] bag loss: 0.6085\n",
            " Testing bag [5/6] bag loss: 0.6003ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [189/300] train loss: 0.6134 test loss: 0.6155, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5756\n",
            " Training bag [1/11] bag loss: 0.5820\n",
            " Training bag [2/11] bag loss: 0.6958\n",
            " Training bag [3/11] bag loss: 0.5733\n",
            " Training bag [4/11] bag loss: 0.5765\n",
            " Training bag [5/11] bag loss: 0.7200\n",
            " Training bag [6/11] bag loss: 0.5790\n",
            " Training bag [7/11] bag loss: 0.5942\n",
            " Training bag [8/11] bag loss: 0.5890\n",
            " Training bag [9/11] bag loss: 0.7051\n",
            " Training bag [10/11] bag loss: 0.5633\n",
            " Testing bag [0/6] bag loss: 0.5793\n",
            " Testing bag [1/6] bag loss: 0.7376\n",
            " Testing bag [2/6] bag loss: 0.5786\n",
            " Testing bag [3/6] bag loss: 0.5885\n",
            " Testing bag [4/6] bag loss: 0.6093\n",
            " Testing bag [5/6] bag loss: 0.6008ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [190/300] train loss: 0.6140 test loss: 0.6157, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5777\n",
            " Training bag [1/11] bag loss: 0.6921\n",
            " Training bag [2/11] bag loss: 0.5760\n",
            " Training bag [3/11] bag loss: 0.5615\n",
            " Training bag [4/11] bag loss: 0.5800\n",
            " Training bag [5/11] bag loss: 0.7191\n",
            " Training bag [6/11] bag loss: 0.5880\n",
            " Training bag [7/11] bag loss: 0.7029\n",
            " Training bag [8/11] bag loss: 0.5950\n",
            " Training bag [9/11] bag loss: 0.5818\n",
            " Training bag [10/11] bag loss: 0.5816\n",
            " Testing bag [0/6] bag loss: 0.5801\n",
            " Testing bag [1/6] bag loss: 0.7336\n",
            " Testing bag [2/6] bag loss: 0.5801\n",
            " Testing bag [3/6] bag loss: 0.5892\n",
            " Testing bag [4/6] bag loss: 0.6090\n",
            " Testing bag [5/6] bag loss: 0.5998ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [191/300] train loss: 0.6142 test loss: 0.6153, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5625\n",
            " Training bag [1/11] bag loss: 0.5787\n",
            " Training bag [2/11] bag loss: 0.7072\n",
            " Training bag [3/11] bag loss: 0.5790\n",
            " Training bag [4/11] bag loss: 0.5793\n",
            " Training bag [5/11] bag loss: 0.5791\n",
            " Training bag [6/11] bag loss: 0.6955\n",
            " Training bag [7/11] bag loss: 0.5729\n",
            " Training bag [8/11] bag loss: 0.7187\n",
            " Training bag [9/11] bag loss: 0.5948\n",
            " Training bag [10/11] bag loss: 0.5909\n",
            " Testing bag [0/6] bag loss: 0.5790\n",
            " Testing bag [1/6] bag loss: 0.7344\n",
            " Testing bag [2/6] bag loss: 0.5785\n",
            " Testing bag [3/6] bag loss: 0.5897\n",
            " Testing bag [4/6] bag loss: 0.6106\n",
            " Testing bag [5/6] bag loss: 0.6011ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [192/300] train loss: 0.6144 test loss: 0.6155, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5606\n",
            " Training bag [1/11] bag loss: 0.5790\n",
            " Training bag [2/11] bag loss: 0.5795\n",
            " Training bag [3/11] bag loss: 0.5794\n",
            " Training bag [4/11] bag loss: 0.5868\n",
            " Training bag [5/11] bag loss: 0.5810\n",
            " Training bag [6/11] bag loss: 0.5726\n",
            " Training bag [7/11] bag loss: 0.7219\n",
            " Training bag [8/11] bag loss: 0.5925\n",
            " Training bag [9/11] bag loss: 0.6943\n",
            " Training bag [10/11] bag loss: 0.7093\n",
            " Testing bag [0/6] bag loss: 0.5792\n",
            " Testing bag [1/6] bag loss: 0.7382\n",
            " Testing bag [2/6] bag loss: 0.5779\n",
            " Testing bag [3/6] bag loss: 0.5882\n",
            " Testing bag [4/6] bag loss: 0.6098\n",
            " Testing bag [5/6] bag loss: 0.6007ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [193/300] train loss: 0.6143 test loss: 0.6157, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5717\n",
            " Training bag [1/11] bag loss: 0.7234\n",
            " Training bag [2/11] bag loss: 0.5633\n",
            " Training bag [3/11] bag loss: 0.5963\n",
            " Training bag [4/11] bag loss: 0.5878\n",
            " Training bag [5/11] bag loss: 0.5807\n",
            " Training bag [6/11] bag loss: 0.6940\n",
            " Training bag [7/11] bag loss: 0.5786\n",
            " Training bag [8/11] bag loss: 0.7057\n",
            " Training bag [9/11] bag loss: 0.5791\n",
            " Training bag [10/11] bag loss: 0.5787\n",
            " Testing bag [0/6] bag loss: 0.5794\n",
            " Testing bag [1/6] bag loss: 0.7362\n",
            " Testing bag [2/6] bag loss: 0.5769\n",
            " Testing bag [3/6] bag loss: 0.5878\n",
            " Testing bag [4/6] bag loss: 0.6103\n",
            " Testing bag [5/6] bag loss: 0.6006ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [194/300] train loss: 0.6145 test loss: 0.6152, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5791\n",
            " Training bag [1/11] bag loss: 0.5755\n",
            " Training bag [2/11] bag loss: 0.5881\n",
            " Training bag [3/11] bag loss: 0.5917\n",
            " Training bag [4/11] bag loss: 0.5724\n",
            " Training bag [5/11] bag loss: 0.7209\n",
            " Training bag [6/11] bag loss: 0.5807\n",
            " Training bag [7/11] bag loss: 0.5772\n",
            " Training bag [8/11] bag loss: 0.7065\n",
            " Training bag [9/11] bag loss: 0.6926\n",
            " Training bag [10/11] bag loss: 0.5629\n",
            " Testing bag [0/6] bag loss: 0.5795\n",
            " Testing bag [1/6] bag loss: 0.7352\n",
            " Testing bag [2/6] bag loss: 0.5781\n",
            " Testing bag [3/6] bag loss: 0.5855\n",
            " Testing bag [4/6] bag loss: 0.6089\n",
            " Testing bag [5/6] bag loss: 0.6009ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [195/300] train loss: 0.6134 test loss: 0.6147, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5634\n",
            " Training bag [1/11] bag loss: 0.6992\n",
            " Training bag [2/11] bag loss: 0.5768\n",
            " Training bag [3/11] bag loss: 0.5783\n",
            " Training bag [4/11] bag loss: 0.7030\n",
            " Training bag [5/11] bag loss: 0.7174\n",
            " Training bag [6/11] bag loss: 0.5800\n",
            " Training bag [7/11] bag loss: 0.5720\n",
            " Training bag [8/11] bag loss: 0.5951\n",
            " Training bag [9/11] bag loss: 0.5796\n",
            " Training bag [10/11] bag loss: 0.5875\n",
            " Testing bag [0/6] bag loss: 0.5780\n",
            " Testing bag [1/6] bag loss: 0.7354\n",
            " Testing bag [2/6] bag loss: 0.5762\n",
            " Testing bag [3/6] bag loss: 0.5891\n",
            " Testing bag [4/6] bag loss: 0.6099\n",
            " Testing bag [5/6] bag loss: 0.6019ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [196/300] train loss: 0.6139 test loss: 0.6151, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7020\n",
            " Training bag [1/11] bag loss: 0.6921\n",
            " Training bag [2/11] bag loss: 0.5638\n",
            " Training bag [3/11] bag loss: 0.5897\n",
            " Training bag [4/11] bag loss: 0.5827\n",
            " Training bag [5/11] bag loss: 0.5709\n",
            " Training bag [6/11] bag loss: 0.5773\n",
            " Training bag [7/11] bag loss: 0.7185\n",
            " Training bag [8/11] bag loss: 0.5796\n",
            " Training bag [9/11] bag loss: 0.5794\n",
            " Training bag [10/11] bag loss: 0.5939\n",
            " Testing bag [0/6] bag loss: 0.5794\n",
            " Testing bag [1/6] bag loss: 0.7378\n",
            " Testing bag [2/6] bag loss: 0.5784\n",
            " Testing bag [3/6] bag loss: 0.5885\n",
            " Testing bag [4/6] bag loss: 0.6094\n",
            " Testing bag [5/6] bag loss: 0.6021ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [197/300] train loss: 0.6136 test loss: 0.6159, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6946\n",
            " Training bag [1/11] bag loss: 0.5805\n",
            " Training bag [2/11] bag loss: 0.5960\n",
            " Training bag [3/11] bag loss: 0.7025\n",
            " Training bag [4/11] bag loss: 0.5755\n",
            " Training bag [5/11] bag loss: 0.5761\n",
            " Training bag [6/11] bag loss: 0.5651\n",
            " Training bag [7/11] bag loss: 0.5888\n",
            " Training bag [8/11] bag loss: 0.7206\n",
            " Training bag [9/11] bag loss: 0.5794\n",
            " Training bag [10/11] bag loss: 0.5794\n",
            " Testing bag [0/6] bag loss: 0.5792\n",
            " Testing bag [1/6] bag loss: 0.7387\n",
            " Testing bag [2/6] bag loss: 0.5775\n",
            " Testing bag [3/6] bag loss: 0.5899\n",
            " Testing bag [4/6] bag loss: 0.6099\n",
            " Testing bag [5/6] bag loss: 0.6009ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [198/300] train loss: 0.6144 test loss: 0.6160, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5872\n",
            " Training bag [1/11] bag loss: 0.5612\n",
            " Training bag [2/11] bag loss: 0.5958\n",
            " Training bag [3/11] bag loss: 0.7059\n",
            " Training bag [4/11] bag loss: 0.5779\n",
            " Training bag [5/11] bag loss: 0.5740\n",
            " Training bag [6/11] bag loss: 0.6938\n",
            " Training bag [7/11] bag loss: 0.7197\n",
            " Training bag [8/11] bag loss: 0.5828\n",
            " Training bag [9/11] bag loss: 0.5758\n",
            " Training bag [10/11] bag loss: 0.5811\n",
            " Testing bag [0/6] bag loss: 0.5807\n",
            " Testing bag [1/6] bag loss: 0.7364\n",
            " Testing bag [2/6] bag loss: 0.5796\n",
            " Testing bag [3/6] bag loss: 0.5848\n",
            " Testing bag [4/6] bag loss: 0.6091\n",
            " Testing bag [5/6] bag loss: 0.6005ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [199/300] train loss: 0.6141 test loss: 0.6152, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7042\n",
            " Training bag [1/11] bag loss: 0.5730\n",
            " Training bag [2/11] bag loss: 0.5913\n",
            " Training bag [3/11] bag loss: 0.5759\n",
            " Training bag [4/11] bag loss: 0.5934\n",
            " Training bag [5/11] bag loss: 0.7195\n",
            " Training bag [6/11] bag loss: 0.5800\n",
            " Training bag [7/11] bag loss: 0.6945\n",
            " Training bag [8/11] bag loss: 0.5826\n",
            " Training bag [9/11] bag loss: 0.5621\n",
            " Training bag [10/11] bag loss: 0.5763\n",
            " Testing bag [0/6] bag loss: 0.5799\n",
            " Testing bag [1/6] bag loss: 0.7386\n",
            " Testing bag [2/6] bag loss: 0.5794\n",
            " Testing bag [3/6] bag loss: 0.5863\n",
            " Testing bag [4/6] bag loss: 0.6104\n",
            " Testing bag [5/6] bag loss: 0.6015ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [200/300] train loss: 0.6139 test loss: 0.6160, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5763\n",
            " Training bag [1/11] bag loss: 0.6911\n",
            " Training bag [2/11] bag loss: 0.5613\n",
            " Training bag [3/11] bag loss: 0.7184\n",
            " Training bag [4/11] bag loss: 0.5899\n",
            " Training bag [5/11] bag loss: 0.5961\n",
            " Training bag [6/11] bag loss: 0.5742\n",
            " Training bag [7/11] bag loss: 0.5726\n",
            " Training bag [8/11] bag loss: 0.7022\n",
            " Training bag [9/11] bag loss: 0.5811\n",
            " Training bag [10/11] bag loss: 0.5801\n",
            " Testing bag [0/6] bag loss: 0.5790\n",
            " Testing bag [1/6] bag loss: 0.7370\n",
            " Testing bag [2/6] bag loss: 0.5795\n",
            " Testing bag [3/6] bag loss: 0.5856\n",
            " Testing bag [4/6] bag loss: 0.6096\n",
            " Testing bag [5/6] bag loss: 0.6012ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [201/300] train loss: 0.6130 test loss: 0.6153, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7187\n",
            " Training bag [1/11] bag loss: 0.5795\n",
            " Training bag [2/11] bag loss: 0.5784\n",
            " Training bag [3/11] bag loss: 0.7070\n",
            " Training bag [4/11] bag loss: 0.5793\n",
            " Training bag [5/11] bag loss: 0.5896\n",
            " Training bag [6/11] bag loss: 0.5725\n",
            " Training bag [7/11] bag loss: 0.5957\n",
            " Training bag [8/11] bag loss: 0.7017\n",
            " Training bag [9/11] bag loss: 0.5625\n",
            " Training bag [10/11] bag loss: 0.5762\n",
            " Testing bag [0/6] bag loss: 0.5803\n",
            " Testing bag [1/6] bag loss: 0.7379\n",
            " Testing bag [2/6] bag loss: 0.5803\n",
            " Testing bag [3/6] bag loss: 0.5862\n",
            " Testing bag [4/6] bag loss: 0.6096\n",
            " Testing bag [5/6] bag loss: 0.6011ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [202/300] train loss: 0.6147 test loss: 0.6159, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7041\n",
            " Training bag [1/11] bag loss: 0.5736\n",
            " Training bag [2/11] bag loss: 0.5785\n",
            " Training bag [3/11] bag loss: 0.5873\n",
            " Training bag [4/11] bag loss: 0.6909\n",
            " Training bag [5/11] bag loss: 0.5815\n",
            " Training bag [6/11] bag loss: 0.5621\n",
            " Training bag [7/11] bag loss: 0.7184\n",
            " Training bag [8/11] bag loss: 0.5798\n",
            " Training bag [9/11] bag loss: 0.5768\n",
            " Training bag [10/11] bag loss: 0.5945\n",
            " Testing bag [0/6] bag loss: 0.5796\n",
            " Testing bag [1/6] bag loss: 0.7387\n",
            " Testing bag [2/6] bag loss: 0.5767\n",
            " Testing bag [3/6] bag loss: 0.5867\n",
            " Testing bag [4/6] bag loss: 0.6106\n",
            " Testing bag [5/6] bag loss: 0.6023ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [203/300] train loss: 0.6134 test loss: 0.6158, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7197\n",
            " Training bag [1/11] bag loss: 0.5788\n",
            " Training bag [2/11] bag loss: 0.5960\n",
            " Training bag [3/11] bag loss: 0.5810\n",
            " Training bag [4/11] bag loss: 0.5760\n",
            " Training bag [5/11] bag loss: 0.5706\n",
            " Training bag [6/11] bag loss: 0.5881\n",
            " Training bag [7/11] bag loss: 0.5615\n",
            " Training bag [8/11] bag loss: 0.7091\n",
            " Training bag [9/11] bag loss: 0.5768\n",
            " Training bag [10/11] bag loss: 0.6923\n",
            " Testing bag [0/6] bag loss: 0.5783\n",
            " Testing bag [1/6] bag loss: 0.7362\n",
            " Testing bag [2/6] bag loss: 0.5777\n",
            " Testing bag [3/6] bag loss: 0.5878\n",
            " Testing bag [4/6] bag loss: 0.6097\n",
            " Testing bag [5/6] bag loss: 0.6002ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [204/300] train loss: 0.6136 test loss: 0.6150, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7095\n",
            " Training bag [1/11] bag loss: 0.6907\n",
            " Training bag [2/11] bag loss: 0.5814\n",
            " Training bag [3/11] bag loss: 0.5755\n",
            " Training bag [4/11] bag loss: 0.5629\n",
            " Training bag [5/11] bag loss: 0.5796\n",
            " Training bag [6/11] bag loss: 0.5964\n",
            " Training bag [7/11] bag loss: 0.7189\n",
            " Training bag [8/11] bag loss: 0.5780\n",
            " Training bag [9/11] bag loss: 0.5913\n",
            " Training bag [10/11] bag loss: 0.5736\n",
            " Testing bag [0/6] bag loss: 0.5790\n",
            " Testing bag [1/6] bag loss: 0.7361\n",
            " Testing bag [2/6] bag loss: 0.5764\n",
            " Testing bag [3/6] bag loss: 0.5894\n",
            " Testing bag [4/6] bag loss: 0.6106\n",
            " Testing bag [5/6] bag loss: 0.6008ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [205/300] train loss: 0.6143 test loss: 0.6154, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5955\n",
            " Training bag [1/11] bag loss: 0.5629\n",
            " Training bag [2/11] bag loss: 0.7199\n",
            " Training bag [3/11] bag loss: 0.5799\n",
            " Training bag [4/11] bag loss: 0.5751\n",
            " Training bag [5/11] bag loss: 0.5779\n",
            " Training bag [6/11] bag loss: 0.5747\n",
            " Training bag [7/11] bag loss: 0.6998\n",
            " Training bag [8/11] bag loss: 0.5881\n",
            " Training bag [9/11] bag loss: 0.7076\n",
            " Training bag [10/11] bag loss: 0.5719\n",
            " Testing bag [0/6] bag loss: 0.5803\n",
            " Testing bag [1/6] bag loss: 0.7365\n",
            " Testing bag [2/6] bag loss: 0.5781\n",
            " Testing bag [3/6] bag loss: 0.5880\n",
            " Testing bag [4/6] bag loss: 0.6093\n",
            " Testing bag [5/6] bag loss: 0.6010ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [206/300] train loss: 0.6139 test loss: 0.6155, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5804\n",
            " Training bag [1/11] bag loss: 0.5618\n",
            " Training bag [2/11] bag loss: 0.6945\n",
            " Training bag [3/11] bag loss: 0.5795\n",
            " Training bag [4/11] bag loss: 0.5938\n",
            " Training bag [5/11] bag loss: 0.5778\n",
            " Training bag [6/11] bag loss: 0.5776\n",
            " Training bag [7/11] bag loss: 0.5709\n",
            " Training bag [8/11] bag loss: 0.7220\n",
            " Training bag [9/11] bag loss: 0.5885\n",
            " Training bag [10/11] bag loss: 0.7074\n",
            " Testing bag [0/6] bag loss: 0.5784\n",
            " Testing bag [1/6] bag loss: 0.7383\n",
            " Testing bag [2/6] bag loss: 0.5772\n",
            " Testing bag [3/6] bag loss: 0.5858\n",
            " Testing bag [4/6] bag loss: 0.6104\n",
            " Testing bag [5/6] bag loss: 0.6005ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [207/300] train loss: 0.6140 test loss: 0.6151, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5605\n",
            " Training bag [1/11] bag loss: 0.5923\n",
            " Training bag [2/11] bag loss: 0.6928\n",
            " Training bag [3/11] bag loss: 0.5750\n",
            " Training bag [4/11] bag loss: 0.5861\n",
            " Training bag [5/11] bag loss: 0.7048\n",
            " Training bag [6/11] bag loss: 0.5797\n",
            " Training bag [7/11] bag loss: 0.5802\n",
            " Training bag [8/11] bag loss: 0.5731\n",
            " Training bag [9/11] bag loss: 0.7208\n",
            " Training bag [10/11] bag loss: 0.5753\n",
            " Testing bag [0/6] bag loss: 0.5792\n",
            " Testing bag [1/6] bag loss: 0.7352\n",
            " Testing bag [2/6] bag loss: 0.5756\n",
            " Testing bag [3/6] bag loss: 0.5866\n",
            " Testing bag [4/6] bag loss: 0.6094\n",
            " Testing bag [5/6] bag loss: 0.6022ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [208/300] train loss: 0.6128 test loss: 0.6147, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5756\n",
            " Training bag [1/11] bag loss: 0.5805\n",
            " Training bag [2/11] bag loss: 0.7203\n",
            " Training bag [3/11] bag loss: 0.5957\n",
            " Training bag [4/11] bag loss: 0.5744\n",
            " Training bag [5/11] bag loss: 0.5864\n",
            " Training bag [6/11] bag loss: 0.7032\n",
            " Training bag [7/11] bag loss: 0.5654\n",
            " Training bag [8/11] bag loss: 0.5737\n",
            " Training bag [9/11] bag loss: 0.5794\n",
            " Training bag [10/11] bag loss: 0.6928\n",
            " Testing bag [0/6] bag loss: 0.5791\n",
            " Testing bag [1/6] bag loss: 0.7391\n",
            " Testing bag [2/6] bag loss: 0.5789\n",
            " Testing bag [3/6] bag loss: 0.5858\n",
            " Testing bag [4/6] bag loss: 0.6093\n",
            " Testing bag [5/6] bag loss: 0.6013ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [209/300] train loss: 0.6134 test loss: 0.6156, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5928\n",
            " Training bag [1/11] bag loss: 0.6925\n",
            " Training bag [2/11] bag loss: 0.5886\n",
            " Training bag [3/11] bag loss: 0.5741\n",
            " Training bag [4/11] bag loss: 0.7192\n",
            " Training bag [5/11] bag loss: 0.5735\n",
            " Training bag [6/11] bag loss: 0.7015\n",
            " Training bag [7/11] bag loss: 0.5807\n",
            " Training bag [8/11] bag loss: 0.5749\n",
            " Training bag [9/11] bag loss: 0.5809\n",
            " Training bag [10/11] bag loss: 0.5633\n",
            " Testing bag [0/6] bag loss: 0.5798\n",
            " Testing bag [1/6] bag loss: 0.7366\n",
            " Testing bag [2/6] bag loss: 0.5790\n",
            " Testing bag [3/6] bag loss: 0.5870\n",
            " Testing bag [4/6] bag loss: 0.6096\n",
            " Testing bag [5/6] bag loss: 0.6003ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [210/300] train loss: 0.6129 test loss: 0.6154, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7190\n",
            " Training bag [1/11] bag loss: 0.5732\n",
            " Training bag [2/11] bag loss: 0.7012\n",
            " Training bag [3/11] bag loss: 0.5758\n",
            " Training bag [4/11] bag loss: 0.5784\n",
            " Training bag [5/11] bag loss: 0.5940\n",
            " Training bag [6/11] bag loss: 0.5789\n",
            " Training bag [7/11] bag loss: 0.5870\n",
            " Training bag [8/11] bag loss: 0.6905\n",
            " Training bag [9/11] bag loss: 0.5594\n",
            " Training bag [10/11] bag loss: 0.5771\n",
            " Testing bag [0/6] bag loss: 0.5781\n",
            " Testing bag [1/6] bag loss: 0.7388\n",
            " Testing bag [2/6] bag loss: 0.5789\n",
            " Testing bag [3/6] bag loss: 0.5861\n",
            " Testing bag [4/6] bag loss: 0.6092\n",
            " Testing bag [5/6] bag loss: 0.6018ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [211/300] train loss: 0.6122 test loss: 0.6155, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5786\n",
            " Training bag [1/11] bag loss: 0.5602\n",
            " Training bag [2/11] bag loss: 0.5788\n",
            " Training bag [3/11] bag loss: 0.5774\n",
            " Training bag [4/11] bag loss: 0.5773\n",
            " Training bag [5/11] bag loss: 0.7033\n",
            " Training bag [6/11] bag loss: 0.5890\n",
            " Training bag [7/11] bag loss: 0.7214\n",
            " Training bag [8/11] bag loss: 0.5922\n",
            " Training bag [9/11] bag loss: 0.6911\n",
            " Training bag [10/11] bag loss: 0.5732\n",
            " Testing bag [0/6] bag loss: 0.5791\n",
            " Testing bag [1/6] bag loss: 0.7380\n",
            " Testing bag [2/6] bag loss: 0.5785\n",
            " Testing bag [3/6] bag loss: 0.5884\n",
            " Testing bag [4/6] bag loss: 0.6090\n",
            " Testing bag [5/6] bag loss: 0.6001ROC AUC score: 0.4444444444444445\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.875\n",
            "\n",
            " Epoch [212/300] train loss: 0.6129 test loss: 0.6155, average score: 0.5000, AUC: class-0>>0.4444444444444445|class-1>>1.0|class-2>>0.875\n",
            "\n",
            " Testing bag [0/4] bag loss: 0.6076\n",
            " Testing bag [1/4] bag loss: 0.7118\n",
            " Testing bag [2/4] bag loss: 0.5823\n",
            " Testing bag [3/4] bag loss: 0.5928ROC AUC score: 1.0\n",
            "ROC AUC score: 1.0\n",
            "ROC AUC score: 0.5\n",
            "âœ… Fold 2 completed | Test Acc: 0.7500 | Test AUCs: [np.float64(1.0), np.float64(1.0), np.float64(0.5)]\n",
            "\n",
            "ðŸŒ€ Starting CV Fold 3\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6888\n",
            " Training bag [1/11] bag loss: 0.7021\n",
            " Training bag [2/11] bag loss: 0.7118\n",
            " Training bag [3/11] bag loss: 0.7086\n",
            " Training bag [4/11] bag loss: 0.6897\n",
            " Training bag [5/11] bag loss: 0.7082\n",
            " Training bag [6/11] bag loss: 0.7027\n",
            " Training bag [7/11] bag loss: 0.6901\n",
            " Training bag [8/11] bag loss: 0.6990\n",
            " Training bag [9/11] bag loss: 0.7010\n",
            " Training bag [10/11] bag loss: 0.6791\n",
            " Testing bag [0/6] bag loss: 0.6850\n",
            " Testing bag [1/6] bag loss: 0.6995\n",
            " Testing bag [2/6] bag loss: 0.6974\n",
            " Testing bag [3/6] bag loss: 0.6865\n",
            " Testing bag [4/6] bag loss: 0.6878\n",
            " Testing bag [5/6] bag loss: 0.6942ROC AUC score: 0.375\n",
            "ROC AUC score: 0.19999999999999996\n",
            "ROC AUC score: 0.3333333333333333\n",
            "\n",
            " Epoch [1/300] train loss: 0.6983 test loss: 0.6917, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.19999999999999996|class-2>>0.3333333333333333\n",
            "Best model saved at: weights/20250626/fold_3_19.pth\n",
            "Best thresholds ===>>> class-0>>0.5026038885116577|class-1>>0.461749404668808|class-2>>0.492666095495224\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6858\n",
            " Training bag [1/11] bag loss: 0.6970\n",
            " Training bag [2/11] bag loss: 0.7025\n",
            " Training bag [3/11] bag loss: 0.7028\n",
            " Training bag [4/11] bag loss: 0.6844\n",
            " Training bag [5/11] bag loss: 0.6988\n",
            " Training bag [6/11] bag loss: 0.6964\n",
            " Training bag [7/11] bag loss: 0.6982\n",
            " Training bag [8/11] bag loss: 0.6968\n",
            " Training bag [9/11] bag loss: 0.6758\n",
            " Training bag [10/11] bag loss: 0.6792\n",
            " Testing bag [0/6] bag loss: 0.6801\n",
            " Testing bag [1/6] bag loss: 0.6936\n",
            " Testing bag [2/6] bag loss: 0.6931\n",
            " Testing bag [3/6] bag loss: 0.6818\n",
            " Testing bag [4/6] bag loss: 0.6841\n",
            " Testing bag [5/6] bag loss: 0.6929ROC AUC score: 0.375\n",
            "ROC AUC score: 0.19999999999999996\n",
            "ROC AUC score: 0.4444444444444444\n",
            "\n",
            " Epoch [2/300] train loss: 0.6925 test loss: 0.6876, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.19999999999999996|class-2>>0.4444444444444444\n",
            "Best model saved at: weights/20250626/fold_3_19.pth\n",
            "Best thresholds ===>>> class-0>>0.4934752881526947|class-1>>0.44985437393188477|class-2>>0.48346850275993347\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6929\n",
            " Training bag [1/11] bag loss: 0.6973\n",
            " Training bag [2/11] bag loss: 0.6965\n",
            " Training bag [3/11] bag loss: 0.6924\n",
            " Training bag [4/11] bag loss: 0.6825\n",
            " Training bag [5/11] bag loss: 0.6811\n",
            " Training bag [6/11] bag loss: 0.6959\n",
            " Training bag [7/11] bag loss: 0.6982\n",
            " Training bag [8/11] bag loss: 0.6912\n",
            " Training bag [9/11] bag loss: 0.6752\n",
            " Training bag [10/11] bag loss: 0.6695\n",
            " Testing bag [0/6] bag loss: 0.6749\n",
            " Testing bag [1/6] bag loss: 0.6882\n",
            " Testing bag [2/6] bag loss: 0.6884\n",
            " Testing bag [3/6] bag loss: 0.6744\n",
            " Testing bag [4/6] bag loss: 0.6768\n",
            " Testing bag [5/6] bag loss: 0.6923ROC AUC score: 0.375\n",
            "ROC AUC score: 0.19999999999999996\n",
            "ROC AUC score: 0.4444444444444444\n",
            "\n",
            " Epoch [3/300] train loss: 0.6884 test loss: 0.6825, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.19999999999999996|class-2>>0.4444444444444444\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6741\n",
            " Training bag [1/11] bag loss: 0.6953\n",
            " Training bag [2/11] bag loss: 0.6920\n",
            " Training bag [3/11] bag loss: 0.6902\n",
            " Training bag [4/11] bag loss: 0.6924\n",
            " Training bag [5/11] bag loss: 0.6898\n",
            " Training bag [6/11] bag loss: 0.6892\n",
            " Training bag [7/11] bag loss: 0.6673\n",
            " Training bag [8/11] bag loss: 0.6683\n",
            " Training bag [9/11] bag loss: 0.6973\n",
            " Training bag [10/11] bag loss: 0.6721\n",
            " Testing bag [0/6] bag loss: 0.6703\n",
            " Testing bag [1/6] bag loss: 0.6831\n",
            " Testing bag [2/6] bag loss: 0.6831\n",
            " Testing bag [3/6] bag loss: 0.6691\n",
            " Testing bag [4/6] bag loss: 0.6694\n",
            " Testing bag [5/6] bag loss: 0.6932ROC AUC score: 0.25\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.6666666666666666\n",
            "\n",
            " Epoch [4/300] train loss: 0.6843 test loss: 0.6780, average score: 0.3333, AUC: class-0>>0.25|class-1>>0.6|class-2>>0.6666666666666666\n",
            "Best model saved at: weights/20250626/fold_3_19.pth\n",
            "Best thresholds ===>>> class-0>>inf|class-1>>0.42700496315956116|class-2>>0.4698270559310913\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6834\n",
            " Training bag [1/11] bag loss: 0.6594\n",
            " Training bag [2/11] bag loss: 0.6829\n",
            " Training bag [3/11] bag loss: 0.6851\n",
            " Training bag [4/11] bag loss: 0.6672\n",
            " Training bag [5/11] bag loss: 0.6756\n",
            " Training bag [6/11] bag loss: 0.7023\n",
            " Training bag [7/11] bag loss: 0.7028\n",
            " Training bag [8/11] bag loss: 0.6964\n",
            " Training bag [9/11] bag loss: 0.6669\n",
            " Training bag [10/11] bag loss: 0.6618\n",
            " Testing bag [0/6] bag loss: 0.6659\n",
            " Testing bag [1/6] bag loss: 0.6784\n",
            " Testing bag [2/6] bag loss: 0.6796\n",
            " Testing bag [3/6] bag loss: 0.6636\n",
            " Testing bag [4/6] bag loss: 0.6667\n",
            " Testing bag [5/6] bag loss: 0.6926ROC AUC score: 0.25\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.6666666666666666\n",
            "\n",
            " Epoch [5/300] train loss: 0.6804 test loss: 0.6745, average score: 0.3333, AUC: class-0>>0.25|class-1>>0.6|class-2>>0.6666666666666666\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6611\n",
            " Training bag [1/11] bag loss: 0.6575\n",
            " Training bag [2/11] bag loss: 0.6834\n",
            " Training bag [3/11] bag loss: 0.6976\n",
            " Training bag [4/11] bag loss: 0.6948\n",
            " Training bag [5/11] bag loss: 0.6818\n",
            " Training bag [6/11] bag loss: 0.6590\n",
            " Training bag [7/11] bag loss: 0.6486\n",
            " Training bag [8/11] bag loss: 0.6796\n",
            " Training bag [9/11] bag loss: 0.6959\n",
            " Training bag [10/11] bag loss: 0.6837\n",
            " Testing bag [0/6] bag loss: 0.6580\n",
            " Testing bag [1/6] bag loss: 0.6773\n",
            " Testing bag [2/6] bag loss: 0.6781\n",
            " Testing bag [3/6] bag loss: 0.6561\n",
            " Testing bag [4/6] bag loss: 0.6590\n",
            " Testing bag [5/6] bag loss: 0.6930ROC AUC score: 0.25\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.6666666666666666\n",
            "\n",
            " Epoch [6/300] train loss: 0.6766 test loss: 0.6703, average score: 0.3333, AUC: class-0>>0.25|class-1>>0.6|class-2>>0.6666666666666666\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6935\n",
            " Training bag [1/11] bag loss: 0.6802\n",
            " Training bag [2/11] bag loss: 0.6556\n",
            " Training bag [3/11] bag loss: 0.6892\n",
            " Training bag [4/11] bag loss: 0.6778\n",
            " Training bag [5/11] bag loss: 0.6739\n",
            " Training bag [6/11] bag loss: 0.6600\n",
            " Training bag [7/11] bag loss: 0.6503\n",
            " Training bag [8/11] bag loss: 0.6949\n",
            " Training bag [9/11] bag loss: 0.6507\n",
            " Training bag [10/11] bag loss: 0.6764\n",
            " Testing bag [0/6] bag loss: 0.6564\n",
            " Testing bag [1/6] bag loss: 0.6734\n",
            " Testing bag [2/6] bag loss: 0.6746\n",
            " Testing bag [3/6] bag loss: 0.6531\n",
            " Testing bag [4/6] bag loss: 0.6560\n",
            " Testing bag [5/6] bag loss: 0.6921ROC AUC score: 0.25\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.6666666666666666\n",
            "\n",
            " Epoch [7/300] train loss: 0.6730 test loss: 0.6676, average score: 0.3333, AUC: class-0>>0.25|class-1>>0.6|class-2>>0.6666666666666666\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6926\n",
            " Training bag [1/11] bag loss: 0.6537\n",
            " Training bag [2/11] bag loss: 0.6739\n",
            " Training bag [3/11] bag loss: 0.6732\n",
            " Training bag [4/11] bag loss: 0.6910\n",
            " Training bag [5/11] bag loss: 0.6492\n",
            " Training bag [6/11] bag loss: 0.6922\n",
            " Training bag [7/11] bag loss: 0.6454\n",
            " Training bag [8/11] bag loss: 0.6754\n",
            " Training bag [9/11] bag loss: 0.6478\n",
            " Training bag [10/11] bag loss: 0.6736\n",
            " Testing bag [0/6] bag loss: 0.6507\n",
            " Testing bag [1/6] bag loss: 0.6707\n",
            " Testing bag [2/6] bag loss: 0.6718\n",
            " Testing bag [3/6] bag loss: 0.6506\n",
            " Testing bag [4/6] bag loss: 0.6502\n",
            " Testing bag [5/6] bag loss: 0.6927ROC AUC score: 0.25\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.6666666666666666\n",
            "\n",
            " Epoch [8/300] train loss: 0.6698 test loss: 0.6644, average score: 0.3333, AUC: class-0>>0.25|class-1>>0.6|class-2>>0.6666666666666666\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6500\n",
            " Training bag [1/11] bag loss: 0.6382\n",
            " Training bag [2/11] bag loss: 0.6388\n",
            " Training bag [3/11] bag loss: 0.6737\n",
            " Training bag [4/11] bag loss: 0.6980\n",
            " Training bag [5/11] bag loss: 0.6376\n",
            " Training bag [6/11] bag loss: 0.6732\n",
            " Training bag [7/11] bag loss: 0.6966\n",
            " Training bag [8/11] bag loss: 0.6975\n",
            " Training bag [9/11] bag loss: 0.6732\n",
            " Training bag [10/11] bag loss: 0.6694\n",
            " Testing bag [0/6] bag loss: 0.6468\n",
            " Testing bag [1/6] bag loss: 0.6661\n",
            " Testing bag [2/6] bag loss: 0.6694\n",
            " Testing bag [3/6] bag loss: 0.6459\n",
            " Testing bag [4/6] bag loss: 0.6450\n",
            " Testing bag [5/6] bag loss: 0.6928ROC AUC score: 0.25\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.6666666666666666\n",
            "\n",
            " Epoch [9/300] train loss: 0.6678 test loss: 0.6610, average score: 0.3333, AUC: class-0>>0.25|class-1>>0.6|class-2>>0.6666666666666666\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6701\n",
            " Training bag [1/11] bag loss: 0.6429\n",
            " Training bag [2/11] bag loss: 0.6628\n",
            " Training bag [3/11] bag loss: 0.6366\n",
            " Training bag [4/11] bag loss: 0.6636\n",
            " Training bag [5/11] bag loss: 0.6988\n",
            " Training bag [6/11] bag loss: 0.6456\n",
            " Training bag [7/11] bag loss: 0.6964\n",
            " Training bag [8/11] bag loss: 0.6372\n",
            " Training bag [9/11] bag loss: 0.6971\n",
            " Training bag [10/11] bag loss: 0.6662\n",
            " Testing bag [0/6] bag loss: 0.6448\n",
            " Testing bag [1/6] bag loss: 0.6646\n",
            " Testing bag [2/6] bag loss: 0.6661\n",
            " Testing bag [3/6] bag loss: 0.6429\n",
            " Testing bag [4/6] bag loss: 0.6425\n",
            " Testing bag [5/6] bag loss: 0.6937ROC AUC score: 0.25\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.6666666666666666\n",
            "\n",
            " Epoch [10/300] train loss: 0.6652 test loss: 0.6591, average score: 0.3333, AUC: class-0>>0.25|class-1>>0.6|class-2>>0.6666666666666666\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6432\n",
            " Training bag [1/11] bag loss: 0.6338\n",
            " Training bag [2/11] bag loss: 0.6642\n",
            " Training bag [3/11] bag loss: 0.6307\n",
            " Training bag [4/11] bag loss: 0.6976\n",
            " Training bag [5/11] bag loss: 0.6659\n",
            " Training bag [6/11] bag loss: 0.6963\n",
            " Training bag [7/11] bag loss: 0.6651\n",
            " Training bag [8/11] bag loss: 0.6299\n",
            " Training bag [9/11] bag loss: 0.6936\n",
            " Training bag [10/11] bag loss: 0.6644\n",
            " Testing bag [0/6] bag loss: 0.6418\n",
            " Testing bag [1/6] bag loss: 0.6603\n",
            " Testing bag [2/6] bag loss: 0.6648\n",
            " Testing bag [3/6] bag loss: 0.6408\n",
            " Testing bag [4/6] bag loss: 0.6410\n",
            " Testing bag [5/6] bag loss: 0.6938ROC AUC score: 0.25\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.6666666666666666\n",
            "\n",
            " Epoch [11/300] train loss: 0.6622 test loss: 0.6571, average score: 0.3333, AUC: class-0>>0.25|class-1>>0.6|class-2>>0.6666666666666666\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6388\n",
            " Training bag [1/11] bag loss: 0.6340\n",
            " Training bag [2/11] bag loss: 0.6615\n",
            " Training bag [3/11] bag loss: 0.6607\n",
            " Training bag [4/11] bag loss: 0.6295\n",
            " Training bag [5/11] bag loss: 0.7010\n",
            " Training bag [6/11] bag loss: 0.6590\n",
            " Training bag [7/11] bag loss: 0.6250\n",
            " Training bag [8/11] bag loss: 0.6975\n",
            " Training bag [9/11] bag loss: 0.6579\n",
            " Training bag [10/11] bag loss: 0.6981\n",
            " Testing bag [0/6] bag loss: 0.6388\n",
            " Testing bag [1/6] bag loss: 0.6567\n",
            " Testing bag [2/6] bag loss: 0.6606\n",
            " Testing bag [3/6] bag loss: 0.6385\n",
            " Testing bag [4/6] bag loss: 0.6375\n",
            " Testing bag [5/6] bag loss: 0.6960ROC AUC score: 0.25\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666666\n",
            "\n",
            " Epoch [12/300] train loss: 0.6603 test loss: 0.6547, average score: 0.3333, AUC: class-0>>0.25|class-1>>0.8|class-2>>0.6666666666666666\n",
            "Best model saved at: weights/20250626/fold_3_19.pth\n",
            "Best thresholds ===>>> class-0>>inf|class-1>>0.3607915937900543|class-2>>0.4301236569881439\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6295\n",
            " Training bag [1/11] bag loss: 0.6358\n",
            " Training bag [2/11] bag loss: 0.6592\n",
            " Training bag [3/11] bag loss: 0.6223\n",
            " Training bag [4/11] bag loss: 0.6593\n",
            " Training bag [5/11] bag loss: 0.6563\n",
            " Training bag [6/11] bag loss: 0.6220\n",
            " Training bag [7/11] bag loss: 0.7039\n",
            " Training bag [8/11] bag loss: 0.6554\n",
            " Training bag [9/11] bag loss: 0.7039\n",
            " Training bag [10/11] bag loss: 0.6982\n",
            " Testing bag [0/6] bag loss: 0.6387\n",
            " Testing bag [1/6] bag loss: 0.6532\n",
            " Testing bag [2/6] bag loss: 0.6577\n",
            " Testing bag [3/6] bag loss: 0.6356\n",
            " Testing bag [4/6] bag loss: 0.6343\n",
            " Testing bag [5/6] bag loss: 0.6973ROC AUC score: 0.25\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666666\n",
            "\n",
            " Epoch [13/300] train loss: 0.6587 test loss: 0.6528, average score: 0.3333, AUC: class-0>>0.25|class-1>>0.8|class-2>>0.6666666666666666\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6963\n",
            " Training bag [1/11] bag loss: 0.6283\n",
            " Training bag [2/11] bag loss: 0.6260\n",
            " Training bag [3/11] bag loss: 0.6948\n",
            " Training bag [4/11] bag loss: 0.6264\n",
            " Training bag [5/11] bag loss: 0.6305\n",
            " Training bag [6/11] bag loss: 0.6621\n",
            " Training bag [7/11] bag loss: 0.6616\n",
            " Training bag [8/11] bag loss: 0.6596\n",
            " Training bag [9/11] bag loss: 0.6967\n",
            " Training bag [10/11] bag loss: 0.6566\n",
            " Testing bag [0/6] bag loss: 0.6364\n",
            " Testing bag [1/6] bag loss: 0.6540\n",
            " Testing bag [2/6] bag loss: 0.6571\n",
            " Testing bag [3/6] bag loss: 0.6339\n",
            " Testing bag [4/6] bag loss: 0.6327\n",
            " Testing bag [5/6] bag loss: 0.6941ROC AUC score: 0.25\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.6666666666666666\n",
            "\n",
            " Epoch [14/300] train loss: 0.6581 test loss: 0.6513, average score: 0.3333, AUC: class-0>>0.25|class-1>>0.6|class-2>>0.6666666666666666\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6949\n",
            " Training bag [1/11] bag loss: 0.6274\n",
            " Training bag [2/11] bag loss: 0.6534\n",
            " Training bag [3/11] bag loss: 0.6231\n",
            " Training bag [4/11] bag loss: 0.6533\n",
            " Training bag [5/11] bag loss: 0.6526\n",
            " Training bag [6/11] bag loss: 0.6323\n",
            " Training bag [7/11] bag loss: 0.6223\n",
            " Training bag [8/11] bag loss: 0.7011\n",
            " Training bag [9/11] bag loss: 0.6498\n",
            " Training bag [10/11] bag loss: 0.6975\n",
            " Testing bag [0/6] bag loss: 0.6333\n",
            " Testing bag [1/6] bag loss: 0.6501\n",
            " Testing bag [2/6] bag loss: 0.6550\n",
            " Testing bag [3/6] bag loss: 0.6320\n",
            " Testing bag [4/6] bag loss: 0.6305\n",
            " Testing bag [5/6] bag loss: 0.6980ROC AUC score: 0.25\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666666\n",
            "\n",
            " Epoch [15/300] train loss: 0.6552 test loss: 0.6498, average score: 0.3333, AUC: class-0>>0.25|class-1>>0.8|class-2>>0.6666666666666666\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6194\n",
            " Training bag [1/11] bag loss: 0.6183\n",
            " Training bag [2/11] bag loss: 0.6172\n",
            " Training bag [3/11] bag loss: 0.6968\n",
            " Training bag [4/11] bag loss: 0.6561\n",
            " Training bag [5/11] bag loss: 0.6534\n",
            " Training bag [6/11] bag loss: 0.6981\n",
            " Training bag [7/11] bag loss: 0.6517\n",
            " Training bag [8/11] bag loss: 0.6489\n",
            " Training bag [9/11] bag loss: 0.6966\n",
            " Training bag [10/11] bag loss: 0.6309\n",
            " Testing bag [0/6] bag loss: 0.6346\n",
            " Testing bag [1/6] bag loss: 0.6471\n",
            " Testing bag [2/6] bag loss: 0.6531\n",
            " Testing bag [3/6] bag loss: 0.6323\n",
            " Testing bag [4/6] bag loss: 0.6313\n",
            " Testing bag [5/6] bag loss: 0.6946ROC AUC score: 0.25\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666666\n",
            "\n",
            " Epoch [16/300] train loss: 0.6534 test loss: 0.6488, average score: 0.3333, AUC: class-0>>0.25|class-1>>0.8|class-2>>0.6666666666666666\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6452\n",
            " Training bag [1/11] bag loss: 0.6952\n",
            " Training bag [2/11] bag loss: 0.6221\n",
            " Training bag [3/11] bag loss: 0.6194\n",
            " Training bag [4/11] bag loss: 0.6946\n",
            " Training bag [5/11] bag loss: 0.6506\n",
            " Training bag [6/11] bag loss: 0.6486\n",
            " Training bag [7/11] bag loss: 0.6306\n",
            " Training bag [8/11] bag loss: 0.6944\n",
            " Training bag [9/11] bag loss: 0.6202\n",
            " Training bag [10/11] bag loss: 0.6483\n",
            " Testing bag [0/6] bag loss: 0.6306\n",
            " Testing bag [1/6] bag loss: 0.6480\n",
            " Testing bag [2/6] bag loss: 0.6517\n",
            " Testing bag [3/6] bag loss: 0.6298\n",
            " Testing bag [4/6] bag loss: 0.6280\n",
            " Testing bag [5/6] bag loss: 0.6951ROC AUC score: 0.25\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [17/300] train loss: 0.6517 test loss: 0.6472, average score: 0.1667, AUC: class-0>>0.25|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6466\n",
            " Training bag [1/11] bag loss: 0.6174\n",
            " Training bag [2/11] bag loss: 0.6287\n",
            " Training bag [3/11] bag loss: 0.6981\n",
            " Training bag [4/11] bag loss: 0.6176\n",
            " Training bag [5/11] bag loss: 0.6101\n",
            " Training bag [6/11] bag loss: 0.6992\n",
            " Training bag [7/11] bag loss: 0.6501\n",
            " Training bag [8/11] bag loss: 0.6963\n",
            " Training bag [9/11] bag loss: 0.6510\n",
            " Training bag [10/11] bag loss: 0.6496\n",
            " Testing bag [0/6] bag loss: 0.6285\n",
            " Testing bag [1/6] bag loss: 0.6470\n",
            " Testing bag [2/6] bag loss: 0.6533\n",
            " Testing bag [3/6] bag loss: 0.6264\n",
            " Testing bag [4/6] bag loss: 0.6246\n",
            " Testing bag [5/6] bag loss: 0.6964ROC AUC score: 0.25\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [18/300] train loss: 0.6513 test loss: 0.6460, average score: 0.1667, AUC: class-0>>0.25|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6445\n",
            " Training bag [1/11] bag loss: 0.6436\n",
            " Training bag [2/11] bag loss: 0.6960\n",
            " Training bag [3/11] bag loss: 0.6972\n",
            " Training bag [4/11] bag loss: 0.6403\n",
            " Training bag [5/11] bag loss: 0.6227\n",
            " Training bag [6/11] bag loss: 0.6228\n",
            " Training bag [7/11] bag loss: 0.6288\n",
            " Training bag [8/11] bag loss: 0.6141\n",
            " Training bag [9/11] bag loss: 0.6427\n",
            " Training bag [10/11] bag loss: 0.7001\n",
            " Testing bag [0/6] bag loss: 0.6296\n",
            " Testing bag [1/6] bag loss: 0.6414\n",
            " Testing bag [2/6] bag loss: 0.6478\n",
            " Testing bag [3/6] bag loss: 0.6254\n",
            " Testing bag [4/6] bag loss: 0.6238\n",
            " Testing bag [5/6] bag loss: 0.6982ROC AUC score: 0.25\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [19/300] train loss: 0.6502 test loss: 0.6444, average score: 0.1667, AUC: class-0>>0.25|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6430\n",
            " Training bag [1/11] bag loss: 0.6963\n",
            " Training bag [2/11] bag loss: 0.6141\n",
            " Training bag [3/11] bag loss: 0.6955\n",
            " Training bag [4/11] bag loss: 0.6422\n",
            " Training bag [5/11] bag loss: 0.6293\n",
            " Training bag [6/11] bag loss: 0.6425\n",
            " Training bag [7/11] bag loss: 0.6179\n",
            " Training bag [8/11] bag loss: 0.6110\n",
            " Training bag [9/11] bag loss: 0.6423\n",
            " Training bag [10/11] bag loss: 0.6996\n",
            " Testing bag [0/6] bag loss: 0.6279\n",
            " Testing bag [1/6] bag loss: 0.6411\n",
            " Testing bag [2/6] bag loss: 0.6473\n",
            " Testing bag [3/6] bag loss: 0.6240\n",
            " Testing bag [4/6] bag loss: 0.6220\n",
            " Testing bag [5/6] bag loss: 0.6989ROC AUC score: 0.25\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [20/300] train loss: 0.6485 test loss: 0.6435, average score: 0.1667, AUC: class-0>>0.25|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6402\n",
            " Training bag [1/11] bag loss: 0.6258\n",
            " Training bag [2/11] bag loss: 0.6122\n",
            " Training bag [3/11] bag loss: 0.6992\n",
            " Training bag [4/11] bag loss: 0.6989\n",
            " Training bag [5/11] bag loss: 0.6434\n",
            " Training bag [6/11] bag loss: 0.6090\n",
            " Training bag [7/11] bag loss: 0.6430\n",
            " Training bag [8/11] bag loss: 0.6973\n",
            " Training bag [9/11] bag loss: 0.6398\n",
            " Training bag [10/11] bag loss: 0.6100\n",
            " Testing bag [0/6] bag loss: 0.6285\n",
            " Testing bag [1/6] bag loss: 0.6386\n",
            " Testing bag [2/6] bag loss: 0.6453\n",
            " Testing bag [3/6] bag loss: 0.6245\n",
            " Testing bag [4/6] bag loss: 0.6223\n",
            " Testing bag [5/6] bag loss: 0.6976ROC AUC score: 0.25\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [21/300] train loss: 0.6472 test loss: 0.6428, average score: 0.1667, AUC: class-0>>0.25|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6377\n",
            " Training bag [1/11] bag loss: 0.6356\n",
            " Training bag [2/11] bag loss: 0.6150\n",
            " Training bag [3/11] bag loss: 0.7017\n",
            " Training bag [4/11] bag loss: 0.6986\n",
            " Training bag [5/11] bag loss: 0.6114\n",
            " Training bag [6/11] bag loss: 0.6080\n",
            " Training bag [7/11] bag loss: 0.6953\n",
            " Training bag [8/11] bag loss: 0.6203\n",
            " Training bag [9/11] bag loss: 0.6433\n",
            " Training bag [10/11] bag loss: 0.6418\n",
            " Testing bag [0/6] bag loss: 0.6233\n",
            " Testing bag [1/6] bag loss: 0.6406\n",
            " Testing bag [2/6] bag loss: 0.6480\n",
            " Testing bag [3/6] bag loss: 0.6212\n",
            " Testing bag [4/6] bag loss: 0.6192\n",
            " Testing bag [5/6] bag loss: 0.6975ROC AUC score: 0.25\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [22/300] train loss: 0.6462 test loss: 0.6416, average score: 0.1667, AUC: class-0>>0.25|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6957\n",
            " Training bag [1/11] bag loss: 0.6404\n",
            " Training bag [2/11] bag loss: 0.6240\n",
            " Training bag [3/11] bag loss: 0.6065\n",
            " Training bag [4/11] bag loss: 0.6378\n",
            " Training bag [5/11] bag loss: 0.7017\n",
            " Training bag [6/11] bag loss: 0.6370\n",
            " Training bag [7/11] bag loss: 0.6970\n",
            " Training bag [8/11] bag loss: 0.6111\n",
            " Training bag [9/11] bag loss: 0.6120\n",
            " Training bag [10/11] bag loss: 0.6343\n",
            " Testing bag [0/6] bag loss: 0.6229\n",
            " Testing bag [1/6] bag loss: 0.6371\n",
            " Testing bag [2/6] bag loss: 0.6441\n",
            " Testing bag [3/6] bag loss: 0.6189\n",
            " Testing bag [4/6] bag loss: 0.6174\n",
            " Testing bag [5/6] bag loss: 0.6985ROC AUC score: 0.25\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [23/300] train loss: 0.6452 test loss: 0.6399, average score: 0.1667, AUC: class-0>>0.25|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6959\n",
            " Training bag [1/11] bag loss: 0.6387\n",
            " Training bag [2/11] bag loss: 0.6359\n",
            " Training bag [3/11] bag loss: 0.6957\n",
            " Training bag [4/11] bag loss: 0.6292\n",
            " Training bag [5/11] bag loss: 0.6247\n",
            " Training bag [6/11] bag loss: 0.6975\n",
            " Training bag [7/11] bag loss: 0.6098\n",
            " Training bag [8/11] bag loss: 0.6127\n",
            " Training bag [9/11] bag loss: 0.6090\n",
            " Training bag [10/11] bag loss: 0.6373\n",
            " Testing bag [0/6] bag loss: 0.6236\n",
            " Testing bag [1/6] bag loss: 0.6365\n",
            " Testing bag [2/6] bag loss: 0.6447\n",
            " Testing bag [3/6] bag loss: 0.6187\n",
            " Testing bag [4/6] bag loss: 0.6167\n",
            " Testing bag [5/6] bag loss: 0.6986ROC AUC score: 0.25\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [24/300] train loss: 0.6442 test loss: 0.6398, average score: 0.1667, AUC: class-0>>0.25|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6013\n",
            " Training bag [1/11] bag loss: 0.6052\n",
            " Training bag [2/11] bag loss: 0.6362\n",
            " Training bag [3/11] bag loss: 0.7003\n",
            " Training bag [4/11] bag loss: 0.6370\n",
            " Training bag [5/11] bag loss: 0.6046\n",
            " Training bag [6/11] bag loss: 0.7035\n",
            " Training bag [7/11] bag loss: 0.6991\n",
            " Training bag [8/11] bag loss: 0.6372\n",
            " Training bag [9/11] bag loss: 0.6156\n",
            " Training bag [10/11] bag loss: 0.6343\n",
            " Testing bag [0/6] bag loss: 0.6197\n",
            " Testing bag [1/6] bag loss: 0.6360\n",
            " Testing bag [2/6] bag loss: 0.6430\n",
            " Testing bag [3/6] bag loss: 0.6171\n",
            " Testing bag [4/6] bag loss: 0.6156\n",
            " Testing bag [5/6] bag loss: 0.6993ROC AUC score: 0.25\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [25/300] train loss: 0.6431 test loss: 0.6384, average score: 0.1667, AUC: class-0>>0.25|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6055\n",
            " Training bag [1/11] bag loss: 0.6976\n",
            " Training bag [2/11] bag loss: 0.6955\n",
            " Training bag [3/11] bag loss: 0.6033\n",
            " Training bag [4/11] bag loss: 0.6367\n",
            " Training bag [5/11] bag loss: 0.6140\n",
            " Training bag [6/11] bag loss: 0.6376\n",
            " Training bag [7/11] bag loss: 0.5957\n",
            " Training bag [8/11] bag loss: 0.6325\n",
            " Training bag [9/11] bag loss: 0.6364\n",
            " Training bag [10/11] bag loss: 0.7048\n",
            " Testing bag [0/6] bag loss: 0.6184\n",
            " Testing bag [1/6] bag loss: 0.6331\n",
            " Testing bag [2/6] bag loss: 0.6405\n",
            " Testing bag [3/6] bag loss: 0.6144\n",
            " Testing bag [4/6] bag loss: 0.6133\n",
            " Testing bag [5/6] bag loss: 0.7018ROC AUC score: 0.25\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [26/300] train loss: 0.6418 test loss: 0.6369, average score: 0.1667, AUC: class-0>>0.25|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7032\n",
            " Training bag [1/11] bag loss: 0.6334\n",
            " Training bag [2/11] bag loss: 0.5995\n",
            " Training bag [3/11] bag loss: 0.6306\n",
            " Training bag [4/11] bag loss: 0.6039\n",
            " Training bag [5/11] bag loss: 0.6992\n",
            " Training bag [6/11] bag loss: 0.6305\n",
            " Training bag [7/11] bag loss: 0.6973\n",
            " Training bag [8/11] bag loss: 0.6071\n",
            " Training bag [9/11] bag loss: 0.6157\n",
            " Training bag [10/11] bag loss: 0.6297\n",
            " Testing bag [0/6] bag loss: 0.6191\n",
            " Testing bag [1/6] bag loss: 0.6321\n",
            " Testing bag [2/6] bag loss: 0.6403\n",
            " Testing bag [3/6] bag loss: 0.6155\n",
            " Testing bag [4/6] bag loss: 0.6136\n",
            " Testing bag [5/6] bag loss: 0.7022ROC AUC score: 0.25\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [27/300] train loss: 0.6409 test loss: 0.6372, average score: 0.1667, AUC: class-0>>0.25|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6004\n",
            " Training bag [1/11] bag loss: 0.6985\n",
            " Training bag [2/11] bag loss: 0.6306\n",
            " Training bag [3/11] bag loss: 0.6318\n",
            " Training bag [4/11] bag loss: 0.5961\n",
            " Training bag [5/11] bag loss: 0.6018\n",
            " Training bag [6/11] bag loss: 0.6309\n",
            " Training bag [7/11] bag loss: 0.7067\n",
            " Training bag [8/11] bag loss: 0.7015\n",
            " Training bag [9/11] bag loss: 0.6273\n",
            " Training bag [10/11] bag loss: 0.6135\n",
            " Testing bag [0/6] bag loss: 0.6187\n",
            " Testing bag [1/6] bag loss: 0.6293\n",
            " Testing bag [2/6] bag loss: 0.6375\n",
            " Testing bag [3/6] bag loss: 0.6144\n",
            " Testing bag [4/6] bag loss: 0.6121\n",
            " Testing bag [5/6] bag loss: 0.7029ROC AUC score: 0.25\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [28/300] train loss: 0.6399 test loss: 0.6358, average score: 0.1667, AUC: class-0>>0.25|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7033\n",
            " Training bag [1/11] bag loss: 0.6271\n",
            " Training bag [2/11] bag loss: 0.6258\n",
            " Training bag [3/11] bag loss: 0.6970\n",
            " Training bag [4/11] bag loss: 0.6932\n",
            " Training bag [5/11] bag loss: 0.6069\n",
            " Training bag [6/11] bag loss: 0.6088\n",
            " Training bag [7/11] bag loss: 0.6304\n",
            " Training bag [8/11] bag loss: 0.6272\n",
            " Training bag [9/11] bag loss: 0.6184\n",
            " Training bag [10/11] bag loss: 0.5972\n",
            " Testing bag [0/6] bag loss: 0.6195\n",
            " Testing bag [1/6] bag loss: 0.6281\n",
            " Testing bag [2/6] bag loss: 0.6361\n",
            " Testing bag [3/6] bag loss: 0.6148\n",
            " Testing bag [4/6] bag loss: 0.6121\n",
            " Testing bag [5/6] bag loss: 0.7028ROC AUC score: 0.25\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [29/300] train loss: 0.6396 test loss: 0.6356, average score: 0.1667, AUC: class-0>>0.25|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7043\n",
            " Training bag [1/11] bag loss: 0.5957\n",
            " Training bag [2/11] bag loss: 0.6095\n",
            " Training bag [3/11] bag loss: 0.6301\n",
            " Training bag [4/11] bag loss: 0.5942\n",
            " Training bag [5/11] bag loss: 0.6278\n",
            " Training bag [6/11] bag loss: 0.7020\n",
            " Training bag [7/11] bag loss: 0.6315\n",
            " Training bag [8/11] bag loss: 0.6277\n",
            " Training bag [9/11] bag loss: 0.6002\n",
            " Training bag [10/11] bag loss: 0.7024\n",
            " Testing bag [0/6] bag loss: 0.6166\n",
            " Testing bag [1/6] bag loss: 0.6259\n",
            " Testing bag [2/6] bag loss: 0.6360\n",
            " Testing bag [3/6] bag loss: 0.6115\n",
            " Testing bag [4/6] bag loss: 0.6090\n",
            " Testing bag [5/6] bag loss: 0.7057ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [30/300] train loss: 0.6387 test loss: 0.6341, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6246\n",
            " Training bag [1/11] bag loss: 0.5932\n",
            " Training bag [2/11] bag loss: 0.6272\n",
            " Training bag [3/11] bag loss: 0.6000\n",
            " Training bag [4/11] bag loss: 0.6233\n",
            " Training bag [5/11] bag loss: 0.7113\n",
            " Training bag [6/11] bag loss: 0.6176\n",
            " Training bag [7/11] bag loss: 0.6113\n",
            " Training bag [8/11] bag loss: 0.5970\n",
            " Training bag [9/11] bag loss: 0.7075\n",
            " Training bag [10/11] bag loss: 0.7050\n",
            " Testing bag [0/6] bag loss: 0.6130\n",
            " Testing bag [1/6] bag loss: 0.6247\n",
            " Testing bag [2/6] bag loss: 0.6365\n",
            " Testing bag [3/6] bag loss: 0.6100\n",
            " Testing bag [4/6] bag loss: 0.6072\n",
            " Testing bag [5/6] bag loss: 0.7071ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [31/300] train loss: 0.6380 test loss: 0.6331, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6058\n",
            " Training bag [1/11] bag loss: 0.6226\n",
            " Training bag [2/11] bag loss: 0.7070\n",
            " Training bag [3/11] bag loss: 0.6268\n",
            " Training bag [4/11] bag loss: 0.7006\n",
            " Training bag [5/11] bag loss: 0.5922\n",
            " Training bag [6/11] bag loss: 0.5982\n",
            " Training bag [7/11] bag loss: 0.6966\n",
            " Training bag [8/11] bag loss: 0.6255\n",
            " Training bag [9/11] bag loss: 0.6288\n",
            " Training bag [10/11] bag loss: 0.5969\n",
            " Testing bag [0/6] bag loss: 0.6172\n",
            " Testing bag [1/6] bag loss: 0.6254\n",
            " Testing bag [2/6] bag loss: 0.6356\n",
            " Testing bag [3/6] bag loss: 0.6109\n",
            " Testing bag [4/6] bag loss: 0.6077\n",
            " Testing bag [5/6] bag loss: 0.7061ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [32/300] train loss: 0.6364 test loss: 0.6338, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5893\n",
            " Training bag [1/11] bag loss: 0.7066\n",
            " Training bag [2/11] bag loss: 0.6987\n",
            " Training bag [3/11] bag loss: 0.6089\n",
            " Training bag [4/11] bag loss: 0.6313\n",
            " Training bag [5/11] bag loss: 0.6932\n",
            " Training bag [6/11] bag loss: 0.6241\n",
            " Training bag [7/11] bag loss: 0.5979\n",
            " Training bag [8/11] bag loss: 0.6288\n",
            " Training bag [9/11] bag loss: 0.6239\n",
            " Training bag [10/11] bag loss: 0.5935\n",
            " Testing bag [0/6] bag loss: 0.6134\n",
            " Testing bag [1/6] bag loss: 0.6247\n",
            " Testing bag [2/6] bag loss: 0.6349\n",
            " Testing bag [3/6] bag loss: 0.6105\n",
            " Testing bag [4/6] bag loss: 0.6074\n",
            " Testing bag [5/6] bag loss: 0.7057ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [33/300] train loss: 0.6360 test loss: 0.6328, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6223\n",
            " Training bag [1/11] bag loss: 0.6984\n",
            " Training bag [2/11] bag loss: 0.6223\n",
            " Training bag [3/11] bag loss: 0.6992\n",
            " Training bag [4/11] bag loss: 0.6148\n",
            " Training bag [5/11] bag loss: 0.5995\n",
            " Training bag [6/11] bag loss: 0.6121\n",
            " Training bag [7/11] bag loss: 0.6212\n",
            " Training bag [8/11] bag loss: 0.5908\n",
            " Training bag [9/11] bag loss: 0.7087\n",
            " Training bag [10/11] bag loss: 0.5991\n",
            " Testing bag [0/6] bag loss: 0.6136\n",
            " Testing bag [1/6] bag loss: 0.6214\n",
            " Testing bag [2/6] bag loss: 0.6322\n",
            " Testing bag [3/6] bag loss: 0.6098\n",
            " Testing bag [4/6] bag loss: 0.6058\n",
            " Testing bag [5/6] bag loss: 0.7067ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [34/300] train loss: 0.6353 test loss: 0.6316, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6221\n",
            " Training bag [1/11] bag loss: 0.6145\n",
            " Training bag [2/11] bag loss: 0.7002\n",
            " Training bag [3/11] bag loss: 0.6083\n",
            " Training bag [4/11] bag loss: 0.7015\n",
            " Training bag [5/11] bag loss: 0.7076\n",
            " Training bag [6/11] bag loss: 0.6183\n",
            " Training bag [7/11] bag loss: 0.5903\n",
            " Training bag [8/11] bag loss: 0.6191\n",
            " Training bag [9/11] bag loss: 0.6002\n",
            " Training bag [10/11] bag loss: 0.5940\n",
            " Testing bag [0/6] bag loss: 0.6133\n",
            " Testing bag [1/6] bag loss: 0.6217\n",
            " Testing bag [2/6] bag loss: 0.6325\n",
            " Testing bag [3/6] bag loss: 0.6094\n",
            " Testing bag [4/6] bag loss: 0.6067\n",
            " Testing bag [5/6] bag loss: 0.7067ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [35/300] train loss: 0.6342 test loss: 0.6317, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6183\n",
            " Training bag [1/11] bag loss: 0.7067\n",
            " Training bag [2/11] bag loss: 0.6204\n",
            " Training bag [3/11] bag loss: 0.6127\n",
            " Training bag [4/11] bag loss: 0.6993\n",
            " Training bag [5/11] bag loss: 0.5993\n",
            " Training bag [6/11] bag loss: 0.6175\n",
            " Training bag [7/11] bag loss: 0.5991\n",
            " Training bag [8/11] bag loss: 0.7008\n",
            " Training bag [9/11] bag loss: 0.5887\n",
            " Training bag [10/11] bag loss: 0.6059\n",
            " Testing bag [0/6] bag loss: 0.6135\n",
            " Testing bag [1/6] bag loss: 0.6202\n",
            " Testing bag [2/6] bag loss: 0.6322\n",
            " Testing bag [3/6] bag loss: 0.6087\n",
            " Testing bag [4/6] bag loss: 0.6044\n",
            " Testing bag [5/6] bag loss: 0.7074ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [36/300] train loss: 0.6335 test loss: 0.6311, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6175\n",
            " Training bag [1/11] bag loss: 0.6056\n",
            " Training bag [2/11] bag loss: 0.6207\n",
            " Training bag [3/11] bag loss: 0.6156\n",
            " Training bag [4/11] bag loss: 0.5874\n",
            " Training bag [5/11] bag loss: 0.7081\n",
            " Training bag [6/11] bag loss: 0.5822\n",
            " Training bag [7/11] bag loss: 0.7050\n",
            " Training bag [8/11] bag loss: 0.6119\n",
            " Training bag [9/11] bag loss: 0.5931\n",
            " Training bag [10/11] bag loss: 0.7133\n",
            " Testing bag [0/6] bag loss: 0.6098\n",
            " Testing bag [1/6] bag loss: 0.6199\n",
            " Testing bag [2/6] bag loss: 0.6320\n",
            " Testing bag [3/6] bag loss: 0.6049\n",
            " Testing bag [4/6] bag loss: 0.6016\n",
            " Testing bag [5/6] bag loss: 0.7115ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [37/300] train loss: 0.6328 test loss: 0.6300, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7010\n",
            " Training bag [1/11] bag loss: 0.7089\n",
            " Training bag [2/11] bag loss: 0.6218\n",
            " Training bag [3/11] bag loss: 0.5948\n",
            " Training bag [4/11] bag loss: 0.6226\n",
            " Training bag [5/11] bag loss: 0.6168\n",
            " Training bag [6/11] bag loss: 0.6986\n",
            " Training bag [7/11] bag loss: 0.5946\n",
            " Training bag [8/11] bag loss: 0.5877\n",
            " Training bag [9/11] bag loss: 0.6055\n",
            " Training bag [10/11] bag loss: 0.6154\n",
            " Testing bag [0/6] bag loss: 0.6116\n",
            " Testing bag [1/6] bag loss: 0.6210\n",
            " Testing bag [2/6] bag loss: 0.6341\n",
            " Testing bag [3/6] bag loss: 0.6063\n",
            " Testing bag [4/6] bag loss: 0.6017\n",
            " Testing bag [5/6] bag loss: 0.7108ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [38/300] train loss: 0.6334 test loss: 0.6309, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5915\n",
            " Training bag [1/11] bag loss: 0.6222\n",
            " Training bag [2/11] bag loss: 0.5797\n",
            " Training bag [3/11] bag loss: 0.5841\n",
            " Training bag [4/11] bag loss: 0.5956\n",
            " Training bag [5/11] bag loss: 0.6200\n",
            " Training bag [6/11] bag loss: 0.7096\n",
            " Training bag [7/11] bag loss: 0.6219\n",
            " Training bag [8/11] bag loss: 0.6123\n",
            " Training bag [9/11] bag loss: 0.7085\n",
            " Training bag [10/11] bag loss: 0.7169\n",
            " Testing bag [0/6] bag loss: 0.6094\n",
            " Testing bag [1/6] bag loss: 0.6184\n",
            " Testing bag [2/6] bag loss: 0.6310\n",
            " Testing bag [3/6] bag loss: 0.6031\n",
            " Testing bag [4/6] bag loss: 0.5990\n",
            " Testing bag [5/6] bag loss: 0.7151ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [39/300] train loss: 0.6329 test loss: 0.6293, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5988\n",
            " Training bag [1/11] bag loss: 0.6197\n",
            " Training bag [2/11] bag loss: 0.6109\n",
            " Training bag [3/11] bag loss: 0.5901\n",
            " Training bag [4/11] bag loss: 0.6141\n",
            " Training bag [5/11] bag loss: 0.5863\n",
            " Training bag [6/11] bag loss: 0.7103\n",
            " Training bag [7/11] bag loss: 0.7053\n",
            " Training bag [8/11] bag loss: 0.7160\n",
            " Training bag [9/11] bag loss: 0.6180\n",
            " Training bag [10/11] bag loss: 0.5813\n",
            " Testing bag [0/6] bag loss: 0.6108\n",
            " Testing bag [1/6] bag loss: 0.6170\n",
            " Testing bag [2/6] bag loss: 0.6338\n",
            " Testing bag [3/6] bag loss: 0.6055\n",
            " Testing bag [4/6] bag loss: 0.6002\n",
            " Testing bag [5/6] bag loss: 0.7116ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [40/300] train loss: 0.6319 test loss: 0.6298, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6102\n",
            " Training bag [1/11] bag loss: 0.5796\n",
            " Training bag [2/11] bag loss: 0.5911\n",
            " Training bag [3/11] bag loss: 0.5981\n",
            " Training bag [4/11] bag loss: 0.6193\n",
            " Training bag [5/11] bag loss: 0.7183\n",
            " Training bag [6/11] bag loss: 0.5801\n",
            " Training bag [7/11] bag loss: 0.6146\n",
            " Training bag [8/11] bag loss: 0.7075\n",
            " Training bag [9/11] bag loss: 0.7035\n",
            " Training bag [10/11] bag loss: 0.6159\n",
            " Testing bag [0/6] bag loss: 0.6077\n",
            " Testing bag [1/6] bag loss: 0.6176\n",
            " Testing bag [2/6] bag loss: 0.6327\n",
            " Testing bag [3/6] bag loss: 0.6026\n",
            " Testing bag [4/6] bag loss: 0.5963\n",
            " Testing bag [5/6] bag loss: 0.7123ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [41/300] train loss: 0.6307 test loss: 0.6282, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5808\n",
            " Training bag [1/11] bag loss: 0.7132\n",
            " Training bag [2/11] bag loss: 0.6167\n",
            " Training bag [3/11] bag loss: 0.7017\n",
            " Training bag [4/11] bag loss: 0.5791\n",
            " Training bag [5/11] bag loss: 0.5892\n",
            " Training bag [6/11] bag loss: 0.6997\n",
            " Training bag [7/11] bag loss: 0.6224\n",
            " Training bag [8/11] bag loss: 0.6134\n",
            " Training bag [9/11] bag loss: 0.5976\n",
            " Training bag [10/11] bag loss: 0.6196\n",
            " Testing bag [0/6] bag loss: 0.6086\n",
            " Testing bag [1/6] bag loss: 0.6173\n",
            " Testing bag [2/6] bag loss: 0.6333\n",
            " Testing bag [3/6] bag loss: 0.6031\n",
            " Testing bag [4/6] bag loss: 0.5964\n",
            " Testing bag [5/6] bag loss: 0.7114ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [42/300] train loss: 0.6303 test loss: 0.6283, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5975\n",
            " Training bag [1/11] bag loss: 0.7026\n",
            " Training bag [2/11] bag loss: 0.6114\n",
            " Training bag [3/11] bag loss: 0.6158\n",
            " Training bag [4/11] bag loss: 0.6103\n",
            " Training bag [5/11] bag loss: 0.7112\n",
            " Training bag [6/11] bag loss: 0.5920\n",
            " Training bag [7/11] bag loss: 0.5797\n",
            " Training bag [8/11] bag loss: 0.6981\n",
            " Training bag [9/11] bag loss: 0.5853\n",
            " Training bag [10/11] bag loss: 0.6170\n",
            " Testing bag [0/6] bag loss: 0.6061\n",
            " Testing bag [1/6] bag loss: 0.6155\n",
            " Testing bag [2/6] bag loss: 0.6313\n",
            " Testing bag [3/6] bag loss: 0.6028\n",
            " Testing bag [4/6] bag loss: 0.5973\n",
            " Testing bag [5/6] bag loss: 0.7126ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [43/300] train loss: 0.6292 test loss: 0.6276, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5863\n",
            " Training bag [1/11] bag loss: 0.6126\n",
            " Training bag [2/11] bag loss: 0.5812\n",
            " Training bag [3/11] bag loss: 0.5717\n",
            " Training bag [4/11] bag loss: 0.6177\n",
            " Training bag [5/11] bag loss: 0.6079\n",
            " Training bag [6/11] bag loss: 0.7079\n",
            " Training bag [7/11] bag loss: 0.7179\n",
            " Training bag [8/11] bag loss: 0.6104\n",
            " Training bag [9/11] bag loss: 0.7055\n",
            " Training bag [10/11] bag loss: 0.6006\n",
            " Testing bag [0/6] bag loss: 0.6080\n",
            " Testing bag [1/6] bag loss: 0.6132\n",
            " Testing bag [2/6] bag loss: 0.6279\n",
            " Testing bag [3/6] bag loss: 0.6043\n",
            " Testing bag [4/6] bag loss: 0.5962\n",
            " Testing bag [5/6] bag loss: 0.7160ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [44/300] train loss: 0.6291 test loss: 0.6276, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6121\n",
            " Training bag [1/11] bag loss: 0.7038\n",
            " Training bag [2/11] bag loss: 0.6031\n",
            " Training bag [3/11] bag loss: 0.6112\n",
            " Training bag [4/11] bag loss: 0.5876\n",
            " Training bag [5/11] bag loss: 0.7013\n",
            " Training bag [6/11] bag loss: 0.7103\n",
            " Training bag [7/11] bag loss: 0.5947\n",
            " Training bag [8/11] bag loss: 0.5798\n",
            " Training bag [9/11] bag loss: 0.5990\n",
            " Training bag [10/11] bag loss: 0.6114\n",
            " Testing bag [0/6] bag loss: 0.6070\n",
            " Testing bag [1/6] bag loss: 0.6131\n",
            " Testing bag [2/6] bag loss: 0.6303\n",
            " Testing bag [3/6] bag loss: 0.6036\n",
            " Testing bag [4/6] bag loss: 0.5957\n",
            " Testing bag [5/6] bag loss: 0.7143ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [45/300] train loss: 0.6286 test loss: 0.6273, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7021\n",
            " Training bag [1/11] bag loss: 0.5981\n",
            " Training bag [2/11] bag loss: 0.6076\n",
            " Training bag [3/11] bag loss: 0.5803\n",
            " Training bag [4/11] bag loss: 0.6977\n",
            " Training bag [5/11] bag loss: 0.6141\n",
            " Training bag [6/11] bag loss: 0.7118\n",
            " Training bag [7/11] bag loss: 0.6111\n",
            " Training bag [8/11] bag loss: 0.5765\n",
            " Training bag [9/11] bag loss: 0.6144\n",
            " Training bag [10/11] bag loss: 0.5883\n",
            " Testing bag [0/6] bag loss: 0.6091\n",
            " Testing bag [1/6] bag loss: 0.6122\n",
            " Testing bag [2/6] bag loss: 0.6282\n",
            " Testing bag [3/6] bag loss: 0.6034\n",
            " Testing bag [4/6] bag loss: 0.5950\n",
            " Testing bag [5/6] bag loss: 0.7148ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [46/300] train loss: 0.6275 test loss: 0.6271, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5802\n",
            " Training bag [1/11] bag loss: 0.7029\n",
            " Training bag [2/11] bag loss: 0.6056\n",
            " Training bag [3/11] bag loss: 0.7138\n",
            " Training bag [4/11] bag loss: 0.5729\n",
            " Training bag [5/11] bag loss: 0.6094\n",
            " Training bag [6/11] bag loss: 0.6144\n",
            " Training bag [7/11] bag loss: 0.5863\n",
            " Training bag [8/11] bag loss: 0.6998\n",
            " Training bag [9/11] bag loss: 0.6115\n",
            " Training bag [10/11] bag loss: 0.5977\n",
            " Testing bag [0/6] bag loss: 0.6067\n",
            " Testing bag [1/6] bag loss: 0.6117\n",
            " Testing bag [2/6] bag loss: 0.6268\n",
            " Testing bag [3/6] bag loss: 0.6031\n",
            " Testing bag [4/6] bag loss: 0.5943\n",
            " Testing bag [5/6] bag loss: 0.7157ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [47/300] train loss: 0.6268 test loss: 0.6264, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6063\n",
            " Training bag [1/11] bag loss: 0.5731\n",
            " Training bag [2/11] bag loss: 0.7045\n",
            " Training bag [3/11] bag loss: 0.5863\n",
            " Training bag [4/11] bag loss: 0.6130\n",
            " Training bag [5/11] bag loss: 0.6030\n",
            " Training bag [6/11] bag loss: 0.7006\n",
            " Training bag [7/11] bag loss: 0.5795\n",
            " Training bag [8/11] bag loss: 0.6099\n",
            " Training bag [9/11] bag loss: 0.5948\n",
            " Training bag [10/11] bag loss: 0.7153\n",
            " Testing bag [0/6] bag loss: 0.6067\n",
            " Testing bag [1/6] bag loss: 0.6099\n",
            " Testing bag [2/6] bag loss: 0.6269\n",
            " Testing bag [3/6] bag loss: 0.6015\n",
            " Testing bag [4/6] bag loss: 0.5932\n",
            " Testing bag [5/6] bag loss: 0.7184ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [48/300] train loss: 0.6260 test loss: 0.6261, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6061\n",
            " Training bag [1/11] bag loss: 0.6998\n",
            " Training bag [2/11] bag loss: 0.7029\n",
            " Training bag [3/11] bag loss: 0.5800\n",
            " Training bag [4/11] bag loss: 0.7083\n",
            " Training bag [5/11] bag loss: 0.5998\n",
            " Training bag [6/11] bag loss: 0.5715\n",
            " Training bag [7/11] bag loss: 0.6056\n",
            " Training bag [8/11] bag loss: 0.6172\n",
            " Training bag [9/11] bag loss: 0.6104\n",
            " Training bag [10/11] bag loss: 0.5863\n",
            " Testing bag [0/6] bag loss: 0.6044\n",
            " Testing bag [1/6] bag loss: 0.6100\n",
            " Testing bag [2/6] bag loss: 0.6279\n",
            " Testing bag [3/6] bag loss: 0.6026\n",
            " Testing bag [4/6] bag loss: 0.5932\n",
            " Testing bag [5/6] bag loss: 0.7155ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [49/300] train loss: 0.6262 test loss: 0.6256, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6119\n",
            " Training bag [1/11] bag loss: 0.6084\n",
            " Training bag [2/11] bag loss: 0.5971\n",
            " Training bag [3/11] bag loss: 0.6018\n",
            " Training bag [4/11] bag loss: 0.7043\n",
            " Training bag [5/11] bag loss: 0.7171\n",
            " Training bag [6/11] bag loss: 0.5801\n",
            " Training bag [7/11] bag loss: 0.5744\n",
            " Training bag [8/11] bag loss: 0.5998\n",
            " Training bag [9/11] bag loss: 0.7048\n",
            " Training bag [10/11] bag loss: 0.5842\n",
            " Testing bag [0/6] bag loss: 0.6037\n",
            " Testing bag [1/6] bag loss: 0.6079\n",
            " Testing bag [2/6] bag loss: 0.6271\n",
            " Testing bag [3/6] bag loss: 0.6013\n",
            " Testing bag [4/6] bag loss: 0.5932\n",
            " Testing bag [5/6] bag loss: 0.7189ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [50/300] train loss: 0.6258 test loss: 0.6254, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6064\n",
            " Training bag [1/11] bag loss: 0.5697\n",
            " Training bag [2/11] bag loss: 0.7006\n",
            " Training bag [3/11] bag loss: 0.5965\n",
            " Training bag [4/11] bag loss: 0.7186\n",
            " Training bag [5/11] bag loss: 0.5753\n",
            " Training bag [6/11] bag loss: 0.6142\n",
            " Training bag [7/11] bag loss: 0.6022\n",
            " Training bag [8/11] bag loss: 0.7043\n",
            " Training bag [9/11] bag loss: 0.6055\n",
            " Training bag [10/11] bag loss: 0.5833\n",
            " Testing bag [0/6] bag loss: 0.6044\n",
            " Testing bag [1/6] bag loss: 0.6094\n",
            " Testing bag [2/6] bag loss: 0.6268\n",
            " Testing bag [3/6] bag loss: 0.6000\n",
            " Testing bag [4/6] bag loss: 0.5913\n",
            " Testing bag [5/6] bag loss: 0.7182ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [51/300] train loss: 0.6252 test loss: 0.6250, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5937\n",
            " Training bag [1/11] bag loss: 0.6006\n",
            " Training bag [2/11] bag loss: 0.6062\n",
            " Training bag [3/11] bag loss: 0.5651\n",
            " Training bag [4/11] bag loss: 0.7035\n",
            " Training bag [5/11] bag loss: 0.6088\n",
            " Training bag [6/11] bag loss: 0.5837\n",
            " Training bag [7/11] bag loss: 0.6041\n",
            " Training bag [8/11] bag loss: 0.7239\n",
            " Training bag [9/11] bag loss: 0.7085\n",
            " Training bag [10/11] bag loss: 0.5759\n",
            " Testing bag [0/6] bag loss: 0.6044\n",
            " Testing bag [1/6] bag loss: 0.6074\n",
            " Testing bag [2/6] bag loss: 0.6256\n",
            " Testing bag [3/6] bag loss: 0.5989\n",
            " Testing bag [4/6] bag loss: 0.5900\n",
            " Testing bag [5/6] bag loss: 0.7199ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [52/300] train loss: 0.6249 test loss: 0.6244, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5969\n",
            " Training bag [1/11] bag loss: 0.6073\n",
            " Training bag [2/11] bag loss: 0.7167\n",
            " Training bag [3/11] bag loss: 0.5997\n",
            " Training bag [4/11] bag loss: 0.6004\n",
            " Training bag [5/11] bag loss: 0.5812\n",
            " Training bag [6/11] bag loss: 0.5890\n",
            " Training bag [7/11] bag loss: 0.7028\n",
            " Training bag [8/11] bag loss: 0.5714\n",
            " Training bag [9/11] bag loss: 0.5967\n",
            " Training bag [10/11] bag loss: 0.7069\n",
            " Testing bag [0/6] bag loss: 0.6046\n",
            " Testing bag [1/6] bag loss: 0.6063\n",
            " Testing bag [2/6] bag loss: 0.6260\n",
            " Testing bag [3/6] bag loss: 0.5989\n",
            " Testing bag [4/6] bag loss: 0.5894\n",
            " Testing bag [5/6] bag loss: 0.7209ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [53/300] train loss: 0.6245 test loss: 0.6243, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6075\n",
            " Training bag [1/11] bag loss: 0.5972\n",
            " Training bag [2/11] bag loss: 0.7005\n",
            " Training bag [3/11] bag loss: 0.5980\n",
            " Training bag [4/11] bag loss: 0.7037\n",
            " Training bag [5/11] bag loss: 0.5667\n",
            " Training bag [6/11] bag loss: 0.5732\n",
            " Training bag [7/11] bag loss: 0.6047\n",
            " Training bag [8/11] bag loss: 0.5797\n",
            " Training bag [9/11] bag loss: 0.6078\n",
            " Training bag [10/11] bag loss: 0.7178\n",
            " Testing bag [0/6] bag loss: 0.5997\n",
            " Testing bag [1/6] bag loss: 0.6076\n",
            " Testing bag [2/6] bag loss: 0.6276\n",
            " Testing bag [3/6] bag loss: 0.5969\n",
            " Testing bag [4/6] bag loss: 0.5876\n",
            " Testing bag [5/6] bag loss: 0.7212ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [54/300] train loss: 0.6233 test loss: 0.6234, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7199\n",
            " Training bag [1/11] bag loss: 0.6017\n",
            " Training bag [2/11] bag loss: 0.6080\n",
            " Training bag [3/11] bag loss: 0.6967\n",
            " Training bag [4/11] bag loss: 0.5956\n",
            " Training bag [5/11] bag loss: 0.5814\n",
            " Training bag [6/11] bag loss: 0.5691\n",
            " Training bag [7/11] bag loss: 0.7026\n",
            " Training bag [8/11] bag loss: 0.6074\n",
            " Training bag [9/11] bag loss: 0.5984\n",
            " Training bag [10/11] bag loss: 0.5833\n",
            " Testing bag [0/6] bag loss: 0.6049\n",
            " Testing bag [1/6] bag loss: 0.6050\n",
            " Testing bag [2/6] bag loss: 0.6267\n",
            " Testing bag [3/6] bag loss: 0.6009\n",
            " Testing bag [4/6] bag loss: 0.5908\n",
            " Testing bag [5/6] bag loss: 0.7193ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [55/300] train loss: 0.6240 test loss: 0.6246, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6066\n",
            " Training bag [1/11] bag loss: 0.7196\n",
            " Training bag [2/11] bag loss: 0.5938\n",
            " Training bag [3/11] bag loss: 0.5679\n",
            " Training bag [4/11] bag loss: 0.5724\n",
            " Training bag [5/11] bag loss: 0.6032\n",
            " Training bag [6/11] bag loss: 0.5802\n",
            " Training bag [7/11] bag loss: 0.7024\n",
            " Training bag [8/11] bag loss: 0.6012\n",
            " Training bag [9/11] bag loss: 0.7055\n",
            " Training bag [10/11] bag loss: 0.5927\n",
            " Testing bag [0/6] bag loss: 0.6020\n",
            " Testing bag [1/6] bag loss: 0.6044\n",
            " Testing bag [2/6] bag loss: 0.6265\n",
            " Testing bag [3/6] bag loss: 0.5997\n",
            " Testing bag [4/6] bag loss: 0.5881\n",
            " Testing bag [5/6] bag loss: 0.7201ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [56/300] train loss: 0.6223 test loss: 0.6235, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5714\n",
            " Training bag [1/11] bag loss: 0.7049\n",
            " Training bag [2/11] bag loss: 0.5613\n",
            " Training bag [3/11] bag loss: 0.5998\n",
            " Training bag [4/11] bag loss: 0.6095\n",
            " Training bag [5/11] bag loss: 0.5756\n",
            " Training bag [6/11] bag loss: 0.6092\n",
            " Training bag [7/11] bag loss: 0.7242\n",
            " Training bag [8/11] bag loss: 0.5998\n",
            " Training bag [9/11] bag loss: 0.7028\n",
            " Training bag [10/11] bag loss: 0.5938\n",
            " Testing bag [0/6] bag loss: 0.6037\n",
            " Testing bag [1/6] bag loss: 0.6044\n",
            " Testing bag [2/6] bag loss: 0.6240\n",
            " Testing bag [3/6] bag loss: 0.5992\n",
            " Testing bag [4/6] bag loss: 0.5871\n",
            " Testing bag [5/6] bag loss: 0.7196ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [57/300] train loss: 0.6229 test loss: 0.6230, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7162\n",
            " Training bag [1/11] bag loss: 0.5789\n",
            " Training bag [2/11] bag loss: 0.6059\n",
            " Training bag [3/11] bag loss: 0.7013\n",
            " Training bag [4/11] bag loss: 0.6025\n",
            " Training bag [5/11] bag loss: 0.5727\n",
            " Training bag [6/11] bag loss: 0.5940\n",
            " Training bag [7/11] bag loss: 0.6987\n",
            " Training bag [8/11] bag loss: 0.5649\n",
            " Training bag [9/11] bag loss: 0.6084\n",
            " Training bag [10/11] bag loss: 0.5946\n",
            " Testing bag [0/6] bag loss: 0.6021\n",
            " Testing bag [1/6] bag loss: 0.6047\n",
            " Testing bag [2/6] bag loss: 0.6249\n",
            " Testing bag [3/6] bag loss: 0.5976\n",
            " Testing bag [4/6] bag loss: 0.5875\n",
            " Testing bag [5/6] bag loss: 0.7209ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [58/300] train loss: 0.6216 test loss: 0.6230, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6001\n",
            " Training bag [1/11] bag loss: 0.5604\n",
            " Training bag [2/11] bag loss: 0.6023\n",
            " Training bag [3/11] bag loss: 0.5682\n",
            " Training bag [4/11] bag loss: 0.7102\n",
            " Training bag [5/11] bag loss: 0.5779\n",
            " Training bag [6/11] bag loss: 0.7201\n",
            " Training bag [7/11] bag loss: 0.5880\n",
            " Training bag [8/11] bag loss: 0.6093\n",
            " Training bag [9/11] bag loss: 0.7032\n",
            " Training bag [10/11] bag loss: 0.5964\n",
            " Testing bag [0/6] bag loss: 0.5983\n",
            " Testing bag [1/6] bag loss: 0.6059\n",
            " Testing bag [2/6] bag loss: 0.6275\n",
            " Testing bag [3/6] bag loss: 0.5949\n",
            " Testing bag [4/6] bag loss: 0.5838\n",
            " Testing bag [5/6] bag loss: 0.7215ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [59/300] train loss: 0.6215 test loss: 0.6220, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5764\n",
            " Training bag [1/11] bag loss: 0.7172\n",
            " Training bag [2/11] bag loss: 0.6074\n",
            " Training bag [3/11] bag loss: 0.5876\n",
            " Training bag [4/11] bag loss: 0.6993\n",
            " Training bag [5/11] bag loss: 0.5664\n",
            " Training bag [6/11] bag loss: 0.6097\n",
            " Training bag [7/11] bag loss: 0.7049\n",
            " Training bag [8/11] bag loss: 0.5966\n",
            " Training bag [9/11] bag loss: 0.5993\n",
            " Training bag [10/11] bag loss: 0.5645\n",
            " Testing bag [0/6] bag loss: 0.6004\n",
            " Testing bag [1/6] bag loss: 0.6038\n",
            " Testing bag [2/6] bag loss: 0.6291\n",
            " Testing bag [3/6] bag loss: 0.5962\n",
            " Testing bag [4/6] bag loss: 0.5867\n",
            " Testing bag [5/6] bag loss: 0.7201ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [60/300] train loss: 0.6208 test loss: 0.6227, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7154\n",
            " Training bag [1/11] bag loss: 0.7011\n",
            " Training bag [2/11] bag loss: 0.6010\n",
            " Training bag [3/11] bag loss: 0.6941\n",
            " Training bag [4/11] bag loss: 0.5653\n",
            " Training bag [5/11] bag loss: 0.5820\n",
            " Training bag [6/11] bag loss: 0.6052\n",
            " Training bag [7/11] bag loss: 0.5954\n",
            " Training bag [8/11] bag loss: 0.5929\n",
            " Training bag [9/11] bag loss: 0.6075\n",
            " Training bag [10/11] bag loss: 0.5700\n",
            " Testing bag [0/6] bag loss: 0.5995\n",
            " Testing bag [1/6] bag loss: 0.6031\n",
            " Testing bag [2/6] bag loss: 0.6250\n",
            " Testing bag [3/6] bag loss: 0.5980\n",
            " Testing bag [4/6] bag loss: 0.5856\n",
            " Testing bag [5/6] bag loss: 0.7222ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [61/300] train loss: 0.6209 test loss: 0.6222, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5905\n",
            " Training bag [1/11] bag loss: 0.7224\n",
            " Training bag [2/11] bag loss: 0.6077\n",
            " Training bag [3/11] bag loss: 0.6030\n",
            " Training bag [4/11] bag loss: 0.6980\n",
            " Training bag [5/11] bag loss: 0.7030\n",
            " Training bag [6/11] bag loss: 0.5707\n",
            " Training bag [7/11] bag loss: 0.5922\n",
            " Training bag [8/11] bag loss: 0.5792\n",
            " Training bag [9/11] bag loss: 0.5983\n",
            " Training bag [10/11] bag loss: 0.5609\n",
            " Testing bag [0/6] bag loss: 0.6009\n",
            " Testing bag [1/6] bag loss: 0.6016\n",
            " Testing bag [2/6] bag loss: 0.6254\n",
            " Testing bag [3/6] bag loss: 0.5976\n",
            " Testing bag [4/6] bag loss: 0.5841\n",
            " Testing bag [5/6] bag loss: 0.7225ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [62/300] train loss: 0.6205 test loss: 0.6220, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6048\n",
            " Training bag [1/11] bag loss: 0.7038\n",
            " Training bag [2/11] bag loss: 0.5620\n",
            " Training bag [3/11] bag loss: 0.5888\n",
            " Training bag [4/11] bag loss: 0.6008\n",
            " Training bag [5/11] bag loss: 0.7238\n",
            " Training bag [6/11] bag loss: 0.5650\n",
            " Training bag [7/11] bag loss: 0.5755\n",
            " Training bag [8/11] bag loss: 0.6991\n",
            " Training bag [9/11] bag loss: 0.5946\n",
            " Training bag [10/11] bag loss: 0.5980\n",
            " Testing bag [0/6] bag loss: 0.6006\n",
            " Testing bag [1/6] bag loss: 0.6044\n",
            " Testing bag [2/6] bag loss: 0.6263\n",
            " Testing bag [3/6] bag loss: 0.5953\n",
            " Testing bag [4/6] bag loss: 0.5823\n",
            " Testing bag [5/6] bag loss: 0.7224ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [63/300] train loss: 0.6197 test loss: 0.6219, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5912\n",
            " Training bag [1/11] bag loss: 0.5569\n",
            " Training bag [2/11] bag loss: 0.6007\n",
            " Training bag [3/11] bag loss: 0.7261\n",
            " Training bag [4/11] bag loss: 0.5780\n",
            " Training bag [5/11] bag loss: 0.5929\n",
            " Training bag [6/11] bag loss: 0.6010\n",
            " Training bag [7/11] bag loss: 0.5914\n",
            " Training bag [8/11] bag loss: 0.7031\n",
            " Training bag [9/11] bag loss: 0.5641\n",
            " Training bag [10/11] bag loss: 0.7076\n",
            " Testing bag [0/6] bag loss: 0.6008\n",
            " Testing bag [1/6] bag loss: 0.6008\n",
            " Testing bag [2/6] bag loss: 0.6225\n",
            " Testing bag [3/6] bag loss: 0.5958\n",
            " Testing bag [4/6] bag loss: 0.5825\n",
            " Testing bag [5/6] bag loss: 0.7253ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [64/300] train loss: 0.6193 test loss: 0.6213, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7066\n",
            " Training bag [1/11] bag loss: 0.5888\n",
            " Training bag [2/11] bag loss: 0.5759\n",
            " Training bag [3/11] bag loss: 0.5532\n",
            " Training bag [4/11] bag loss: 0.6087\n",
            " Training bag [5/11] bag loss: 0.7007\n",
            " Training bag [6/11] bag loss: 0.5930\n",
            " Training bag [7/11] bag loss: 0.6020\n",
            " Training bag [8/11] bag loss: 0.5618\n",
            " Training bag [9/11] bag loss: 0.5973\n",
            " Training bag [10/11] bag loss: 0.7257\n",
            " Testing bag [0/6] bag loss: 0.5983\n",
            " Testing bag [1/6] bag loss: 0.6015\n",
            " Testing bag [2/6] bag loss: 0.6263\n",
            " Testing bag [3/6] bag loss: 0.5939\n",
            " Testing bag [4/6] bag loss: 0.5812\n",
            " Testing bag [5/6] bag loss: 0.7262ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [65/300] train loss: 0.6194 test loss: 0.6212, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7002\n",
            " Training bag [1/11] bag loss: 0.5885\n",
            " Training bag [2/11] bag loss: 0.5729\n",
            " Training bag [3/11] bag loss: 0.6077\n",
            " Training bag [4/11] bag loss: 0.5626\n",
            " Training bag [5/11] bag loss: 0.5926\n",
            " Training bag [6/11] bag loss: 0.6012\n",
            " Training bag [7/11] bag loss: 0.5928\n",
            " Training bag [8/11] bag loss: 0.7236\n",
            " Training bag [9/11] bag loss: 0.7072\n",
            " Training bag [10/11] bag loss: 0.5590\n",
            " Testing bag [0/6] bag loss: 0.6010\n",
            " Testing bag [1/6] bag loss: 0.5982\n",
            " Testing bag [2/6] bag loss: 0.6258\n",
            " Testing bag [3/6] bag loss: 0.5942\n",
            " Testing bag [4/6] bag loss: 0.5816\n",
            " Testing bag [5/6] bag loss: 0.7248ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [66/300] train loss: 0.6189 test loss: 0.6209, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5754\n",
            " Training bag [1/11] bag loss: 0.7060\n",
            " Training bag [2/11] bag loss: 0.7183\n",
            " Training bag [3/11] bag loss: 0.6963\n",
            " Training bag [4/11] bag loss: 0.5968\n",
            " Training bag [5/11] bag loss: 0.5920\n",
            " Training bag [6/11] bag loss: 0.6042\n",
            " Training bag [7/11] bag loss: 0.5995\n",
            " Training bag [8/11] bag loss: 0.5945\n",
            " Training bag [9/11] bag loss: 0.5707\n",
            " Training bag [10/11] bag loss: 0.5601\n",
            " Testing bag [0/6] bag loss: 0.6005\n",
            " Testing bag [1/6] bag loss: 0.5982\n",
            " Testing bag [2/6] bag loss: 0.6225\n",
            " Testing bag [3/6] bag loss: 0.5968\n",
            " Testing bag [4/6] bag loss: 0.5830\n",
            " Testing bag [5/6] bag loss: 0.7252ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [67/300] train loss: 0.6194 test loss: 0.6210, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5907\n",
            " Training bag [1/11] bag loss: 0.5747\n",
            " Training bag [2/11] bag loss: 0.7055\n",
            " Training bag [3/11] bag loss: 0.6019\n",
            " Training bag [4/11] bag loss: 0.5546\n",
            " Training bag [5/11] bag loss: 0.5873\n",
            " Training bag [6/11] bag loss: 0.7004\n",
            " Training bag [7/11] bag loss: 0.5597\n",
            " Training bag [8/11] bag loss: 0.6019\n",
            " Training bag [9/11] bag loss: 0.5890\n",
            " Training bag [10/11] bag loss: 0.7225\n",
            " Testing bag [0/6] bag loss: 0.5983\n",
            " Testing bag [1/6] bag loss: 0.5995\n",
            " Testing bag [2/6] bag loss: 0.6236\n",
            " Testing bag [3/6] bag loss: 0.5943\n",
            " Testing bag [4/6] bag loss: 0.5790\n",
            " Testing bag [5/6] bag loss: 0.7275ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [68/300] train loss: 0.6171 test loss: 0.6204, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5863\n",
            " Training bag [1/11] bag loss: 0.5867\n",
            " Training bag [2/11] bag loss: 0.5607\n",
            " Training bag [3/11] bag loss: 0.5505\n",
            " Training bag [4/11] bag loss: 0.5943\n",
            " Training bag [5/11] bag loss: 0.7132\n",
            " Training bag [6/11] bag loss: 0.7305\n",
            " Training bag [7/11] bag loss: 0.5707\n",
            " Training bag [8/11] bag loss: 0.6047\n",
            " Training bag [9/11] bag loss: 0.6996\n",
            " Training bag [10/11] bag loss: 0.5983\n",
            " Testing bag [0/6] bag loss: 0.5989\n",
            " Testing bag [1/6] bag loss: 0.5994\n",
            " Testing bag [2/6] bag loss: 0.6280\n",
            " Testing bag [3/6] bag loss: 0.5919\n",
            " Testing bag [4/6] bag loss: 0.5805\n",
            " Testing bag [5/6] bag loss: 0.7270ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [69/300] train loss: 0.6178 test loss: 0.6209, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5992\n",
            " Training bag [1/11] bag loss: 0.5874\n",
            " Training bag [2/11] bag loss: 0.5712\n",
            " Training bag [3/11] bag loss: 0.5610\n",
            " Training bag [4/11] bag loss: 0.7027\n",
            " Training bag [5/11] bag loss: 0.5873\n",
            " Training bag [6/11] bag loss: 0.5488\n",
            " Training bag [7/11] bag loss: 0.7117\n",
            " Training bag [8/11] bag loss: 0.6050\n",
            " Training bag [9/11] bag loss: 0.7229\n",
            " Training bag [10/11] bag loss: 0.5936\n",
            " Testing bag [0/6] bag loss: 0.5968\n",
            " Testing bag [1/6] bag loss: 0.5996\n",
            " Testing bag [2/6] bag loss: 0.6251\n",
            " Testing bag [3/6] bag loss: 0.5941\n",
            " Testing bag [4/6] bag loss: 0.5792\n",
            " Testing bag [5/6] bag loss: 0.7262ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [70/300] train loss: 0.6173 test loss: 0.6202, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6011\n",
            " Training bag [1/11] bag loss: 0.5834\n",
            " Training bag [2/11] bag loss: 0.7281\n",
            " Training bag [3/11] bag loss: 0.7015\n",
            " Training bag [4/11] bag loss: 0.7044\n",
            " Training bag [5/11] bag loss: 0.5604\n",
            " Training bag [6/11] bag loss: 0.5924\n",
            " Training bag [7/11] bag loss: 0.5686\n",
            " Training bag [8/11] bag loss: 0.5759\n",
            " Training bag [9/11] bag loss: 0.5923\n",
            " Training bag [10/11] bag loss: 0.5899\n",
            " Testing bag [0/6] bag loss: 0.5982\n",
            " Testing bag [1/6] bag loss: 0.5984\n",
            " Testing bag [2/6] bag loss: 0.6225\n",
            " Testing bag [3/6] bag loss: 0.5932\n",
            " Testing bag [4/6] bag loss: 0.5794\n",
            " Testing bag [5/6] bag loss: 0.7265ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [71/300] train loss: 0.6180 test loss: 0.6197, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5894\n",
            " Training bag [1/11] bag loss: 0.5989\n",
            " Training bag [2/11] bag loss: 0.5897\n",
            " Training bag [3/11] bag loss: 0.5753\n",
            " Training bag [4/11] bag loss: 0.5929\n",
            " Training bag [5/11] bag loss: 0.5546\n",
            " Training bag [6/11] bag loss: 0.5592\n",
            " Training bag [7/11] bag loss: 0.7359\n",
            " Training bag [8/11] bag loss: 0.7062\n",
            " Training bag [9/11] bag loss: 0.7121\n",
            " Training bag [10/11] bag loss: 0.5846\n",
            " Testing bag [0/6] bag loss: 0.5970\n",
            " Testing bag [1/6] bag loss: 0.5977\n",
            " Testing bag [2/6] bag loss: 0.6226\n",
            " Testing bag [3/6] bag loss: 0.5928\n",
            " Testing bag [4/6] bag loss: 0.5779\n",
            " Testing bag [5/6] bag loss: 0.7279ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [72/300] train loss: 0.6181 test loss: 0.6193, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5854\n",
            " Training bag [1/11] bag loss: 0.5497\n",
            " Training bag [2/11] bag loss: 0.5563\n",
            " Training bag [3/11] bag loss: 0.5672\n",
            " Training bag [4/11] bag loss: 0.7087\n",
            " Training bag [5/11] bag loss: 0.6067\n",
            " Training bag [6/11] bag loss: 0.7246\n",
            " Training bag [7/11] bag loss: 0.5944\n",
            " Training bag [8/11] bag loss: 0.6996\n",
            " Training bag [9/11] bag loss: 0.6010\n",
            " Training bag [10/11] bag loss: 0.5857\n",
            " Testing bag [0/6] bag loss: 0.5959\n",
            " Testing bag [1/6] bag loss: 0.5984\n",
            " Testing bag [2/6] bag loss: 0.6254\n",
            " Testing bag [3/6] bag loss: 0.5930\n",
            " Testing bag [4/6] bag loss: 0.5771\n",
            " Testing bag [5/6] bag loss: 0.7279ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [73/300] train loss: 0.6163 test loss: 0.6196, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7034\n",
            " Training bag [1/11] bag loss: 0.5512\n",
            " Training bag [2/11] bag loss: 0.5942\n",
            " Training bag [3/11] bag loss: 0.6969\n",
            " Training bag [4/11] bag loss: 0.7184\n",
            " Training bag [5/11] bag loss: 0.5725\n",
            " Training bag [6/11] bag loss: 0.6016\n",
            " Training bag [7/11] bag loss: 0.5864\n",
            " Training bag [8/11] bag loss: 0.5849\n",
            " Training bag [9/11] bag loss: 0.5942\n",
            " Training bag [10/11] bag loss: 0.5611\n",
            " Testing bag [0/6] bag loss: 0.5975\n",
            " Testing bag [1/6] bag loss: 0.5962\n",
            " Testing bag [2/6] bag loss: 0.6230\n",
            " Testing bag [3/6] bag loss: 0.5959\n",
            " Testing bag [4/6] bag loss: 0.5785\n",
            " Testing bag [5/6] bag loss: 0.7277ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [74/300] train loss: 0.6150 test loss: 0.6198, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7058\n",
            " Training bag [1/11] bag loss: 0.7255\n",
            " Training bag [2/11] bag loss: 0.5726\n",
            " Training bag [3/11] bag loss: 0.5998\n",
            " Training bag [4/11] bag loss: 0.5929\n",
            " Training bag [5/11] bag loss: 0.5614\n",
            " Training bag [6/11] bag loss: 0.5871\n",
            " Training bag [7/11] bag loss: 0.5999\n",
            " Training bag [8/11] bag loss: 0.7007\n",
            " Training bag [9/11] bag loss: 0.5823\n",
            " Training bag [10/11] bag loss: 0.5507\n",
            " Testing bag [0/6] bag loss: 0.6006\n",
            " Testing bag [1/6] bag loss: 0.5961\n",
            " Testing bag [2/6] bag loss: 0.6236\n",
            " Testing bag [3/6] bag loss: 0.5936\n",
            " Testing bag [4/6] bag loss: 0.5782\n",
            " Testing bag [5/6] bag loss: 0.7289ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [75/300] train loss: 0.6162 test loss: 0.6202, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5617\n",
            " Training bag [1/11] bag loss: 0.5901\n",
            " Training bag [2/11] bag loss: 0.5845\n",
            " Training bag [3/11] bag loss: 0.5670\n",
            " Training bag [4/11] bag loss: 0.5820\n",
            " Training bag [5/11] bag loss: 0.7347\n",
            " Training bag [6/11] bag loss: 0.5446\n",
            " Training bag [7/11] bag loss: 0.6006\n",
            " Training bag [8/11] bag loss: 0.7050\n",
            " Training bag [9/11] bag loss: 0.7093\n",
            " Training bag [10/11] bag loss: 0.5912\n",
            " Testing bag [0/6] bag loss: 0.5963\n",
            " Testing bag [1/6] bag loss: 0.5955\n",
            " Testing bag [2/6] bag loss: 0.6225\n",
            " Testing bag [3/6] bag loss: 0.5931\n",
            " Testing bag [4/6] bag loss: 0.5767\n",
            " Testing bag [5/6] bag loss: 0.7312ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [76/300] train loss: 0.6155 test loss: 0.6192, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7009\n",
            " Training bag [1/11] bag loss: 0.5590\n",
            " Training bag [2/11] bag loss: 0.5976\n",
            " Training bag [3/11] bag loss: 0.7209\n",
            " Training bag [4/11] bag loss: 0.5950\n",
            " Training bag [5/11] bag loss: 0.5742\n",
            " Training bag [6/11] bag loss: 0.7022\n",
            " Training bag [7/11] bag loss: 0.5921\n",
            " Training bag [8/11] bag loss: 0.5886\n",
            " Training bag [9/11] bag loss: 0.5835\n",
            " Training bag [10/11] bag loss: 0.5487\n",
            " Testing bag [0/6] bag loss: 0.6007\n",
            " Testing bag [1/6] bag loss: 0.5949\n",
            " Testing bag [2/6] bag loss: 0.6238\n",
            " Testing bag [3/6] bag loss: 0.5958\n",
            " Testing bag [4/6] bag loss: 0.5779\n",
            " Testing bag [5/6] bag loss: 0.7294ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [77/300] train loss: 0.6148 test loss: 0.6204, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7268\n",
            " Training bag [1/11] bag loss: 0.5852\n",
            " Training bag [2/11] bag loss: 0.5874\n",
            " Training bag [3/11] bag loss: 0.5479\n",
            " Training bag [4/11] bag loss: 0.7046\n",
            " Training bag [5/11] bag loss: 0.5937\n",
            " Training bag [6/11] bag loss: 0.5803\n",
            " Training bag [7/11] bag loss: 0.5699\n",
            " Training bag [8/11] bag loss: 0.5566\n",
            " Training bag [9/11] bag loss: 0.6997\n",
            " Training bag [10/11] bag loss: 0.5967\n",
            " Testing bag [0/6] bag loss: 0.5963\n",
            " Testing bag [1/6] bag loss: 0.5939\n",
            " Testing bag [2/6] bag loss: 0.6230\n",
            " Testing bag [3/6] bag loss: 0.5922\n",
            " Testing bag [4/6] bag loss: 0.5748\n",
            " Testing bag [5/6] bag loss: 0.7316ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [78/300] train loss: 0.6135 test loss: 0.6186, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5981\n",
            " Training bag [1/11] bag loss: 0.5834\n",
            " Training bag [2/11] bag loss: 0.5476\n",
            " Training bag [3/11] bag loss: 0.7005\n",
            " Training bag [4/11] bag loss: 0.5725\n",
            " Training bag [5/11] bag loss: 0.7067\n",
            " Training bag [6/11] bag loss: 0.5583\n",
            " Training bag [7/11] bag loss: 0.5797\n",
            " Training bag [8/11] bag loss: 0.5833\n",
            " Training bag [9/11] bag loss: 0.5951\n",
            " Training bag [10/11] bag loss: 0.7320\n",
            " Testing bag [0/6] bag loss: 0.5962\n",
            " Testing bag [1/6] bag loss: 0.5945\n",
            " Testing bag [2/6] bag loss: 0.6218\n",
            " Testing bag [3/6] bag loss: 0.5931\n",
            " Testing bag [4/6] bag loss: 0.5764\n",
            " Testing bag [5/6] bag loss: 0.7326ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [79/300] train loss: 0.6143 test loss: 0.6191, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5546\n",
            " Training bag [1/11] bag loss: 0.5821\n",
            " Training bag [2/11] bag loss: 0.7251\n",
            " Training bag [3/11] bag loss: 0.5393\n",
            " Training bag [4/11] bag loss: 0.5654\n",
            " Training bag [5/11] bag loss: 0.5837\n",
            " Training bag [6/11] bag loss: 0.6998\n",
            " Training bag [7/11] bag loss: 0.6033\n",
            " Training bag [8/11] bag loss: 0.5959\n",
            " Training bag [9/11] bag loss: 0.7068\n",
            " Training bag [10/11] bag loss: 0.5866\n",
            " Testing bag [0/6] bag loss: 0.5963\n",
            " Testing bag [1/6] bag loss: 0.5940\n",
            " Testing bag [2/6] bag loss: 0.6221\n",
            " Testing bag [3/6] bag loss: 0.5922\n",
            " Testing bag [4/6] bag loss: 0.5734\n",
            " Testing bag [5/6] bag loss: 0.7298ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [80/300] train loss: 0.6130 test loss: 0.6180, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5927\n",
            " Training bag [1/11] bag loss: 0.5949\n",
            " Training bag [2/11] bag loss: 0.5575\n",
            " Training bag [3/11] bag loss: 0.5465\n",
            " Training bag [4/11] bag loss: 0.7267\n",
            " Training bag [5/11] bag loss: 0.5812\n",
            " Training bag [6/11] bag loss: 0.5684\n",
            " Training bag [7/11] bag loss: 0.5747\n",
            " Training bag [8/11] bag loss: 0.7059\n",
            " Training bag [9/11] bag loss: 0.7108\n",
            " Training bag [10/11] bag loss: 0.5867\n",
            " Testing bag [0/6] bag loss: 0.5987\n",
            " Testing bag [1/6] bag loss: 0.5916\n",
            " Testing bag [2/6] bag loss: 0.6208\n",
            " Testing bag [3/6] bag loss: 0.5939\n",
            " Testing bag [4/6] bag loss: 0.5786\n",
            " Testing bag [5/6] bag loss: 0.7320ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [81/300] train loss: 0.6132 test loss: 0.6192, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7047\n",
            " Training bag [1/11] bag loss: 0.5949\n",
            " Training bag [2/11] bag loss: 0.7210\n",
            " Training bag [3/11] bag loss: 0.5833\n",
            " Training bag [4/11] bag loss: 0.6932\n",
            " Training bag [5/11] bag loss: 0.5909\n",
            " Training bag [6/11] bag loss: 0.5616\n",
            " Training bag [7/11] bag loss: 0.5892\n",
            " Training bag [8/11] bag loss: 0.5477\n",
            " Training bag [9/11] bag loss: 0.5707\n",
            " Training bag [10/11] bag loss: 0.5812\n",
            " Testing bag [0/6] bag loss: 0.5986\n",
            " Testing bag [1/6] bag loss: 0.5932\n",
            " Testing bag [2/6] bag loss: 0.6239\n",
            " Testing bag [3/6] bag loss: 0.5934\n",
            " Testing bag [4/6] bag loss: 0.5761\n",
            " Testing bag [5/6] bag loss: 0.7298ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [82/300] train loss: 0.6126 test loss: 0.6192, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5923\n",
            " Training bag [1/11] bag loss: 0.5757\n",
            " Training bag [2/11] bag loss: 0.5781\n",
            " Training bag [3/11] bag loss: 0.7265\n",
            " Training bag [4/11] bag loss: 0.5876\n",
            " Training bag [5/11] bag loss: 0.5764\n",
            " Training bag [6/11] bag loss: 0.5609\n",
            " Training bag [7/11] bag loss: 0.7090\n",
            " Training bag [8/11] bag loss: 0.5896\n",
            " Training bag [9/11] bag loss: 0.5479\n",
            " Training bag [10/11] bag loss: 0.7004\n",
            " Testing bag [0/6] bag loss: 0.5968\n",
            " Testing bag [1/6] bag loss: 0.5916\n",
            " Testing bag [2/6] bag loss: 0.6214\n",
            " Testing bag [3/6] bag loss: 0.5930\n",
            " Testing bag [4/6] bag loss: 0.5738\n",
            " Testing bag [5/6] bag loss: 0.7333ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [83/300] train loss: 0.6131 test loss: 0.6183, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5435\n",
            " Training bag [1/11] bag loss: 0.5818\n",
            " Training bag [2/11] bag loss: 0.5835\n",
            " Training bag [3/11] bag loss: 0.7340\n",
            " Training bag [4/11] bag loss: 0.5952\n",
            " Training bag [5/11] bag loss: 0.5762\n",
            " Training bag [6/11] bag loss: 0.7064\n",
            " Training bag [7/11] bag loss: 0.6981\n",
            " Training bag [8/11] bag loss: 0.5695\n",
            " Training bag [9/11] bag loss: 0.5918\n",
            " Training bag [10/11] bag loss: 0.5572\n",
            " Testing bag [0/6] bag loss: 0.5974\n",
            " Testing bag [1/6] bag loss: 0.5906\n",
            " Testing bag [2/6] bag loss: 0.6216\n",
            " Testing bag [3/6] bag loss: 0.5940\n",
            " Testing bag [4/6] bag loss: 0.5774\n",
            " Testing bag [5/6] bag loss: 0.7320ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [84/300] train loss: 0.6125 test loss: 0.6188, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7026\n",
            " Training bag [1/11] bag loss: 0.5829\n",
            " Training bag [2/11] bag loss: 0.5701\n",
            " Training bag [3/11] bag loss: 0.5560\n",
            " Training bag [4/11] bag loss: 0.5926\n",
            " Training bag [5/11] bag loss: 0.5939\n",
            " Training bag [6/11] bag loss: 0.7017\n",
            " Training bag [7/11] bag loss: 0.7244\n",
            " Training bag [8/11] bag loss: 0.5750\n",
            " Training bag [9/11] bag loss: 0.5478\n",
            " Training bag [10/11] bag loss: 0.5869\n",
            " Testing bag [0/6] bag loss: 0.5998\n",
            " Testing bag [1/6] bag loss: 0.5914\n",
            " Testing bag [2/6] bag loss: 0.6201\n",
            " Testing bag [3/6] bag loss: 0.5947\n",
            " Testing bag [4/6] bag loss: 0.5773\n",
            " Testing bag [5/6] bag loss: 0.7325ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [85/300] train loss: 0.6122 test loss: 0.6193, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5913\n",
            " Training bag [1/11] bag loss: 0.6961\n",
            " Training bag [2/11] bag loss: 0.7229\n",
            " Training bag [3/11] bag loss: 0.5558\n",
            " Training bag [4/11] bag loss: 0.5832\n",
            " Training bag [5/11] bag loss: 0.7030\n",
            " Training bag [6/11] bag loss: 0.5876\n",
            " Training bag [7/11] bag loss: 0.5918\n",
            " Training bag [8/11] bag loss: 0.5437\n",
            " Training bag [9/11] bag loss: 0.5701\n",
            " Training bag [10/11] bag loss: 0.5782\n",
            " Testing bag [0/6] bag loss: 0.5974\n",
            " Testing bag [1/6] bag loss: 0.5909\n",
            " Testing bag [2/6] bag loss: 0.6227\n",
            " Testing bag [3/6] bag loss: 0.5916\n",
            " Testing bag [4/6] bag loss: 0.5735\n",
            " Testing bag [5/6] bag loss: 0.7317ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [86/300] train loss: 0.6113 test loss: 0.6180, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5911\n",
            " Training bag [1/11] bag loss: 0.5797\n",
            " Training bag [2/11] bag loss: 0.5711\n",
            " Training bag [3/11] bag loss: 0.7265\n",
            " Training bag [4/11] bag loss: 0.5719\n",
            " Training bag [5/11] bag loss: 0.7053\n",
            " Training bag [6/11] bag loss: 0.5460\n",
            " Training bag [7/11] bag loss: 0.6960\n",
            " Training bag [8/11] bag loss: 0.5880\n",
            " Training bag [9/11] bag loss: 0.5945\n",
            " Training bag [10/11] bag loss: 0.5540\n",
            " Testing bag [0/6] bag loss: 0.5956\n",
            " Testing bag [1/6] bag loss: 0.5902\n",
            " Testing bag [2/6] bag loss: 0.6219\n",
            " Testing bag [3/6] bag loss: 0.5928\n",
            " Testing bag [4/6] bag loss: 0.5738\n",
            " Testing bag [5/6] bag loss: 0.7331ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [87/300] train loss: 0.6113 test loss: 0.6179, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5946\n",
            " Training bag [1/11] bag loss: 0.5665\n",
            " Training bag [2/11] bag loss: 0.7053\n",
            " Training bag [3/11] bag loss: 0.6982\n",
            " Training bag [4/11] bag loss: 0.5869\n",
            " Training bag [5/11] bag loss: 0.5521\n",
            " Training bag [6/11] bag loss: 0.5942\n",
            " Training bag [7/11] bag loss: 0.5790\n",
            " Training bag [8/11] bag loss: 0.5402\n",
            " Training bag [9/11] bag loss: 0.7315\n",
            " Training bag [10/11] bag loss: 0.5819\n",
            " Testing bag [0/6] bag loss: 0.5939\n",
            " Testing bag [1/6] bag loss: 0.5913\n",
            " Testing bag [2/6] bag loss: 0.6248\n",
            " Testing bag [3/6] bag loss: 0.5897\n",
            " Testing bag [4/6] bag loss: 0.5706\n",
            " Testing bag [5/6] bag loss: 0.7344ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [88/300] train loss: 0.6119 test loss: 0.6175, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5656\n",
            " Training bag [1/11] bag loss: 0.5942\n",
            " Training bag [2/11] bag loss: 0.5744\n",
            " Training bag [3/11] bag loss: 0.7070\n",
            " Training bag [4/11] bag loss: 0.5864\n",
            " Training bag [5/11] bag loss: 0.5532\n",
            " Training bag [6/11] bag loss: 0.7269\n",
            " Training bag [7/11] bag loss: 0.6991\n",
            " Training bag [8/11] bag loss: 0.5873\n",
            " Training bag [9/11] bag loss: 0.5447\n",
            " Training bag [10/11] bag loss: 0.5805\n",
            " Testing bag [0/6] bag loss: 0.5950\n",
            " Testing bag [1/6] bag loss: 0.5911\n",
            " Testing bag [2/6] bag loss: 0.6247\n",
            " Testing bag [3/6] bag loss: 0.5913\n",
            " Testing bag [4/6] bag loss: 0.5716\n",
            " Testing bag [5/6] bag loss: 0.7344ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [89/300] train loss: 0.6108 test loss: 0.6180, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6979\n",
            " Training bag [1/11] bag loss: 0.5848\n",
            " Training bag [2/11] bag loss: 0.5859\n",
            " Training bag [3/11] bag loss: 0.7031\n",
            " Training bag [4/11] bag loss: 0.5569\n",
            " Training bag [5/11] bag loss: 0.5704\n",
            " Training bag [6/11] bag loss: 0.5920\n",
            " Training bag [7/11] bag loss: 0.5476\n",
            " Training bag [8/11] bag loss: 0.7245\n",
            " Training bag [9/11] bag loss: 0.5829\n",
            " Training bag [10/11] bag loss: 0.5734\n",
            " Testing bag [0/6] bag loss: 0.5955\n",
            " Testing bag [1/6] bag loss: 0.5904\n",
            " Testing bag [2/6] bag loss: 0.6233\n",
            " Testing bag [3/6] bag loss: 0.5906\n",
            " Testing bag [4/6] bag loss: 0.5726\n",
            " Testing bag [5/6] bag loss: 0.7344ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [90/300] train loss: 0.6108 test loss: 0.6178, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5930\n",
            " Training bag [1/11] bag loss: 0.5706\n",
            " Training bag [2/11] bag loss: 0.5683\n",
            " Training bag [3/11] bag loss: 0.7071\n",
            " Training bag [4/11] bag loss: 0.5414\n",
            " Training bag [5/11] bag loss: 0.5841\n",
            " Training bag [6/11] bag loss: 0.7010\n",
            " Training bag [7/11] bag loss: 0.5516\n",
            " Training bag [8/11] bag loss: 0.7333\n",
            " Training bag [9/11] bag loss: 0.5806\n",
            " Training bag [10/11] bag loss: 0.5833\n",
            " Testing bag [0/6] bag loss: 0.5984\n",
            " Testing bag [1/6] bag loss: 0.5891\n",
            " Testing bag [2/6] bag loss: 0.6264\n",
            " Testing bag [3/6] bag loss: 0.5909\n",
            " Testing bag [4/6] bag loss: 0.5729\n",
            " Testing bag [5/6] bag loss: 0.7351ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [91/300] train loss: 0.6104 test loss: 0.6188, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5638\n",
            " Training bag [1/11] bag loss: 0.5812\n",
            " Training bag [2/11] bag loss: 0.5477\n",
            " Training bag [3/11] bag loss: 0.5329\n",
            " Training bag [4/11] bag loss: 0.5838\n",
            " Training bag [5/11] bag loss: 0.7298\n",
            " Training bag [6/11] bag loss: 0.5769\n",
            " Training bag [7/11] bag loss: 0.7074\n",
            " Training bag [8/11] bag loss: 0.6985\n",
            " Training bag [9/11] bag loss: 0.5895\n",
            " Training bag [10/11] bag loss: 0.5982\n",
            " Testing bag [0/6] bag loss: 0.5961\n",
            " Testing bag [1/6] bag loss: 0.5893\n",
            " Testing bag [2/6] bag loss: 0.6251\n",
            " Testing bag [3/6] bag loss: 0.5892\n",
            " Testing bag [4/6] bag loss: 0.5690\n",
            " Testing bag [5/6] bag loss: 0.7344ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [92/300] train loss: 0.6100 test loss: 0.6172, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5884\n",
            " Training bag [1/11] bag loss: 0.5369\n",
            " Training bag [2/11] bag loss: 0.5796\n",
            " Training bag [3/11] bag loss: 0.5820\n",
            " Training bag [4/11] bag loss: 0.5485\n",
            " Training bag [5/11] bag loss: 0.7014\n",
            " Training bag [6/11] bag loss: 0.5946\n",
            " Training bag [7/11] bag loss: 0.7090\n",
            " Training bag [8/11] bag loss: 0.5720\n",
            " Training bag [9/11] bag loss: 0.5642\n",
            " Training bag [10/11] bag loss: 0.7277\n",
            " Testing bag [0/6] bag loss: 0.5969\n",
            " Testing bag [1/6] bag loss: 0.5877\n",
            " Testing bag [2/6] bag loss: 0.6239\n",
            " Testing bag [3/6] bag loss: 0.5906\n",
            " Testing bag [4/6] bag loss: 0.5704\n",
            " Testing bag [5/6] bag loss: 0.7356ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [93/300] train loss: 0.6095 test loss: 0.6175, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5910\n",
            " Training bag [1/11] bag loss: 0.5688\n",
            " Training bag [2/11] bag loss: 0.5764\n",
            " Training bag [3/11] bag loss: 0.7066\n",
            " Training bag [4/11] bag loss: 0.5512\n",
            " Training bag [5/11] bag loss: 0.5860\n",
            " Training bag [6/11] bag loss: 0.5425\n",
            " Training bag [7/11] bag loss: 0.5850\n",
            " Training bag [8/11] bag loss: 0.5632\n",
            " Training bag [9/11] bag loss: 0.7043\n",
            " Training bag [10/11] bag loss: 0.7364\n",
            " Testing bag [0/6] bag loss: 0.5974\n",
            " Testing bag [1/6] bag loss: 0.5881\n",
            " Testing bag [2/6] bag loss: 0.6222\n",
            " Testing bag [3/6] bag loss: 0.5909\n",
            " Testing bag [4/6] bag loss: 0.5706\n",
            " Testing bag [5/6] bag loss: 0.7381ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [94/300] train loss: 0.6101 test loss: 0.6179, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7277\n",
            " Training bag [1/11] bag loss: 0.5656\n",
            " Training bag [2/11] bag loss: 0.5730\n",
            " Training bag [3/11] bag loss: 0.5882\n",
            " Training bag [4/11] bag loss: 0.5470\n",
            " Training bag [5/11] bag loss: 0.5816\n",
            " Training bag [6/11] bag loss: 0.5941\n",
            " Training bag [7/11] bag loss: 0.5354\n",
            " Training bag [8/11] bag loss: 0.5756\n",
            " Training bag [9/11] bag loss: 0.7039\n",
            " Training bag [10/11] bag loss: 0.7090\n",
            " Testing bag [0/6] bag loss: 0.5928\n",
            " Testing bag [1/6] bag loss: 0.5878\n",
            " Testing bag [2/6] bag loss: 0.6207\n",
            " Testing bag [3/6] bag loss: 0.5883\n",
            " Testing bag [4/6] bag loss: 0.5680\n",
            " Testing bag [5/6] bag loss: 0.7363ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [95/300] train loss: 0.6092 test loss: 0.6156, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5838\n",
            " Training bag [1/11] bag loss: 0.5370\n",
            " Training bag [2/11] bag loss: 0.7276\n",
            " Training bag [3/11] bag loss: 0.5824\n",
            " Training bag [4/11] bag loss: 0.5819\n",
            " Training bag [5/11] bag loss: 0.5650\n",
            " Training bag [6/11] bag loss: 0.5488\n",
            " Training bag [7/11] bag loss: 0.6980\n",
            " Training bag [8/11] bag loss: 0.5934\n",
            " Training bag [9/11] bag loss: 0.7047\n",
            " Training bag [10/11] bag loss: 0.5735\n",
            " Testing bag [0/6] bag loss: 0.5939\n",
            " Testing bag [1/6] bag loss: 0.5877\n",
            " Testing bag [2/6] bag loss: 0.6223\n",
            " Testing bag [3/6] bag loss: 0.5867\n",
            " Testing bag [4/6] bag loss: 0.5688\n",
            " Testing bag [5/6] bag loss: 0.7365ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [96/300] train loss: 0.6087 test loss: 0.6160, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5612\n",
            " Training bag [1/11] bag loss: 0.6987\n",
            " Training bag [2/11] bag loss: 0.5457\n",
            " Training bag [3/11] bag loss: 0.5903\n",
            " Training bag [4/11] bag loss: 0.7245\n",
            " Training bag [5/11] bag loss: 0.5785\n",
            " Training bag [6/11] bag loss: 0.7010\n",
            " Training bag [7/11] bag loss: 0.5722\n",
            " Training bag [8/11] bag loss: 0.5357\n",
            " Training bag [9/11] bag loss: 0.5814\n",
            " Training bag [10/11] bag loss: 0.5920\n",
            " Testing bag [0/6] bag loss: 0.5955\n",
            " Testing bag [1/6] bag loss: 0.5876\n",
            " Testing bag [2/6] bag loss: 0.6225\n",
            " Testing bag [3/6] bag loss: 0.5895\n",
            " Testing bag [4/6] bag loss: 0.5694\n",
            " Testing bag [5/6] bag loss: 0.7339ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [97/300] train loss: 0.6074 test loss: 0.6164, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5809\n",
            " Training bag [1/11] bag loss: 0.5809\n",
            " Training bag [2/11] bag loss: 0.7039\n",
            " Training bag [3/11] bag loss: 0.6956\n",
            " Training bag [4/11] bag loss: 0.5712\n",
            " Training bag [5/11] bag loss: 0.5490\n",
            " Training bag [6/11] bag loss: 0.5347\n",
            " Training bag [7/11] bag loss: 0.5617\n",
            " Training bag [8/11] bag loss: 0.5945\n",
            " Training bag [9/11] bag loss: 0.5890\n",
            " Training bag [10/11] bag loss: 0.7367\n",
            " Testing bag [0/6] bag loss: 0.5968\n",
            " Testing bag [1/6] bag loss: 0.5870\n",
            " Testing bag [2/6] bag loss: 0.6223\n",
            " Testing bag [3/6] bag loss: 0.5903\n",
            " Testing bag [4/6] bag loss: 0.5686\n",
            " Testing bag [5/6] bag loss: 0.7382ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [98/300] train loss: 0.6089 test loss: 0.6172, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5606\n",
            " Training bag [1/11] bag loss: 0.5849\n",
            " Training bag [2/11] bag loss: 0.5773\n",
            " Training bag [3/11] bag loss: 0.7361\n",
            " Training bag [4/11] bag loss: 0.5905\n",
            " Training bag [5/11] bag loss: 0.5832\n",
            " Training bag [6/11] bag loss: 0.7060\n",
            " Training bag [7/11] bag loss: 0.5677\n",
            " Training bag [8/11] bag loss: 0.5396\n",
            " Training bag [9/11] bag loss: 0.6967\n",
            " Training bag [10/11] bag loss: 0.5503\n",
            " Testing bag [0/6] bag loss: 0.5958\n",
            " Testing bag [1/6] bag loss: 0.5850\n",
            " Testing bag [2/6] bag loss: 0.6221\n",
            " Testing bag [3/6] bag loss: 0.5928\n",
            " Testing bag [4/6] bag loss: 0.5687\n",
            " Testing bag [5/6] bag loss: 0.7356ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [99/300] train loss: 0.6084 test loss: 0.6167, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5814\n",
            " Training bag [1/11] bag loss: 0.5678\n",
            " Training bag [2/11] bag loss: 0.5439\n",
            " Training bag [3/11] bag loss: 0.5894\n",
            " Training bag [4/11] bag loss: 0.5854\n",
            " Training bag [5/11] bag loss: 0.5624\n",
            " Training bag [6/11] bag loss: 0.7423\n",
            " Training bag [7/11] bag loss: 0.7097\n",
            " Training bag [8/11] bag loss: 0.5727\n",
            " Training bag [9/11] bag loss: 0.5345\n",
            " Training bag [10/11] bag loss: 0.6972\n",
            " Testing bag [0/6] bag loss: 0.5961\n",
            " Testing bag [1/6] bag loss: 0.5858\n",
            " Testing bag [2/6] bag loss: 0.6222\n",
            " Testing bag [3/6] bag loss: 0.5912\n",
            " Testing bag [4/6] bag loss: 0.5684\n",
            " Testing bag [5/6] bag loss: 0.7382ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [100/300] train loss: 0.6079 test loss: 0.6170, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5888\n",
            " Training bag [1/11] bag loss: 0.7036\n",
            " Training bag [2/11] bag loss: 0.5482\n",
            " Training bag [3/11] bag loss: 0.6954\n",
            " Training bag [4/11] bag loss: 0.5696\n",
            " Training bag [5/11] bag loss: 0.5780\n",
            " Training bag [6/11] bag loss: 0.5832\n",
            " Training bag [7/11] bag loss: 0.5840\n",
            " Training bag [8/11] bag loss: 0.7334\n",
            " Training bag [9/11] bag loss: 0.5671\n",
            " Training bag [10/11] bag loss: 0.5399\n",
            " Testing bag [0/6] bag loss: 0.5987\n",
            " Testing bag [1/6] bag loss: 0.5839\n",
            " Testing bag [2/6] bag loss: 0.6221\n",
            " Testing bag [3/6] bag loss: 0.5909\n",
            " Testing bag [4/6] bag loss: 0.5694\n",
            " Testing bag [5/6] bag loss: 0.7372ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [101/300] train loss: 0.6083 test loss: 0.6170, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7342\n",
            " Training bag [1/11] bag loss: 0.5462\n",
            " Training bag [2/11] bag loss: 0.5628\n",
            " Training bag [3/11] bag loss: 0.7015\n",
            " Training bag [4/11] bag loss: 0.5962\n",
            " Training bag [5/11] bag loss: 0.5706\n",
            " Training bag [6/11] bag loss: 0.5335\n",
            " Training bag [7/11] bag loss: 0.5779\n",
            " Training bag [8/11] bag loss: 0.5764\n",
            " Training bag [9/11] bag loss: 0.5858\n",
            " Training bag [10/11] bag loss: 0.6957\n",
            " Testing bag [0/6] bag loss: 0.5948\n",
            " Testing bag [1/6] bag loss: 0.5862\n",
            " Testing bag [2/6] bag loss: 0.6241\n",
            " Testing bag [3/6] bag loss: 0.5895\n",
            " Testing bag [4/6] bag loss: 0.5663\n",
            " Testing bag [5/6] bag loss: 0.7373ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [102/300] train loss: 0.6073 test loss: 0.6164, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5290\n",
            " Training bag [1/11] bag loss: 0.5855\n",
            " Training bag [2/11] bag loss: 0.7038\n",
            " Training bag [3/11] bag loss: 0.7363\n",
            " Training bag [4/11] bag loss: 0.5914\n",
            " Training bag [5/11] bag loss: 0.5463\n",
            " Training bag [6/11] bag loss: 0.5751\n",
            " Training bag [7/11] bag loss: 0.6936\n",
            " Training bag [8/11] bag loss: 0.5633\n",
            " Training bag [9/11] bag loss: 0.5819\n",
            " Training bag [10/11] bag loss: 0.5693\n",
            " Testing bag [0/6] bag loss: 0.5959\n",
            " Testing bag [1/6] bag loss: 0.5865\n",
            " Testing bag [2/6] bag loss: 0.6231\n",
            " Testing bag [3/6] bag loss: 0.5888\n",
            " Testing bag [4/6] bag loss: 0.5673\n",
            " Testing bag [5/6] bag loss: 0.7369ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [103/300] train loss: 0.6069 test loss: 0.6164, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5695\n",
            " Training bag [1/11] bag loss: 0.5442\n",
            " Training bag [2/11] bag loss: 0.7372\n",
            " Training bag [3/11] bag loss: 0.5839\n",
            " Training bag [4/11] bag loss: 0.5383\n",
            " Training bag [5/11] bag loss: 0.5866\n",
            " Training bag [6/11] bag loss: 0.5602\n",
            " Training bag [7/11] bag loss: 0.5717\n",
            " Training bag [8/11] bag loss: 0.7090\n",
            " Training bag [9/11] bag loss: 0.5801\n",
            " Training bag [10/11] bag loss: 0.6976\n",
            " Testing bag [0/6] bag loss: 0.5953\n",
            " Testing bag [1/6] bag loss: 0.5830\n",
            " Testing bag [2/6] bag loss: 0.6204\n",
            " Testing bag [3/6] bag loss: 0.5882\n",
            " Testing bag [4/6] bag loss: 0.5669\n",
            " Testing bag [5/6] bag loss: 0.7390ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [104/300] train loss: 0.6071 test loss: 0.6155, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7286\n",
            " Training bag [1/11] bag loss: 0.5669\n",
            " Training bag [2/11] bag loss: 0.5613\n",
            " Training bag [3/11] bag loss: 0.6927\n",
            " Training bag [4/11] bag loss: 0.5760\n",
            " Training bag [5/11] bag loss: 0.5819\n",
            " Training bag [6/11] bag loss: 0.5361\n",
            " Training bag [7/11] bag loss: 0.5826\n",
            " Training bag [8/11] bag loss: 0.5885\n",
            " Training bag [9/11] bag loss: 0.7029\n",
            " Training bag [10/11] bag loss: 0.5427\n",
            " Testing bag [0/6] bag loss: 0.5982\n",
            " Testing bag [1/6] bag loss: 0.5839\n",
            " Testing bag [2/6] bag loss: 0.6205\n",
            " Testing bag [3/6] bag loss: 0.5905\n",
            " Testing bag [4/6] bag loss: 0.5681\n",
            " Testing bag [5/6] bag loss: 0.7390ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [105/300] train loss: 0.6055 test loss: 0.6167, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5348\n",
            " Training bag [1/11] bag loss: 0.5830\n",
            " Training bag [2/11] bag loss: 0.7043\n",
            " Training bag [3/11] bag loss: 0.5760\n",
            " Training bag [4/11] bag loss: 0.5434\n",
            " Training bag [5/11] bag loss: 0.5664\n",
            " Training bag [6/11] bag loss: 0.7293\n",
            " Training bag [7/11] bag loss: 0.5864\n",
            " Training bag [8/11] bag loss: 0.5640\n",
            " Training bag [9/11] bag loss: 0.5810\n",
            " Training bag [10/11] bag loss: 0.6951\n",
            " Testing bag [0/6] bag loss: 0.5971\n",
            " Testing bag [1/6] bag loss: 0.5843\n",
            " Testing bag [2/6] bag loss: 0.6210\n",
            " Testing bag [3/6] bag loss: 0.5902\n",
            " Testing bag [4/6] bag loss: 0.5659\n",
            " Testing bag [5/6] bag loss: 0.7399ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [106/300] train loss: 0.6058 test loss: 0.6164, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5646\n",
            " Training bag [1/11] bag loss: 0.5863\n",
            " Training bag [2/11] bag loss: 0.7042\n",
            " Training bag [3/11] bag loss: 0.5377\n",
            " Training bag [4/11] bag loss: 0.5812\n",
            " Training bag [5/11] bag loss: 0.5592\n",
            " Training bag [6/11] bag loss: 0.6995\n",
            " Training bag [7/11] bag loss: 0.5725\n",
            " Training bag [8/11] bag loss: 0.5828\n",
            " Training bag [9/11] bag loss: 0.5419\n",
            " Training bag [10/11] bag loss: 0.7378\n",
            " Testing bag [0/6] bag loss: 0.5957\n",
            " Testing bag [1/6] bag loss: 0.5839\n",
            " Testing bag [2/6] bag loss: 0.6225\n",
            " Testing bag [3/6] bag loss: 0.5902\n",
            " Testing bag [4/6] bag loss: 0.5653\n",
            " Testing bag [5/6] bag loss: 0.7403ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [107/300] train loss: 0.6062 test loss: 0.6163, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5867\n",
            " Training bag [1/11] bag loss: 0.5280\n",
            " Training bag [2/11] bag loss: 0.5633\n",
            " Training bag [3/11] bag loss: 0.5404\n",
            " Training bag [4/11] bag loss: 0.7405\n",
            " Training bag [5/11] bag loss: 0.5701\n",
            " Training bag [6/11] bag loss: 0.7051\n",
            " Training bag [7/11] bag loss: 0.5803\n",
            " Training bag [8/11] bag loss: 0.5821\n",
            " Training bag [9/11] bag loss: 0.5635\n",
            " Training bag [10/11] bag loss: 0.6990\n",
            " Testing bag [0/6] bag loss: 0.5961\n",
            " Testing bag [1/6] bag loss: 0.5827\n",
            " Testing bag [2/6] bag loss: 0.6227\n",
            " Testing bag [3/6] bag loss: 0.5901\n",
            " Testing bag [4/6] bag loss: 0.5674\n",
            " Testing bag [5/6] bag loss: 0.7381ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [108/300] train loss: 0.6054 test loss: 0.6162, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5414\n",
            " Training bag [1/11] bag loss: 0.5646\n",
            " Training bag [2/11] bag loss: 0.5826\n",
            " Training bag [3/11] bag loss: 0.5302\n",
            " Training bag [4/11] bag loss: 0.7309\n",
            " Training bag [5/11] bag loss: 0.7039\n",
            " Training bag [6/11] bag loss: 0.5790\n",
            " Training bag [7/11] bag loss: 0.6940\n",
            " Training bag [8/11] bag loss: 0.5759\n",
            " Training bag [9/11] bag loss: 0.5913\n",
            " Training bag [10/11] bag loss: 0.5585\n",
            " Testing bag [0/6] bag loss: 0.5938\n",
            " Testing bag [1/6] bag loss: 0.5840\n",
            " Testing bag [2/6] bag loss: 0.6225\n",
            " Testing bag [3/6] bag loss: 0.5915\n",
            " Testing bag [4/6] bag loss: 0.5671\n",
            " Testing bag [5/6] bag loss: 0.7387ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [109/300] train loss: 0.6048 test loss: 0.6163, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5635\n",
            " Training bag [1/11] bag loss: 0.5434\n",
            " Training bag [2/11] bag loss: 0.5577\n",
            " Training bag [3/11] bag loss: 0.5706\n",
            " Training bag [4/11] bag loss: 0.6979\n",
            " Training bag [5/11] bag loss: 0.7395\n",
            " Training bag [6/11] bag loss: 0.5880\n",
            " Training bag [7/11] bag loss: 0.5798\n",
            " Training bag [8/11] bag loss: 0.5324\n",
            " Training bag [9/11] bag loss: 0.5848\n",
            " Training bag [10/11] bag loss: 0.7051\n",
            " Testing bag [0/6] bag loss: 0.5956\n",
            " Testing bag [1/6] bag loss: 0.5842\n",
            " Testing bag [2/6] bag loss: 0.6211\n",
            " Testing bag [3/6] bag loss: 0.5902\n",
            " Testing bag [4/6] bag loss: 0.5637\n",
            " Testing bag [5/6] bag loss: 0.7412ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [110/300] train loss: 0.6057 test loss: 0.6160, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5598\n",
            " Training bag [1/11] bag loss: 0.5629\n",
            " Training bag [2/11] bag loss: 0.7371\n",
            " Training bag [3/11] bag loss: 0.5709\n",
            " Training bag [4/11] bag loss: 0.5300\n",
            " Training bag [5/11] bag loss: 0.5791\n",
            " Training bag [6/11] bag loss: 0.6942\n",
            " Training bag [7/11] bag loss: 0.5804\n",
            " Training bag [8/11] bag loss: 0.5393\n",
            " Training bag [9/11] bag loss: 0.5877\n",
            " Training bag [10/11] bag loss: 0.7039\n",
            " Testing bag [0/6] bag loss: 0.5935\n",
            " Testing bag [1/6] bag loss: 0.5830\n",
            " Testing bag [2/6] bag loss: 0.6213\n",
            " Testing bag [3/6] bag loss: 0.5894\n",
            " Testing bag [4/6] bag loss: 0.5657\n",
            " Testing bag [5/6] bag loss: 0.7401ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [111/300] train loss: 0.6041 test loss: 0.6155, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7052\n",
            " Training bag [1/11] bag loss: 0.5305\n",
            " Training bag [2/11] bag loss: 0.5779\n",
            " Training bag [3/11] bag loss: 0.5900\n",
            " Training bag [4/11] bag loss: 0.5439\n",
            " Training bag [5/11] bag loss: 0.5803\n",
            " Training bag [6/11] bag loss: 0.7376\n",
            " Training bag [7/11] bag loss: 0.5653\n",
            " Training bag [8/11] bag loss: 0.6970\n",
            " Training bag [9/11] bag loss: 0.5608\n",
            " Training bag [10/11] bag loss: 0.5843\n",
            " Testing bag [0/6] bag loss: 0.5954\n",
            " Testing bag [1/6] bag loss: 0.5824\n",
            " Testing bag [2/6] bag loss: 0.6223\n",
            " Testing bag [3/6] bag loss: 0.5894\n",
            " Testing bag [4/6] bag loss: 0.5668\n",
            " Testing bag [5/6] bag loss: 0.7395ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [112/300] train loss: 0.6066 test loss: 0.6160, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5596\n",
            " Training bag [1/11] bag loss: 0.5771\n",
            " Training bag [2/11] bag loss: 0.7396\n",
            " Training bag [3/11] bag loss: 0.5808\n",
            " Training bag [4/11] bag loss: 0.5410\n",
            " Training bag [5/11] bag loss: 0.5295\n",
            " Training bag [6/11] bag loss: 0.7047\n",
            " Training bag [7/11] bag loss: 0.5661\n",
            " Training bag [8/11] bag loss: 0.5922\n",
            " Training bag [9/11] bag loss: 0.5729\n",
            " Training bag [10/11] bag loss: 0.6942\n",
            " Testing bag [0/6] bag loss: 0.5952\n",
            " Testing bag [1/6] bag loss: 0.5832\n",
            " Testing bag [2/6] bag loss: 0.6249\n",
            " Testing bag [3/6] bag loss: 0.5868\n",
            " Testing bag [4/6] bag loss: 0.5643\n",
            " Testing bag [5/6] bag loss: 0.7412ROC AUC score: 0.375\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [113/300] train loss: 0.6053 test loss: 0.6159, average score: 0.1667, AUC: class-0>>0.375|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Testing bag [0/4] bag loss: 0.6592\n",
            " Testing bag [1/4] bag loss: 0.6364\n",
            " Testing bag [2/4] bag loss: 0.6996\n",
            " Testing bag [3/4] bag loss: 0.6599ROC AUC score: 0.75\n",
            "ROC AUC score: 0.6666666666666667\n",
            "ROC AUC score: 0.0\n",
            "âœ… Fold 3 completed | Test Acc: 0.5000 | Test AUCs: [np.float64(0.75), np.float64(0.667), np.float64(0.0)]\n",
            "\n",
            "ðŸŒ€ Starting CV Fold 4\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6868\n",
            " Training bag [1/11] bag loss: 0.6920\n",
            " Training bag [2/11] bag loss: 0.6972\n",
            " Training bag [3/11] bag loss: 0.6830\n",
            " Training bag [4/11] bag loss: 0.6832\n",
            " Training bag [5/11] bag loss: 0.6920\n",
            " Training bag [6/11] bag loss: 0.6750\n",
            " Training bag [7/11] bag loss: 0.7046\n",
            " Training bag [8/11] bag loss: 0.7000\n",
            " Training bag [9/11] bag loss: 0.6950\n",
            " Training bag [10/11] bag loss: 0.6959\n",
            " Testing bag [0/6] bag loss: 0.6824\n",
            " Testing bag [1/6] bag loss: 0.6836\n",
            " Testing bag [2/6] bag loss: 0.6950\n",
            " Testing bag [3/6] bag loss: 0.6794\n",
            " Testing bag [4/6] bag loss: 0.6930\n",
            " Testing bag [5/6] bag loss: 0.6948ROC AUC score: 0.875\n",
            "ROC AUC score: 0.19999999999999996\n",
            "ROC AUC score: 0.888888888888889\n",
            "\n",
            " Epoch [1/300] train loss: 0.6913 test loss: 0.6880, average score: 0.1667, AUC: class-0>>0.875|class-1>>0.19999999999999996|class-2>>0.888888888888889\n",
            "Best model saved at: weights/20250626/fold_4_19.pth\n",
            "Best thresholds ===>>> class-0>>0.4618235230445862|class-1>>0.47296005487442017|class-2>>0.47552117705345154\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6800\n",
            " Training bag [1/11] bag loss: 0.6935\n",
            " Training bag [2/11] bag loss: 0.6925\n",
            " Training bag [3/11] bag loss: 0.6889\n",
            " Training bag [4/11] bag loss: 0.6992\n",
            " Training bag [5/11] bag loss: 0.6777\n",
            " Training bag [6/11] bag loss: 0.6940\n",
            " Training bag [7/11] bag loss: 0.6813\n",
            " Training bag [8/11] bag loss: 0.6923\n",
            " Training bag [9/11] bag loss: 0.6786\n",
            " Training bag [10/11] bag loss: 0.6792\n",
            " Testing bag [0/6] bag loss: 0.6813\n",
            " Testing bag [1/6] bag loss: 0.6819\n",
            " Testing bag [2/6] bag loss: 0.6853\n",
            " Testing bag [3/6] bag loss: 0.6790\n",
            " Testing bag [4/6] bag loss: 0.6910\n",
            " Testing bag [5/6] bag loss: 0.6838ROC AUC score: 0.875\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.888888888888889\n",
            "\n",
            " Epoch [2/300] train loss: 0.6870 test loss: 0.6837, average score: 0.3333, AUC: class-0>>0.875|class-1>>0.6|class-2>>0.888888888888889\n",
            "Best model saved at: weights/20250626/fold_4_19.pth\n",
            "Best thresholds ===>>> class-0>>0.45890864729881287|class-1>>0.46062907576560974|class-2>>0.4633612036705017\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6840\n",
            " Training bag [1/11] bag loss: 0.6909\n",
            " Training bag [2/11] bag loss: 0.6794\n",
            " Training bag [3/11] bag loss: 0.6817\n",
            " Training bag [4/11] bag loss: 0.6759\n",
            " Training bag [5/11] bag loss: 0.6817\n",
            " Training bag [6/11] bag loss: 0.6770\n",
            " Training bag [7/11] bag loss: 0.6941\n",
            " Training bag [8/11] bag loss: 0.6757\n",
            " Training bag [9/11] bag loss: 0.6953\n",
            " Training bag [10/11] bag loss: 0.6704\n",
            " Testing bag [0/6] bag loss: 0.6751\n",
            " Testing bag [1/6] bag loss: 0.6779\n",
            " Testing bag [2/6] bag loss: 0.6807\n",
            " Testing bag [3/6] bag loss: 0.6747\n",
            " Testing bag [4/6] bag loss: 0.6930\n",
            " Testing bag [5/6] bag loss: 0.6783ROC AUC score: 0.875\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.7777777777777779\n",
            "\n",
            " Epoch [3/300] train loss: 0.6824 test loss: 0.6800, average score: 0.3333, AUC: class-0>>0.875|class-1>>0.6|class-2>>0.7777777777777779\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6778\n",
            " Training bag [1/11] bag loss: 0.6669\n",
            " Training bag [2/11] bag loss: 0.6818\n",
            " Training bag [3/11] bag loss: 0.6980\n",
            " Training bag [4/11] bag loss: 0.6768\n",
            " Training bag [5/11] bag loss: 0.6933\n",
            " Training bag [6/11] bag loss: 0.6699\n",
            " Training bag [7/11] bag loss: 0.6906\n",
            " Training bag [8/11] bag loss: 0.6700\n",
            " Training bag [9/11] bag loss: 0.6727\n",
            " Training bag [10/11] bag loss: 0.6713\n",
            " Testing bag [0/6] bag loss: 0.6717\n",
            " Testing bag [1/6] bag loss: 0.6748\n",
            " Testing bag [2/6] bag loss: 0.6742\n",
            " Testing bag [3/6] bag loss: 0.6708\n",
            " Testing bag [4/6] bag loss: 0.6916\n",
            " Testing bag [5/6] bag loss: 0.6747ROC AUC score: 1.0\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.7777777777777779\n",
            "\n",
            " Epoch [4/300] train loss: 0.6790 test loss: 0.6763, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.6|class-2>>0.7777777777777779\n",
            "Best model saved at: weights/20250626/fold_4_19.pth\n",
            "Best thresholds ===>>> class-0>>0.44679322838783264|class-1>>0.4370266795158386|class-2>>0.44928473234176636\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6899\n",
            " Training bag [1/11] bag loss: 0.6912\n",
            " Training bag [2/11] bag loss: 0.6642\n",
            " Training bag [3/11] bag loss: 0.6787\n",
            " Training bag [4/11] bag loss: 0.6653\n",
            " Training bag [5/11] bag loss: 0.6768\n",
            " Training bag [6/11] bag loss: 0.6770\n",
            " Training bag [7/11] bag loss: 0.6894\n",
            " Training bag [8/11] bag loss: 0.6672\n",
            " Training bag [9/11] bag loss: 0.6685\n",
            " Training bag [10/11] bag loss: 0.6597\n",
            " Testing bag [0/6] bag loss: 0.6683\n",
            " Testing bag [1/6] bag loss: 0.6688\n",
            " Testing bag [2/6] bag loss: 0.6693\n",
            " Testing bag [3/6] bag loss: 0.6667\n",
            " Testing bag [4/6] bag loss: 0.6941\n",
            " Testing bag [5/6] bag loss: 0.6694ROC AUC score: 1.0\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.7777777777777779\n",
            "\n",
            " Epoch [5/300] train loss: 0.6753 test loss: 0.6728, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.6|class-2>>0.7777777777777779\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6611\n",
            " Training bag [1/11] bag loss: 0.6625\n",
            " Training bag [2/11] bag loss: 0.6546\n",
            " Training bag [3/11] bag loss: 0.6941\n",
            " Training bag [4/11] bag loss: 0.6764\n",
            " Training bag [5/11] bag loss: 0.6467\n",
            " Training bag [6/11] bag loss: 0.6937\n",
            " Training bag [7/11] bag loss: 0.6770\n",
            " Training bag [8/11] bag loss: 0.6949\n",
            " Training bag [9/11] bag loss: 0.6686\n",
            " Training bag [10/11] bag loss: 0.6697\n",
            " Testing bag [0/6] bag loss: 0.6600\n",
            " Testing bag [1/6] bag loss: 0.6626\n",
            " Testing bag [2/6] bag loss: 0.6697\n",
            " Testing bag [3/6] bag loss: 0.6605\n",
            " Testing bag [4/6] bag loss: 0.6933\n",
            " Testing bag [5/6] bag loss: 0.6697ROC AUC score: 1.0\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [6/300] train loss: 0.6727 test loss: 0.6693, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.6|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6937\n",
            " Training bag [1/11] bag loss: 0.6500\n",
            " Training bag [2/11] bag loss: 0.6677\n",
            " Training bag [3/11] bag loss: 0.6548\n",
            " Training bag [4/11] bag loss: 0.6568\n",
            " Training bag [5/11] bag loss: 0.6478\n",
            " Training bag [6/11] bag loss: 0.6938\n",
            " Training bag [7/11] bag loss: 0.6719\n",
            " Training bag [8/11] bag loss: 0.6938\n",
            " Training bag [9/11] bag loss: 0.6704\n",
            " Training bag [10/11] bag loss: 0.6621\n",
            " Testing bag [0/6] bag loss: 0.6569\n",
            " Testing bag [1/6] bag loss: 0.6586\n",
            " Testing bag [2/6] bag loss: 0.6639\n",
            " Testing bag [3/6] bag loss: 0.6546\n",
            " Testing bag [4/6] bag loss: 0.6940\n",
            " Testing bag [5/6] bag loss: 0.6646ROC AUC score: 1.0\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.7777777777777779\n",
            "\n",
            " Epoch [7/300] train loss: 0.6693 test loss: 0.6654, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.6|class-2>>0.7777777777777779\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6492\n",
            " Training bag [1/11] bag loss: 0.6947\n",
            " Training bag [2/11] bag loss: 0.6659\n",
            " Training bag [3/11] bag loss: 0.6637\n",
            " Training bag [4/11] bag loss: 0.6922\n",
            " Training bag [5/11] bag loss: 0.6510\n",
            " Training bag [6/11] bag loss: 0.6898\n",
            " Training bag [7/11] bag loss: 0.6561\n",
            " Training bag [8/11] bag loss: 0.6467\n",
            " Training bag [9/11] bag loss: 0.6622\n",
            " Training bag [10/11] bag loss: 0.6574\n",
            " Testing bag [0/6] bag loss: 0.6548\n",
            " Testing bag [1/6] bag loss: 0.6562\n",
            " Testing bag [2/6] bag loss: 0.6599\n",
            " Testing bag [3/6] bag loss: 0.6553\n",
            " Testing bag [4/6] bag loss: 0.6947\n",
            " Testing bag [5/6] bag loss: 0.6599ROC AUC score: 1.0\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [8/300] train loss: 0.6663 test loss: 0.6635, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.6|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6547\n",
            " Training bag [1/11] bag loss: 0.6548\n",
            " Training bag [2/11] bag loss: 0.6566\n",
            " Training bag [3/11] bag loss: 0.6954\n",
            " Training bag [4/11] bag loss: 0.6481\n",
            " Training bag [5/11] bag loss: 0.6982\n",
            " Training bag [6/11] bag loss: 0.6512\n",
            " Training bag [7/11] bag loss: 0.6497\n",
            " Training bag [8/11] bag loss: 0.6946\n",
            " Training bag [9/11] bag loss: 0.6567\n",
            " Training bag [10/11] bag loss: 0.6490\n",
            " Testing bag [0/6] bag loss: 0.6550\n",
            " Testing bag [1/6] bag loss: 0.6575\n",
            " Testing bag [2/6] bag loss: 0.6526\n",
            " Testing bag [3/6] bag loss: 0.6544\n",
            " Testing bag [4/6] bag loss: 0.6956\n",
            " Testing bag [5/6] bag loss: 0.6539ROC AUC score: 1.0\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [9/300] train loss: 0.6645 test loss: 0.6615, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.6|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6560\n",
            " Training bag [1/11] bag loss: 0.6472\n",
            " Training bag [2/11] bag loss: 0.6421\n",
            " Training bag [3/11] bag loss: 0.6497\n",
            " Training bag [4/11] bag loss: 0.6447\n",
            " Training bag [5/11] bag loss: 0.7031\n",
            " Training bag [6/11] bag loss: 0.6454\n",
            " Training bag [7/11] bag loss: 0.6985\n",
            " Training bag [8/11] bag loss: 0.6442\n",
            " Training bag [9/11] bag loss: 0.6967\n",
            " Training bag [10/11] bag loss: 0.6514\n",
            " Testing bag [0/6] bag loss: 0.6514\n",
            " Testing bag [1/6] bag loss: 0.6514\n",
            " Testing bag [2/6] bag loss: 0.6501\n",
            " Testing bag [3/6] bag loss: 0.6500\n",
            " Testing bag [4/6] bag loss: 0.6992\n",
            " Testing bag [5/6] bag loss: 0.6491ROC AUC score: 1.0\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.7777777777777779\n",
            "\n",
            " Epoch [10/300] train loss: 0.6617 test loss: 0.6585, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.6|class-2>>0.7777777777777779\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6506\n",
            " Training bag [1/11] bag loss: 0.6459\n",
            " Training bag [2/11] bag loss: 0.6950\n",
            " Training bag [3/11] bag loss: 0.6434\n",
            " Training bag [4/11] bag loss: 0.6419\n",
            " Training bag [5/11] bag loss: 0.6335\n",
            " Training bag [6/11] bag loss: 0.6433\n",
            " Training bag [7/11] bag loss: 0.6499\n",
            " Training bag [8/11] bag loss: 0.7004\n",
            " Training bag [9/11] bag loss: 0.6461\n",
            " Training bag [10/11] bag loss: 0.7040\n",
            " Testing bag [0/6] bag loss: 0.6476\n",
            " Testing bag [1/6] bag loss: 0.6479\n",
            " Testing bag [2/6] bag loss: 0.6477\n",
            " Testing bag [3/6] bag loss: 0.6473\n",
            " Testing bag [4/6] bag loss: 0.7000\n",
            " Testing bag [5/6] bag loss: 0.6470ROC AUC score: 1.0\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [11/300] train loss: 0.6594 test loss: 0.6562, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.6|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6963\n",
            " Training bag [1/11] bag loss: 0.6458\n",
            " Training bag [2/11] bag loss: 0.6468\n",
            " Training bag [3/11] bag loss: 0.6974\n",
            " Training bag [4/11] bag loss: 0.6490\n",
            " Training bag [5/11] bag loss: 0.6413\n",
            " Training bag [6/11] bag loss: 0.6468\n",
            " Training bag [7/11] bag loss: 0.6365\n",
            " Training bag [8/11] bag loss: 0.6407\n",
            " Training bag [9/11] bag loss: 0.6952\n",
            " Training bag [10/11] bag loss: 0.6361\n",
            " Testing bag [0/6] bag loss: 0.6476\n",
            " Testing bag [1/6] bag loss: 0.6471\n",
            " Testing bag [2/6] bag loss: 0.6438\n",
            " Testing bag [3/6] bag loss: 0.6466\n",
            " Testing bag [4/6] bag loss: 0.6987\n",
            " Testing bag [5/6] bag loss: 0.6433ROC AUC score: 1.0\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.7777777777777779\n",
            "\n",
            " Epoch [12/300] train loss: 0.6574 test loss: 0.6545, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.6|class-2>>0.7777777777777779\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6957\n",
            " Training bag [1/11] bag loss: 0.6484\n",
            " Training bag [2/11] bag loss: 0.6364\n",
            " Training bag [3/11] bag loss: 0.6334\n",
            " Training bag [4/11] bag loss: 0.6425\n",
            " Training bag [5/11] bag loss: 0.6491\n",
            " Training bag [6/11] bag loss: 0.6974\n",
            " Training bag [7/11] bag loss: 0.6264\n",
            " Training bag [8/11] bag loss: 0.6422\n",
            " Training bag [9/11] bag loss: 0.7009\n",
            " Training bag [10/11] bag loss: 0.6431\n",
            " Testing bag [0/6] bag loss: 0.6420\n",
            " Testing bag [1/6] bag loss: 0.6430\n",
            " Testing bag [2/6] bag loss: 0.6453\n",
            " Testing bag [3/6] bag loss: 0.6424\n",
            " Testing bag [4/6] bag loss: 0.7014\n",
            " Testing bag [5/6] bag loss: 0.6436ROC AUC score: 1.0\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.7777777777777779\n",
            "\n",
            " Epoch [13/300] train loss: 0.6560 test loss: 0.6530, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.6|class-2>>0.7777777777777779\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6472\n",
            " Training bag [1/11] bag loss: 0.6310\n",
            " Training bag [2/11] bag loss: 0.6992\n",
            " Training bag [3/11] bag loss: 0.6365\n",
            " Training bag [4/11] bag loss: 0.6416\n",
            " Training bag [5/11] bag loss: 0.7023\n",
            " Training bag [6/11] bag loss: 0.6287\n",
            " Training bag [7/11] bag loss: 0.6953\n",
            " Training bag [8/11] bag loss: 0.6225\n",
            " Training bag [9/11] bag loss: 0.6459\n",
            " Training bag [10/11] bag loss: 0.6414\n",
            " Testing bag [0/6] bag loss: 0.6411\n",
            " Testing bag [1/6] bag loss: 0.6418\n",
            " Testing bag [2/6] bag loss: 0.6409\n",
            " Testing bag [3/6] bag loss: 0.6404\n",
            " Testing bag [4/6] bag loss: 0.6991\n",
            " Testing bag [5/6] bag loss: 0.6422ROC AUC score: 1.0\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.7777777777777779\n",
            "\n",
            " Epoch [14/300] train loss: 0.6538 test loss: 0.6509, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.6|class-2>>0.7777777777777779\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6281\n",
            " Training bag [1/11] bag loss: 0.6429\n",
            " Training bag [2/11] bag loss: 0.6258\n",
            " Training bag [3/11] bag loss: 0.6359\n",
            " Training bag [4/11] bag loss: 0.6427\n",
            " Training bag [5/11] bag loss: 0.7079\n",
            " Training bag [6/11] bag loss: 0.6322\n",
            " Training bag [7/11] bag loss: 0.7036\n",
            " Training bag [8/11] bag loss: 0.6343\n",
            " Training bag [9/11] bag loss: 0.6993\n",
            " Training bag [10/11] bag loss: 0.6248\n",
            " Testing bag [0/6] bag loss: 0.6415\n",
            " Testing bag [1/6] bag loss: 0.6412\n",
            " Testing bag [2/6] bag loss: 0.6364\n",
            " Testing bag [3/6] bag loss: 0.6405\n",
            " Testing bag [4/6] bag loss: 0.7013\n",
            " Testing bag [5/6] bag loss: 0.6353ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.7777777777777779\n",
            "\n",
            " Epoch [15/300] train loss: 0.6525 test loss: 0.6494, average score: 0.6667, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.7777777777777779\n",
            "Best model saved at: weights/20250626/fold_4_19.pth\n",
            "Best thresholds ===>>> class-0>>0.4035181701183319|class-1>>0.3459818959236145|class-2>>0.3982011079788208\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6381\n",
            " Training bag [1/11] bag loss: 0.7044\n",
            " Training bag [2/11] bag loss: 0.6285\n",
            " Training bag [3/11] bag loss: 0.6215\n",
            " Training bag [4/11] bag loss: 0.6344\n",
            " Training bag [5/11] bag loss: 0.6978\n",
            " Training bag [6/11] bag loss: 0.6232\n",
            " Training bag [7/11] bag loss: 0.6343\n",
            " Training bag [8/11] bag loss: 0.6988\n",
            " Training bag [9/11] bag loss: 0.6336\n",
            " Training bag [10/11] bag loss: 0.6437\n",
            " Testing bag [0/6] bag loss: 0.6382\n",
            " Testing bag [1/6] bag loss: 0.6374\n",
            " Testing bag [2/6] bag loss: 0.6374\n",
            " Testing bag [3/6] bag loss: 0.6370\n",
            " Testing bag [4/6] bag loss: 0.7030\n",
            " Testing bag [5/6] bag loss: 0.6376ROC AUC score: 1.0\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.7777777777777779\n",
            "\n",
            " Epoch [16/300] train loss: 0.6508 test loss: 0.6484, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.6|class-2>>0.7777777777777779\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6221\n",
            " Training bag [1/11] bag loss: 0.6307\n",
            " Training bag [2/11] bag loss: 0.6374\n",
            " Training bag [3/11] bag loss: 0.6169\n",
            " Training bag [4/11] bag loss: 0.7030\n",
            " Training bag [5/11] bag loss: 0.6331\n",
            " Training bag [6/11] bag loss: 0.7039\n",
            " Training bag [7/11] bag loss: 0.6310\n",
            " Training bag [8/11] bag loss: 0.7050\n",
            " Training bag [9/11] bag loss: 0.6237\n",
            " Training bag [10/11] bag loss: 0.6369\n",
            " Testing bag [0/6] bag loss: 0.6375\n",
            " Testing bag [1/6] bag loss: 0.6382\n",
            " Testing bag [2/6] bag loss: 0.6341\n",
            " Testing bag [3/6] bag loss: 0.6367\n",
            " Testing bag [4/6] bag loss: 0.7033\n",
            " Testing bag [5/6] bag loss: 0.6350ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [17/300] train loss: 0.6494 test loss: 0.6475, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6261\n",
            " Training bag [1/11] bag loss: 0.6200\n",
            " Training bag [2/11] bag loss: 0.6214\n",
            " Training bag [3/11] bag loss: 0.7082\n",
            " Training bag [4/11] bag loss: 0.7026\n",
            " Training bag [5/11] bag loss: 0.6306\n",
            " Training bag [6/11] bag loss: 0.6145\n",
            " Training bag [7/11] bag loss: 0.6354\n",
            " Training bag [8/11] bag loss: 0.6321\n",
            " Training bag [9/11] bag loss: 0.6343\n",
            " Training bag [10/11] bag loss: 0.7008\n",
            " Testing bag [0/6] bag loss: 0.6365\n",
            " Testing bag [1/6] bag loss: 0.6354\n",
            " Testing bag [2/6] bag loss: 0.6292\n",
            " Testing bag [3/6] bag loss: 0.6351\n",
            " Testing bag [4/6] bag loss: 0.7044\n",
            " Testing bag [5/6] bag loss: 0.6306ROC AUC score: 1.0\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [18/300] train loss: 0.6478 test loss: 0.6452, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.6|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6320\n",
            " Training bag [1/11] bag loss: 0.7072\n",
            " Training bag [2/11] bag loss: 0.6339\n",
            " Training bag [3/11] bag loss: 0.6983\n",
            " Training bag [4/11] bag loss: 0.6348\n",
            " Training bag [5/11] bag loss: 0.6230\n",
            " Training bag [6/11] bag loss: 0.6988\n",
            " Training bag [7/11] bag loss: 0.6218\n",
            " Training bag [8/11] bag loss: 0.6211\n",
            " Training bag [9/11] bag loss: 0.6225\n",
            " Training bag [10/11] bag loss: 0.6268\n",
            " Testing bag [0/6] bag loss: 0.6360\n",
            " Testing bag [1/6] bag loss: 0.6354\n",
            " Testing bag [2/6] bag loss: 0.6304\n",
            " Testing bag [3/6] bag loss: 0.6350\n",
            " Testing bag [4/6] bag loss: 0.7039\n",
            " Testing bag [5/6] bag loss: 0.6306ROC AUC score: 1.0\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [19/300] train loss: 0.6473 test loss: 0.6452, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.6|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6198\n",
            " Training bag [1/11] bag loss: 0.6290\n",
            " Training bag [2/11] bag loss: 0.7093\n",
            " Training bag [3/11] bag loss: 0.6073\n",
            " Training bag [4/11] bag loss: 0.6264\n",
            " Training bag [5/11] bag loss: 0.6085\n",
            " Training bag [6/11] bag loss: 0.7020\n",
            " Training bag [7/11] bag loss: 0.6309\n",
            " Training bag [8/11] bag loss: 0.6353\n",
            " Training bag [9/11] bag loss: 0.6333\n",
            " Training bag [10/11] bag loss: 0.7061\n",
            " Testing bag [0/6] bag loss: 0.6333\n",
            " Testing bag [1/6] bag loss: 0.6315\n",
            " Testing bag [2/6] bag loss: 0.6271\n",
            " Testing bag [3/6] bag loss: 0.6320\n",
            " Testing bag [4/6] bag loss: 0.7080\n",
            " Testing bag [5/6] bag loss: 0.6283ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [20/300] train loss: 0.6462 test loss: 0.6434, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6294\n",
            " Training bag [1/11] bag loss: 0.6295\n",
            " Training bag [2/11] bag loss: 0.6066\n",
            " Training bag [3/11] bag loss: 0.7060\n",
            " Training bag [4/11] bag loss: 0.6200\n",
            " Training bag [5/11] bag loss: 0.6293\n",
            " Training bag [6/11] bag loss: 0.6167\n",
            " Training bag [7/11] bag loss: 0.6106\n",
            " Training bag [8/11] bag loss: 0.6206\n",
            " Training bag [9/11] bag loss: 0.7154\n",
            " Training bag [10/11] bag loss: 0.7056\n",
            " Testing bag [0/6] bag loss: 0.6332\n",
            " Testing bag [1/6] bag loss: 0.6314\n",
            " Testing bag [2/6] bag loss: 0.6235\n",
            " Testing bag [3/6] bag loss: 0.6307\n",
            " Testing bag [4/6] bag loss: 0.7101\n",
            " Testing bag [5/6] bag loss: 0.6250ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [21/300] train loss: 0.6445 test loss: 0.6423, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7051\n",
            " Training bag [1/11] bag loss: 0.6215\n",
            " Training bag [2/11] bag loss: 0.6183\n",
            " Training bag [3/11] bag loss: 0.6261\n",
            " Training bag [4/11] bag loss: 0.7069\n",
            " Training bag [5/11] bag loss: 0.6304\n",
            " Training bag [6/11] bag loss: 0.6268\n",
            " Training bag [7/11] bag loss: 0.6079\n",
            " Training bag [8/11] bag loss: 0.6160\n",
            " Training bag [9/11] bag loss: 0.7019\n",
            " Training bag [10/11] bag loss: 0.6119\n",
            " Testing bag [0/6] bag loss: 0.6344\n",
            " Testing bag [1/6] bag loss: 0.6323\n",
            " Testing bag [2/6] bag loss: 0.6221\n",
            " Testing bag [3/6] bag loss: 0.6317\n",
            " Testing bag [4/6] bag loss: 0.7059\n",
            " Testing bag [5/6] bag loss: 0.6225ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [22/300] train loss: 0.6430 test loss: 0.6415, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7072\n",
            " Training bag [1/11] bag loss: 0.6110\n",
            " Training bag [2/11] bag loss: 0.6058\n",
            " Training bag [3/11] bag loss: 0.6246\n",
            " Training bag [4/11] bag loss: 0.7002\n",
            " Training bag [5/11] bag loss: 0.6216\n",
            " Training bag [6/11] bag loss: 0.6247\n",
            " Training bag [7/11] bag loss: 0.6298\n",
            " Training bag [8/11] bag loss: 0.7043\n",
            " Training bag [9/11] bag loss: 0.6129\n",
            " Training bag [10/11] bag loss: 0.6271\n",
            " Testing bag [0/6] bag loss: 0.6313\n",
            " Testing bag [1/6] bag loss: 0.6303\n",
            " Testing bag [2/6] bag loss: 0.6219\n",
            " Testing bag [3/6] bag loss: 0.6294\n",
            " Testing bag [4/6] bag loss: 0.7079\n",
            " Testing bag [5/6] bag loss: 0.6252ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [23/300] train loss: 0.6426 test loss: 0.6410, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6147\n",
            " Training bag [1/11] bag loss: 0.6227\n",
            " Training bag [2/11] bag loss: 0.6266\n",
            " Training bag [3/11] bag loss: 0.7136\n",
            " Training bag [4/11] bag loss: 0.6141\n",
            " Training bag [5/11] bag loss: 0.6208\n",
            " Training bag [6/11] bag loss: 0.6141\n",
            " Training bag [7/11] bag loss: 0.7090\n",
            " Training bag [8/11] bag loss: 0.6110\n",
            " Training bag [9/11] bag loss: 0.6066\n",
            " Training bag [10/11] bag loss: 0.7044\n",
            " Testing bag [0/6] bag loss: 0.6314\n",
            " Testing bag [1/6] bag loss: 0.6283\n",
            " Testing bag [2/6] bag loss: 0.6193\n",
            " Testing bag [3/6] bag loss: 0.6294\n",
            " Testing bag [4/6] bag loss: 0.7092\n",
            " Testing bag [5/6] bag loss: 0.6202ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [24/300] train loss: 0.6416 test loss: 0.6396, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7065\n",
            " Training bag [1/11] bag loss: 0.6023\n",
            " Training bag [2/11] bag loss: 0.6245\n",
            " Training bag [3/11] bag loss: 0.7004\n",
            " Training bag [4/11] bag loss: 0.6286\n",
            " Training bag [5/11] bag loss: 0.7050\n",
            " Training bag [6/11] bag loss: 0.6098\n",
            " Training bag [7/11] bag loss: 0.6297\n",
            " Training bag [8/11] bag loss: 0.6019\n",
            " Training bag [9/11] bag loss: 0.6216\n",
            " Training bag [10/11] bag loss: 0.6160\n",
            " Testing bag [0/6] bag loss: 0.6297\n",
            " Testing bag [1/6] bag loss: 0.6269\n",
            " Testing bag [2/6] bag loss: 0.6222\n",
            " Testing bag [3/6] bag loss: 0.6272\n",
            " Testing bag [4/6] bag loss: 0.7068\n",
            " Testing bag [5/6] bag loss: 0.6227ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [25/300] train loss: 0.6406 test loss: 0.6392, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6010\n",
            " Training bag [1/11] bag loss: 0.7057\n",
            " Training bag [2/11] bag loss: 0.6075\n",
            " Training bag [3/11] bag loss: 0.6249\n",
            " Training bag [4/11] bag loss: 0.7094\n",
            " Training bag [5/11] bag loss: 0.6151\n",
            " Training bag [6/11] bag loss: 0.6024\n",
            " Training bag [7/11] bag loss: 0.6172\n",
            " Training bag [8/11] bag loss: 0.6220\n",
            " Training bag [9/11] bag loss: 0.7041\n",
            " Training bag [10/11] bag loss: 0.6235\n",
            " Testing bag [0/6] bag loss: 0.6290\n",
            " Testing bag [1/6] bag loss: 0.6252\n",
            " Testing bag [2/6] bag loss: 0.6184\n",
            " Testing bag [3/6] bag loss: 0.6262\n",
            " Testing bag [4/6] bag loss: 0.7076\n",
            " Testing bag [5/6] bag loss: 0.6196ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [26/300] train loss: 0.6393 test loss: 0.6377, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6001\n",
            " Training bag [1/11] bag loss: 0.6113\n",
            " Training bag [2/11] bag loss: 0.6213\n",
            " Training bag [3/11] bag loss: 0.7057\n",
            " Training bag [4/11] bag loss: 0.6096\n",
            " Training bag [5/11] bag loss: 0.6183\n",
            " Training bag [6/11] bag loss: 0.6012\n",
            " Training bag [7/11] bag loss: 0.7108\n",
            " Training bag [8/11] bag loss: 0.6219\n",
            " Training bag [9/11] bag loss: 0.7140\n",
            " Training bag [10/11] bag loss: 0.6142\n",
            " Testing bag [0/6] bag loss: 0.6275\n",
            " Testing bag [1/6] bag loss: 0.6247\n",
            " Testing bag [2/6] bag loss: 0.6172\n",
            " Testing bag [3/6] bag loss: 0.6252\n",
            " Testing bag [4/6] bag loss: 0.7100\n",
            " Testing bag [5/6] bag loss: 0.6181ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [27/300] train loss: 0.6390 test loss: 0.6371, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6120\n",
            " Training bag [1/11] bag loss: 0.6062\n",
            " Training bag [2/11] bag loss: 0.6163\n",
            " Training bag [3/11] bag loss: 0.7069\n",
            " Training bag [4/11] bag loss: 0.6269\n",
            " Training bag [5/11] bag loss: 0.7089\n",
            " Training bag [6/11] bag loss: 0.7118\n",
            " Training bag [7/11] bag loss: 0.6123\n",
            " Training bag [8/11] bag loss: 0.6159\n",
            " Training bag [9/11] bag loss: 0.6051\n",
            " Training bag [10/11] bag loss: 0.5998\n",
            " Testing bag [0/6] bag loss: 0.6307\n",
            " Testing bag [1/6] bag loss: 0.6266\n",
            " Testing bag [2/6] bag loss: 0.6127\n",
            " Testing bag [3/6] bag loss: 0.6283\n",
            " Testing bag [4/6] bag loss: 0.7069\n",
            " Testing bag [5/6] bag loss: 0.6167ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [28/300] train loss: 0.6384 test loss: 0.6370, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6092\n",
            " Training bag [1/11] bag loss: 0.6050\n",
            " Training bag [2/11] bag loss: 0.6138\n",
            " Training bag [3/11] bag loss: 0.6094\n",
            " Training bag [4/11] bag loss: 0.5976\n",
            " Training bag [5/11] bag loss: 0.7093\n",
            " Training bag [6/11] bag loss: 0.7120\n",
            " Training bag [7/11] bag loss: 0.6207\n",
            " Training bag [8/11] bag loss: 0.7163\n",
            " Training bag [9/11] bag loss: 0.6182\n",
            " Training bag [10/11] bag loss: 0.5992\n",
            " Testing bag [0/6] bag loss: 0.6281\n",
            " Testing bag [1/6] bag loss: 0.6247\n",
            " Testing bag [2/6] bag loss: 0.6129\n",
            " Testing bag [3/6] bag loss: 0.6249\n",
            " Testing bag [4/6] bag loss: 0.7087\n",
            " Testing bag [5/6] bag loss: 0.6154ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [29/300] train loss: 0.6373 test loss: 0.6358, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6165\n",
            " Training bag [1/11] bag loss: 0.6062\n",
            " Training bag [2/11] bag loss: 0.6191\n",
            " Training bag [3/11] bag loss: 0.5919\n",
            " Training bag [4/11] bag loss: 0.6046\n",
            " Training bag [5/11] bag loss: 0.7106\n",
            " Training bag [6/11] bag loss: 0.6092\n",
            " Training bag [7/11] bag loss: 0.5937\n",
            " Training bag [8/11] bag loss: 0.6148\n",
            " Training bag [9/11] bag loss: 0.7136\n",
            " Training bag [10/11] bag loss: 0.7194\n",
            " Testing bag [0/6] bag loss: 0.6250\n",
            " Testing bag [1/6] bag loss: 0.6208\n",
            " Testing bag [2/6] bag loss: 0.6127\n",
            " Testing bag [3/6] bag loss: 0.6224\n",
            " Testing bag [4/6] bag loss: 0.7137\n",
            " Testing bag [5/6] bag loss: 0.6127ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [30/300] train loss: 0.6363 test loss: 0.6345, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6161\n",
            " Training bag [1/11] bag loss: 0.6036\n",
            " Training bag [2/11] bag loss: 0.7075\n",
            " Training bag [3/11] bag loss: 0.7076\n",
            " Training bag [4/11] bag loss: 0.6084\n",
            " Training bag [5/11] bag loss: 0.6152\n",
            " Training bag [6/11] bag loss: 0.7124\n",
            " Training bag [7/11] bag loss: 0.5994\n",
            " Training bag [8/11] bag loss: 0.6019\n",
            " Training bag [9/11] bag loss: 0.6248\n",
            " Training bag [10/11] bag loss: 0.5970\n",
            " Testing bag [0/6] bag loss: 0.6291\n",
            " Testing bag [1/6] bag loss: 0.6232\n",
            " Testing bag [2/6] bag loss: 0.6109\n",
            " Testing bag [3/6] bag loss: 0.6248\n",
            " Testing bag [4/6] bag loss: 0.7098\n",
            " Testing bag [5/6] bag loss: 0.6112ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [31/300] train loss: 0.6358 test loss: 0.6348, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6048\n",
            " Training bag [1/11] bag loss: 0.5944\n",
            " Training bag [2/11] bag loss: 0.5957\n",
            " Training bag [3/11] bag loss: 0.7096\n",
            " Training bag [4/11] bag loss: 0.7059\n",
            " Training bag [5/11] bag loss: 0.6164\n",
            " Training bag [6/11] bag loss: 0.6158\n",
            " Training bag [7/11] bag loss: 0.6162\n",
            " Training bag [8/11] bag loss: 0.7142\n",
            " Training bag [9/11] bag loss: 0.6018\n",
            " Training bag [10/11] bag loss: 0.6039\n",
            " Testing bag [0/6] bag loss: 0.6256\n",
            " Testing bag [1/6] bag loss: 0.6201\n",
            " Testing bag [2/6] bag loss: 0.6118\n",
            " Testing bag [3/6] bag loss: 0.6211\n",
            " Testing bag [4/6] bag loss: 0.7107\n",
            " Testing bag [5/6] bag loss: 0.6133ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [32/300] train loss: 0.6344 test loss: 0.6338, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5943\n",
            " Training bag [1/11] bag loss: 0.5992\n",
            " Training bag [2/11] bag loss: 0.6034\n",
            " Training bag [3/11] bag loss: 0.7099\n",
            " Training bag [4/11] bag loss: 0.5889\n",
            " Training bag [5/11] bag loss: 0.6080\n",
            " Training bag [6/11] bag loss: 0.6107\n",
            " Training bag [7/11] bag loss: 0.6144\n",
            " Training bag [8/11] bag loss: 0.7188\n",
            " Training bag [9/11] bag loss: 0.7120\n",
            " Training bag [10/11] bag loss: 0.6144\n",
            " Testing bag [0/6] bag loss: 0.6222\n",
            " Testing bag [1/6] bag loss: 0.6185\n",
            " Testing bag [2/6] bag loss: 0.6105\n",
            " Testing bag [3/6] bag loss: 0.6190\n",
            " Testing bag [4/6] bag loss: 0.7142\n",
            " Testing bag [5/6] bag loss: 0.6125ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [33/300] train loss: 0.6340 test loss: 0.6328, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7129\n",
            " Training bag [1/11] bag loss: 0.5934\n",
            " Training bag [2/11] bag loss: 0.6142\n",
            " Training bag [3/11] bag loss: 0.7056\n",
            " Training bag [4/11] bag loss: 0.6043\n",
            " Training bag [5/11] bag loss: 0.5919\n",
            " Training bag [6/11] bag loss: 0.6115\n",
            " Training bag [7/11] bag loss: 0.6176\n",
            " Training bag [8/11] bag loss: 0.5966\n",
            " Training bag [9/11] bag loss: 0.6022\n",
            " Training bag [10/11] bag loss: 0.7088\n",
            " Testing bag [0/6] bag loss: 0.6240\n",
            " Testing bag [1/6] bag loss: 0.6174\n",
            " Testing bag [2/6] bag loss: 0.6072\n",
            " Testing bag [3/6] bag loss: 0.6205\n",
            " Testing bag [4/6] bag loss: 0.7150\n",
            " Testing bag [5/6] bag loss: 0.6097ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [34/300] train loss: 0.6326 test loss: 0.6323, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6099\n",
            " Training bag [1/11] bag loss: 0.5895\n",
            " Training bag [2/11] bag loss: 0.6139\n",
            " Training bag [3/11] bag loss: 0.5970\n",
            " Training bag [4/11] bag loss: 0.5893\n",
            " Training bag [5/11] bag loss: 0.5960\n",
            " Training bag [6/11] bag loss: 0.6020\n",
            " Training bag [7/11] bag loss: 0.6086\n",
            " Training bag [8/11] bag loss: 0.7173\n",
            " Training bag [9/11] bag loss: 0.7253\n",
            " Training bag [10/11] bag loss: 0.7149\n",
            " Testing bag [0/6] bag loss: 0.6230\n",
            " Testing bag [1/6] bag loss: 0.6174\n",
            " Testing bag [2/6] bag loss: 0.6047\n",
            " Testing bag [3/6] bag loss: 0.6170\n",
            " Testing bag [4/6] bag loss: 0.7161\n",
            " Testing bag [5/6] bag loss: 0.6079ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [35/300] train loss: 0.6331 test loss: 0.6310, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7104\n",
            " Training bag [1/11] bag loss: 0.6109\n",
            " Training bag [2/11] bag loss: 0.5963\n",
            " Training bag [3/11] bag loss: 0.5913\n",
            " Training bag [4/11] bag loss: 0.5975\n",
            " Training bag [5/11] bag loss: 0.7185\n",
            " Training bag [6/11] bag loss: 0.6033\n",
            " Training bag [7/11] bag loss: 0.6047\n",
            " Training bag [8/11] bag loss: 0.6173\n",
            " Training bag [9/11] bag loss: 0.5884\n",
            " Training bag [10/11] bag loss: 0.7100\n",
            " Testing bag [0/6] bag loss: 0.6247\n",
            " Testing bag [1/6] bag loss: 0.6168\n",
            " Testing bag [2/6] bag loss: 0.6045\n",
            " Testing bag [3/6] bag loss: 0.6203\n",
            " Testing bag [4/6] bag loss: 0.7130\n",
            " Testing bag [5/6] bag loss: 0.6064ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [36/300] train loss: 0.6317 test loss: 0.6310, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5876\n",
            " Training bag [1/11] bag loss: 0.6104\n",
            " Training bag [2/11] bag loss: 0.5995\n",
            " Training bag [3/11] bag loss: 0.5857\n",
            " Training bag [4/11] bag loss: 0.5942\n",
            " Training bag [5/11] bag loss: 0.7151\n",
            " Training bag [6/11] bag loss: 0.7125\n",
            " Training bag [7/11] bag loss: 0.6136\n",
            " Training bag [8/11] bag loss: 0.6065\n",
            " Training bag [9/11] bag loss: 0.7181\n",
            " Training bag [10/11] bag loss: 0.5987\n",
            " Testing bag [0/6] bag loss: 0.6255\n",
            " Testing bag [1/6] bag loss: 0.6173\n",
            " Testing bag [2/6] bag loss: 0.6034\n",
            " Testing bag [3/6] bag loss: 0.6202\n",
            " Testing bag [4/6] bag loss: 0.7140\n",
            " Testing bag [5/6] bag loss: 0.6063ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [37/300] train loss: 0.6311 test loss: 0.6311, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6142\n",
            " Training bag [1/11] bag loss: 0.6073\n",
            " Training bag [2/11] bag loss: 0.5944\n",
            " Training bag [3/11] bag loss: 0.7115\n",
            " Training bag [4/11] bag loss: 0.5997\n",
            " Training bag [5/11] bag loss: 0.5839\n",
            " Training bag [6/11] bag loss: 0.5853\n",
            " Training bag [7/11] bag loss: 0.7196\n",
            " Training bag [8/11] bag loss: 0.7102\n",
            " Training bag [9/11] bag loss: 0.6132\n",
            " Training bag [10/11] bag loss: 0.5985\n",
            " Testing bag [0/6] bag loss: 0.6228\n",
            " Testing bag [1/6] bag loss: 0.6154\n",
            " Testing bag [2/6] bag loss: 0.6058\n",
            " Testing bag [3/6] bag loss: 0.6164\n",
            " Testing bag [4/6] bag loss: 0.7114\n",
            " Testing bag [5/6] bag loss: 0.6095ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [38/300] train loss: 0.6307 test loss: 0.6302, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6111\n",
            " Training bag [1/11] bag loss: 0.7093\n",
            " Training bag [2/11] bag loss: 0.5956\n",
            " Training bag [3/11] bag loss: 0.5964\n",
            " Training bag [4/11] bag loss: 0.6046\n",
            " Training bag [5/11] bag loss: 0.7088\n",
            " Training bag [6/11] bag loss: 0.6156\n",
            " Training bag [7/11] bag loss: 0.5910\n",
            " Training bag [8/11] bag loss: 0.5919\n",
            " Training bag [9/11] bag loss: 0.5860\n",
            " Training bag [10/11] bag loss: 0.7189\n",
            " Testing bag [0/6] bag loss: 0.6237\n",
            " Testing bag [1/6] bag loss: 0.6164\n",
            " Testing bag [2/6] bag loss: 0.6018\n",
            " Testing bag [3/6] bag loss: 0.6185\n",
            " Testing bag [4/6] bag loss: 0.7142\n",
            " Testing bag [5/6] bag loss: 0.6046ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.5555555555555556\n",
            "\n",
            " Epoch [39/300] train loss: 0.6299 test loss: 0.6299, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.5555555555555556\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7103\n",
            " Training bag [1/11] bag loss: 0.5873\n",
            " Training bag [2/11] bag loss: 0.6122\n",
            " Training bag [3/11] bag loss: 0.7127\n",
            " Training bag [4/11] bag loss: 0.6120\n",
            " Training bag [5/11] bag loss: 0.6082\n",
            " Training bag [6/11] bag loss: 0.5839\n",
            " Training bag [7/11] bag loss: 0.5933\n",
            " Training bag [8/11] bag loss: 0.7076\n",
            " Training bag [9/11] bag loss: 0.6021\n",
            " Training bag [10/11] bag loss: 0.5963\n",
            " Testing bag [0/6] bag loss: 0.6211\n",
            " Testing bag [1/6] bag loss: 0.6138\n",
            " Testing bag [2/6] bag loss: 0.6035\n",
            " Testing bag [3/6] bag loss: 0.6152\n",
            " Testing bag [4/6] bag loss: 0.7120\n",
            " Testing bag [5/6] bag loss: 0.6082ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [40/300] train loss: 0.6296 test loss: 0.6290, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6099\n",
            " Training bag [1/11] bag loss: 0.7077\n",
            " Training bag [2/11] bag loss: 0.6111\n",
            " Training bag [3/11] bag loss: 0.7142\n",
            " Training bag [4/11] bag loss: 0.5982\n",
            " Training bag [5/11] bag loss: 0.7059\n",
            " Training bag [6/11] bag loss: 0.5836\n",
            " Training bag [7/11] bag loss: 0.5832\n",
            " Training bag [8/11] bag loss: 0.6072\n",
            " Training bag [9/11] bag loss: 0.5936\n",
            " Training bag [10/11] bag loss: 0.5963\n",
            " Testing bag [0/6] bag loss: 0.6242\n",
            " Testing bag [1/6] bag loss: 0.6159\n",
            " Testing bag [2/6] bag loss: 0.6002\n",
            " Testing bag [3/6] bag loss: 0.6174\n",
            " Testing bag [4/6] bag loss: 0.7110\n",
            " Testing bag [5/6] bag loss: 0.6059ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [41/300] train loss: 0.6283 test loss: 0.6291, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5959\n",
            " Training bag [1/11] bag loss: 0.5934\n",
            " Training bag [2/11] bag loss: 0.6103\n",
            " Training bag [3/11] bag loss: 0.6038\n",
            " Training bag [4/11] bag loss: 0.7206\n",
            " Training bag [5/11] bag loss: 0.5782\n",
            " Training bag [6/11] bag loss: 0.7125\n",
            " Training bag [7/11] bag loss: 0.6082\n",
            " Training bag [8/11] bag loss: 0.5797\n",
            " Training bag [9/11] bag loss: 0.5918\n",
            " Training bag [10/11] bag loss: 0.7101\n",
            " Testing bag [0/6] bag loss: 0.6221\n",
            " Testing bag [1/6] bag loss: 0.6125\n",
            " Testing bag [2/6] bag loss: 0.5991\n",
            " Testing bag [3/6] bag loss: 0.6151\n",
            " Testing bag [4/6] bag loss: 0.7154\n",
            " Testing bag [5/6] bag loss: 0.6044ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [42/300] train loss: 0.6277 test loss: 0.6281, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5904\n",
            " Training bag [1/11] bag loss: 0.5817\n",
            " Training bag [2/11] bag loss: 0.6046\n",
            " Training bag [3/11] bag loss: 0.6100\n",
            " Training bag [4/11] bag loss: 0.7123\n",
            " Training bag [5/11] bag loss: 0.5926\n",
            " Training bag [6/11] bag loss: 0.7197\n",
            " Training bag [7/11] bag loss: 0.5797\n",
            " Training bag [8/11] bag loss: 0.6014\n",
            " Training bag [9/11] bag loss: 0.5928\n",
            " Training bag [10/11] bag loss: 0.7116\n",
            " Testing bag [0/6] bag loss: 0.6221\n",
            " Testing bag [1/6] bag loss: 0.6140\n",
            " Testing bag [2/6] bag loss: 0.5987\n",
            " Testing bag [3/6] bag loss: 0.6161\n",
            " Testing bag [4/6] bag loss: 0.7151\n",
            " Testing bag [5/6] bag loss: 0.6021ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [43/300] train loss: 0.6270 test loss: 0.6280, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6100\n",
            " Training bag [1/11] bag loss: 0.7094\n",
            " Training bag [2/11] bag loss: 0.5948\n",
            " Training bag [3/11] bag loss: 0.7063\n",
            " Training bag [4/11] bag loss: 0.5786\n",
            " Training bag [5/11] bag loss: 0.5895\n",
            " Training bag [6/11] bag loss: 0.5909\n",
            " Training bag [7/11] bag loss: 0.5765\n",
            " Training bag [8/11] bag loss: 0.7156\n",
            " Training bag [9/11] bag loss: 0.6130\n",
            " Training bag [10/11] bag loss: 0.6072\n",
            " Testing bag [0/6] bag loss: 0.6202\n",
            " Testing bag [1/6] bag loss: 0.6126\n",
            " Testing bag [2/6] bag loss: 0.6009\n",
            " Testing bag [3/6] bag loss: 0.6146\n",
            " Testing bag [4/6] bag loss: 0.7117\n",
            " Testing bag [5/6] bag loss: 0.6058ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [44/300] train loss: 0.6265 test loss: 0.6276, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5951\n",
            " Training bag [1/11] bag loss: 0.6098\n",
            " Training bag [2/11] bag loss: 0.5759\n",
            " Training bag [3/11] bag loss: 0.6017\n",
            " Training bag [4/11] bag loss: 0.7182\n",
            " Training bag [5/11] bag loss: 0.5722\n",
            " Training bag [6/11] bag loss: 0.7114\n",
            " Training bag [7/11] bag loss: 0.5873\n",
            " Training bag [8/11] bag loss: 0.7089\n",
            " Training bag [9/11] bag loss: 0.6100\n",
            " Training bag [10/11] bag loss: 0.5932\n",
            " Testing bag [0/6] bag loss: 0.6214\n",
            " Testing bag [1/6] bag loss: 0.6102\n",
            " Testing bag [2/6] bag loss: 0.6004\n",
            " Testing bag [3/6] bag loss: 0.6149\n",
            " Testing bag [4/6] bag loss: 0.7152\n",
            " Testing bag [5/6] bag loss: 0.6048ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [45/300] train loss: 0.6258 test loss: 0.6278, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6044\n",
            " Training bag [1/11] bag loss: 0.6051\n",
            " Training bag [2/11] bag loss: 0.7093\n",
            " Training bag [3/11] bag loss: 0.5780\n",
            " Training bag [4/11] bag loss: 0.5893\n",
            " Training bag [5/11] bag loss: 0.5925\n",
            " Training bag [6/11] bag loss: 0.7177\n",
            " Training bag [7/11] bag loss: 0.5838\n",
            " Training bag [8/11] bag loss: 0.7085\n",
            " Training bag [9/11] bag loss: 0.5820\n",
            " Training bag [10/11] bag loss: 0.6113\n",
            " Testing bag [0/6] bag loss: 0.6235\n",
            " Testing bag [1/6] bag loss: 0.6145\n",
            " Testing bag [2/6] bag loss: 0.5965\n",
            " Testing bag [3/6] bag loss: 0.6175\n",
            " Testing bag [4/6] bag loss: 0.7120\n",
            " Testing bag [5/6] bag loss: 0.6002ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [46/300] train loss: 0.6256 test loss: 0.6274, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6034\n",
            " Training bag [1/11] bag loss: 0.5757\n",
            " Training bag [2/11] bag loss: 0.7155\n",
            " Training bag [3/11] bag loss: 0.5908\n",
            " Training bag [4/11] bag loss: 0.5884\n",
            " Training bag [5/11] bag loss: 0.7097\n",
            " Training bag [6/11] bag loss: 0.6008\n",
            " Training bag [7/11] bag loss: 0.5780\n",
            " Training bag [8/11] bag loss: 0.6075\n",
            " Training bag [9/11] bag loss: 0.7094\n",
            " Training bag [10/11] bag loss: 0.5891\n",
            " Testing bag [0/6] bag loss: 0.6202\n",
            " Testing bag [1/6] bag loss: 0.6105\n",
            " Testing bag [2/6] bag loss: 0.5970\n",
            " Testing bag [3/6] bag loss: 0.6130\n",
            " Testing bag [4/6] bag loss: 0.7142\n",
            " Testing bag [5/6] bag loss: 0.6027ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [47/300] train loss: 0.6244 test loss: 0.6263, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5731\n",
            " Training bag [1/11] bag loss: 0.7079\n",
            " Training bag [2/11] bag loss: 0.5773\n",
            " Training bag [3/11] bag loss: 0.5840\n",
            " Training bag [4/11] bag loss: 0.7131\n",
            " Training bag [5/11] bag loss: 0.5981\n",
            " Training bag [6/11] bag loss: 0.6097\n",
            " Training bag [7/11] bag loss: 0.6037\n",
            " Training bag [8/11] bag loss: 0.7079\n",
            " Training bag [9/11] bag loss: 0.6068\n",
            " Training bag [10/11] bag loss: 0.5895\n",
            " Testing bag [0/6] bag loss: 0.6195\n",
            " Testing bag [1/6] bag loss: 0.6079\n",
            " Testing bag [2/6] bag loss: 0.5980\n",
            " Testing bag [3/6] bag loss: 0.6139\n",
            " Testing bag [4/6] bag loss: 0.7144\n",
            " Testing bag [5/6] bag loss: 0.6032ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [48/300] train loss: 0.6247 test loss: 0.6262, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5739\n",
            " Training bag [1/11] bag loss: 0.7089\n",
            " Training bag [2/11] bag loss: 0.6029\n",
            " Training bag [3/11] bag loss: 0.6064\n",
            " Training bag [4/11] bag loss: 0.5844\n",
            " Training bag [5/11] bag loss: 0.7092\n",
            " Training bag [6/11] bag loss: 0.5949\n",
            " Training bag [7/11] bag loss: 0.5693\n",
            " Training bag [8/11] bag loss: 0.5890\n",
            " Training bag [9/11] bag loss: 0.6048\n",
            " Training bag [10/11] bag loss: 0.7200\n",
            " Testing bag [0/6] bag loss: 0.6195\n",
            " Testing bag [1/6] bag loss: 0.6106\n",
            " Testing bag [2/6] bag loss: 0.5953\n",
            " Testing bag [3/6] bag loss: 0.6124\n",
            " Testing bag [4/6] bag loss: 0.7151\n",
            " Testing bag [5/6] bag loss: 0.6003ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [49/300] train loss: 0.6240 test loss: 0.6255, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5887\n",
            " Training bag [1/11] bag loss: 0.5834\n",
            " Training bag [2/11] bag loss: 0.5879\n",
            " Training bag [3/11] bag loss: 0.5731\n",
            " Training bag [4/11] bag loss: 0.5698\n",
            " Training bag [5/11] bag loss: 0.5982\n",
            " Training bag [6/11] bag loss: 0.7147\n",
            " Training bag [7/11] bag loss: 0.6001\n",
            " Training bag [8/11] bag loss: 0.6059\n",
            " Training bag [9/11] bag loss: 0.7176\n",
            " Training bag [10/11] bag loss: 0.7223\n",
            " Testing bag [0/6] bag loss: 0.6192\n",
            " Testing bag [1/6] bag loss: 0.6096\n",
            " Testing bag [2/6] bag loss: 0.5929\n",
            " Testing bag [3/6] bag loss: 0.6138\n",
            " Testing bag [4/6] bag loss: 0.7150\n",
            " Testing bag [5/6] bag loss: 0.5984ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [50/300] train loss: 0.6238 test loss: 0.6248, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7094\n",
            " Training bag [1/11] bag loss: 0.6051\n",
            " Training bag [2/11] bag loss: 0.5913\n",
            " Training bag [3/11] bag loss: 0.6026\n",
            " Training bag [4/11] bag loss: 0.7109\n",
            " Training bag [5/11] bag loss: 0.6003\n",
            " Training bag [6/11] bag loss: 0.5901\n",
            " Training bag [7/11] bag loss: 0.7136\n",
            " Training bag [8/11] bag loss: 0.5819\n",
            " Training bag [9/11] bag loss: 0.5754\n",
            " Training bag [10/11] bag loss: 0.5735\n",
            " Testing bag [0/6] bag loss: 0.6249\n",
            " Testing bag [1/6] bag loss: 0.6106\n",
            " Testing bag [2/6] bag loss: 0.5927\n",
            " Testing bag [3/6] bag loss: 0.6151\n",
            " Testing bag [4/6] bag loss: 0.7125\n",
            " Testing bag [5/6] bag loss: 0.5972ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [51/300] train loss: 0.6231 test loss: 0.6255, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5861\n",
            " Training bag [1/11] bag loss: 0.5680\n",
            " Training bag [2/11] bag loss: 0.6013\n",
            " Training bag [3/11] bag loss: 0.5823\n",
            " Training bag [4/11] bag loss: 0.6027\n",
            " Training bag [5/11] bag loss: 0.5874\n",
            " Training bag [6/11] bag loss: 0.5664\n",
            " Training bag [7/11] bag loss: 0.7273\n",
            " Training bag [8/11] bag loss: 0.6011\n",
            " Training bag [9/11] bag loss: 0.7151\n",
            " Training bag [10/11] bag loss: 0.7164\n",
            " Testing bag [0/6] bag loss: 0.6191\n",
            " Testing bag [1/6] bag loss: 0.6081\n",
            " Testing bag [2/6] bag loss: 0.5925\n",
            " Testing bag [3/6] bag loss: 0.6120\n",
            " Testing bag [4/6] bag loss: 0.7155\n",
            " Testing bag [5/6] bag loss: 0.5971ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [52/300] train loss: 0.6231 test loss: 0.6241, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5813\n",
            " Training bag [1/11] bag loss: 0.5722\n",
            " Training bag [2/11] bag loss: 0.6051\n",
            " Training bag [3/11] bag loss: 0.7148\n",
            " Training bag [4/11] bag loss: 0.5999\n",
            " Training bag [5/11] bag loss: 0.7153\n",
            " Training bag [6/11] bag loss: 0.5669\n",
            " Training bag [7/11] bag loss: 0.7075\n",
            " Training bag [8/11] bag loss: 0.5864\n",
            " Training bag [9/11] bag loss: 0.6047\n",
            " Training bag [10/11] bag loss: 0.5888\n",
            " Testing bag [0/6] bag loss: 0.6206\n",
            " Testing bag [1/6] bag loss: 0.6090\n",
            " Testing bag [2/6] bag loss: 0.5941\n",
            " Testing bag [3/6] bag loss: 0.6124\n",
            " Testing bag [4/6] bag loss: 0.7153\n",
            " Testing bag [5/6] bag loss: 0.5987ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [53/300] train loss: 0.6221 test loss: 0.6250, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5676\n",
            " Training bag [1/11] bag loss: 0.6015\n",
            " Training bag [2/11] bag loss: 0.6015\n",
            " Training bag [3/11] bag loss: 0.7203\n",
            " Training bag [4/11] bag loss: 0.6050\n",
            " Training bag [5/11] bag loss: 0.5770\n",
            " Training bag [6/11] bag loss: 0.5840\n",
            " Training bag [7/11] bag loss: 0.5845\n",
            " Training bag [8/11] bag loss: 0.5697\n",
            " Training bag [9/11] bag loss: 0.7170\n",
            " Training bag [10/11] bag loss: 0.7136\n",
            " Testing bag [0/6] bag loss: 0.6197\n",
            " Testing bag [1/6] bag loss: 0.6072\n",
            " Testing bag [2/6] bag loss: 0.5913\n",
            " Testing bag [3/6] bag loss: 0.6125\n",
            " Testing bag [4/6] bag loss: 0.7156\n",
            " Testing bag [5/6] bag loss: 0.5957ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [54/300] train loss: 0.6220 test loss: 0.6237, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5978\n",
            " Training bag [1/11] bag loss: 0.7097\n",
            " Training bag [2/11] bag loss: 0.6048\n",
            " Training bag [3/11] bag loss: 0.5860\n",
            " Training bag [4/11] bag loss: 0.7097\n",
            " Training bag [5/11] bag loss: 0.5974\n",
            " Training bag [6/11] bag loss: 0.7113\n",
            " Training bag [7/11] bag loss: 0.5888\n",
            " Training bag [8/11] bag loss: 0.5793\n",
            " Training bag [9/11] bag loss: 0.5709\n",
            " Training bag [10/11] bag loss: 0.5690\n",
            " Testing bag [0/6] bag loss: 0.6230\n",
            " Testing bag [1/6] bag loss: 0.6115\n",
            " Testing bag [2/6] bag loss: 0.5915\n",
            " Testing bag [3/6] bag loss: 0.6146\n",
            " Testing bag [4/6] bag loss: 0.7140\n",
            " Testing bag [5/6] bag loss: 0.5967ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [55/300] train loss: 0.6204 test loss: 0.6252, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6044\n",
            " Training bag [1/11] bag loss: 0.5797\n",
            " Training bag [2/11] bag loss: 0.5634\n",
            " Training bag [3/11] bag loss: 0.5899\n",
            " Training bag [4/11] bag loss: 0.7121\n",
            " Training bag [5/11] bag loss: 0.6028\n",
            " Training bag [6/11] bag loss: 0.5607\n",
            " Training bag [7/11] bag loss: 0.7187\n",
            " Training bag [8/11] bag loss: 0.5796\n",
            " Training bag [9/11] bag loss: 0.5984\n",
            " Training bag [10/11] bag loss: 0.7133\n",
            " Testing bag [0/6] bag loss: 0.6182\n",
            " Testing bag [1/6] bag loss: 0.6068\n",
            " Testing bag [2/6] bag loss: 0.5916\n",
            " Testing bag [3/6] bag loss: 0.6110\n",
            " Testing bag [4/6] bag loss: 0.7152\n",
            " Testing bag [5/6] bag loss: 0.5955ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [56/300] train loss: 0.6203 test loss: 0.6231, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5856\n",
            " Training bag [1/11] bag loss: 0.5638\n",
            " Training bag [2/11] bag loss: 0.7099\n",
            " Training bag [3/11] bag loss: 0.5981\n",
            " Training bag [4/11] bag loss: 0.7104\n",
            " Training bag [5/11] bag loss: 0.7151\n",
            " Training bag [6/11] bag loss: 0.6073\n",
            " Training bag [7/11] bag loss: 0.5841\n",
            " Training bag [8/11] bag loss: 0.5715\n",
            " Training bag [9/11] bag loss: 0.6006\n",
            " Training bag [10/11] bag loss: 0.5835\n",
            " Testing bag [0/6] bag loss: 0.6202\n",
            " Testing bag [1/6] bag loss: 0.6056\n",
            " Testing bag [2/6] bag loss: 0.5920\n",
            " Testing bag [3/6] bag loss: 0.6101\n",
            " Testing bag [4/6] bag loss: 0.7124\n",
            " Testing bag [5/6] bag loss: 0.5985ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [57/300] train loss: 0.6209 test loss: 0.6231, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5638\n",
            " Training bag [1/11] bag loss: 0.5864\n",
            " Training bag [2/11] bag loss: 0.5946\n",
            " Training bag [3/11] bag loss: 0.5641\n",
            " Training bag [4/11] bag loss: 0.5962\n",
            " Training bag [5/11] bag loss: 0.7140\n",
            " Training bag [6/11] bag loss: 0.6039\n",
            " Training bag [7/11] bag loss: 0.5804\n",
            " Training bag [8/11] bag loss: 0.7223\n",
            " Training bag [9/11] bag loss: 0.7141\n",
            " Training bag [10/11] bag loss: 0.5795\n",
            " Testing bag [0/6] bag loss: 0.6189\n",
            " Testing bag [1/6] bag loss: 0.6061\n",
            " Testing bag [2/6] bag loss: 0.5892\n",
            " Testing bag [3/6] bag loss: 0.6099\n",
            " Testing bag [4/6] bag loss: 0.7153\n",
            " Testing bag [5/6] bag loss: 0.5963ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [58/300] train loss: 0.6199 test loss: 0.6226, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6004\n",
            " Training bag [1/11] bag loss: 0.7111\n",
            " Training bag [2/11] bag loss: 0.5804\n",
            " Training bag [3/11] bag loss: 0.5668\n",
            " Training bag [4/11] bag loss: 0.5960\n",
            " Training bag [5/11] bag loss: 0.5771\n",
            " Training bag [6/11] bag loss: 0.5579\n",
            " Training bag [7/11] bag loss: 0.5994\n",
            " Training bag [8/11] bag loss: 0.5849\n",
            " Training bag [9/11] bag loss: 0.7237\n",
            " Training bag [10/11] bag loss: 0.7134\n",
            " Testing bag [0/6] bag loss: 0.6186\n",
            " Testing bag [1/6] bag loss: 0.6058\n",
            " Testing bag [2/6] bag loss: 0.5886\n",
            " Testing bag [3/6] bag loss: 0.6108\n",
            " Testing bag [4/6] bag loss: 0.7172\n",
            " Testing bag [5/6] bag loss: 0.5937ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [59/300] train loss: 0.6192 test loss: 0.6225, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5939\n",
            " Training bag [1/11] bag loss: 0.5782\n",
            " Training bag [2/11] bag loss: 0.5678\n",
            " Training bag [3/11] bag loss: 0.7114\n",
            " Training bag [4/11] bag loss: 0.7125\n",
            " Training bag [5/11] bag loss: 0.6003\n",
            " Training bag [6/11] bag loss: 0.5803\n",
            " Training bag [7/11] bag loss: 0.5617\n",
            " Training bag [8/11] bag loss: 0.7175\n",
            " Training bag [9/11] bag loss: 0.6047\n",
            " Training bag [10/11] bag loss: 0.5827\n",
            " Testing bag [0/6] bag loss: 0.6208\n",
            " Testing bag [1/6] bag loss: 0.6048\n",
            " Testing bag [2/6] bag loss: 0.5899\n",
            " Testing bag [3/6] bag loss: 0.6098\n",
            " Testing bag [4/6] bag loss: 0.7139\n",
            " Testing bag [5/6] bag loss: 0.5943ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [60/300] train loss: 0.6192 test loss: 0.6223, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7066\n",
            " Training bag [1/11] bag loss: 0.5940\n",
            " Training bag [2/11] bag loss: 0.5976\n",
            " Training bag [3/11] bag loss: 0.5652\n",
            " Training bag [4/11] bag loss: 0.5758\n",
            " Training bag [5/11] bag loss: 0.5764\n",
            " Training bag [6/11] bag loss: 0.6065\n",
            " Training bag [7/11] bag loss: 0.7142\n",
            " Training bag [8/11] bag loss: 0.5824\n",
            " Training bag [9/11] bag loss: 0.5619\n",
            " Training bag [10/11] bag loss: 0.7203\n",
            " Testing bag [0/6] bag loss: 0.6210\n",
            " Testing bag [1/6] bag loss: 0.6060\n",
            " Testing bag [2/6] bag loss: 0.5880\n",
            " Testing bag [3/6] bag loss: 0.6112\n",
            " Testing bag [4/6] bag loss: 0.7142\n",
            " Testing bag [5/6] bag loss: 0.5934ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [61/300] train loss: 0.6183 test loss: 0.6223, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7089\n",
            " Training bag [1/11] bag loss: 0.7086\n",
            " Training bag [2/11] bag loss: 0.5606\n",
            " Training bag [3/11] bag loss: 0.6033\n",
            " Training bag [4/11] bag loss: 0.5752\n",
            " Training bag [5/11] bag loss: 0.7133\n",
            " Training bag [6/11] bag loss: 0.6070\n",
            " Training bag [7/11] bag loss: 0.5853\n",
            " Training bag [8/11] bag loss: 0.6009\n",
            " Training bag [9/11] bag loss: 0.5853\n",
            " Training bag [10/11] bag loss: 0.5687\n",
            " Testing bag [0/6] bag loss: 0.6197\n",
            " Testing bag [1/6] bag loss: 0.6063\n",
            " Testing bag [2/6] bag loss: 0.5889\n",
            " Testing bag [3/6] bag loss: 0.6101\n",
            " Testing bag [4/6] bag loss: 0.7132\n",
            " Testing bag [5/6] bag loss: 0.5933ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [62/300] train loss: 0.6197 test loss: 0.6219, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5954\n",
            " Training bag [1/11] bag loss: 0.7080\n",
            " Training bag [2/11] bag loss: 0.5645\n",
            " Training bag [3/11] bag loss: 0.7107\n",
            " Training bag [4/11] bag loss: 0.7143\n",
            " Training bag [5/11] bag loss: 0.5836\n",
            " Training bag [6/11] bag loss: 0.5621\n",
            " Training bag [7/11] bag loss: 0.6060\n",
            " Training bag [8/11] bag loss: 0.6007\n",
            " Training bag [9/11] bag loss: 0.5790\n",
            " Training bag [10/11] bag loss: 0.5788\n",
            " Testing bag [0/6] bag loss: 0.6218\n",
            " Testing bag [1/6] bag loss: 0.6052\n",
            " Testing bag [2/6] bag loss: 0.5882\n",
            " Testing bag [3/6] bag loss: 0.6111\n",
            " Testing bag [4/6] bag loss: 0.7153\n",
            " Testing bag [5/6] bag loss: 0.5932ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [63/300] train loss: 0.6185 test loss: 0.6225, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7069\n",
            " Training bag [1/11] bag loss: 0.5563\n",
            " Training bag [2/11] bag loss: 0.6029\n",
            " Training bag [3/11] bag loss: 0.5967\n",
            " Training bag [4/11] bag loss: 0.7146\n",
            " Training bag [5/11] bag loss: 0.5843\n",
            " Training bag [6/11] bag loss: 0.7095\n",
            " Training bag [7/11] bag loss: 0.6007\n",
            " Training bag [8/11] bag loss: 0.5662\n",
            " Training bag [9/11] bag loss: 0.5775\n",
            " Training bag [10/11] bag loss: 0.5776\n",
            " Testing bag [0/6] bag loss: 0.6173\n",
            " Testing bag [1/6] bag loss: 0.6045\n",
            " Testing bag [2/6] bag loss: 0.5888\n",
            " Testing bag [3/6] bag loss: 0.6086\n",
            " Testing bag [4/6] bag loss: 0.7130\n",
            " Testing bag [5/6] bag loss: 0.5947ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [64/300] train loss: 0.6176 test loss: 0.6212, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7158\n",
            " Training bag [1/11] bag loss: 0.5762\n",
            " Training bag [2/11] bag loss: 0.5742\n",
            " Training bag [3/11] bag loss: 0.5545\n",
            " Training bag [4/11] bag loss: 0.5991\n",
            " Training bag [5/11] bag loss: 0.5832\n",
            " Training bag [6/11] bag loss: 0.7145\n",
            " Training bag [7/11] bag loss: 0.6033\n",
            " Training bag [8/11] bag loss: 0.5920\n",
            " Training bag [9/11] bag loss: 0.7100\n",
            " Training bag [10/11] bag loss: 0.5607\n",
            " Testing bag [0/6] bag loss: 0.6204\n",
            " Testing bag [1/6] bag loss: 0.6059\n",
            " Testing bag [2/6] bag loss: 0.5856\n",
            " Testing bag [3/6] bag loss: 0.6107\n",
            " Testing bag [4/6] bag loss: 0.7147\n",
            " Testing bag [5/6] bag loss: 0.5911ROC AUC score: 0.875\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [65/300] train loss: 0.6167 test loss: 0.6214, average score: 0.3333, AUC: class-0>>0.875|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7108\n",
            " Training bag [1/11] bag loss: 0.5932\n",
            " Training bag [2/11] bag loss: 0.7056\n",
            " Training bag [3/11] bag loss: 0.5642\n",
            " Training bag [4/11] bag loss: 0.6018\n",
            " Training bag [5/11] bag loss: 0.7139\n",
            " Training bag [6/11] bag loss: 0.5851\n",
            " Training bag [7/11] bag loss: 0.5757\n",
            " Training bag [8/11] bag loss: 0.5979\n",
            " Training bag [9/11] bag loss: 0.5585\n",
            " Training bag [10/11] bag loss: 0.5777\n",
            " Testing bag [0/6] bag loss: 0.6221\n",
            " Testing bag [1/6] bag loss: 0.6065\n",
            " Testing bag [2/6] bag loss: 0.5869\n",
            " Testing bag [3/6] bag loss: 0.6110\n",
            " Testing bag [4/6] bag loss: 0.7133\n",
            " Testing bag [5/6] bag loss: 0.5928ROC AUC score: 0.875\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [66/300] train loss: 0.6168 test loss: 0.6221, average score: 0.3333, AUC: class-0>>0.875|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7139\n",
            " Training bag [1/11] bag loss: 0.5938\n",
            " Training bag [2/11] bag loss: 0.7093\n",
            " Training bag [3/11] bag loss: 0.5706\n",
            " Training bag [4/11] bag loss: 0.5792\n",
            " Training bag [5/11] bag loss: 0.6057\n",
            " Training bag [6/11] bag loss: 0.5909\n",
            " Training bag [7/11] bag loss: 0.5592\n",
            " Training bag [8/11] bag loss: 0.7083\n",
            " Training bag [9/11] bag loss: 0.5780\n",
            " Training bag [10/11] bag loss: 0.5663\n",
            " Testing bag [0/6] bag loss: 0.6224\n",
            " Testing bag [1/6] bag loss: 0.6054\n",
            " Testing bag [2/6] bag loss: 0.5846\n",
            " Testing bag [3/6] bag loss: 0.6107\n",
            " Testing bag [4/6] bag loss: 0.7126\n",
            " Testing bag [5/6] bag loss: 0.5916ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [67/300] train loss: 0.6159 test loss: 0.6212, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5959\n",
            " Training bag [1/11] bag loss: 0.6009\n",
            " Training bag [2/11] bag loss: 0.5543\n",
            " Training bag [3/11] bag loss: 0.5790\n",
            " Training bag [4/11] bag loss: 0.5910\n",
            " Training bag [5/11] bag loss: 0.7183\n",
            " Training bag [6/11] bag loss: 0.7179\n",
            " Training bag [7/11] bag loss: 0.7106\n",
            " Training bag [8/11] bag loss: 0.5675\n",
            " Training bag [9/11] bag loss: 0.5746\n",
            " Training bag [10/11] bag loss: 0.5652\n",
            " Testing bag [0/6] bag loss: 0.6229\n",
            " Testing bag [1/6] bag loss: 0.6051\n",
            " Testing bag [2/6] bag loss: 0.5857\n",
            " Testing bag [3/6] bag loss: 0.6105\n",
            " Testing bag [4/6] bag loss: 0.7141\n",
            " Testing bag [5/6] bag loss: 0.5897ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [68/300] train loss: 0.6159 test loss: 0.6214, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5952\n",
            " Training bag [1/11] bag loss: 0.5766\n",
            " Training bag [2/11] bag loss: 0.5682\n",
            " Training bag [3/11] bag loss: 0.7167\n",
            " Training bag [4/11] bag loss: 0.5558\n",
            " Training bag [5/11] bag loss: 0.5873\n",
            " Training bag [6/11] bag loss: 0.5640\n",
            " Training bag [7/11] bag loss: 0.7196\n",
            " Training bag [8/11] bag loss: 0.6022\n",
            " Training bag [9/11] bag loss: 0.5747\n",
            " Training bag [10/11] bag loss: 0.7117\n",
            " Testing bag [0/6] bag loss: 0.6169\n",
            " Testing bag [1/6] bag loss: 0.6032\n",
            " Testing bag [2/6] bag loss: 0.5834\n",
            " Testing bag [3/6] bag loss: 0.6085\n",
            " Testing bag [4/6] bag loss: 0.7151\n",
            " Testing bag [5/6] bag loss: 0.5910ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [69/300] train loss: 0.6156 test loss: 0.6197, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7181\n",
            " Training bag [1/11] bag loss: 0.7066\n",
            " Training bag [2/11] bag loss: 0.5748\n",
            " Training bag [3/11] bag loss: 0.5766\n",
            " Training bag [4/11] bag loss: 0.5986\n",
            " Training bag [5/11] bag loss: 0.5519\n",
            " Training bag [6/11] bag loss: 0.5957\n",
            " Training bag [7/11] bag loss: 0.5547\n",
            " Training bag [8/11] bag loss: 0.7129\n",
            " Training bag [9/11] bag loss: 0.5813\n",
            " Training bag [10/11] bag loss: 0.6008\n",
            " Testing bag [0/6] bag loss: 0.6178\n",
            " Testing bag [1/6] bag loss: 0.6012\n",
            " Testing bag [2/6] bag loss: 0.5882\n",
            " Testing bag [3/6] bag loss: 0.6050\n",
            " Testing bag [4/6] bag loss: 0.7154\n",
            " Testing bag [5/6] bag loss: 0.5920ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [70/300] train loss: 0.6156 test loss: 0.6199, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7127\n",
            " Training bag [1/11] bag loss: 0.5542\n",
            " Training bag [2/11] bag loss: 0.5989\n",
            " Training bag [3/11] bag loss: 0.5455\n",
            " Training bag [4/11] bag loss: 0.6016\n",
            " Training bag [5/11] bag loss: 0.5769\n",
            " Training bag [6/11] bag loss: 0.5825\n",
            " Training bag [7/11] bag loss: 0.7123\n",
            " Training bag [8/11] bag loss: 0.5905\n",
            " Training bag [9/11] bag loss: 0.5706\n",
            " Training bag [10/11] bag loss: 0.7161\n",
            " Testing bag [0/6] bag loss: 0.6165\n",
            " Testing bag [1/6] bag loss: 0.6012\n",
            " Testing bag [2/6] bag loss: 0.5844\n",
            " Testing bag [3/6] bag loss: 0.6070\n",
            " Testing bag [4/6] bag loss: 0.7146\n",
            " Testing bag [5/6] bag loss: 0.5897ROC AUC score: 0.875\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [71/300] train loss: 0.6147 test loss: 0.6189, average score: 0.3333, AUC: class-0>>0.875|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7145\n",
            " Training bag [1/11] bag loss: 0.5478\n",
            " Training bag [2/11] bag loss: 0.5983\n",
            " Training bag [3/11] bag loss: 0.5677\n",
            " Training bag [4/11] bag loss: 0.5925\n",
            " Training bag [5/11] bag loss: 0.5705\n",
            " Training bag [6/11] bag loss: 0.5754\n",
            " Training bag [7/11] bag loss: 0.7117\n",
            " Training bag [8/11] bag loss: 0.5999\n",
            " Training bag [9/11] bag loss: 0.7198\n",
            " Training bag [10/11] bag loss: 0.5623\n",
            " Testing bag [0/6] bag loss: 0.6198\n",
            " Testing bag [1/6] bag loss: 0.6037\n",
            " Testing bag [2/6] bag loss: 0.5832\n",
            " Testing bag [3/6] bag loss: 0.6093\n",
            " Testing bag [4/6] bag loss: 0.7132\n",
            " Testing bag [5/6] bag loss: 0.5888ROC AUC score: 0.875\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [72/300] train loss: 0.6146 test loss: 0.6197, average score: 0.3333, AUC: class-0>>0.875|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5512\n",
            " Training bag [1/11] bag loss: 0.7085\n",
            " Training bag [2/11] bag loss: 0.7181\n",
            " Training bag [3/11] bag loss: 0.5965\n",
            " Training bag [4/11] bag loss: 0.5529\n",
            " Training bag [5/11] bag loss: 0.6021\n",
            " Training bag [6/11] bag loss: 0.5828\n",
            " Training bag [7/11] bag loss: 0.5941\n",
            " Training bag [8/11] bag loss: 0.5680\n",
            " Training bag [9/11] bag loss: 0.5715\n",
            " Training bag [10/11] bag loss: 0.7163\n",
            " Testing bag [0/6] bag loss: 0.6157\n",
            " Testing bag [1/6] bag loss: 0.6006\n",
            " Testing bag [2/6] bag loss: 0.5837\n",
            " Testing bag [3/6] bag loss: 0.6064\n",
            " Testing bag [4/6] bag loss: 0.7138\n",
            " Testing bag [5/6] bag loss: 0.5900ROC AUC score: 0.875\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [73/300] train loss: 0.6147 test loss: 0.6184, average score: 0.3333, AUC: class-0>>0.875|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5682\n",
            " Training bag [1/11] bag loss: 0.5691\n",
            " Training bag [2/11] bag loss: 0.5967\n",
            " Training bag [3/11] bag loss: 0.7113\n",
            " Training bag [4/11] bag loss: 0.7142\n",
            " Training bag [5/11] bag loss: 0.5920\n",
            " Training bag [6/11] bag loss: 0.5981\n",
            " Training bag [7/11] bag loss: 0.7123\n",
            " Training bag [8/11] bag loss: 0.5551\n",
            " Training bag [9/11] bag loss: 0.5498\n",
            " Training bag [10/11] bag loss: 0.5797\n",
            " Testing bag [0/6] bag loss: 0.6176\n",
            " Testing bag [1/6] bag loss: 0.6011\n",
            " Testing bag [2/6] bag loss: 0.5847\n",
            " Testing bag [3/6] bag loss: 0.6068\n",
            " Testing bag [4/6] bag loss: 0.7119\n",
            " Testing bag [5/6] bag loss: 0.5898ROC AUC score: 0.875\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [74/300] train loss: 0.6133 test loss: 0.6186, average score: 0.3333, AUC: class-0>>0.875|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7131\n",
            " Training bag [1/11] bag loss: 0.5976\n",
            " Training bag [2/11] bag loss: 0.5775\n",
            " Training bag [3/11] bag loss: 0.5995\n",
            " Training bag [4/11] bag loss: 0.7117\n",
            " Training bag [5/11] bag loss: 0.5502\n",
            " Training bag [6/11] bag loss: 0.5690\n",
            " Training bag [7/11] bag loss: 0.5936\n",
            " Training bag [8/11] bag loss: 0.7077\n",
            " Training bag [9/11] bag loss: 0.5713\n",
            " Training bag [10/11] bag loss: 0.5592\n",
            " Testing bag [0/6] bag loss: 0.6183\n",
            " Testing bag [1/6] bag loss: 0.6027\n",
            " Testing bag [2/6] bag loss: 0.5814\n",
            " Testing bag [3/6] bag loss: 0.6072\n",
            " Testing bag [4/6] bag loss: 0.7169\n",
            " Testing bag [5/6] bag loss: 0.5885ROC AUC score: 1.0\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [75/300] train loss: 0.6137 test loss: 0.6191, average score: 0.5000, AUC: class-0>>1.0|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5572\n",
            " Training bag [1/11] bag loss: 0.5908\n",
            " Training bag [2/11] bag loss: 0.5452\n",
            " Training bag [3/11] bag loss: 0.7156\n",
            " Training bag [4/11] bag loss: 0.5770\n",
            " Training bag [5/11] bag loss: 0.7135\n",
            " Training bag [6/11] bag loss: 0.5989\n",
            " Training bag [7/11] bag loss: 0.5666\n",
            " Training bag [8/11] bag loss: 0.7077\n",
            " Training bag [9/11] bag loss: 0.5706\n",
            " Training bag [10/11] bag loss: 0.5976\n",
            " Testing bag [0/6] bag loss: 0.6163\n",
            " Testing bag [1/6] bag loss: 0.5992\n",
            " Testing bag [2/6] bag loss: 0.5852\n",
            " Testing bag [3/6] bag loss: 0.6050\n",
            " Testing bag [4/6] bag loss: 0.7161\n",
            " Testing bag [5/6] bag loss: 0.5924ROC AUC score: 0.875\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [76/300] train loss: 0.6128 test loss: 0.6190, average score: 0.3333, AUC: class-0>>0.875|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5950\n",
            " Training bag [1/11] bag loss: 0.7142\n",
            " Training bag [2/11] bag loss: 0.5976\n",
            " Training bag [3/11] bag loss: 0.5761\n",
            " Training bag [4/11] bag loss: 0.5479\n",
            " Training bag [5/11] bag loss: 0.5875\n",
            " Training bag [6/11] bag loss: 0.5652\n",
            " Training bag [7/11] bag loss: 0.7103\n",
            " Training bag [8/11] bag loss: 0.5696\n",
            " Training bag [9/11] bag loss: 0.5577\n",
            " Training bag [10/11] bag loss: 0.7168\n",
            " Testing bag [0/6] bag loss: 0.6187\n",
            " Testing bag [1/6] bag loss: 0.6000\n",
            " Testing bag [2/6] bag loss: 0.5810\n",
            " Testing bag [3/6] bag loss: 0.6080\n",
            " Testing bag [4/6] bag loss: 0.7176\n",
            " Testing bag [5/6] bag loss: 0.5884ROC AUC score: 0.875\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [77/300] train loss: 0.6125 test loss: 0.6190, average score: 0.3333, AUC: class-0>>0.875|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5760\n",
            " Training bag [1/11] bag loss: 0.5932\n",
            " Training bag [2/11] bag loss: 0.5858\n",
            " Training bag [3/11] bag loss: 0.6029\n",
            " Training bag [4/11] bag loss: 0.5462\n",
            " Training bag [5/11] bag loss: 0.7188\n",
            " Training bag [6/11] bag loss: 0.5631\n",
            " Training bag [7/11] bag loss: 0.5672\n",
            " Training bag [8/11] bag loss: 0.7117\n",
            " Training bag [9/11] bag loss: 0.7166\n",
            " Training bag [10/11] bag loss: 0.5527\n",
            " Testing bag [0/6] bag loss: 0.6193\n",
            " Testing bag [1/6] bag loss: 0.6004\n",
            " Testing bag [2/6] bag loss: 0.5811\n",
            " Testing bag [3/6] bag loss: 0.6072\n",
            " Testing bag [4/6] bag loss: 0.7182\n",
            " Testing bag [5/6] bag loss: 0.5880ROC AUC score: 0.875\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [78/300] train loss: 0.6122 test loss: 0.6190, average score: 0.3333, AUC: class-0>>0.875|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5970\n",
            " Training bag [1/11] bag loss: 0.7070\n",
            " Training bag [2/11] bag loss: 0.7143\n",
            " Training bag [3/11] bag loss: 0.5421\n",
            " Training bag [4/11] bag loss: 0.5797\n",
            " Training bag [5/11] bag loss: 0.5540\n",
            " Training bag [6/11] bag loss: 0.5635\n",
            " Training bag [7/11] bag loss: 0.5956\n",
            " Training bag [8/11] bag loss: 0.5993\n",
            " Training bag [9/11] bag loss: 0.5720\n",
            " Training bag [10/11] bag loss: 0.7157\n",
            " Testing bag [0/6] bag loss: 0.6170\n",
            " Testing bag [1/6] bag loss: 0.5978\n",
            " Testing bag [2/6] bag loss: 0.5843\n",
            " Testing bag [3/6] bag loss: 0.6043\n",
            " Testing bag [4/6] bag loss: 0.7151\n",
            " Testing bag [5/6] bag loss: 0.5886ROC AUC score: 0.875\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [79/300] train loss: 0.6127 test loss: 0.6178, average score: 0.3333, AUC: class-0>>0.875|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5474\n",
            " Training bag [1/11] bag loss: 0.5703\n",
            " Training bag [2/11] bag loss: 0.5882\n",
            " Training bag [3/11] bag loss: 0.5944\n",
            " Training bag [4/11] bag loss: 0.5423\n",
            " Training bag [5/11] bag loss: 0.5742\n",
            " Training bag [6/11] bag loss: 0.7136\n",
            " Training bag [7/11] bag loss: 0.7206\n",
            " Training bag [8/11] bag loss: 0.5635\n",
            " Training bag [9/11] bag loss: 0.7144\n",
            " Training bag [10/11] bag loss: 0.5951\n",
            " Testing bag [0/6] bag loss: 0.6164\n",
            " Testing bag [1/6] bag loss: 0.5982\n",
            " Testing bag [2/6] bag loss: 0.5834\n",
            " Testing bag [3/6] bag loss: 0.6059\n",
            " Testing bag [4/6] bag loss: 0.7146\n",
            " Testing bag [5/6] bag loss: 0.5885ROC AUC score: 0.875\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [80/300] train loss: 0.6113 test loss: 0.6178, average score: 0.3333, AUC: class-0>>0.875|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7155\n",
            " Training bag [1/11] bag loss: 0.5652\n",
            " Training bag [2/11] bag loss: 0.5986\n",
            " Training bag [3/11] bag loss: 0.5667\n",
            " Training bag [4/11] bag loss: 0.5955\n",
            " Training bag [5/11] bag loss: 0.5425\n",
            " Training bag [6/11] bag loss: 0.5441\n",
            " Training bag [7/11] bag loss: 0.5783\n",
            " Training bag [8/11] bag loss: 0.5871\n",
            " Training bag [9/11] bag loss: 0.7121\n",
            " Training bag [10/11] bag loss: 0.7171\n",
            " Testing bag [0/6] bag loss: 0.6160\n",
            " Testing bag [1/6] bag loss: 0.5976\n",
            " Testing bag [2/6] bag loss: 0.5813\n",
            " Testing bag [3/6] bag loss: 0.6037\n",
            " Testing bag [4/6] bag loss: 0.7166\n",
            " Testing bag [5/6] bag loss: 0.5896ROC AUC score: 0.875\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [81/300] train loss: 0.6112 test loss: 0.6175, average score: 0.3333, AUC: class-0>>0.875|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7152\n",
            " Training bag [1/11] bag loss: 0.5757\n",
            " Training bag [2/11] bag loss: 0.7059\n",
            " Training bag [3/11] bag loss: 0.5688\n",
            " Training bag [4/11] bag loss: 0.5992\n",
            " Training bag [5/11] bag loss: 0.5702\n",
            " Training bag [6/11] bag loss: 0.5948\n",
            " Training bag [7/11] bag loss: 0.5431\n",
            " Training bag [8/11] bag loss: 0.5447\n",
            " Training bag [9/11] bag loss: 0.7176\n",
            " Training bag [10/11] bag loss: 0.5919\n",
            " Testing bag [0/6] bag loss: 0.6175\n",
            " Testing bag [1/6] bag loss: 0.5990\n",
            " Testing bag [2/6] bag loss: 0.5813\n",
            " Testing bag [3/6] bag loss: 0.6056\n",
            " Testing bag [4/6] bag loss: 0.7128\n",
            " Testing bag [5/6] bag loss: 0.5883ROC AUC score: 0.875\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [82/300] train loss: 0.6116 test loss: 0.6174, average score: 0.3333, AUC: class-0>>0.875|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5736\n",
            " Training bag [1/11] bag loss: 0.5874\n",
            " Training bag [2/11] bag loss: 0.7150\n",
            " Training bag [3/11] bag loss: 0.5903\n",
            " Training bag [4/11] bag loss: 0.5456\n",
            " Training bag [5/11] bag loss: 0.7166\n",
            " Training bag [6/11] bag loss: 0.6002\n",
            " Training bag [7/11] bag loss: 0.5558\n",
            " Training bag [8/11] bag loss: 0.7046\n",
            " Training bag [9/11] bag loss: 0.5677\n",
            " Training bag [10/11] bag loss: 0.5661\n",
            " Testing bag [0/6] bag loss: 0.6203\n",
            " Testing bag [1/6] bag loss: 0.6001\n",
            " Testing bag [2/6] bag loss: 0.5792\n",
            " Testing bag [3/6] bag loss: 0.6077\n",
            " Testing bag [4/6] bag loss: 0.7124\n",
            " Testing bag [5/6] bag loss: 0.5877ROC AUC score: 0.875\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [83/300] train loss: 0.6112 test loss: 0.6179, average score: 0.3333, AUC: class-0>>0.875|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7121\n",
            " Training bag [1/11] bag loss: 0.5945\n",
            " Training bag [2/11] bag loss: 0.7029\n",
            " Training bag [3/11] bag loss: 0.5960\n",
            " Training bag [4/11] bag loss: 0.5659\n",
            " Training bag [5/11] bag loss: 0.5514\n",
            " Training bag [6/11] bag loss: 0.7100\n",
            " Training bag [7/11] bag loss: 0.5927\n",
            " Training bag [8/11] bag loss: 0.5759\n",
            " Training bag [9/11] bag loss: 0.5674\n",
            " Training bag [10/11] bag loss: 0.5432\n",
            " Testing bag [0/6] bag loss: 0.6193\n",
            " Testing bag [1/6] bag loss: 0.6004\n",
            " Testing bag [2/6] bag loss: 0.5792\n",
            " Testing bag [3/6] bag loss: 0.6072\n",
            " Testing bag [4/6] bag loss: 0.7130\n",
            " Testing bag [5/6] bag loss: 0.5856ROC AUC score: 0.875\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [84/300] train loss: 0.6102 test loss: 0.6174, average score: 0.3333, AUC: class-0>>0.875|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5670\n",
            " Training bag [1/11] bag loss: 0.7126\n",
            " Training bag [2/11] bag loss: 0.7040\n",
            " Training bag [3/11] bag loss: 0.5778\n",
            " Training bag [4/11] bag loss: 0.7108\n",
            " Training bag [5/11] bag loss: 0.5955\n",
            " Training bag [6/11] bag loss: 0.5673\n",
            " Training bag [7/11] bag loss: 0.5492\n",
            " Training bag [8/11] bag loss: 0.5452\n",
            " Training bag [9/11] bag loss: 0.5896\n",
            " Training bag [10/11] bag loss: 0.5967\n",
            " Testing bag [0/6] bag loss: 0.6188\n",
            " Testing bag [1/6] bag loss: 0.5996\n",
            " Testing bag [2/6] bag loss: 0.5800\n",
            " Testing bag [3/6] bag loss: 0.6072\n",
            " Testing bag [4/6] bag loss: 0.7116\n",
            " Testing bag [5/6] bag loss: 0.5864ROC AUC score: 0.875\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [85/300] train loss: 0.6105 test loss: 0.6173, average score: 0.3333, AUC: class-0>>0.875|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5716\n",
            " Training bag [1/11] bag loss: 0.5648\n",
            " Training bag [2/11] bag loss: 0.5928\n",
            " Training bag [3/11] bag loss: 0.5959\n",
            " Training bag [4/11] bag loss: 0.7167\n",
            " Training bag [5/11] bag loss: 0.7070\n",
            " Training bag [6/11] bag loss: 0.5914\n",
            " Training bag [7/11] bag loss: 0.5618\n",
            " Training bag [8/11] bag loss: 0.7153\n",
            " Training bag [9/11] bag loss: 0.5495\n",
            " Training bag [10/11] bag loss: 0.5409\n",
            " Testing bag [0/6] bag loss: 0.6193\n",
            " Testing bag [1/6] bag loss: 0.6005\n",
            " Testing bag [2/6] bag loss: 0.5783\n",
            " Testing bag [3/6] bag loss: 0.6078\n",
            " Testing bag [4/6] bag loss: 0.7140\n",
            " Testing bag [5/6] bag loss: 0.5852ROC AUC score: 0.875\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [86/300] train loss: 0.6098 test loss: 0.6175, average score: 0.3333, AUC: class-0>>0.875|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5443\n",
            " Training bag [1/11] bag loss: 0.5654\n",
            " Training bag [2/11] bag loss: 0.7053\n",
            " Training bag [3/11] bag loss: 0.7151\n",
            " Training bag [4/11] bag loss: 0.5892\n",
            " Training bag [5/11] bag loss: 0.5921\n",
            " Training bag [6/11] bag loss: 0.7123\n",
            " Training bag [7/11] bag loss: 0.6010\n",
            " Training bag [8/11] bag loss: 0.5696\n",
            " Training bag [9/11] bag loss: 0.5377\n",
            " Training bag [10/11] bag loss: 0.5767\n",
            " Testing bag [0/6] bag loss: 0.6168\n",
            " Testing bag [1/6] bag loss: 0.5948\n",
            " Testing bag [2/6] bag loss: 0.5818\n",
            " Testing bag [3/6] bag loss: 0.6061\n",
            " Testing bag [4/6] bag loss: 0.7155\n",
            " Testing bag [5/6] bag loss: 0.5869ROC AUC score: 0.875\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [87/300] train loss: 0.6099 test loss: 0.6170, average score: 0.3333, AUC: class-0>>0.875|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7110\n",
            " Training bag [1/11] bag loss: 0.7055\n",
            " Training bag [2/11] bag loss: 0.5939\n",
            " Training bag [3/11] bag loss: 0.5859\n",
            " Training bag [4/11] bag loss: 0.5521\n",
            " Training bag [5/11] bag loss: 0.5647\n",
            " Training bag [6/11] bag loss: 0.5677\n",
            " Training bag [7/11] bag loss: 0.5725\n",
            " Training bag [8/11] bag loss: 0.5408\n",
            " Training bag [9/11] bag loss: 0.7158\n",
            " Training bag [10/11] bag loss: 0.5969\n",
            " Testing bag [0/6] bag loss: 0.6203\n",
            " Testing bag [1/6] bag loss: 0.5968\n",
            " Testing bag [2/6] bag loss: 0.5796\n",
            " Testing bag [3/6] bag loss: 0.6069\n",
            " Testing bag [4/6] bag loss: 0.7140\n",
            " Testing bag [5/6] bag loss: 0.5848ROC AUC score: 0.875\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [88/300] train loss: 0.6097 test loss: 0.6171, average score: 0.3333, AUC: class-0>>0.875|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5928\n",
            " Training bag [1/11] bag loss: 0.7136\n",
            " Training bag [2/11] bag loss: 0.5696\n",
            " Training bag [3/11] bag loss: 0.5512\n",
            " Training bag [4/11] bag loss: 0.5381\n",
            " Training bag [5/11] bag loss: 0.5592\n",
            " Training bag [6/11] bag loss: 0.5956\n",
            " Training bag [7/11] bag loss: 0.7181\n",
            " Training bag [8/11] bag loss: 0.7098\n",
            " Training bag [9/11] bag loss: 0.5858\n",
            " Training bag [10/11] bag loss: 0.5652\n",
            " Testing bag [0/6] bag loss: 0.6204\n",
            " Testing bag [1/6] bag loss: 0.5971\n",
            " Testing bag [2/6] bag loss: 0.5782\n",
            " Testing bag [3/6] bag loss: 0.6051\n",
            " Testing bag [4/6] bag loss: 0.7126\n",
            " Testing bag [5/6] bag loss: 0.5862ROC AUC score: 0.875\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [89/300] train loss: 0.6090 test loss: 0.6166, average score: 0.3333, AUC: class-0>>0.875|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7020\n",
            " Training bag [1/11] bag loss: 0.5972\n",
            " Training bag [2/11] bag loss: 0.5871\n",
            " Training bag [3/11] bag loss: 0.5611\n",
            " Training bag [4/11] bag loss: 0.5645\n",
            " Training bag [5/11] bag loss: 0.5735\n",
            " Training bag [6/11] bag loss: 0.5901\n",
            " Training bag [7/11] bag loss: 0.7179\n",
            " Training bag [8/11] bag loss: 0.7164\n",
            " Training bag [9/11] bag loss: 0.5402\n",
            " Training bag [10/11] bag loss: 0.5459\n",
            " Testing bag [0/6] bag loss: 0.6190\n",
            " Testing bag [1/6] bag loss: 0.5999\n",
            " Testing bag [2/6] bag loss: 0.5762\n",
            " Testing bag [3/6] bag loss: 0.6062\n",
            " Testing bag [4/6] bag loss: 0.7115\n",
            " Testing bag [5/6] bag loss: 0.5837ROC AUC score: 0.875\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [90/300] train loss: 0.6087 test loss: 0.6161, average score: 0.3333, AUC: class-0>>0.875|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5620\n",
            " Training bag [1/11] bag loss: 0.7133\n",
            " Training bag [2/11] bag loss: 0.5946\n",
            " Training bag [3/11] bag loss: 0.5716\n",
            " Training bag [4/11] bag loss: 0.5442\n",
            " Training bag [5/11] bag loss: 0.5373\n",
            " Training bag [6/11] bag loss: 0.7051\n",
            " Training bag [7/11] bag loss: 0.5875\n",
            " Training bag [8/11] bag loss: 0.5935\n",
            " Training bag [9/11] bag loss: 0.5595\n",
            " Training bag [10/11] bag loss: 0.7157\n",
            " Testing bag [0/6] bag loss: 0.6185\n",
            " Testing bag [1/6] bag loss: 0.5963\n",
            " Testing bag [2/6] bag loss: 0.5778\n",
            " Testing bag [3/6] bag loss: 0.6043\n",
            " Testing bag [4/6] bag loss: 0.7174\n",
            " Testing bag [5/6] bag loss: 0.5859ROC AUC score: 0.875\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [91/300] train loss: 0.6077 test loss: 0.6167, average score: 0.3333, AUC: class-0>>0.875|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5346\n",
            " Training bag [1/11] bag loss: 0.7040\n",
            " Training bag [2/11] bag loss: 0.7087\n",
            " Training bag [3/11] bag loss: 0.5382\n",
            " Training bag [4/11] bag loss: 0.7112\n",
            " Training bag [5/11] bag loss: 0.5750\n",
            " Training bag [6/11] bag loss: 0.5606\n",
            " Training bag [7/11] bag loss: 0.5961\n",
            " Training bag [8/11] bag loss: 0.5672\n",
            " Training bag [9/11] bag loss: 0.5929\n",
            " Training bag [10/11] bag loss: 0.5927\n",
            " Testing bag [0/6] bag loss: 0.6178\n",
            " Testing bag [1/6] bag loss: 0.5959\n",
            " Testing bag [2/6] bag loss: 0.5819\n",
            " Testing bag [3/6] bag loss: 0.6047\n",
            " Testing bag [4/6] bag loss: 0.7129\n",
            " Testing bag [5/6] bag loss: 0.5866ROC AUC score: 0.875\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [92/300] train loss: 0.6074 test loss: 0.6166, average score: 0.3333, AUC: class-0>>0.875|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5431\n",
            " Training bag [1/11] bag loss: 0.5898\n",
            " Training bag [2/11] bag loss: 0.5938\n",
            " Training bag [3/11] bag loss: 0.5623\n",
            " Training bag [4/11] bag loss: 0.7170\n",
            " Training bag [5/11] bag loss: 0.7167\n",
            " Training bag [6/11] bag loss: 0.5378\n",
            " Training bag [7/11] bag loss: 0.5623\n",
            " Training bag [8/11] bag loss: 0.5670\n",
            " Training bag [9/11] bag loss: 0.7045\n",
            " Training bag [10/11] bag loss: 0.5936\n",
            " Testing bag [0/6] bag loss: 0.6198\n",
            " Testing bag [1/6] bag loss: 0.5981\n",
            " Testing bag [2/6] bag loss: 0.5786\n",
            " Testing bag [3/6] bag loss: 0.6067\n",
            " Testing bag [4/6] bag loss: 0.7115\n",
            " Testing bag [5/6] bag loss: 0.5840ROC AUC score: 0.875\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [93/300] train loss: 0.6080 test loss: 0.6165, average score: 0.3333, AUC: class-0>>0.875|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5853\n",
            " Training bag [1/11] bag loss: 0.7028\n",
            " Training bag [2/11] bag loss: 0.5620\n",
            " Training bag [3/11] bag loss: 0.5922\n",
            " Training bag [4/11] bag loss: 0.5606\n",
            " Training bag [5/11] bag loss: 0.7165\n",
            " Training bag [6/11] bag loss: 0.5959\n",
            " Training bag [7/11] bag loss: 0.5359\n",
            " Training bag [8/11] bag loss: 0.7122\n",
            " Training bag [9/11] bag loss: 0.5686\n",
            " Training bag [10/11] bag loss: 0.5471\n",
            " Testing bag [0/6] bag loss: 0.6179\n",
            " Testing bag [1/6] bag loss: 0.5969\n",
            " Testing bag [2/6] bag loss: 0.5779\n",
            " Testing bag [3/6] bag loss: 0.6051\n",
            " Testing bag [4/6] bag loss: 0.7136\n",
            " Testing bag [5/6] bag loss: 0.5842ROC AUC score: 0.875\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [94/300] train loss: 0.6072 test loss: 0.6159, average score: 0.3333, AUC: class-0>>0.875|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7126\n",
            " Training bag [1/11] bag loss: 0.5919\n",
            " Training bag [2/11] bag loss: 0.7070\n",
            " Training bag [3/11] bag loss: 0.5635\n",
            " Training bag [4/11] bag loss: 0.5667\n",
            " Training bag [5/11] bag loss: 0.5962\n",
            " Training bag [6/11] bag loss: 0.5351\n",
            " Training bag [7/11] bag loss: 0.5810\n",
            " Training bag [8/11] bag loss: 0.5446\n",
            " Training bag [9/11] bag loss: 0.5599\n",
            " Training bag [10/11] bag loss: 0.7049\n",
            " Testing bag [0/6] bag loss: 0.6184\n",
            " Testing bag [1/6] bag loss: 0.5965\n",
            " Testing bag [2/6] bag loss: 0.5782\n",
            " Testing bag [3/6] bag loss: 0.6044\n",
            " Testing bag [4/6] bag loss: 0.7147\n",
            " Testing bag [5/6] bag loss: 0.5857ROC AUC score: 0.875\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [95/300] train loss: 0.6057 test loss: 0.6163, average score: 0.3333, AUC: class-0>>0.875|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7146\n",
            " Training bag [1/11] bag loss: 0.5911\n",
            " Training bag [2/11] bag loss: 0.5620\n",
            " Training bag [3/11] bag loss: 0.5662\n",
            " Training bag [4/11] bag loss: 0.5988\n",
            " Training bag [5/11] bag loss: 0.5358\n",
            " Training bag [6/11] bag loss: 0.7028\n",
            " Training bag [7/11] bag loss: 0.7145\n",
            " Training bag [8/11] bag loss: 0.5592\n",
            " Training bag [9/11] bag loss: 0.5852\n",
            " Training bag [10/11] bag loss: 0.5400\n",
            " Testing bag [0/6] bag loss: 0.6181\n",
            " Testing bag [1/6] bag loss: 0.5974\n",
            " Testing bag [2/6] bag loss: 0.5794\n",
            " Testing bag [3/6] bag loss: 0.6044\n",
            " Testing bag [4/6] bag loss: 0.7132\n",
            " Testing bag [5/6] bag loss: 0.5869ROC AUC score: 0.875\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [96/300] train loss: 0.6064 test loss: 0.6166, average score: 0.3333, AUC: class-0>>0.875|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5335\n",
            " Training bag [1/11] bag loss: 0.7023\n",
            " Training bag [2/11] bag loss: 0.5922\n",
            " Training bag [3/11] bag loss: 0.7135\n",
            " Training bag [4/11] bag loss: 0.5728\n",
            " Training bag [5/11] bag loss: 0.5585\n",
            " Training bag [6/11] bag loss: 0.5839\n",
            " Training bag [7/11] bag loss: 0.5647\n",
            " Training bag [8/11] bag loss: 0.5969\n",
            " Training bag [9/11] bag loss: 0.5398\n",
            " Training bag [10/11] bag loss: 0.7127\n",
            " Testing bag [0/6] bag loss: 0.6207\n",
            " Testing bag [1/6] bag loss: 0.5968\n",
            " Testing bag [2/6] bag loss: 0.5758\n",
            " Testing bag [3/6] bag loss: 0.6034\n",
            " Testing bag [4/6] bag loss: 0.7154\n",
            " Testing bag [5/6] bag loss: 0.5846ROC AUC score: 0.875\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [97/300] train loss: 0.6065 test loss: 0.6161, average score: 0.3333, AUC: class-0>>0.875|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5901\n",
            " Training bag [1/11] bag loss: 0.5623\n",
            " Training bag [2/11] bag loss: 0.5306\n",
            " Training bag [3/11] bag loss: 0.5869\n",
            " Training bag [4/11] bag loss: 0.5409\n",
            " Training bag [5/11] bag loss: 0.5909\n",
            " Training bag [6/11] bag loss: 0.5539\n",
            " Training bag [7/11] bag loss: 0.7199\n",
            " Training bag [8/11] bag loss: 0.5674\n",
            " Training bag [9/11] bag loss: 0.7195\n",
            " Training bag [10/11] bag loss: 0.7053\n",
            " Testing bag [0/6] bag loss: 0.6181\n",
            " Testing bag [1/6] bag loss: 0.5954\n",
            " Testing bag [2/6] bag loss: 0.5768\n",
            " Testing bag [3/6] bag loss: 0.6013\n",
            " Testing bag [4/6] bag loss: 0.7190\n",
            " Testing bag [5/6] bag loss: 0.5827ROC AUC score: 0.875\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [98/300] train loss: 0.6062 test loss: 0.6156, average score: 0.3333, AUC: class-0>>0.875|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5921\n",
            " Training bag [1/11] bag loss: 0.7148\n",
            " Training bag [2/11] bag loss: 0.5814\n",
            " Training bag [3/11] bag loss: 0.5413\n",
            " Training bag [4/11] bag loss: 0.5947\n",
            " Training bag [5/11] bag loss: 0.5673\n",
            " Training bag [6/11] bag loss: 0.5338\n",
            " Training bag [7/11] bag loss: 0.7155\n",
            " Training bag [8/11] bag loss: 0.7080\n",
            " Training bag [9/11] bag loss: 0.5578\n",
            " Training bag [10/11] bag loss: 0.5627\n",
            " Testing bag [0/6] bag loss: 0.6157\n",
            " Testing bag [1/6] bag loss: 0.5953\n",
            " Testing bag [2/6] bag loss: 0.5781\n",
            " Testing bag [3/6] bag loss: 0.6037\n",
            " Testing bag [4/6] bag loss: 0.7136\n",
            " Testing bag [5/6] bag loss: 0.5838ROC AUC score: 0.875\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [99/300] train loss: 0.6063 test loss: 0.6150, average score: 0.3333, AUC: class-0>>0.875|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5421\n",
            " Training bag [1/11] bag loss: 0.5932\n",
            " Training bag [2/11] bag loss: 0.5684\n",
            " Training bag [3/11] bag loss: 0.5821\n",
            " Training bag [4/11] bag loss: 0.5541\n",
            " Training bag [5/11] bag loss: 0.5348\n",
            " Training bag [6/11] bag loss: 0.5558\n",
            " Training bag [7/11] bag loss: 0.7154\n",
            " Training bag [8/11] bag loss: 0.7164\n",
            " Training bag [9/11] bag loss: 0.5922\n",
            " Training bag [10/11] bag loss: 0.7180\n",
            " Testing bag [0/6] bag loss: 0.6164\n",
            " Testing bag [1/6] bag loss: 0.5966\n",
            " Testing bag [2/6] bag loss: 0.5750\n",
            " Testing bag [3/6] bag loss: 0.6026\n",
            " Testing bag [4/6] bag loss: 0.7187\n",
            " Testing bag [5/6] bag loss: 0.5842ROC AUC score: 0.875\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [100/300] train loss: 0.6066 test loss: 0.6156, average score: 0.3333, AUC: class-0>>0.875|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7118\n",
            " Training bag [1/11] bag loss: 0.5929\n",
            " Training bag [2/11] bag loss: 0.5615\n",
            " Training bag [3/11] bag loss: 0.5715\n",
            " Training bag [4/11] bag loss: 0.5301\n",
            " Training bag [5/11] bag loss: 0.5338\n",
            " Training bag [6/11] bag loss: 0.5847\n",
            " Training bag [7/11] bag loss: 0.7093\n",
            " Training bag [8/11] bag loss: 0.5889\n",
            " Training bag [9/11] bag loss: 0.7179\n",
            " Training bag [10/11] bag loss: 0.5593\n",
            " Testing bag [0/6] bag loss: 0.6184\n",
            " Testing bag [1/6] bag loss: 0.5948\n",
            " Testing bag [2/6] bag loss: 0.5771\n",
            " Testing bag [3/6] bag loss: 0.6045\n",
            " Testing bag [4/6] bag loss: 0.7129\n",
            " Testing bag [5/6] bag loss: 0.5822ROC AUC score: 0.875\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [101/300] train loss: 0.6056 test loss: 0.6150, average score: 0.3333, AUC: class-0>>0.875|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5817\n",
            " Training bag [1/11] bag loss: 0.5558\n",
            " Training bag [2/11] bag loss: 0.5891\n",
            " Training bag [3/11] bag loss: 0.5279\n",
            " Training bag [4/11] bag loss: 0.5345\n",
            " Training bag [5/11] bag loss: 0.7167\n",
            " Training bag [6/11] bag loss: 0.5671\n",
            " Training bag [7/11] bag loss: 0.7194\n",
            " Training bag [8/11] bag loss: 0.5524\n",
            " Training bag [9/11] bag loss: 0.7080\n",
            " Training bag [10/11] bag loss: 0.5925\n",
            " Testing bag [0/6] bag loss: 0.6168\n",
            " Testing bag [1/6] bag loss: 0.5900\n",
            " Testing bag [2/6] bag loss: 0.5764\n",
            " Testing bag [3/6] bag loss: 0.6012\n",
            " Testing bag [4/6] bag loss: 0.7143\n",
            " Testing bag [5/6] bag loss: 0.5840ROC AUC score: 0.875\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [102/300] train loss: 0.6041 test loss: 0.6138, average score: 0.3333, AUC: class-0>>0.875|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5940\n",
            " Training bag [1/11] bag loss: 0.5882\n",
            " Training bag [2/11] bag loss: 0.5283\n",
            " Training bag [3/11] bag loss: 0.5663\n",
            " Training bag [4/11] bag loss: 0.5548\n",
            " Training bag [5/11] bag loss: 0.5360\n",
            " Training bag [6/11] bag loss: 0.7214\n",
            " Training bag [7/11] bag loss: 0.5530\n",
            " Training bag [8/11] bag loss: 0.7109\n",
            " Training bag [9/11] bag loss: 0.7174\n",
            " Training bag [10/11] bag loss: 0.5869\n",
            " Testing bag [0/6] bag loss: 0.6150\n",
            " Testing bag [1/6] bag loss: 0.5926\n",
            " Testing bag [2/6] bag loss: 0.5772\n",
            " Testing bag [3/6] bag loss: 0.6005\n",
            " Testing bag [4/6] bag loss: 0.7127\n",
            " Testing bag [5/6] bag loss: 0.5854ROC AUC score: 0.875\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [103/300] train loss: 0.6052 test loss: 0.6139, average score: 0.3333, AUC: class-0>>0.875|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5920\n",
            " Training bag [1/11] bag loss: 0.5811\n",
            " Training bag [2/11] bag loss: 0.5574\n",
            " Training bag [3/11] bag loss: 0.7024\n",
            " Training bag [4/11] bag loss: 0.5367\n",
            " Training bag [5/11] bag loss: 0.7129\n",
            " Training bag [6/11] bag loss: 0.5916\n",
            " Training bag [7/11] bag loss: 0.5708\n",
            " Training bag [8/11] bag loss: 0.7156\n",
            " Training bag [9/11] bag loss: 0.5299\n",
            " Training bag [10/11] bag loss: 0.5587\n",
            " Testing bag [0/6] bag loss: 0.6164\n",
            " Testing bag [1/6] bag loss: 0.5933\n",
            " Testing bag [2/6] bag loss: 0.5750\n",
            " Testing bag [3/6] bag loss: 0.6009\n",
            " Testing bag [4/6] bag loss: 0.7140\n",
            " Testing bag [5/6] bag loss: 0.5858ROC AUC score: 0.875\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [104/300] train loss: 0.6045 test loss: 0.6142, average score: 0.3333, AUC: class-0>>0.875|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7042\n",
            " Training bag [1/11] bag loss: 0.5860\n",
            " Training bag [2/11] bag loss: 0.5553\n",
            " Training bag [3/11] bag loss: 0.5409\n",
            " Training bag [4/11] bag loss: 0.7158\n",
            " Training bag [5/11] bag loss: 0.5908\n",
            " Training bag [6/11] bag loss: 0.5667\n",
            " Training bag [7/11] bag loss: 0.5977\n",
            " Training bag [8/11] bag loss: 0.7087\n",
            " Training bag [9/11] bag loss: 0.5603\n",
            " Training bag [10/11] bag loss: 0.5283\n",
            " Testing bag [0/6] bag loss: 0.6176\n",
            " Testing bag [1/6] bag loss: 0.5967\n",
            " Testing bag [2/6] bag loss: 0.5747\n",
            " Testing bag [3/6] bag loss: 0.6022\n",
            " Testing bag [4/6] bag loss: 0.7119\n",
            " Testing bag [5/6] bag loss: 0.5820ROC AUC score: 0.875\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [105/300] train loss: 0.6050 test loss: 0.6142, average score: 0.3333, AUC: class-0>>0.875|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5813\n",
            " Training bag [1/11] bag loss: 0.5896\n",
            " Training bag [2/11] bag loss: 0.5565\n",
            " Training bag [3/11] bag loss: 0.5643\n",
            " Training bag [4/11] bag loss: 0.7146\n",
            " Training bag [5/11] bag loss: 0.5265\n",
            " Training bag [6/11] bag loss: 0.7197\n",
            " Training bag [7/11] bag loss: 0.5904\n",
            " Training bag [8/11] bag loss: 0.7049\n",
            " Training bag [9/11] bag loss: 0.5352\n",
            " Training bag [10/11] bag loss: 0.5566\n",
            " Testing bag [0/6] bag loss: 0.6196\n",
            " Testing bag [1/6] bag loss: 0.5984\n",
            " Testing bag [2/6] bag loss: 0.5744\n",
            " Testing bag [3/6] bag loss: 0.6056\n",
            " Testing bag [4/6] bag loss: 0.7114\n",
            " Testing bag [5/6] bag loss: 0.5816ROC AUC score: 0.875\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [106/300] train loss: 0.6036 test loss: 0.6152, average score: 0.3333, AUC: class-0>>0.875|class-1>>0.6|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5907\n",
            " Training bag [1/11] bag loss: 0.5674\n",
            " Training bag [2/11] bag loss: 0.7112\n",
            " Training bag [3/11] bag loss: 0.5267\n",
            " Training bag [4/11] bag loss: 0.6989\n",
            " Training bag [5/11] bag loss: 0.7124\n",
            " Training bag [6/11] bag loss: 0.5331\n",
            " Training bag [7/11] bag loss: 0.5940\n",
            " Training bag [8/11] bag loss: 0.5563\n",
            " Training bag [9/11] bag loss: 0.5874\n",
            " Training bag [10/11] bag loss: 0.5600\n",
            " Testing bag [0/6] bag loss: 0.6152\n",
            " Testing bag [1/6] bag loss: 0.5924\n",
            " Testing bag [2/6] bag loss: 0.5752\n",
            " Testing bag [3/6] bag loss: 0.6036\n",
            " Testing bag [4/6] bag loss: 0.7118\n",
            " Testing bag [5/6] bag loss: 0.5862ROC AUC score: 0.875\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [107/300] train loss: 0.6035 test loss: 0.6141, average score: 0.3333, AUC: class-0>>0.875|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.6952\n",
            " Training bag [1/11] bag loss: 0.5235\n",
            " Training bag [2/11] bag loss: 0.5934\n",
            " Training bag [3/11] bag loss: 0.5842\n",
            " Training bag [4/11] bag loss: 0.5506\n",
            " Training bag [5/11] bag loss: 0.7129\n",
            " Training bag [6/11] bag loss: 0.5725\n",
            " Training bag [7/11] bag loss: 0.5582\n",
            " Training bag [8/11] bag loss: 0.5927\n",
            " Training bag [9/11] bag loss: 0.7168\n",
            " Training bag [10/11] bag loss: 0.5368\n",
            " Testing bag [0/6] bag loss: 0.6170\n",
            " Testing bag [1/6] bag loss: 0.5948\n",
            " Testing bag [2/6] bag loss: 0.5760\n",
            " Testing bag [3/6] bag loss: 0.6033\n",
            " Testing bag [4/6] bag loss: 0.7115\n",
            " Testing bag [5/6] bag loss: 0.5852ROC AUC score: 0.875\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [108/300] train loss: 0.6034 test loss: 0.6147, average score: 0.3333, AUC: class-0>>0.875|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5345\n",
            " Training bag [1/11] bag loss: 0.5588\n",
            " Training bag [2/11] bag loss: 0.5809\n",
            " Training bag [3/11] bag loss: 0.5255\n",
            " Training bag [4/11] bag loss: 0.7016\n",
            " Training bag [5/11] bag loss: 0.7164\n",
            " Training bag [6/11] bag loss: 0.5653\n",
            " Training bag [7/11] bag loss: 0.5913\n",
            " Training bag [8/11] bag loss: 0.5909\n",
            " Training bag [9/11] bag loss: 0.5550\n",
            " Training bag [10/11] bag loss: 0.7095\n",
            " Testing bag [0/6] bag loss: 0.6174\n",
            " Testing bag [1/6] bag loss: 0.5927\n",
            " Testing bag [2/6] bag loss: 0.5718\n",
            " Testing bag [3/6] bag loss: 0.6030\n",
            " Testing bag [4/6] bag loss: 0.7124\n",
            " Testing bag [5/6] bag loss: 0.5828ROC AUC score: 0.875\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [109/300] train loss: 0.6027 test loss: 0.6134, average score: 0.3333, AUC: class-0>>0.875|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5547\n",
            " Training bag [1/11] bag loss: 0.5559\n",
            " Training bag [2/11] bag loss: 0.7193\n",
            " Training bag [3/11] bag loss: 0.5913\n",
            " Training bag [4/11] bag loss: 0.5653\n",
            " Training bag [5/11] bag loss: 0.5290\n",
            " Training bag [6/11] bag loss: 0.5347\n",
            " Training bag [7/11] bag loss: 0.7093\n",
            " Training bag [8/11] bag loss: 0.7119\n",
            " Training bag [9/11] bag loss: 0.5849\n",
            " Training bag [10/11] bag loss: 0.5924\n",
            " Testing bag [0/6] bag loss: 0.6193\n",
            " Testing bag [1/6] bag loss: 0.5923\n",
            " Testing bag [2/6] bag loss: 0.5751\n",
            " Testing bag [3/6] bag loss: 0.6042\n",
            " Testing bag [4/6] bag loss: 0.7137\n",
            " Testing bag [5/6] bag loss: 0.5822ROC AUC score: 0.875\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [110/300] train loss: 0.6044 test loss: 0.6145, average score: 0.3333, AUC: class-0>>0.875|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5229\n",
            " Training bag [1/11] bag loss: 0.7140\n",
            " Training bag [2/11] bag loss: 0.5267\n",
            " Training bag [3/11] bag loss: 0.6957\n",
            " Training bag [4/11] bag loss: 0.5946\n",
            " Training bag [5/11] bag loss: 0.5881\n",
            " Training bag [6/11] bag loss: 0.5569\n",
            " Training bag [7/11] bag loss: 0.5874\n",
            " Training bag [8/11] bag loss: 0.7062\n",
            " Training bag [9/11] bag loss: 0.5677\n",
            " Training bag [10/11] bag loss: 0.5516\n",
            " Testing bag [0/6] bag loss: 0.6162\n",
            " Testing bag [1/6] bag loss: 0.5940\n",
            " Testing bag [2/6] bag loss: 0.5748\n",
            " Testing bag [3/6] bag loss: 0.6045\n",
            " Testing bag [4/6] bag loss: 0.7117\n",
            " Testing bag [5/6] bag loss: 0.5848ROC AUC score: 0.875\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [111/300] train loss: 0.6011 test loss: 0.6143, average score: 0.3333, AUC: class-0>>0.875|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5687\n",
            " Training bag [1/11] bag loss: 0.5308\n",
            " Training bag [2/11] bag loss: 0.5909\n",
            " Training bag [3/11] bag loss: 0.5910\n",
            " Training bag [4/11] bag loss: 0.7011\n",
            " Training bag [5/11] bag loss: 0.5513\n",
            " Training bag [6/11] bag loss: 0.5197\n",
            " Training bag [7/11] bag loss: 0.7105\n",
            " Training bag [8/11] bag loss: 0.5823\n",
            " Training bag [9/11] bag loss: 0.7147\n",
            " Training bag [10/11] bag loss: 0.5576\n",
            " Testing bag [0/6] bag loss: 0.6162\n",
            " Testing bag [1/6] bag loss: 0.5929\n",
            " Testing bag [2/6] bag loss: 0.5746\n",
            " Testing bag [3/6] bag loss: 0.6017\n",
            " Testing bag [4/6] bag loss: 0.7113\n",
            " Testing bag [5/6] bag loss: 0.5835ROC AUC score: 0.875\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [112/300] train loss: 0.6017 test loss: 0.6134, average score: 0.3333, AUC: class-0>>0.875|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.7131\n",
            " Training bag [1/11] bag loss: 0.5901\n",
            " Training bag [2/11] bag loss: 0.5325\n",
            " Training bag [3/11] bag loss: 0.5588\n",
            " Training bag [4/11] bag loss: 0.5822\n",
            " Training bag [5/11] bag loss: 0.7101\n",
            " Training bag [6/11] bag loss: 0.5218\n",
            " Training bag [7/11] bag loss: 0.5545\n",
            " Training bag [8/11] bag loss: 0.5647\n",
            " Training bag [9/11] bag loss: 0.5912\n",
            " Training bag [10/11] bag loss: 0.6990\n",
            " Testing bag [0/6] bag loss: 0.6177\n",
            " Testing bag [1/6] bag loss: 0.5935\n",
            " Testing bag [2/6] bag loss: 0.5724\n",
            " Testing bag [3/6] bag loss: 0.6024\n",
            " Testing bag [4/6] bag loss: 0.7114\n",
            " Testing bag [5/6] bag loss: 0.5827ROC AUC score: 0.875\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [113/300] train loss: 0.6016 test loss: 0.6133, average score: 0.3333, AUC: class-0>>0.875|class-1>>0.6|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5833\n",
            " Training bag [1/11] bag loss: 0.6975\n",
            " Training bag [2/11] bag loss: 0.5893\n",
            " Training bag [3/11] bag loss: 0.7146\n",
            " Training bag [4/11] bag loss: 0.5352\n",
            " Training bag [5/11] bag loss: 0.5637\n",
            " Training bag [6/11] bag loss: 0.5538\n",
            " Training bag [7/11] bag loss: 0.5551\n",
            " Training bag [8/11] bag loss: 0.7093\n",
            " Training bag [9/11] bag loss: 0.5243\n",
            " Training bag [10/11] bag loss: 0.5945\n",
            " Testing bag [0/6] bag loss: 0.6182\n",
            " Testing bag [1/6] bag loss: 0.5971\n",
            " Testing bag [2/6] bag loss: 0.5736\n",
            " Testing bag [3/6] bag loss: 0.6045\n",
            " Testing bag [4/6] bag loss: 0.7119\n",
            " Testing bag [5/6] bag loss: 0.5851ROC AUC score: 0.875\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [114/300] train loss: 0.6019 test loss: 0.6150, average score: 0.3333, AUC: class-0>>0.875|class-1>>0.6|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5912\n",
            " Training bag [1/11] bag loss: 0.5824\n",
            " Training bag [2/11] bag loss: 0.5554\n",
            " Training bag [3/11] bag loss: 0.7172\n",
            " Training bag [4/11] bag loss: 0.5293\n",
            " Training bag [5/11] bag loss: 0.5904\n",
            " Training bag [6/11] bag loss: 0.7054\n",
            " Training bag [7/11] bag loss: 0.5629\n",
            " Training bag [8/11] bag loss: 0.6965\n",
            " Training bag [9/11] bag loss: 0.5244\n",
            " Training bag [10/11] bag loss: 0.5515\n",
            " Testing bag [0/6] bag loss: 0.6191\n",
            " Testing bag [1/6] bag loss: 0.5947\n",
            " Testing bag [2/6] bag loss: 0.5722\n",
            " Testing bag [3/6] bag loss: 0.6052\n",
            " Testing bag [4/6] bag loss: 0.7116\n",
            " Testing bag [5/6] bag loss: 0.5829ROC AUC score: 0.875\n",
            "ROC AUC score: 0.8\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [115/300] train loss: 0.6006 test loss: 0.6143, average score: 0.3333, AUC: class-0>>0.875|class-1>>0.8|class-2>>0.6666666666666667\n",
            "\n",
            " Training bag [0/11] bag loss: 0.5214\n",
            " Training bag [1/11] bag loss: 0.7126\n",
            " Training bag [2/11] bag loss: 0.7008\n",
            " Training bag [3/11] bag loss: 0.5665\n",
            " Training bag [4/11] bag loss: 0.5335\n",
            " Training bag [5/11] bag loss: 0.5875\n",
            " Training bag [6/11] bag loss: 0.5481\n",
            " Training bag [7/11] bag loss: 0.5598\n",
            " Training bag [8/11] bag loss: 0.5880\n",
            " Training bag [9/11] bag loss: 0.5918\n",
            " Training bag [10/11] bag loss: 0.7077\n",
            " Testing bag [0/6] bag loss: 0.6167\n",
            " Testing bag [1/6] bag loss: 0.5935\n",
            " Testing bag [2/6] bag loss: 0.5752\n",
            " Testing bag [3/6] bag loss: 0.5992\n",
            " Testing bag [4/6] bag loss: 0.7128\n",
            " Testing bag [5/6] bag loss: 0.5831ROC AUC score: 0.875\n",
            "ROC AUC score: 0.6\n",
            "ROC AUC score: 0.6666666666666667\n",
            "\n",
            " Epoch [116/300] train loss: 0.6016 test loss: 0.6134, average score: 0.3333, AUC: class-0>>0.875|class-1>>0.6|class-2>>0.6666666666666667\n",
            "\n",
            " Testing bag [0/4] bag loss: 0.6984\n",
            " Testing bag [1/4] bag loss: 0.6398\n",
            " Testing bag [2/4] bag loss: 0.6355\n",
            " Testing bag [3/4] bag loss: 0.6376ROC AUC score: 0.5\n",
            "ROC AUC score: 0.6666666666666667\n",
            "ROC AUC score: 0.6666666666666667\n",
            "âœ… Fold 4 completed | Test Acc: 0.5000 | Test AUCs: [np.float64(0.5), np.float64(0.667), np.float64(0.667)]\n",
            "\n",
            "ðŸ“Š Final Summary:\n",
            "Mean Test Accuracy: 0.4900 | Mean Test AUC: 0.6222\n",
            "\n",
            "\n",
            "  0%|          | 0/21 [00:00<?, ?it/s]\n",
            "  5%|â–         | 1/21 [00:12<04:11, 12.55s/it]\n",
            " 10%|â–‰         | 2/21 [00:14<01:59,  6.31s/it]\n",
            " 14%|â–ˆâ–        | 3/21 [00:17<01:23,  4.64s/it]\n",
            " 19%|â–ˆâ–‰        | 4/21 [00:22<01:26,  5.07s/it]\n",
            " 24%|â–ˆâ–ˆâ–       | 5/21 [00:25<01:05,  4.08s/it]\n",
            " 29%|â–ˆâ–ˆâ–Š       | 6/21 [00:26<00:49,  3.29s/it]\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 7/21 [00:28<00:36,  2.59s/it]\n",
            " 38%|â–ˆâ–ˆâ–ˆâ–Š      | 8/21 [00:34<00:48,  3.74s/it]\n",
            " 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 9/21 [00:37<00:42,  3.50s/it]\n",
            " 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 10/21 [00:40<00:37,  3.44s/it]\n",
            " 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 11/21 [00:40<00:24,  2.44s/it]\n",
            " 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 12/21 [00:40<00:15,  1.76s/it]\n",
            " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 13/21 [00:41<00:11,  1.38s/it]\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 14/21 [00:42<00:08,  1.28s/it]\n",
            " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 15/21 [00:43<00:06,  1.08s/it]\n",
            " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 16/21 [00:44<00:06,  1.21s/it]\n",
            " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 17/21 [00:45<00:04,  1.17s/it]\n",
            " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 18/21 [00:48<00:04,  1.56s/it]\n",
            " 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 19/21 [00:49<00:03,  1.59s/it]\n",
            " 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 20/21 [00:50<00:01,  1.17s/it]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:51<00:00,  1.30s/it]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:51<00:00,  2.46s/it]\n",
            "/content/dsmil-wsi/train_tcga.py:63: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)\n",
            "  bag_label = Tensor(stacked_data[0, args.feats_size:]).unsqueeze(0)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## to train paste into train_tcga.py the content of train_MLiA.py\n",
        "%cd /content/dsmil-wsi\n",
        "!MPLBACKEND=Agg conda run -n dsmil python train_tcga.py --dataset=MLiA_dataset --num_classes=3 --feats_size=1024 --num_epochs=300  --dropout_patch=0.60 --lr=1e-4 --weight_decay=1e-4 --stop_epochs=100 --eval_scheme=5-fold-cv-custom --split=0.2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### With SIMclr feature extraction"
      ],
      "metadata": {
        "id": "SJg5pJIn33hR"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "485bfa79",
        "outputId": "69b4d0d4-5f8f-444b-ad06-820855587a10"
      },
      "source": [
        "%cd /content/dsmil-wsi\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "# URL for the dataset\n",
        "url = \"https://zenodo.org/records/15700269/files/datasetWSI.zip?download=1\"\n",
        "\n",
        "# Define the download and extraction path\n",
        "download_path = 'datasetWSI.zip'\n",
        "extract_path = 'datasetWSI/'\n",
        "\n",
        "# Download the file using wget\n",
        "!wget -O \"$download_path\" \"$url\"\n",
        "\n",
        "# Create the extraction directory if it doesn't exist\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "# Extract the ZIP file\n",
        "with zipfile.ZipFile(download_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(f\"Downloaded and extracted to {extract_path}\")\n",
        "\n",
        "# List the contents of the extracted folder\n",
        "extracted_files = os.listdir(extract_path)\n",
        "print(\"Extracted files:\", extracted_files)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/dsmil-wsi\n",
            "--2025-06-27 07:58:58--  https://zenodo.org/records/15700269/files/datasetWSI.zip?download=1\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.45.92, 188.185.48.194, 188.185.43.25, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.45.92|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11982067512 (11G) [application/octet-stream]\n",
            "Saving to: â€˜datasetWSI.zipâ€™\n",
            "\n",
            "datasetWSI.zip      100%[===================>]  11.16G  2.63MB/s    in 62m 42s \n",
            "\n",
            "2025-06-27 09:01:41 (3.04 MB/s) - â€˜datasetWSI.zipâ€™ saved [11982067512/11982067512]\n",
            "\n",
            "Downloaded and extracted to datasetWSI/\n",
            "Extracted files: ['ndpi_files']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "\n",
        "old_path = '/content/dsmil-wsi/datasetWSI'\n",
        "new_path = '/content/dsmil-wsi/WSI'\n",
        "\n",
        "os.rename(old_path, new_path)\n",
        "print(f\"Renamed: {old_path} â†’ {new_path}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkTE0p556lfC",
        "outputId": "4014b0e0-a482-40dc-9fef-70c63012406a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Renamed: /content/dsmil-wsi/datasetWSI â†’ /content/dsmil-wsi/WSI\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda run -n dsmil pip install openslide-python openslide-bin\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLnPhwUMCqq9",
        "outputId": "0e1dceec-ed92-4183-80bf-382c1ebe01e1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openslide-python\n",
            "  Downloading openslide_python-1.4.2-cp311-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting openslide-bin\n",
            "  Downloading openslide_bin-4.0.0.8-py3-none-manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/envs/dsmil/lib/python3.13/site-packages (from openslide-python) (11.1.0)\n",
            "Downloading openslide_python-1.4.2-cp311-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.whl (36 kB)\n",
            "Downloading openslide_bin-4.0.0.8-py3-none-manylinux_2_28_x86_64.whl (4.3 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4.3/4.3 MB 17.2 MB/s eta 0:00:00\n",
            "Installing collected packages: openslide-python, openslide-bin\n",
            "\n",
            "Successfully installed openslide-bin-4.0.0.8 openslide-python-1.4.2\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PATCH CROPPING\n",
        "%cd /content/dsmil-wsi\n",
        "!MPLBACKEND=Agg conda run -n dsmil python deepzoom_tiler.py --magnifications 0 -b 10 -d ndpi_files --workers 4 --slide_format ndpi --tile_size 256\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1duXFdKCNK1",
        "outputId": "761428f9-9241-4f27-f2cb-54b6d2964693"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mOutput streaming troncato alle ultime 5000 righe.\u001b[0m\n",
            " Patch [3128/4865]\n",
            " Patch [3129/4865]\n",
            " Patch [3130/4865]\n",
            " Patch [3131/4865]\n",
            " Patch [3132/4865]\n",
            " Patch [3133/4865]\n",
            " Patch [3134/4865]\n",
            " Patch [3135/4865]\n",
            " Patch [3136/4865]\n",
            " Patch [3137/4865]\n",
            " Patch [3138/4865]\n",
            " Patch [3139/4865]\n",
            " Patch [3140/4865]\n",
            " Patch [3141/4865]\n",
            " Patch [3142/4865]\n",
            " Patch [3143/4865]\n",
            " Patch [3144/4865]\n",
            " Patch [3145/4865]\n",
            " Patch [3146/4865]\n",
            " Patch [3147/4865]\n",
            " Patch [3148/4865]\n",
            " Patch [3149/4865]\n",
            " Patch [3150/4865]\n",
            " Patch [3151/4865]\n",
            " Patch [3152/4865]\n",
            " Patch [3153/4865]\n",
            " Patch [3154/4865]\n",
            " Patch [3155/4865]\n",
            " Patch [3156/4865]\n",
            " Patch [3157/4865]\n",
            " Patch [3158/4865]\n",
            " Patch [3159/4865]\n",
            " Patch [3160/4865]\n",
            " Patch [3161/4865]\n",
            " Patch [3162/4865]\n",
            " Patch [3163/4865]\n",
            " Patch [3164/4865]\n",
            " Patch [3165/4865]\n",
            " Patch [3166/4865]\n",
            " Patch [3167/4865]\n",
            " Patch [3168/4865]\n",
            " Patch [3169/4865]\n",
            " Patch [3170/4865]\n",
            " Patch [3171/4865]\n",
            " Patch [3172/4865]\n",
            " Patch [3173/4865]\n",
            " Patch [3174/4865]\n",
            " Patch [3175/4865]\n",
            " Patch [3176/4865]\n",
            " Patch [3177/4865]\n",
            " Patch [3178/4865]\n",
            " Patch [3179/4865]\n",
            " Patch [3180/4865]\n",
            " Patch [3181/4865]\n",
            " Patch [3182/4865]\n",
            " Patch [3183/4865]\n",
            " Patch [3184/4865]\n",
            " Patch [3185/4865]\n",
            " Patch [3186/4865]\n",
            " Patch [3187/4865]\n",
            " Patch [3188/4865]\n",
            " Patch [3189/4865]\n",
            " Patch [3190/4865]\n",
            " Patch [3191/4865]\n",
            " Patch [3192/4865]\n",
            " Patch [3193/4865]\n",
            " Patch [3194/4865]\n",
            " Patch [3195/4865]\n",
            " Patch [3196/4865]\n",
            " Patch [3197/4865]\n",
            " Patch [3198/4865]\n",
            " Patch [3199/4865]\n",
            " Patch [3200/4865]\n",
            " Patch [3201/4865]\n",
            " Patch [3202/4865]\n",
            " Patch [3203/4865]\n",
            " Patch [3204/4865]\n",
            " Patch [3205/4865]\n",
            " Patch [3206/4865]\n",
            " Patch [3207/4865]\n",
            " Patch [3208/4865]\n",
            " Patch [3209/4865]\n",
            " Patch [3210/4865]\n",
            " Patch [3211/4865]\n",
            " Patch [3212/4865]\n",
            " Patch [3213/4865]\n",
            " Patch [3214/4865]\n",
            " Patch [3215/4865]\n",
            " Patch [3216/4865]\n",
            " Patch [3217/4865]\n",
            " Patch [3218/4865]\n",
            " Patch [3219/4865]\n",
            " Patch [3220/4865]\n",
            " Patch [3221/4865]\n",
            " Patch [3222/4865]\n",
            " Patch [3223/4865]\n",
            " Patch [3224/4865]\n",
            " Patch [3225/4865]\n",
            " Patch [3226/4865]\n",
            " Patch [3227/4865]\n",
            " Patch [3228/4865]\n",
            " Patch [3229/4865]\n",
            " Patch [3230/4865]\n",
            " Patch [3231/4865]\n",
            " Patch [3232/4865]\n",
            " Patch [3233/4865]\n",
            " Patch [3234/4865]\n",
            " Patch [3235/4865]\n",
            " Patch [3236/4865]\n",
            " Patch [3237/4865]\n",
            " Patch [3238/4865]\n",
            " Patch [3239/4865]\n",
            " Patch [3240/4865]\n",
            " Patch [3241/4865]\n",
            " Patch [3242/4865]\n",
            " Patch [3243/4865]\n",
            " Patch [3244/4865]\n",
            " Patch [3245/4865]\n",
            " Patch [3246/4865]\n",
            " Patch [3247/4865]\n",
            " Patch [3248/4865]\n",
            " Patch [3249/4865]\n",
            " Patch [3250/4865]\n",
            " Patch [3251/4865]\n",
            " Patch [3252/4865]\n",
            " Patch [3253/4865]\n",
            " Patch [3254/4865]\n",
            " Patch [3255/4865]\n",
            " Patch [3256/4865]\n",
            " Patch [3257/4865]\n",
            " Patch [3258/4865]\n",
            " Patch [3259/4865]\n",
            " Patch [3260/4865]\n",
            " Patch [3261/4865]\n",
            " Patch [3262/4865]\n",
            " Patch [3263/4865]\n",
            " Patch [3264/4865]\n",
            " Patch [3265/4865]\n",
            " Patch [3266/4865]\n",
            " Patch [3267/4865]\n",
            " Patch [3268/4865]\n",
            " Patch [3269/4865]\n",
            " Patch [3270/4865]\n",
            " Patch [3271/4865]\n",
            " Patch [3272/4865]\n",
            " Patch [3273/4865]\n",
            " Patch [3274/4865]\n",
            " Patch [3275/4865]\n",
            " Patch [3276/4865]\n",
            " Patch [3277/4865]\n",
            " Patch [3278/4865]\n",
            " Patch [3279/4865]\n",
            " Patch [3280/4865]\n",
            " Patch [3281/4865]\n",
            " Patch [3282/4865]\n",
            " Patch [3283/4865]\n",
            " Patch [3284/4865]\n",
            " Patch [3285/4865]\n",
            " Patch [3286/4865]\n",
            " Patch [3287/4865]\n",
            " Patch [3288/4865]\n",
            " Patch [3289/4865]\n",
            " Patch [3290/4865]\n",
            " Patch [3291/4865]\n",
            " Patch [3292/4865]\n",
            " Patch [3293/4865]\n",
            " Patch [3294/4865]\n",
            " Patch [3295/4865]\n",
            " Patch [3296/4865]\n",
            " Patch [3297/4865]\n",
            " Patch [3298/4865]\n",
            " Patch [3299/4865]\n",
            " Patch [3300/4865]\n",
            " Patch [3301/4865]\n",
            " Patch [3302/4865]\n",
            " Patch [3303/4865]\n",
            " Patch [3304/4865]\n",
            " Patch [3305/4865]\n",
            " Patch [3306/4865]\n",
            " Patch [3307/4865]\n",
            " Patch [3308/4865]\n",
            " Patch [3309/4865]\n",
            " Patch [3310/4865]\n",
            " Patch [3311/4865]\n",
            " Patch [3312/4865]\n",
            " Patch [3313/4865]\n",
            " Patch [3314/4865]\n",
            " Patch [3315/4865]\n",
            " Patch [3316/4865]\n",
            " Patch [3317/4865]\n",
            " Patch [3318/4865]\n",
            " Patch [3319/4865]\n",
            " Patch [3320/4865]\n",
            " Patch [3321/4865]\n",
            " Patch [3322/4865]\n",
            " Patch [3323/4865]\n",
            " Patch [3324/4865]\n",
            " Patch [3325/4865]\n",
            " Patch [3326/4865]\n",
            " Patch [3327/4865]\n",
            " Patch [3328/4865]\n",
            " Patch [3329/4865]\n",
            " Patch [3330/4865]\n",
            " Patch [3331/4865]\n",
            " Patch [3332/4865]\n",
            " Patch [3333/4865]\n",
            " Patch [3334/4865]\n",
            " Patch [3335/4865]\n",
            " Patch [3336/4865]\n",
            " Patch [3337/4865]\n",
            " Patch [3338/4865]\n",
            " Patch [3339/4865]\n",
            " Patch [3340/4865]\n",
            " Patch [3341/4865]\n",
            " Patch [3342/4865]\n",
            " Patch [3343/4865]\n",
            " Patch [3344/4865]\n",
            " Patch [3345/4865]\n",
            " Patch [3346/4865]\n",
            " Patch [3347/4865]\n",
            " Patch [3348/4865]\n",
            " Patch [3349/4865]\n",
            " Patch [3350/4865]\n",
            " Patch [3351/4865]\n",
            " Patch [3352/4865]\n",
            " Patch [3353/4865]\n",
            " Patch [3354/4865]\n",
            " Patch [3355/4865]\n",
            " Patch [3356/4865]\n",
            " Patch [3357/4865]\n",
            " Patch [3358/4865]\n",
            " Patch [3359/4865]\n",
            " Patch [3360/4865]\n",
            " Patch [3361/4865]\n",
            " Patch [3362/4865]\n",
            " Patch [3363/4865]\n",
            " Patch [3364/4865]\n",
            " Patch [3365/4865]\n",
            " Patch [3366/4865]\n",
            " Patch [3367/4865]\n",
            " Patch [3368/4865]\n",
            " Patch [3369/4865]\n",
            " Patch [3370/4865]\n",
            " Patch [3371/4865]\n",
            " Patch [3372/4865]\n",
            " Patch [3373/4865]\n",
            " Patch [3374/4865]\n",
            " Patch [3375/4865]\n",
            " Patch [3376/4865]\n",
            " Patch [3377/4865]\n",
            " Patch [3378/4865]\n",
            " Patch [3379/4865]\n",
            " Patch [3380/4865]\n",
            " Patch [3381/4865]\n",
            " Patch [3382/4865]\n",
            " Patch [3383/4865]\n",
            " Patch [3384/4865]\n",
            " Patch [3385/4865]\n",
            " Patch [3386/4865]\n",
            " Patch [3387/4865]\n",
            " Patch [3388/4865]\n",
            " Patch [3389/4865]\n",
            " Patch [3390/4865]\n",
            " Patch [3391/4865]\n",
            " Patch [3392/4865]\n",
            " Patch [3393/4865]\n",
            " Patch [3394/4865]\n",
            " Patch [3395/4865]\n",
            " Patch [3396/4865]\n",
            " Patch [3397/4865]\n",
            " Patch [3398/4865]\n",
            " Patch [3399/4865]\n",
            " Patch [3400/4865]\n",
            " Patch [3401/4865]\n",
            " Patch [3402/4865]\n",
            " Patch [3403/4865]\n",
            " Patch [3404/4865]\n",
            " Patch [3405/4865]\n",
            " Patch [3406/4865]\n",
            " Patch [3407/4865]\n",
            " Patch [3408/4865]\n",
            " Patch [3409/4865]\n",
            " Patch [3410/4865]\n",
            " Patch [3411/4865]\n",
            " Patch [3412/4865]\n",
            " Patch [3413/4865]\n",
            " Patch [3414/4865]\n",
            " Patch [3415/4865]\n",
            " Patch [3416/4865]\n",
            " Patch [3417/4865]\n",
            " Patch [3418/4865]\n",
            " Patch [3419/4865]\n",
            " Patch [3420/4865]\n",
            " Patch [3421/4865]\n",
            " Patch [3422/4865]\n",
            " Patch [3423/4865]\n",
            " Patch [3424/4865]\n",
            " Patch [3425/4865]\n",
            " Patch [3426/4865]\n",
            " Patch [3427/4865]\n",
            " Patch [3428/4865]\n",
            " Patch [3429/4865]\n",
            " Patch [3430/4865]\n",
            " Patch [3431/4865]\n",
            " Patch [3432/4865]\n",
            " Patch [3433/4865]\n",
            " Patch [3434/4865]\n",
            " Patch [3435/4865]\n",
            " Patch [3436/4865]\n",
            " Patch [3437/4865]\n",
            " Patch [3438/4865]\n",
            " Patch [3439/4865]\n",
            " Patch [3440/4865]\n",
            " Patch [3441/4865]\n",
            " Patch [3442/4865]\n",
            " Patch [3443/4865]\n",
            " Patch [3444/4865]\n",
            " Patch [3445/4865]\n",
            " Patch [3446/4865]\n",
            " Patch [3447/4865]\n",
            " Patch [3448/4865]\n",
            " Patch [3449/4865]\n",
            " Patch [3450/4865]\n",
            " Patch [3451/4865]\n",
            " Patch [3452/4865]\n",
            " Patch [3453/4865]\n",
            " Patch [3454/4865]\n",
            " Patch [3455/4865]\n",
            " Patch [3456/4865]\n",
            " Patch [3457/4865]\n",
            " Patch [3458/4865]\n",
            " Patch [3459/4865]\n",
            " Patch [3460/4865]\n",
            " Patch [3461/4865]\n",
            " Patch [3462/4865]\n",
            " Patch [3463/4865]\n",
            " Patch [3464/4865]\n",
            " Patch [3465/4865]\n",
            " Patch [3466/4865]\n",
            " Patch [3467/4865]\n",
            " Patch [3468/4865]\n",
            " Patch [3469/4865]\n",
            " Patch [3470/4865]\n",
            " Patch [3471/4865]\n",
            " Patch [3472/4865]\n",
            " Patch [3473/4865]\n",
            " Patch [3474/4865]\n",
            " Patch [3475/4865]\n",
            " Patch [3476/4865]\n",
            " Patch [3477/4865]\n",
            " Patch [3478/4865]\n",
            " Patch [3479/4865]\n",
            " Patch [3480/4865]\n",
            " Patch [3481/4865]\n",
            " Patch [3482/4865]\n",
            " Patch [3483/4865]\n",
            " Patch [3484/4865]\n",
            " Patch [3485/4865]\n",
            " Patch [3486/4865]\n",
            " Patch [3487/4865]\n",
            " Patch [3488/4865]\n",
            " Patch [3489/4865]\n",
            " Patch [3490/4865]\n",
            " Patch [3491/4865]\n",
            " Patch [3492/4865]\n",
            " Patch [3493/4865]\n",
            " Patch [3494/4865]\n",
            " Patch [3495/4865]\n",
            " Patch [3496/4865]\n",
            " Patch [3497/4865]\n",
            " Patch [3498/4865]\n",
            " Patch [3499/4865]\n",
            " Patch [3500/4865]\n",
            " Patch [3501/4865]\n",
            " Patch [3502/4865]\n",
            " Patch [3503/4865]\n",
            " Patch [3504/4865]\n",
            " Patch [3505/4865]\n",
            " Patch [3506/4865]\n",
            " Patch [3507/4865]\n",
            " Patch [3508/4865]\n",
            " Patch [3509/4865]\n",
            " Patch [3510/4865]\n",
            " Patch [3511/4865]\n",
            " Patch [3512/4865]\n",
            " Patch [3513/4865]\n",
            " Patch [3514/4865]\n",
            " Patch [3515/4865]\n",
            " Patch [3516/4865]\n",
            " Patch [3517/4865]\n",
            " Patch [3518/4865]\n",
            " Patch [3519/4865]\n",
            " Patch [3520/4865]\n",
            " Patch [3521/4865]\n",
            " Patch [3522/4865]\n",
            " Patch [3523/4865]\n",
            " Patch [3524/4865]\n",
            " Patch [3525/4865]\n",
            " Patch [3526/4865]\n",
            " Patch [3527/4865]\n",
            " Patch [3528/4865]\n",
            " Patch [3529/4865]\n",
            " Patch [3530/4865]\n",
            " Patch [3531/4865]\n",
            " Patch [3532/4865]\n",
            " Patch [3533/4865]\n",
            " Patch [3534/4865]\n",
            " Patch [3535/4865]\n",
            " Patch [3536/4865]\n",
            " Patch [3537/4865]\n",
            " Patch [3538/4865]\n",
            " Patch [3539/4865]\n",
            " Patch [3540/4865]\n",
            " Patch [3541/4865]\n",
            " Patch [3542/4865]\n",
            " Patch [3543/4865]\n",
            " Patch [3544/4865]\n",
            " Patch [3545/4865]\n",
            " Patch [3546/4865]\n",
            " Patch [3547/4865]\n",
            " Patch [3548/4865]\n",
            " Patch [3549/4865]\n",
            " Patch [3550/4865]\n",
            " Patch [3551/4865]\n",
            " Patch [3552/4865]\n",
            " Patch [3553/4865]\n",
            " Patch [3554/4865]\n",
            " Patch [3555/4865]\n",
            " Patch [3556/4865]\n",
            " Patch [3557/4865]\n",
            " Patch [3558/4865]\n",
            " Patch [3559/4865]\n",
            " Patch [3560/4865]\n",
            " Patch [3561/4865]\n",
            " Patch [3562/4865]\n",
            " Patch [3563/4865]\n",
            " Patch [3564/4865]\n",
            " Patch [3565/4865]\n",
            " Patch [3566/4865]\n",
            " Patch [3567/4865]\n",
            " Patch [3568/4865]\n",
            " Patch [3569/4865]\n",
            " Patch [3570/4865]\n",
            " Patch [3571/4865]\n",
            " Patch [3572/4865]\n",
            " Patch [3573/4865]\n",
            " Patch [3574/4865]\n",
            " Patch [3575/4865]\n",
            " Patch [3576/4865]\n",
            " Patch [3577/4865]\n",
            " Patch [3578/4865]\n",
            " Patch [3579/4865]\n",
            " Patch [3580/4865]\n",
            " Patch [3581/4865]\n",
            " Patch [3582/4865]\n",
            " Patch [3583/4865]\n",
            " Patch [3584/4865]\n",
            " Patch [3585/4865]\n",
            " Patch [3586/4865]\n",
            " Patch [3587/4865]\n",
            " Patch [3588/4865]\n",
            " Patch [3589/4865]\n",
            " Patch [3590/4865]\n",
            " Patch [3591/4865]\n",
            " Patch [3592/4865]\n",
            " Patch [3593/4865]\n",
            " Patch [3594/4865]\n",
            " Patch [3595/4865]\n",
            " Patch [3596/4865]\n",
            " Patch [3597/4865]\n",
            " Patch [3598/4865]\n",
            " Patch [3599/4865]\n",
            " Patch [3600/4865]\n",
            " Patch [3601/4865]\n",
            " Patch [3602/4865]\n",
            " Patch [3603/4865]\n",
            " Patch [3604/4865]\n",
            " Patch [3605/4865]\n",
            " Patch [3606/4865]\n",
            " Patch [3607/4865]\n",
            " Patch [3608/4865]\n",
            " Patch [3609/4865]\n",
            " Patch [3610/4865]\n",
            " Patch [3611/4865]\n",
            " Patch [3612/4865]\n",
            " Patch [3613/4865]\n",
            " Patch [3614/4865]\n",
            " Patch [3615/4865]\n",
            " Patch [3616/4865]\n",
            " Patch [3617/4865]\n",
            " Patch [3618/4865]\n",
            " Patch [3619/4865]\n",
            " Patch [3620/4865]\n",
            " Patch [3621/4865]\n",
            " Patch [3622/4865]\n",
            " Patch [3623/4865]\n",
            " Patch [3624/4865]\n",
            " Patch [3625/4865]\n",
            " Patch [3626/4865]\n",
            " Patch [3627/4865]\n",
            " Patch [3628/4865]\n",
            " Patch [3629/4865]\n",
            " Patch [3630/4865]\n",
            " Patch [3631/4865]\n",
            " Patch [3632/4865]\n",
            " Patch [3633/4865]\n",
            " Patch [3634/4865]\n",
            " Patch [3635/4865]\n",
            " Patch [3636/4865]\n",
            " Patch [3637/4865]\n",
            " Patch [3638/4865]\n",
            " Patch [3639/4865]\n",
            " Patch [3640/4865]\n",
            " Patch [3641/4865]\n",
            " Patch [3642/4865]\n",
            " Patch [3643/4865]\n",
            " Patch [3644/4865]\n",
            " Patch [3645/4865]\n",
            " Patch [3646/4865]\n",
            " Patch [3647/4865]\n",
            " Patch [3648/4865]\n",
            " Patch [3649/4865]\n",
            " Patch [3650/4865]\n",
            " Patch [3651/4865]\n",
            " Patch [3652/4865]\n",
            " Patch [3653/4865]\n",
            " Patch [3654/4865]\n",
            " Patch [3655/4865]\n",
            " Patch [3656/4865]\n",
            " Patch [3657/4865]\n",
            " Patch [3658/4865]\n",
            " Patch [3659/4865]\n",
            " Patch [3660/4865]\n",
            " Patch [3661/4865]\n",
            " Patch [3662/4865]\n",
            " Patch [3663/4865]\n",
            " Patch [3664/4865]\n",
            " Patch [3665/4865]\n",
            " Patch [3666/4865]\n",
            " Patch [3667/4865]\n",
            " Patch [3668/4865]\n",
            " Patch [3669/4865]\n",
            " Patch [3670/4865]\n",
            " Patch [3671/4865]\n",
            " Patch [3672/4865]\n",
            " Patch [3673/4865]\n",
            " Patch [3674/4865]\n",
            " Patch [3675/4865]\n",
            " Patch [3676/4865]\n",
            " Patch [3677/4865]\n",
            " Patch [3678/4865]\n",
            " Patch [3679/4865]\n",
            " Patch [3680/4865]\n",
            " Patch [3681/4865]\n",
            " Patch [3682/4865]\n",
            " Patch [3683/4865]\n",
            " Patch [3684/4865]\n",
            " Patch [3685/4865]\n",
            " Patch [3686/4865]\n",
            " Patch [3687/4865]\n",
            " Patch [3688/4865]\n",
            " Patch [3689/4865]\n",
            " Patch [3690/4865]\n",
            " Patch [3691/4865]\n",
            " Patch [3692/4865]\n",
            " Patch [3693/4865]\n",
            " Patch [3694/4865]\n",
            " Patch [3695/4865]\n",
            " Patch [3696/4865]\n",
            " Patch [3697/4865]\n",
            " Patch [3698/4865]\n",
            " Patch [3699/4865]\n",
            " Patch [3700/4865]\n",
            " Patch [3701/4865]\n",
            " Patch [3702/4865]\n",
            " Patch [3703/4865]\n",
            " Patch [3704/4865]\n",
            " Patch [3705/4865]\n",
            " Patch [3706/4865]\n",
            " Patch [3707/4865]\n",
            " Patch [3708/4865]\n",
            " Patch [3709/4865]\n",
            " Patch [3710/4865]\n",
            " Patch [3711/4865]\n",
            " Patch [3712/4865]\n",
            " Patch [3713/4865]\n",
            " Patch [3714/4865]\n",
            " Patch [3715/4865]\n",
            " Patch [3716/4865]\n",
            " Patch [3717/4865]\n",
            " Patch [3718/4865]\n",
            " Patch [3719/4865]\n",
            " Patch [3720/4865]\n",
            " Patch [3721/4865]\n",
            " Patch [3722/4865]\n",
            " Patch [3723/4865]\n",
            " Patch [3724/4865]\n",
            " Patch [3725/4865]\n",
            " Patch [3726/4865]\n",
            " Patch [3727/4865]\n",
            " Patch [3728/4865]\n",
            " Patch [3729/4865]\n",
            " Patch [3730/4865]\n",
            " Patch [3731/4865]\n",
            " Patch [3732/4865]\n",
            " Patch [3733/4865]\n",
            " Patch [3734/4865]\n",
            " Patch [3735/4865]\n",
            " Patch [3736/4865]\n",
            " Patch [3737/4865]\n",
            " Patch [3738/4865]\n",
            " Patch [3739/4865]\n",
            " Patch [3740/4865]\n",
            " Patch [3741/4865]\n",
            " Patch [3742/4865]\n",
            " Patch [3743/4865]\n",
            " Patch [3744/4865]\n",
            " Patch [3745/4865]\n",
            " Patch [3746/4865]\n",
            " Patch [3747/4865]\n",
            " Patch [3748/4865]\n",
            " Patch [3749/4865]\n",
            " Patch [3750/4865]\n",
            " Patch [3751/4865]\n",
            " Patch [3752/4865]\n",
            " Patch [3753/4865]\n",
            " Patch [3754/4865]\n",
            " Patch [3755/4865]\n",
            " Patch [3756/4865]\n",
            " Patch [3757/4865]\n",
            " Patch [3758/4865]\n",
            " Patch [3759/4865]\n",
            " Patch [3760/4865]\n",
            " Patch [3761/4865]\n",
            " Patch [3762/4865]\n",
            " Patch [3763/4865]\n",
            " Patch [3764/4865]\n",
            " Patch [3765/4865]\n",
            " Patch [3766/4865]\n",
            " Patch [3767/4865]\n",
            " Patch [3768/4865]\n",
            " Patch [3769/4865]\n",
            " Patch [3770/4865]\n",
            " Patch [3771/4865]\n",
            " Patch [3772/4865]\n",
            " Patch [3773/4865]\n",
            " Patch [3774/4865]\n",
            " Patch [3775/4865]\n",
            " Patch [3776/4865]\n",
            " Patch [3777/4865]\n",
            " Patch [3778/4865]\n",
            " Patch [3779/4865]\n",
            " Patch [3780/4865]\n",
            " Patch [3781/4865]\n",
            " Patch [3782/4865]\n",
            " Patch [3783/4865]\n",
            " Patch [3784/4865]\n",
            " Patch [3785/4865]\n",
            " Patch [3786/4865]\n",
            " Patch [3787/4865]\n",
            " Patch [3788/4865]\n",
            " Patch [3789/4865]\n",
            " Patch [3790/4865]\n",
            " Patch [3791/4865]\n",
            " Patch [3792/4865]\n",
            " Patch [3793/4865]\n",
            " Patch [3794/4865]\n",
            " Patch [3795/4865]\n",
            " Patch [3796/4865]\n",
            " Patch [3797/4865]\n",
            " Patch [3798/4865]\n",
            " Patch [3799/4865]\n",
            " Patch [3800/4865]\n",
            " Patch [3801/4865]\n",
            " Patch [3802/4865]\n",
            " Patch [3803/4865]\n",
            " Patch [3804/4865]\n",
            " Patch [3805/4865]\n",
            " Patch [3806/4865]\n",
            " Patch [3807/4865]\n",
            " Patch [3808/4865]\n",
            " Patch [3809/4865]\n",
            " Patch [3810/4865]\n",
            " Patch [3811/4865]\n",
            " Patch [3812/4865]\n",
            " Patch [3813/4865]\n",
            " Patch [3814/4865]\n",
            " Patch [3815/4865]\n",
            " Patch [3816/4865]\n",
            " Patch [3817/4865]\n",
            " Patch [3818/4865]\n",
            " Patch [3819/4865]\n",
            " Patch [3820/4865]\n",
            " Patch [3821/4865]\n",
            " Patch [3822/4865]\n",
            " Patch [3823/4865]\n",
            " Patch [3824/4865]\n",
            " Patch [3825/4865]\n",
            " Patch [3826/4865]\n",
            " Patch [3827/4865]\n",
            " Patch [3828/4865]\n",
            " Patch [3829/4865]\n",
            " Patch [3830/4865]\n",
            " Patch [3831/4865]\n",
            " Patch [3832/4865]\n",
            " Patch [3833/4865]\n",
            " Patch [3834/4865]\n",
            " Patch [3835/4865]\n",
            " Patch [3836/4865]\n",
            " Patch [3837/4865]\n",
            " Patch [3838/4865]\n",
            " Patch [3839/4865]\n",
            " Patch [3840/4865]\n",
            " Patch [3841/4865]\n",
            " Patch [3842/4865]\n",
            " Patch [3843/4865]\n",
            " Patch [3844/4865]\n",
            " Patch [3845/4865]\n",
            " Patch [3846/4865]\n",
            " Patch [3847/4865]\n",
            " Patch [3848/4865]\n",
            " Patch [3849/4865]\n",
            " Patch [3850/4865]\n",
            " Patch [3851/4865]\n",
            " Patch [3852/4865]\n",
            " Patch [3853/4865]\n",
            " Patch [3854/4865]\n",
            " Patch [3855/4865]\n",
            " Patch [3856/4865]\n",
            " Patch [3857/4865]\n",
            " Patch [3858/4865]\n",
            " Patch [3859/4865]\n",
            " Patch [3860/4865]\n",
            " Patch [3861/4865]\n",
            " Patch [3862/4865]\n",
            " Patch [3863/4865]\n",
            " Patch [3864/4865]\n",
            " Patch [3865/4865]\n",
            " Patch [3866/4865]\n",
            " Patch [3867/4865]\n",
            " Patch [3868/4865]\n",
            " Patch [3869/4865]\n",
            " Patch [3870/4865]\n",
            " Patch [3871/4865]\n",
            " Patch [3872/4865]\n",
            " Patch [3873/4865]\n",
            " Patch [3874/4865]\n",
            " Patch [3875/4865]\n",
            " Patch [3876/4865]\n",
            " Patch [3877/4865]\n",
            " Patch [3878/4865]\n",
            " Patch [3879/4865]\n",
            " Patch [3880/4865]\n",
            " Patch [3881/4865]\n",
            " Patch [3882/4865]\n",
            " Patch [3883/4865]\n",
            " Patch [3884/4865]\n",
            " Patch [3885/4865]\n",
            " Patch [3886/4865]\n",
            " Patch [3887/4865]\n",
            " Patch [3888/4865]\n",
            " Patch [3889/4865]\n",
            " Patch [3890/4865]\n",
            " Patch [3891/4865]\n",
            " Patch [3892/4865]\n",
            " Patch [3893/4865]\n",
            " Patch [3894/4865]\n",
            " Patch [3895/4865]\n",
            " Patch [3896/4865]\n",
            " Patch [3897/4865]\n",
            " Patch [3898/4865]\n",
            " Patch [3899/4865]\n",
            " Patch [3900/4865]\n",
            " Patch [3901/4865]\n",
            " Patch [3902/4865]\n",
            " Patch [3903/4865]\n",
            " Patch [3904/4865]\n",
            " Patch [3905/4865]\n",
            " Patch [3906/4865]\n",
            " Patch [3907/4865]\n",
            " Patch [3908/4865]\n",
            " Patch [3909/4865]\n",
            " Patch [3910/4865]\n",
            " Patch [3911/4865]\n",
            " Patch [3912/4865]\n",
            " Patch [3913/4865]\n",
            " Patch [3914/4865]\n",
            " Patch [3915/4865]\n",
            " Patch [3916/4865]\n",
            " Patch [3917/4865]\n",
            " Patch [3918/4865]\n",
            " Patch [3919/4865]\n",
            " Patch [3920/4865]\n",
            " Patch [3921/4865]\n",
            " Patch [3922/4865]\n",
            " Patch [3923/4865]\n",
            " Patch [3924/4865]\n",
            " Patch [3925/4865]\n",
            " Patch [3926/4865]\n",
            " Patch [3927/4865]\n",
            " Patch [3928/4865]\n",
            " Patch [3929/4865]\n",
            " Patch [3930/4865]\n",
            " Patch [3931/4865]\n",
            " Patch [3932/4865]\n",
            " Patch [3933/4865]\n",
            " Patch [3934/4865]\n",
            " Patch [3935/4865]\n",
            " Patch [3936/4865]\n",
            " Patch [3937/4865]\n",
            " Patch [3938/4865]\n",
            " Patch [3939/4865]\n",
            " Patch [3940/4865]\n",
            " Patch [3941/4865]\n",
            " Patch [3942/4865]\n",
            " Patch [3943/4865]\n",
            " Patch [3944/4865]\n",
            " Patch [3945/4865]\n",
            " Patch [3946/4865]\n",
            " Patch [3947/4865]\n",
            " Patch [3948/4865]\n",
            " Patch [3949/4865]\n",
            " Patch [3950/4865]\n",
            " Patch [3951/4865]\n",
            " Patch [3952/4865]\n",
            " Patch [3953/4865]\n",
            " Patch [3954/4865]\n",
            " Patch [3955/4865]\n",
            " Patch [3956/4865]\n",
            " Patch [3957/4865]\n",
            " Patch [3958/4865]\n",
            " Patch [3959/4865]\n",
            " Patch [3960/4865]\n",
            " Patch [3961/4865]\n",
            " Patch [3962/4865]\n",
            " Patch [3963/4865]\n",
            " Patch [3964/4865]\n",
            " Patch [3965/4865]\n",
            " Patch [3966/4865]\n",
            " Patch [3967/4865]\n",
            " Patch [3968/4865]\n",
            " Patch [3969/4865]\n",
            " Patch [3970/4865]\n",
            " Patch [3971/4865]\n",
            " Patch [3972/4865]\n",
            " Patch [3973/4865]\n",
            " Patch [3974/4865]\n",
            " Patch [3975/4865]\n",
            " Patch [3976/4865]\n",
            " Patch [3977/4865]\n",
            " Patch [3978/4865]\n",
            " Patch [3979/4865]\n",
            " Patch [3980/4865]\n",
            " Patch [3981/4865]\n",
            " Patch [3982/4865]\n",
            " Patch [3983/4865]\n",
            " Patch [3984/4865]\n",
            " Patch [3985/4865]\n",
            " Patch [3986/4865]\n",
            " Patch [3987/4865]\n",
            " Patch [3988/4865]\n",
            " Patch [3989/4865]\n",
            " Patch [3990/4865]\n",
            " Patch [3991/4865]\n",
            " Patch [3992/4865]\n",
            " Patch [3993/4865]\n",
            " Patch [3994/4865]\n",
            " Patch [3995/4865]\n",
            " Patch [3996/4865]\n",
            " Patch [3997/4865]\n",
            " Patch [3998/4865]\n",
            " Patch [3999/4865]\n",
            " Patch [4000/4865]\n",
            " Patch [4001/4865]\n",
            " Patch [4002/4865]\n",
            " Patch [4003/4865]\n",
            " Patch [4004/4865]\n",
            " Patch [4005/4865]\n",
            " Patch [4006/4865]\n",
            " Patch [4007/4865]\n",
            " Patch [4008/4865]\n",
            " Patch [4009/4865]\n",
            " Patch [4010/4865]\n",
            " Patch [4011/4865]\n",
            " Patch [4012/4865]\n",
            " Patch [4013/4865]\n",
            " Patch [4014/4865]\n",
            " Patch [4015/4865]\n",
            " Patch [4016/4865]\n",
            " Patch [4017/4865]\n",
            " Patch [4018/4865]\n",
            " Patch [4019/4865]\n",
            " Patch [4020/4865]\n",
            " Patch [4021/4865]\n",
            " Patch [4022/4865]\n",
            " Patch [4023/4865]\n",
            " Patch [4024/4865]\n",
            " Patch [4025/4865]\n",
            " Patch [4026/4865]\n",
            " Patch [4027/4865]\n",
            " Patch [4028/4865]\n",
            " Patch [4029/4865]\n",
            " Patch [4030/4865]\n",
            " Patch [4031/4865]\n",
            " Patch [4032/4865]\n",
            " Patch [4033/4865]\n",
            " Patch [4034/4865]\n",
            " Patch [4035/4865]\n",
            " Patch [4036/4865]\n",
            " Patch [4037/4865]\n",
            " Patch [4038/4865]\n",
            " Patch [4039/4865]\n",
            " Patch [4040/4865]\n",
            " Patch [4041/4865]\n",
            " Patch [4042/4865]\n",
            " Patch [4043/4865]\n",
            " Patch [4044/4865]\n",
            " Patch [4045/4865]\n",
            " Patch [4046/4865]\n",
            " Patch [4047/4865]\n",
            " Patch [4048/4865]\n",
            " Patch [4049/4865]\n",
            " Patch [4050/4865]\n",
            " Patch [4051/4865]\n",
            " Patch [4052/4865]\n",
            " Patch [4053/4865]\n",
            " Patch [4054/4865]\n",
            " Patch [4055/4865]\n",
            " Patch [4056/4865]\n",
            " Patch [4057/4865]\n",
            " Patch [4058/4865]\n",
            " Patch [4059/4865]\n",
            " Patch [4060/4865]\n",
            " Patch [4061/4865]\n",
            " Patch [4062/4865]\n",
            " Patch [4063/4865]\n",
            " Patch [4064/4865]\n",
            " Patch [4065/4865]\n",
            " Patch [4066/4865]\n",
            " Patch [4067/4865]\n",
            " Patch [4068/4865]\n",
            " Patch [4069/4865]\n",
            " Patch [4070/4865]\n",
            " Patch [4071/4865]\n",
            " Patch [4072/4865]\n",
            " Patch [4073/4865]\n",
            " Patch [4074/4865]\n",
            " Patch [4075/4865]\n",
            " Patch [4076/4865]\n",
            " Patch [4077/4865]\n",
            " Patch [4078/4865]\n",
            " Patch [4079/4865]\n",
            " Patch [4080/4865]\n",
            " Patch [4081/4865]\n",
            " Patch [4082/4865]\n",
            " Patch [4083/4865]\n",
            " Patch [4084/4865]\n",
            " Patch [4085/4865]\n",
            " Patch [4086/4865]\n",
            " Patch [4087/4865]\n",
            " Patch [4088/4865]\n",
            " Patch [4089/4865]\n",
            " Patch [4090/4865]\n",
            " Patch [4091/4865]\n",
            " Patch [4092/4865]\n",
            " Patch [4093/4865]\n",
            " Patch [4094/4865]\n",
            " Patch [4095/4865]\n",
            " Patch [4096/4865]\n",
            " Patch [4097/4865]\n",
            " Patch [4098/4865]\n",
            " Patch [4099/4865]\n",
            " Patch [4100/4865]\n",
            " Patch [4101/4865]\n",
            " Patch [4102/4865]\n",
            " Patch [4103/4865]\n",
            " Patch [4104/4865]\n",
            " Patch [4105/4865]\n",
            " Patch [4106/4865]\n",
            " Patch [4107/4865]\n",
            " Patch [4108/4865]\n",
            " Patch [4109/4865]\n",
            " Patch [4110/4865]\n",
            " Patch [4111/4865]\n",
            " Patch [4112/4865]\n",
            " Patch [4113/4865]\n",
            " Patch [4114/4865]\n",
            " Patch [4115/4865]\n",
            " Patch [4116/4865]\n",
            " Patch [4117/4865]\n",
            " Patch [4118/4865]\n",
            " Patch [4119/4865]\n",
            " Patch [4120/4865]\n",
            " Patch [4121/4865]\n",
            " Patch [4122/4865]\n",
            " Patch [4123/4865]\n",
            " Patch [4124/4865]\n",
            " Patch [4125/4865]\n",
            " Patch [4126/4865]\n",
            " Patch [4127/4865]\n",
            " Patch [4128/4865]\n",
            " Patch [4129/4865]\n",
            " Patch [4130/4865]\n",
            " Patch [4131/4865]\n",
            " Patch [4132/4865]\n",
            " Patch [4133/4865]\n",
            " Patch [4134/4865]\n",
            " Patch [4135/4865]\n",
            " Patch [4136/4865]\n",
            " Patch [4137/4865]\n",
            " Patch [4138/4865]\n",
            " Patch [4139/4865]\n",
            " Patch [4140/4865]\n",
            " Patch [4141/4865]\n",
            " Patch [4142/4865]\n",
            " Patch [4143/4865]\n",
            " Patch [4144/4865]\n",
            " Patch [4145/4865]\n",
            " Patch [4146/4865]\n",
            " Patch [4147/4865]\n",
            " Patch [4148/4865]\n",
            " Patch [4149/4865]\n",
            " Patch [4150/4865]\n",
            " Patch [4151/4865]\n",
            " Patch [4152/4865]\n",
            " Patch [4153/4865]\n",
            " Patch [4154/4865]\n",
            " Patch [4155/4865]\n",
            " Patch [4156/4865]\n",
            " Patch [4157/4865]\n",
            " Patch [4158/4865]\n",
            " Patch [4159/4865]\n",
            " Patch [4160/4865]\n",
            " Patch [4161/4865]\n",
            " Patch [4162/4865]\n",
            " Patch [4163/4865]\n",
            " Patch [4164/4865]\n",
            " Patch [4165/4865]\n",
            " Patch [4166/4865]\n",
            " Patch [4167/4865]\n",
            " Patch [4168/4865]\n",
            " Patch [4169/4865]\n",
            " Patch [4170/4865]\n",
            " Patch [4171/4865]\n",
            " Patch [4172/4865]\n",
            " Patch [4173/4865]\n",
            " Patch [4174/4865]\n",
            " Patch [4175/4865]\n",
            " Patch [4176/4865]\n",
            " Patch [4177/4865]\n",
            " Patch [4178/4865]\n",
            " Patch [4179/4865]\n",
            " Patch [4180/4865]\n",
            " Patch [4181/4865]\n",
            " Patch [4182/4865]\n",
            " Patch [4183/4865]\n",
            " Patch [4184/4865]\n",
            " Patch [4185/4865]\n",
            " Patch [4186/4865]\n",
            " Patch [4187/4865]\n",
            " Patch [4188/4865]\n",
            " Patch [4189/4865]\n",
            " Patch [4190/4865]\n",
            " Patch [4191/4865]\n",
            " Patch [4192/4865]\n",
            " Patch [4193/4865]\n",
            " Patch [4194/4865]\n",
            " Patch [4195/4865]\n",
            " Patch [4196/4865]\n",
            " Patch [4197/4865]\n",
            " Patch [4198/4865]\n",
            " Patch [4199/4865]\n",
            " Patch [4200/4865]\n",
            " Patch [4201/4865]\n",
            " Patch [4202/4865]\n",
            " Patch [4203/4865]\n",
            " Patch [4204/4865]\n",
            " Patch [4205/4865]\n",
            " Patch [4206/4865]\n",
            " Patch [4207/4865]\n",
            " Patch [4208/4865]\n",
            " Patch [4209/4865]\n",
            " Patch [4210/4865]\n",
            " Patch [4211/4865]\n",
            " Patch [4212/4865]\n",
            " Patch [4213/4865]\n",
            " Patch [4214/4865]\n",
            " Patch [4215/4865]\n",
            " Patch [4216/4865]\n",
            " Patch [4217/4865]\n",
            " Patch [4218/4865]\n",
            " Patch [4219/4865]\n",
            " Patch [4220/4865]\n",
            " Patch [4221/4865]\n",
            " Patch [4222/4865]\n",
            " Patch [4223/4865]\n",
            " Patch [4224/4865]\n",
            " Patch [4225/4865]\n",
            " Patch [4226/4865]\n",
            " Patch [4227/4865]\n",
            " Patch [4228/4865]\n",
            " Patch [4229/4865]\n",
            " Patch [4230/4865]\n",
            " Patch [4231/4865]\n",
            " Patch [4232/4865]\n",
            " Patch [4233/4865]\n",
            " Patch [4234/4865]\n",
            " Patch [4235/4865]\n",
            " Patch [4236/4865]\n",
            " Patch [4237/4865]\n",
            " Patch [4238/4865]\n",
            " Patch [4239/4865]\n",
            " Patch [4240/4865]\n",
            " Patch [4241/4865]\n",
            " Patch [4242/4865]\n",
            " Patch [4243/4865]\n",
            " Patch [4244/4865]\n",
            " Patch [4245/4865]\n",
            " Patch [4246/4865]\n",
            " Patch [4247/4865]\n",
            " Patch [4248/4865]\n",
            " Patch [4249/4865]\n",
            " Patch [4250/4865]\n",
            " Patch [4251/4865]\n",
            " Patch [4252/4865]\n",
            " Patch [4253/4865]\n",
            " Patch [4254/4865]\n",
            " Patch [4255/4865]\n",
            " Patch [4256/4865]\n",
            " Patch [4257/4865]\n",
            " Patch [4258/4865]\n",
            " Patch [4259/4865]\n",
            " Patch [4260/4865]\n",
            " Patch [4261/4865]\n",
            " Patch [4262/4865]\n",
            " Patch [4263/4865]\n",
            " Patch [4264/4865]\n",
            " Patch [4265/4865]\n",
            " Patch [4266/4865]\n",
            " Patch [4267/4865]\n",
            " Patch [4268/4865]\n",
            " Patch [4269/4865]\n",
            " Patch [4270/4865]\n",
            " Patch [4271/4865]\n",
            " Patch [4272/4865]\n",
            " Patch [4273/4865]\n",
            " Patch [4274/4865]\n",
            " Patch [4275/4865]\n",
            " Patch [4276/4865]\n",
            " Patch [4277/4865]\n",
            " Patch [4278/4865]\n",
            " Patch [4279/4865]\n",
            " Patch [4280/4865]\n",
            " Patch [4281/4865]\n",
            " Patch [4282/4865]\n",
            " Patch [4283/4865]\n",
            " Patch [4284/4865]\n",
            " Patch [4285/4865]\n",
            " Patch [4286/4865]\n",
            " Patch [4287/4865]\n",
            " Patch [4288/4865]\n",
            " Patch [4289/4865]\n",
            " Patch [4290/4865]\n",
            " Patch [4291/4865]\n",
            " Patch [4292/4865]\n",
            " Patch [4293/4865]\n",
            " Patch [4294/4865]\n",
            " Patch [4295/4865]\n",
            " Patch [4296/4865]\n",
            " Patch [4297/4865]\n",
            " Patch [4298/4865]\n",
            " Patch [4299/4865]\n",
            " Patch [4300/4865]\n",
            " Patch [4301/4865]\n",
            " Patch [4302/4865]\n",
            " Patch [4303/4865]\n",
            " Patch [4304/4865]\n",
            " Patch [4305/4865]\n",
            " Patch [4306/4865]\n",
            " Patch [4307/4865]\n",
            " Patch [4308/4865]\n",
            " Patch [4309/4865]\n",
            " Patch [4310/4865]\n",
            " Patch [4311/4865]\n",
            " Patch [4312/4865]\n",
            " Patch [4313/4865]\n",
            " Patch [4314/4865]\n",
            " Patch [4315/4865]\n",
            " Patch [4316/4865]\n",
            " Patch [4317/4865]\n",
            " Patch [4318/4865]\n",
            " Patch [4319/4865]\n",
            " Patch [4320/4865]\n",
            " Patch [4321/4865]\n",
            " Patch [4322/4865]\n",
            " Patch [4323/4865]\n",
            " Patch [4324/4865]\n",
            " Patch [4325/4865]\n",
            " Patch [4326/4865]\n",
            " Patch [4327/4865]\n",
            " Patch [4328/4865]\n",
            " Patch [4329/4865]\n",
            " Patch [4330/4865]\n",
            " Patch [4331/4865]\n",
            " Patch [4332/4865]\n",
            " Patch [4333/4865]\n",
            " Patch [4334/4865]\n",
            " Patch [4335/4865]\n",
            " Patch [4336/4865]\n",
            " Patch [4337/4865]\n",
            " Patch [4338/4865]\n",
            " Patch [4339/4865]\n",
            " Patch [4340/4865]\n",
            " Patch [4341/4865]\n",
            " Patch [4342/4865]\n",
            " Patch [4343/4865]\n",
            " Patch [4344/4865]\n",
            " Patch [4345/4865]\n",
            " Patch [4346/4865]\n",
            " Patch [4347/4865]\n",
            " Patch [4348/4865]\n",
            " Patch [4349/4865]\n",
            " Patch [4350/4865]\n",
            " Patch [4351/4865]\n",
            " Patch [4352/4865]\n",
            " Patch [4353/4865]\n",
            " Patch [4354/4865]\n",
            " Patch [4355/4865]\n",
            " Patch [4356/4865]\n",
            " Patch [4357/4865]\n",
            " Patch [4358/4865]\n",
            " Patch [4359/4865]\n",
            " Patch [4360/4865]\n",
            " Patch [4361/4865]\n",
            " Patch [4362/4865]\n",
            " Patch [4363/4865]\n",
            " Patch [4364/4865]\n",
            " Patch [4365/4865]\n",
            " Patch [4366/4865]\n",
            " Patch [4367/4865]\n",
            " Patch [4368/4865]\n",
            " Patch [4369/4865]\n",
            " Patch [4370/4865]\n",
            " Patch [4371/4865]\n",
            " Patch [4372/4865]\n",
            " Patch [4373/4865]\n",
            " Patch [4374/4865]\n",
            " Patch [4375/4865]\n",
            " Patch [4376/4865]\n",
            " Patch [4377/4865]\n",
            " Patch [4378/4865]\n",
            " Patch [4379/4865]\n",
            " Patch [4380/4865]\n",
            " Patch [4381/4865]\n",
            " Patch [4382/4865]\n",
            " Patch [4383/4865]\n",
            " Patch [4384/4865]\n",
            " Patch [4385/4865]\n",
            " Patch [4386/4865]\n",
            " Patch [4387/4865]\n",
            " Patch [4388/4865]\n",
            " Patch [4389/4865]\n",
            " Patch [4390/4865]\n",
            " Patch [4391/4865]\n",
            " Patch [4392/4865]\n",
            " Patch [4393/4865]\n",
            " Patch [4394/4865]\n",
            " Patch [4395/4865]\n",
            " Patch [4396/4865]\n",
            " Patch [4397/4865]\n",
            " Patch [4398/4865]\n",
            " Patch [4399/4865]\n",
            " Patch [4400/4865]\n",
            " Patch [4401/4865]\n",
            " Patch [4402/4865]\n",
            " Patch [4403/4865]\n",
            " Patch [4404/4865]\n",
            " Patch [4405/4865]\n",
            " Patch [4406/4865]\n",
            " Patch [4407/4865]\n",
            " Patch [4408/4865]\n",
            " Patch [4409/4865]\n",
            " Patch [4410/4865]\n",
            " Patch [4411/4865]\n",
            " Patch [4412/4865]\n",
            " Patch [4413/4865]\n",
            " Patch [4414/4865]\n",
            " Patch [4415/4865]\n",
            " Patch [4416/4865]\n",
            " Patch [4417/4865]\n",
            " Patch [4418/4865]\n",
            " Patch [4419/4865]\n",
            " Patch [4420/4865]\n",
            " Patch [4421/4865]\n",
            " Patch [4422/4865]\n",
            " Patch [4423/4865]\n",
            " Patch [4424/4865]\n",
            " Patch [4425/4865]\n",
            " Patch [4426/4865]\n",
            " Patch [4427/4865]\n",
            " Patch [4428/4865]\n",
            " Patch [4429/4865]\n",
            " Patch [4430/4865]\n",
            " Patch [4431/4865]\n",
            " Patch [4432/4865]\n",
            " Patch [4433/4865]\n",
            " Patch [4434/4865]\n",
            " Patch [4435/4865]\n",
            " Patch [4436/4865]\n",
            " Patch [4437/4865]\n",
            " Patch [4438/4865]\n",
            " Patch [4439/4865]\n",
            " Patch [4440/4865]\n",
            " Patch [4441/4865]\n",
            " Patch [4442/4865]\n",
            " Patch [4443/4865]\n",
            " Patch [4444/4865]\n",
            " Patch [4445/4865]\n",
            " Patch [4446/4865]\n",
            " Patch [4447/4865]\n",
            " Patch [4448/4865]\n",
            " Patch [4449/4865]\n",
            " Patch [4450/4865]\n",
            " Patch [4451/4865]\n",
            " Patch [4452/4865]\n",
            " Patch [4453/4865]\n",
            " Patch [4454/4865]\n",
            " Patch [4455/4865]\n",
            " Patch [4456/4865]\n",
            " Patch [4457/4865]\n",
            " Patch [4458/4865]\n",
            " Patch [4459/4865]\n",
            " Patch [4460/4865]\n",
            " Patch [4461/4865]\n",
            " Patch [4462/4865]\n",
            " Patch [4463/4865]\n",
            " Patch [4464/4865]\n",
            " Patch [4465/4865]\n",
            " Patch [4466/4865]\n",
            " Patch [4467/4865]\n",
            " Patch [4468/4865]\n",
            " Patch [4469/4865]\n",
            " Patch [4470/4865]\n",
            " Patch [4471/4865]\n",
            " Patch [4472/4865]\n",
            " Patch [4473/4865]\n",
            " Patch [4474/4865]\n",
            " Patch [4475/4865]\n",
            " Patch [4476/4865]\n",
            " Patch [4477/4865]\n",
            " Patch [4478/4865]\n",
            " Patch [4479/4865]\n",
            " Patch [4480/4865]\n",
            " Patch [4481/4865]\n",
            " Patch [4482/4865]\n",
            " Patch [4483/4865]\n",
            " Patch [4484/4865]\n",
            " Patch [4485/4865]\n",
            " Patch [4486/4865]\n",
            " Patch [4487/4865]\n",
            " Patch [4488/4865]\n",
            " Patch [4489/4865]\n",
            " Patch [4490/4865]\n",
            " Patch [4491/4865]\n",
            " Patch [4492/4865]\n",
            " Patch [4493/4865]\n",
            " Patch [4494/4865]\n",
            " Patch [4495/4865]\n",
            " Patch [4496/4865]\n",
            " Patch [4497/4865]\n",
            " Patch [4498/4865]\n",
            " Patch [4499/4865]\n",
            " Patch [4500/4865]\n",
            " Patch [4501/4865]\n",
            " Patch [4502/4865]\n",
            " Patch [4503/4865]\n",
            " Patch [4504/4865]\n",
            " Patch [4505/4865]\n",
            " Patch [4506/4865]\n",
            " Patch [4507/4865]\n",
            " Patch [4508/4865]\n",
            " Patch [4509/4865]\n",
            " Patch [4510/4865]\n",
            " Patch [4511/4865]\n",
            " Patch [4512/4865]\n",
            " Patch [4513/4865]\n",
            " Patch [4514/4865]\n",
            " Patch [4515/4865]\n",
            " Patch [4516/4865]\n",
            " Patch [4517/4865]\n",
            " Patch [4518/4865]\n",
            " Patch [4519/4865]\n",
            " Patch [4520/4865]\n",
            " Patch [4521/4865]\n",
            " Patch [4522/4865]\n",
            " Patch [4523/4865]\n",
            " Patch [4524/4865]\n",
            " Patch [4525/4865]\n",
            " Patch [4526/4865]\n",
            " Patch [4527/4865]\n",
            " Patch [4528/4865]\n",
            " Patch [4529/4865]\n",
            " Patch [4530/4865]\n",
            " Patch [4531/4865]\n",
            " Patch [4532/4865]\n",
            " Patch [4533/4865]\n",
            " Patch [4534/4865]\n",
            " Patch [4535/4865]\n",
            " Patch [4536/4865]\n",
            " Patch [4537/4865]\n",
            " Patch [4538/4865]\n",
            " Patch [4539/4865]\n",
            " Patch [4540/4865]\n",
            " Patch [4541/4865]\n",
            " Patch [4542/4865]\n",
            " Patch [4543/4865]\n",
            " Patch [4544/4865]\n",
            " Patch [4545/4865]\n",
            " Patch [4546/4865]\n",
            " Patch [4547/4865]\n",
            " Patch [4548/4865]\n",
            " Patch [4549/4865]\n",
            " Patch [4550/4865]\n",
            " Patch [4551/4865]\n",
            " Patch [4552/4865]\n",
            " Patch [4553/4865]\n",
            " Patch [4554/4865]\n",
            " Patch [4555/4865]\n",
            " Patch [4556/4865]\n",
            " Patch [4557/4865]\n",
            " Patch [4558/4865]\n",
            " Patch [4559/4865]\n",
            " Patch [4560/4865]\n",
            " Patch [4561/4865]\n",
            " Patch [4562/4865]\n",
            " Patch [4563/4865]\n",
            " Patch [4564/4865]\n",
            " Patch [4565/4865]\n",
            " Patch [4566/4865]\n",
            " Patch [4567/4865]\n",
            " Patch [4568/4865]\n",
            " Patch [4569/4865]\n",
            " Patch [4570/4865]\n",
            " Patch [4571/4865]\n",
            " Patch [4572/4865]\n",
            " Patch [4573/4865]\n",
            " Patch [4574/4865]\n",
            " Patch [4575/4865]\n",
            " Patch [4576/4865]\n",
            " Patch [4577/4865]\n",
            " Patch [4578/4865]\n",
            " Patch [4579/4865]\n",
            " Patch [4580/4865]\n",
            " Patch [4581/4865]\n",
            " Patch [4582/4865]\n",
            " Patch [4583/4865]\n",
            " Patch [4584/4865]\n",
            " Patch [4585/4865]\n",
            " Patch [4586/4865]\n",
            " Patch [4587/4865]\n",
            " Patch [4588/4865]\n",
            " Patch [4589/4865]\n",
            " Patch [4590/4865]\n",
            " Patch [4591/4865]\n",
            " Patch [4592/4865]\n",
            " Patch [4593/4865]\n",
            " Patch [4594/4865]\n",
            " Patch [4595/4865]\n",
            " Patch [4596/4865]\n",
            " Patch [4597/4865]\n",
            " Patch [4598/4865]\n",
            " Patch [4599/4865]\n",
            " Patch [4600/4865]\n",
            " Patch [4601/4865]\n",
            " Patch [4602/4865]\n",
            " Patch [4603/4865]\n",
            " Patch [4604/4865]\n",
            " Patch [4605/4865]\n",
            " Patch [4606/4865]\n",
            " Patch [4607/4865]\n",
            " Patch [4608/4865]\n",
            " Patch [4609/4865]\n",
            " Patch [4610/4865]\n",
            " Patch [4611/4865]\n",
            " Patch [4612/4865]\n",
            " Patch [4613/4865]\n",
            " Patch [4614/4865]\n",
            " Patch [4615/4865]\n",
            " Patch [4616/4865]\n",
            " Patch [4617/4865]\n",
            " Patch [4618/4865]\n",
            " Patch [4619/4865]\n",
            " Patch [4620/4865]\n",
            " Patch [4621/4865]\n",
            " Patch [4622/4865]\n",
            " Patch [4623/4865]\n",
            " Patch [4624/4865]\n",
            " Patch [4625/4865]\n",
            " Patch [4626/4865]\n",
            " Patch [4627/4865]\n",
            " Patch [4628/4865]\n",
            " Patch [4629/4865]\n",
            " Patch [4630/4865]\n",
            " Patch [4631/4865]\n",
            " Patch [4632/4865]\n",
            " Patch [4633/4865]\n",
            " Patch [4634/4865]\n",
            " Patch [4635/4865]\n",
            " Patch [4636/4865]\n",
            " Patch [4637/4865]\n",
            " Patch [4638/4865]\n",
            " Patch [4639/4865]\n",
            " Patch [4640/4865]\n",
            " Patch [4641/4865]\n",
            " Patch [4642/4865]\n",
            " Patch [4643/4865]\n",
            " Patch [4644/4865]\n",
            " Patch [4645/4865]\n",
            " Patch [4646/4865]\n",
            " Patch [4647/4865]\n",
            " Patch [4648/4865]\n",
            " Patch [4649/4865]\n",
            " Patch [4650/4865]\n",
            " Patch [4651/4865]\n",
            " Patch [4652/4865]\n",
            " Patch [4653/4865]\n",
            " Patch [4654/4865]\n",
            " Patch [4655/4865]\n",
            " Patch [4656/4865]\n",
            " Patch [4657/4865]\n",
            " Patch [4658/4865]\n",
            " Patch [4659/4865]\n",
            " Patch [4660/4865]\n",
            " Patch [4661/4865]\n",
            " Patch [4662/4865]\n",
            " Patch [4663/4865]\n",
            " Patch [4664/4865]\n",
            " Patch [4665/4865]\n",
            " Patch [4666/4865]\n",
            " Patch [4667/4865]\n",
            " Patch [4668/4865]\n",
            " Patch [4669/4865]\n",
            " Patch [4670/4865]\n",
            " Patch [4671/4865]\n",
            " Patch [4672/4865]\n",
            " Patch [4673/4865]\n",
            " Patch [4674/4865]\n",
            " Patch [4675/4865]\n",
            " Patch [4676/4865]\n",
            " Patch [4677/4865]\n",
            " Patch [4678/4865]\n",
            " Patch [4679/4865]\n",
            " Patch [4680/4865]\n",
            " Patch [4681/4865]\n",
            " Patch [4682/4865]\n",
            " Patch [4683/4865]\n",
            " Patch [4684/4865]\n",
            " Patch [4685/4865]\n",
            " Patch [4686/4865]\n",
            " Patch [4687/4865]\n",
            " Patch [4688/4865]\n",
            " Patch [4689/4865]\n",
            " Patch [4690/4865]\n",
            " Patch [4691/4865]\n",
            " Patch [4692/4865]\n",
            " Patch [4693/4865]\n",
            " Patch [4694/4865]\n",
            " Patch [4695/4865]\n",
            " Patch [4696/4865]\n",
            " Patch [4697/4865]\n",
            " Patch [4698/4865]\n",
            " Patch [4699/4865]\n",
            " Patch [4700/4865]\n",
            " Patch [4701/4865]\n",
            " Patch [4702/4865]\n",
            " Patch [4703/4865]\n",
            " Patch [4704/4865]\n",
            " Patch [4705/4865]\n",
            " Patch [4706/4865]\n",
            " Patch [4707/4865]\n",
            " Patch [4708/4865]\n",
            " Patch [4709/4865]\n",
            " Patch [4710/4865]\n",
            " Patch [4711/4865]\n",
            " Patch [4712/4865]\n",
            " Patch [4713/4865]\n",
            " Patch [4714/4865]\n",
            " Patch [4715/4865]\n",
            " Patch [4716/4865]\n",
            " Patch [4717/4865]\n",
            " Patch [4718/4865]\n",
            " Patch [4719/4865]\n",
            " Patch [4720/4865]\n",
            " Patch [4721/4865]\n",
            " Patch [4722/4865]\n",
            " Patch [4723/4865]\n",
            " Patch [4724/4865]\n",
            " Patch [4725/4865]\n",
            " Patch [4726/4865]\n",
            " Patch [4727/4865]\n",
            " Patch [4728/4865]\n",
            " Patch [4729/4865]\n",
            " Patch [4730/4865]\n",
            " Patch [4731/4865]\n",
            " Patch [4732/4865]\n",
            " Patch [4733/4865]\n",
            " Patch [4734/4865]\n",
            " Patch [4735/4865]\n",
            " Patch [4736/4865]\n",
            " Patch [4737/4865]\n",
            " Patch [4738/4865]\n",
            " Patch [4739/4865]\n",
            " Patch [4740/4865]\n",
            " Patch [4741/4865]\n",
            " Patch [4742/4865]\n",
            " Patch [4743/4865]\n",
            " Patch [4744/4865]\n",
            " Patch [4745/4865]\n",
            " Patch [4746/4865]\n",
            " Patch [4747/4865]\n",
            " Patch [4748/4865]\n",
            " Patch [4749/4865]\n",
            " Patch [4750/4865]\n",
            " Patch [4751/4865]\n",
            " Patch [4752/4865]\n",
            " Patch [4753/4865]\n",
            " Patch [4754/4865]\n",
            " Patch [4755/4865]\n",
            " Patch [4756/4865]\n",
            " Patch [4757/4865]\n",
            " Patch [4758/4865]\n",
            " Patch [4759/4865]\n",
            " Patch [4760/4865]\n",
            " Patch [4761/4865]\n",
            " Patch [4762/4865]\n",
            " Patch [4763/4865]\n",
            " Patch [4764/4865]\n",
            " Patch [4765/4865]\n",
            " Patch [4766/4865]\n",
            " Patch [4767/4865]\n",
            " Patch [4768/4865]\n",
            " Patch [4769/4865]\n",
            " Patch [4770/4865]\n",
            " Patch [4771/4865]\n",
            " Patch [4772/4865]\n",
            " Patch [4773/4865]\n",
            " Patch [4774/4865]\n",
            " Patch [4775/4865]\n",
            " Patch [4776/4865]\n",
            " Patch [4777/4865]\n",
            " Patch [4778/4865]\n",
            " Patch [4779/4865]\n",
            " Patch [4780/4865]\n",
            " Patch [4781/4865]\n",
            " Patch [4782/4865]\n",
            " Patch [4783/4865]\n",
            " Patch [4784/4865]\n",
            " Patch [4785/4865]\n",
            " Patch [4786/4865]\n",
            " Patch [4787/4865]\n",
            " Patch [4788/4865]\n",
            " Patch [4789/4865]\n",
            " Patch [4790/4865]\n",
            " Patch [4791/4865]\n",
            " Patch [4792/4865]\n",
            " Patch [4793/4865]\n",
            " Patch [4794/4865]\n",
            " Patch [4795/4865]\n",
            " Patch [4796/4865]\n",
            " Patch [4797/4865]\n",
            " Patch [4798/4865]\n",
            " Patch [4799/4865]\n",
            " Patch [4800/4865]\n",
            " Patch [4801/4865]\n",
            " Patch [4802/4865]\n",
            " Patch [4803/4865]\n",
            " Patch [4804/4865]\n",
            " Patch [4805/4865]\n",
            " Patch [4806/4865]\n",
            " Patch [4807/4865]\n",
            " Patch [4808/4865]\n",
            " Patch [4809/4865]\n",
            " Patch [4810/4865]\n",
            " Patch [4811/4865]\n",
            " Patch [4812/4865]\n",
            " Patch [4813/4865]\n",
            " Patch [4814/4865]\n",
            " Patch [4815/4865]\n",
            " Patch [4816/4865]\n",
            " Patch [4817/4865]\n",
            " Patch [4818/4865]\n",
            " Patch [4819/4865]\n",
            " Patch [4820/4865]\n",
            " Patch [4821/4865]\n",
            " Patch [4822/4865]\n",
            " Patch [4823/4865]\n",
            " Patch [4824/4865]\n",
            " Patch [4825/4865]\n",
            " Patch [4826/4865]\n",
            " Patch [4827/4865]\n",
            " Patch [4828/4865]\n",
            " Patch [4829/4865]\n",
            " Patch [4830/4865]\n",
            " Patch [4831/4865]\n",
            " Patch [4832/4865]\n",
            " Patch [4833/4865]\n",
            " Patch [4834/4865]\n",
            " Patch [4835/4865]\n",
            " Patch [4836/4865]\n",
            " Patch [4837/4865]\n",
            " Patch [4838/4865]\n",
            " Patch [4839/4865]\n",
            " Patch [4840/4865]\n",
            " Patch [4841/4865]\n",
            " Patch [4842/4865]\n",
            " Patch [4843/4865]\n",
            " Patch [4844/4865]\n",
            " Patch [4845/4865]\n",
            " Patch [4846/4865]\n",
            " Patch [4847/4865]\n",
            " Patch [4848/4865]\n",
            " Patch [4849/4865]\n",
            " Patch [4850/4865]\n",
            " Patch [4851/4865]\n",
            " Patch [4852/4865]\n",
            " Patch [4853/4865]\n",
            " Patch [4854/4865]\n",
            " Patch [4855/4865]\n",
            " Patch [4856/4865]\n",
            " Patch [4857/4865]\n",
            " Patch [4858/4865]\n",
            " Patch [4859/4865]\n",
            " Patch [4860/4865]\n",
            " Patch [4861/4865]\n",
            " Patch [4862/4865]\n",
            " Patch [4863/4865]\n",
            " Patch [4864/4865]\n",
            " Patch [4865/4865]Done.\n",
            "Process slide 22/22\n",
            "\n",
            " Organizing patches\n",
            "\n",
            " Patch [1/1124]\n",
            " Patch [2/1124]\n",
            " Patch [3/1124]\n",
            " Patch [4/1124]\n",
            " Patch [5/1124]\n",
            " Patch [6/1124]\n",
            " Patch [7/1124]\n",
            " Patch [8/1124]\n",
            " Patch [9/1124]\n",
            " Patch [10/1124]\n",
            " Patch [11/1124]\n",
            " Patch [12/1124]\n",
            " Patch [13/1124]\n",
            " Patch [14/1124]\n",
            " Patch [15/1124]\n",
            " Patch [16/1124]\n",
            " Patch [17/1124]\n",
            " Patch [18/1124]\n",
            " Patch [19/1124]\n",
            " Patch [20/1124]\n",
            " Patch [21/1124]\n",
            " Patch [22/1124]\n",
            " Patch [23/1124]\n",
            " Patch [24/1124]\n",
            " Patch [25/1124]\n",
            " Patch [26/1124]\n",
            " Patch [27/1124]\n",
            " Patch [28/1124]\n",
            " Patch [29/1124]\n",
            " Patch [30/1124]\n",
            " Patch [31/1124]\n",
            " Patch [32/1124]\n",
            " Patch [33/1124]\n",
            " Patch [34/1124]\n",
            " Patch [35/1124]\n",
            " Patch [36/1124]\n",
            " Patch [37/1124]\n",
            " Patch [38/1124]\n",
            " Patch [39/1124]\n",
            " Patch [40/1124]\n",
            " Patch [41/1124]\n",
            " Patch [42/1124]\n",
            " Patch [43/1124]\n",
            " Patch [44/1124]\n",
            " Patch [45/1124]\n",
            " Patch [46/1124]\n",
            " Patch [47/1124]\n",
            " Patch [48/1124]\n",
            " Patch [49/1124]\n",
            " Patch [50/1124]\n",
            " Patch [51/1124]\n",
            " Patch [52/1124]\n",
            " Patch [53/1124]\n",
            " Patch [54/1124]\n",
            " Patch [55/1124]\n",
            " Patch [56/1124]\n",
            " Patch [57/1124]\n",
            " Patch [58/1124]\n",
            " Patch [59/1124]\n",
            " Patch [60/1124]\n",
            " Patch [61/1124]\n",
            " Patch [62/1124]\n",
            " Patch [63/1124]\n",
            " Patch [64/1124]\n",
            " Patch [65/1124]\n",
            " Patch [66/1124]\n",
            " Patch [67/1124]\n",
            " Patch [68/1124]\n",
            " Patch [69/1124]\n",
            " Patch [70/1124]\n",
            " Patch [71/1124]\n",
            " Patch [72/1124]\n",
            " Patch [73/1124]\n",
            " Patch [74/1124]\n",
            " Patch [75/1124]\n",
            " Patch [76/1124]\n",
            " Patch [77/1124]\n",
            " Patch [78/1124]\n",
            " Patch [79/1124]\n",
            " Patch [80/1124]\n",
            " Patch [81/1124]\n",
            " Patch [82/1124]\n",
            " Patch [83/1124]\n",
            " Patch [84/1124]\n",
            " Patch [85/1124]\n",
            " Patch [86/1124]\n",
            " Patch [87/1124]\n",
            " Patch [88/1124]\n",
            " Patch [89/1124]\n",
            " Patch [90/1124]\n",
            " Patch [91/1124]\n",
            " Patch [92/1124]\n",
            " Patch [93/1124]\n",
            " Patch [94/1124]\n",
            " Patch [95/1124]\n",
            " Patch [96/1124]\n",
            " Patch [97/1124]\n",
            " Patch [98/1124]\n",
            " Patch [99/1124]\n",
            " Patch [100/1124]\n",
            " Patch [101/1124]\n",
            " Patch [102/1124]\n",
            " Patch [103/1124]\n",
            " Patch [104/1124]\n",
            " Patch [105/1124]\n",
            " Patch [106/1124]\n",
            " Patch [107/1124]\n",
            " Patch [108/1124]\n",
            " Patch [109/1124]\n",
            " Patch [110/1124]\n",
            " Patch [111/1124]\n",
            " Patch [112/1124]\n",
            " Patch [113/1124]\n",
            " Patch [114/1124]\n",
            " Patch [115/1124]\n",
            " Patch [116/1124]\n",
            " Patch [117/1124]\n",
            " Patch [118/1124]\n",
            " Patch [119/1124]\n",
            " Patch [120/1124]\n",
            " Patch [121/1124]\n",
            " Patch [122/1124]\n",
            " Patch [123/1124]\n",
            " Patch [124/1124]\n",
            " Patch [125/1124]\n",
            " Patch [126/1124]\n",
            " Patch [127/1124]\n",
            " Patch [128/1124]\n",
            " Patch [129/1124]\n",
            " Patch [130/1124]\n",
            " Patch [131/1124]\n",
            " Patch [132/1124]\n",
            " Patch [133/1124]\n",
            " Patch [134/1124]\n",
            " Patch [135/1124]\n",
            " Patch [136/1124]\n",
            " Patch [137/1124]\n",
            " Patch [138/1124]\n",
            " Patch [139/1124]\n",
            " Patch [140/1124]\n",
            " Patch [141/1124]\n",
            " Patch [142/1124]\n",
            " Patch [143/1124]\n",
            " Patch [144/1124]\n",
            " Patch [145/1124]\n",
            " Patch [146/1124]\n",
            " Patch [147/1124]\n",
            " Patch [148/1124]\n",
            " Patch [149/1124]\n",
            " Patch [150/1124]\n",
            " Patch [151/1124]\n",
            " Patch [152/1124]\n",
            " Patch [153/1124]\n",
            " Patch [154/1124]\n",
            " Patch [155/1124]\n",
            " Patch [156/1124]\n",
            " Patch [157/1124]\n",
            " Patch [158/1124]\n",
            " Patch [159/1124]\n",
            " Patch [160/1124]\n",
            " Patch [161/1124]\n",
            " Patch [162/1124]\n",
            " Patch [163/1124]\n",
            " Patch [164/1124]\n",
            " Patch [165/1124]\n",
            " Patch [166/1124]\n",
            " Patch [167/1124]\n",
            " Patch [168/1124]\n",
            " Patch [169/1124]\n",
            " Patch [170/1124]\n",
            " Patch [171/1124]\n",
            " Patch [172/1124]\n",
            " Patch [173/1124]\n",
            " Patch [174/1124]\n",
            " Patch [175/1124]\n",
            " Patch [176/1124]\n",
            " Patch [177/1124]\n",
            " Patch [178/1124]\n",
            " Patch [179/1124]\n",
            " Patch [180/1124]\n",
            " Patch [181/1124]\n",
            " Patch [182/1124]\n",
            " Patch [183/1124]\n",
            " Patch [184/1124]\n",
            " Patch [185/1124]\n",
            " Patch [186/1124]\n",
            " Patch [187/1124]\n",
            " Patch [188/1124]\n",
            " Patch [189/1124]\n",
            " Patch [190/1124]\n",
            " Patch [191/1124]\n",
            " Patch [192/1124]\n",
            " Patch [193/1124]\n",
            " Patch [194/1124]\n",
            " Patch [195/1124]\n",
            " Patch [196/1124]\n",
            " Patch [197/1124]\n",
            " Patch [198/1124]\n",
            " Patch [199/1124]\n",
            " Patch [200/1124]\n",
            " Patch [201/1124]\n",
            " Patch [202/1124]\n",
            " Patch [203/1124]\n",
            " Patch [204/1124]\n",
            " Patch [205/1124]\n",
            " Patch [206/1124]\n",
            " Patch [207/1124]\n",
            " Patch [208/1124]\n",
            " Patch [209/1124]\n",
            " Patch [210/1124]\n",
            " Patch [211/1124]\n",
            " Patch [212/1124]\n",
            " Patch [213/1124]\n",
            " Patch [214/1124]\n",
            " Patch [215/1124]\n",
            " Patch [216/1124]\n",
            " Patch [217/1124]\n",
            " Patch [218/1124]\n",
            " Patch [219/1124]\n",
            " Patch [220/1124]\n",
            " Patch [221/1124]\n",
            " Patch [222/1124]\n",
            " Patch [223/1124]\n",
            " Patch [224/1124]\n",
            " Patch [225/1124]\n",
            " Patch [226/1124]\n",
            " Patch [227/1124]\n",
            " Patch [228/1124]\n",
            " Patch [229/1124]\n",
            " Patch [230/1124]\n",
            " Patch [231/1124]\n",
            " Patch [232/1124]\n",
            " Patch [233/1124]\n",
            " Patch [234/1124]\n",
            " Patch [235/1124]\n",
            " Patch [236/1124]\n",
            " Patch [237/1124]\n",
            " Patch [238/1124]\n",
            " Patch [239/1124]\n",
            " Patch [240/1124]\n",
            " Patch [241/1124]\n",
            " Patch [242/1124]\n",
            " Patch [243/1124]\n",
            " Patch [244/1124]\n",
            " Patch [245/1124]\n",
            " Patch [246/1124]\n",
            " Patch [247/1124]\n",
            " Patch [248/1124]\n",
            " Patch [249/1124]\n",
            " Patch [250/1124]\n",
            " Patch [251/1124]\n",
            " Patch [252/1124]\n",
            " Patch [253/1124]\n",
            " Patch [254/1124]\n",
            " Patch [255/1124]\n",
            " Patch [256/1124]\n",
            " Patch [257/1124]\n",
            " Patch [258/1124]\n",
            " Patch [259/1124]\n",
            " Patch [260/1124]\n",
            " Patch [261/1124]\n",
            " Patch [262/1124]\n",
            " Patch [263/1124]\n",
            " Patch [264/1124]\n",
            " Patch [265/1124]\n",
            " Patch [266/1124]\n",
            " Patch [267/1124]\n",
            " Patch [268/1124]\n",
            " Patch [269/1124]\n",
            " Patch [270/1124]\n",
            " Patch [271/1124]\n",
            " Patch [272/1124]\n",
            " Patch [273/1124]\n",
            " Patch [274/1124]\n",
            " Patch [275/1124]\n",
            " Patch [276/1124]\n",
            " Patch [277/1124]\n",
            " Patch [278/1124]\n",
            " Patch [279/1124]\n",
            " Patch [280/1124]\n",
            " Patch [281/1124]\n",
            " Patch [282/1124]\n",
            " Patch [283/1124]\n",
            " Patch [284/1124]\n",
            " Patch [285/1124]\n",
            " Patch [286/1124]\n",
            " Patch [287/1124]\n",
            " Patch [288/1124]\n",
            " Patch [289/1124]\n",
            " Patch [290/1124]\n",
            " Patch [291/1124]\n",
            " Patch [292/1124]\n",
            " Patch [293/1124]\n",
            " Patch [294/1124]\n",
            " Patch [295/1124]\n",
            " Patch [296/1124]\n",
            " Patch [297/1124]\n",
            " Patch [298/1124]\n",
            " Patch [299/1124]\n",
            " Patch [300/1124]\n",
            " Patch [301/1124]\n",
            " Patch [302/1124]\n",
            " Patch [303/1124]\n",
            " Patch [304/1124]\n",
            " Patch [305/1124]\n",
            " Patch [306/1124]\n",
            " Patch [307/1124]\n",
            " Patch [308/1124]\n",
            " Patch [309/1124]\n",
            " Patch [310/1124]\n",
            " Patch [311/1124]\n",
            " Patch [312/1124]\n",
            " Patch [313/1124]\n",
            " Patch [314/1124]\n",
            " Patch [315/1124]\n",
            " Patch [316/1124]\n",
            " Patch [317/1124]\n",
            " Patch [318/1124]\n",
            " Patch [319/1124]\n",
            " Patch [320/1124]\n",
            " Patch [321/1124]\n",
            " Patch [322/1124]\n",
            " Patch [323/1124]\n",
            " Patch [324/1124]\n",
            " Patch [325/1124]\n",
            " Patch [326/1124]\n",
            " Patch [327/1124]\n",
            " Patch [328/1124]\n",
            " Patch [329/1124]\n",
            " Patch [330/1124]\n",
            " Patch [331/1124]\n",
            " Patch [332/1124]\n",
            " Patch [333/1124]\n",
            " Patch [334/1124]\n",
            " Patch [335/1124]\n",
            " Patch [336/1124]\n",
            " Patch [337/1124]\n",
            " Patch [338/1124]\n",
            " Patch [339/1124]\n",
            " Patch [340/1124]\n",
            " Patch [341/1124]\n",
            " Patch [342/1124]\n",
            " Patch [343/1124]\n",
            " Patch [344/1124]\n",
            " Patch [345/1124]\n",
            " Patch [346/1124]\n",
            " Patch [347/1124]\n",
            " Patch [348/1124]\n",
            " Patch [349/1124]\n",
            " Patch [350/1124]\n",
            " Patch [351/1124]\n",
            " Patch [352/1124]\n",
            " Patch [353/1124]\n",
            " Patch [354/1124]\n",
            " Patch [355/1124]\n",
            " Patch [356/1124]\n",
            " Patch [357/1124]\n",
            " Patch [358/1124]\n",
            " Patch [359/1124]\n",
            " Patch [360/1124]\n",
            " Patch [361/1124]\n",
            " Patch [362/1124]\n",
            " Patch [363/1124]\n",
            " Patch [364/1124]\n",
            " Patch [365/1124]\n",
            " Patch [366/1124]\n",
            " Patch [367/1124]\n",
            " Patch [368/1124]\n",
            " Patch [369/1124]\n",
            " Patch [370/1124]\n",
            " Patch [371/1124]\n",
            " Patch [372/1124]\n",
            " Patch [373/1124]\n",
            " Patch [374/1124]\n",
            " Patch [375/1124]\n",
            " Patch [376/1124]\n",
            " Patch [377/1124]\n",
            " Patch [378/1124]\n",
            " Patch [379/1124]\n",
            " Patch [380/1124]\n",
            " Patch [381/1124]\n",
            " Patch [382/1124]\n",
            " Patch [383/1124]\n",
            " Patch [384/1124]\n",
            " Patch [385/1124]\n",
            " Patch [386/1124]\n",
            " Patch [387/1124]\n",
            " Patch [388/1124]\n",
            " Patch [389/1124]\n",
            " Patch [390/1124]\n",
            " Patch [391/1124]\n",
            " Patch [392/1124]\n",
            " Patch [393/1124]\n",
            " Patch [394/1124]\n",
            " Patch [395/1124]\n",
            " Patch [396/1124]\n",
            " Patch [397/1124]\n",
            " Patch [398/1124]\n",
            " Patch [399/1124]\n",
            " Patch [400/1124]\n",
            " Patch [401/1124]\n",
            " Patch [402/1124]\n",
            " Patch [403/1124]\n",
            " Patch [404/1124]\n",
            " Patch [405/1124]\n",
            " Patch [406/1124]\n",
            " Patch [407/1124]\n",
            " Patch [408/1124]\n",
            " Patch [409/1124]\n",
            " Patch [410/1124]\n",
            " Patch [411/1124]\n",
            " Patch [412/1124]\n",
            " Patch [413/1124]\n",
            " Patch [414/1124]\n",
            " Patch [415/1124]\n",
            " Patch [416/1124]\n",
            " Patch [417/1124]\n",
            " Patch [418/1124]\n",
            " Patch [419/1124]\n",
            " Patch [420/1124]\n",
            " Patch [421/1124]\n",
            " Patch [422/1124]\n",
            " Patch [423/1124]\n",
            " Patch [424/1124]\n",
            " Patch [425/1124]\n",
            " Patch [426/1124]\n",
            " Patch [427/1124]\n",
            " Patch [428/1124]\n",
            " Patch [429/1124]\n",
            " Patch [430/1124]\n",
            " Patch [431/1124]\n",
            " Patch [432/1124]\n",
            " Patch [433/1124]\n",
            " Patch [434/1124]\n",
            " Patch [435/1124]\n",
            " Patch [436/1124]\n",
            " Patch [437/1124]\n",
            " Patch [438/1124]\n",
            " Patch [439/1124]\n",
            " Patch [440/1124]\n",
            " Patch [441/1124]\n",
            " Patch [442/1124]\n",
            " Patch [443/1124]\n",
            " Patch [444/1124]\n",
            " Patch [445/1124]\n",
            " Patch [446/1124]\n",
            " Patch [447/1124]\n",
            " Patch [448/1124]\n",
            " Patch [449/1124]\n",
            " Patch [450/1124]\n",
            " Patch [451/1124]\n",
            " Patch [452/1124]\n",
            " Patch [453/1124]\n",
            " Patch [454/1124]\n",
            " Patch [455/1124]\n",
            " Patch [456/1124]\n",
            " Patch [457/1124]\n",
            " Patch [458/1124]\n",
            " Patch [459/1124]\n",
            " Patch [460/1124]\n",
            " Patch [461/1124]\n",
            " Patch [462/1124]\n",
            " Patch [463/1124]\n",
            " Patch [464/1124]\n",
            " Patch [465/1124]\n",
            " Patch [466/1124]\n",
            " Patch [467/1124]\n",
            " Patch [468/1124]\n",
            " Patch [469/1124]\n",
            " Patch [470/1124]\n",
            " Patch [471/1124]\n",
            " Patch [472/1124]\n",
            " Patch [473/1124]\n",
            " Patch [474/1124]\n",
            " Patch [475/1124]\n",
            " Patch [476/1124]\n",
            " Patch [477/1124]\n",
            " Patch [478/1124]\n",
            " Patch [479/1124]\n",
            " Patch [480/1124]\n",
            " Patch [481/1124]\n",
            " Patch [482/1124]\n",
            " Patch [483/1124]\n",
            " Patch [484/1124]\n",
            " Patch [485/1124]\n",
            " Patch [486/1124]\n",
            " Patch [487/1124]\n",
            " Patch [488/1124]\n",
            " Patch [489/1124]\n",
            " Patch [490/1124]\n",
            " Patch [491/1124]\n",
            " Patch [492/1124]\n",
            " Patch [493/1124]\n",
            " Patch [494/1124]\n",
            " Patch [495/1124]\n",
            " Patch [496/1124]\n",
            " Patch [497/1124]\n",
            " Patch [498/1124]\n",
            " Patch [499/1124]\n",
            " Patch [500/1124]\n",
            " Patch [501/1124]\n",
            " Patch [502/1124]\n",
            " Patch [503/1124]\n",
            " Patch [504/1124]\n",
            " Patch [505/1124]\n",
            " Patch [506/1124]\n",
            " Patch [507/1124]\n",
            " Patch [508/1124]\n",
            " Patch [509/1124]\n",
            " Patch [510/1124]\n",
            " Patch [511/1124]\n",
            " Patch [512/1124]\n",
            " Patch [513/1124]\n",
            " Patch [514/1124]\n",
            " Patch [515/1124]\n",
            " Patch [516/1124]\n",
            " Patch [517/1124]\n",
            " Patch [518/1124]\n",
            " Patch [519/1124]\n",
            " Patch [520/1124]\n",
            " Patch [521/1124]\n",
            " Patch [522/1124]\n",
            " Patch [523/1124]\n",
            " Patch [524/1124]\n",
            " Patch [525/1124]\n",
            " Patch [526/1124]\n",
            " Patch [527/1124]\n",
            " Patch [528/1124]\n",
            " Patch [529/1124]\n",
            " Patch [530/1124]\n",
            " Patch [531/1124]\n",
            " Patch [532/1124]\n",
            " Patch [533/1124]\n",
            " Patch [534/1124]\n",
            " Patch [535/1124]\n",
            " Patch [536/1124]\n",
            " Patch [537/1124]\n",
            " Patch [538/1124]\n",
            " Patch [539/1124]\n",
            " Patch [540/1124]\n",
            " Patch [541/1124]\n",
            " Patch [542/1124]\n",
            " Patch [543/1124]\n",
            " Patch [544/1124]\n",
            " Patch [545/1124]\n",
            " Patch [546/1124]\n",
            " Patch [547/1124]\n",
            " Patch [548/1124]\n",
            " Patch [549/1124]\n",
            " Patch [550/1124]\n",
            " Patch [551/1124]\n",
            " Patch [552/1124]\n",
            " Patch [553/1124]\n",
            " Patch [554/1124]\n",
            " Patch [555/1124]\n",
            " Patch [556/1124]\n",
            " Patch [557/1124]\n",
            " Patch [558/1124]\n",
            " Patch [559/1124]\n",
            " Patch [560/1124]\n",
            " Patch [561/1124]\n",
            " Patch [562/1124]\n",
            " Patch [563/1124]\n",
            " Patch [564/1124]\n",
            " Patch [565/1124]\n",
            " Patch [566/1124]\n",
            " Patch [567/1124]\n",
            " Patch [568/1124]\n",
            " Patch [569/1124]\n",
            " Patch [570/1124]\n",
            " Patch [571/1124]\n",
            " Patch [572/1124]\n",
            " Patch [573/1124]\n",
            " Patch [574/1124]\n",
            " Patch [575/1124]\n",
            " Patch [576/1124]\n",
            " Patch [577/1124]\n",
            " Patch [578/1124]\n",
            " Patch [579/1124]\n",
            " Patch [580/1124]\n",
            " Patch [581/1124]\n",
            " Patch [582/1124]\n",
            " Patch [583/1124]\n",
            " Patch [584/1124]\n",
            " Patch [585/1124]\n",
            " Patch [586/1124]\n",
            " Patch [587/1124]\n",
            " Patch [588/1124]\n",
            " Patch [589/1124]\n",
            " Patch [590/1124]\n",
            " Patch [591/1124]\n",
            " Patch [592/1124]\n",
            " Patch [593/1124]\n",
            " Patch [594/1124]\n",
            " Patch [595/1124]\n",
            " Patch [596/1124]\n",
            " Patch [597/1124]\n",
            " Patch [598/1124]\n",
            " Patch [599/1124]\n",
            " Patch [600/1124]\n",
            " Patch [601/1124]\n",
            " Patch [602/1124]\n",
            " Patch [603/1124]\n",
            " Patch [604/1124]\n",
            " Patch [605/1124]\n",
            " Patch [606/1124]\n",
            " Patch [607/1124]\n",
            " Patch [608/1124]\n",
            " Patch [609/1124]\n",
            " Patch [610/1124]\n",
            " Patch [611/1124]\n",
            " Patch [612/1124]\n",
            " Patch [613/1124]\n",
            " Patch [614/1124]\n",
            " Patch [615/1124]\n",
            " Patch [616/1124]\n",
            " Patch [617/1124]\n",
            " Patch [618/1124]\n",
            " Patch [619/1124]\n",
            " Patch [620/1124]\n",
            " Patch [621/1124]\n",
            " Patch [622/1124]\n",
            " Patch [623/1124]\n",
            " Patch [624/1124]\n",
            " Patch [625/1124]\n",
            " Patch [626/1124]\n",
            " Patch [627/1124]\n",
            " Patch [628/1124]\n",
            " Patch [629/1124]\n",
            " Patch [630/1124]\n",
            " Patch [631/1124]\n",
            " Patch [632/1124]\n",
            " Patch [633/1124]\n",
            " Patch [634/1124]\n",
            " Patch [635/1124]\n",
            " Patch [636/1124]\n",
            " Patch [637/1124]\n",
            " Patch [638/1124]\n",
            " Patch [639/1124]\n",
            " Patch [640/1124]\n",
            " Patch [641/1124]\n",
            " Patch [642/1124]\n",
            " Patch [643/1124]\n",
            " Patch [644/1124]\n",
            " Patch [645/1124]\n",
            " Patch [646/1124]\n",
            " Patch [647/1124]\n",
            " Patch [648/1124]\n",
            " Patch [649/1124]\n",
            " Patch [650/1124]\n",
            " Patch [651/1124]\n",
            " Patch [652/1124]\n",
            " Patch [653/1124]\n",
            " Patch [654/1124]\n",
            " Patch [655/1124]\n",
            " Patch [656/1124]\n",
            " Patch [657/1124]\n",
            " Patch [658/1124]\n",
            " Patch [659/1124]\n",
            " Patch [660/1124]\n",
            " Patch [661/1124]\n",
            " Patch [662/1124]\n",
            " Patch [663/1124]\n",
            " Patch [664/1124]\n",
            " Patch [665/1124]\n",
            " Patch [666/1124]\n",
            " Patch [667/1124]\n",
            " Patch [668/1124]\n",
            " Patch [669/1124]\n",
            " Patch [670/1124]\n",
            " Patch [671/1124]\n",
            " Patch [672/1124]\n",
            " Patch [673/1124]\n",
            " Patch [674/1124]\n",
            " Patch [675/1124]\n",
            " Patch [676/1124]\n",
            " Patch [677/1124]\n",
            " Patch [678/1124]\n",
            " Patch [679/1124]\n",
            " Patch [680/1124]\n",
            " Patch [681/1124]\n",
            " Patch [682/1124]\n",
            " Patch [683/1124]\n",
            " Patch [684/1124]\n",
            " Patch [685/1124]\n",
            " Patch [686/1124]\n",
            " Patch [687/1124]\n",
            " Patch [688/1124]\n",
            " Patch [689/1124]\n",
            " Patch [690/1124]\n",
            " Patch [691/1124]\n",
            " Patch [692/1124]\n",
            " Patch [693/1124]\n",
            " Patch [694/1124]\n",
            " Patch [695/1124]\n",
            " Patch [696/1124]\n",
            " Patch [697/1124]\n",
            " Patch [698/1124]\n",
            " Patch [699/1124]\n",
            " Patch [700/1124]\n",
            " Patch [701/1124]\n",
            " Patch [702/1124]\n",
            " Patch [703/1124]\n",
            " Patch [704/1124]\n",
            " Patch [705/1124]\n",
            " Patch [706/1124]\n",
            " Patch [707/1124]\n",
            " Patch [708/1124]\n",
            " Patch [709/1124]\n",
            " Patch [710/1124]\n",
            " Patch [711/1124]\n",
            " Patch [712/1124]\n",
            " Patch [713/1124]\n",
            " Patch [714/1124]\n",
            " Patch [715/1124]\n",
            " Patch [716/1124]\n",
            " Patch [717/1124]\n",
            " Patch [718/1124]\n",
            " Patch [719/1124]\n",
            " Patch [720/1124]\n",
            " Patch [721/1124]\n",
            " Patch [722/1124]\n",
            " Patch [723/1124]\n",
            " Patch [724/1124]\n",
            " Patch [725/1124]\n",
            " Patch [726/1124]\n",
            " Patch [727/1124]\n",
            " Patch [728/1124]\n",
            " Patch [729/1124]\n",
            " Patch [730/1124]\n",
            " Patch [731/1124]\n",
            " Patch [732/1124]\n",
            " Patch [733/1124]\n",
            " Patch [734/1124]\n",
            " Patch [735/1124]\n",
            " Patch [736/1124]\n",
            " Patch [737/1124]\n",
            " Patch [738/1124]\n",
            " Patch [739/1124]\n",
            " Patch [740/1124]\n",
            " Patch [741/1124]\n",
            " Patch [742/1124]\n",
            " Patch [743/1124]\n",
            " Patch [744/1124]\n",
            " Patch [745/1124]\n",
            " Patch [746/1124]\n",
            " Patch [747/1124]\n",
            " Patch [748/1124]\n",
            " Patch [749/1124]\n",
            " Patch [750/1124]\n",
            " Patch [751/1124]\n",
            " Patch [752/1124]\n",
            " Patch [753/1124]\n",
            " Patch [754/1124]\n",
            " Patch [755/1124]\n",
            " Patch [756/1124]\n",
            " Patch [757/1124]\n",
            " Patch [758/1124]\n",
            " Patch [759/1124]\n",
            " Patch [760/1124]\n",
            " Patch [761/1124]\n",
            " Patch [762/1124]\n",
            " Patch [763/1124]\n",
            " Patch [764/1124]\n",
            " Patch [765/1124]\n",
            " Patch [766/1124]\n",
            " Patch [767/1124]\n",
            " Patch [768/1124]\n",
            " Patch [769/1124]\n",
            " Patch [770/1124]\n",
            " Patch [771/1124]\n",
            " Patch [772/1124]\n",
            " Patch [773/1124]\n",
            " Patch [774/1124]\n",
            " Patch [775/1124]\n",
            " Patch [776/1124]\n",
            " Patch [777/1124]\n",
            " Patch [778/1124]\n",
            " Patch [779/1124]\n",
            " Patch [780/1124]\n",
            " Patch [781/1124]\n",
            " Patch [782/1124]\n",
            " Patch [783/1124]\n",
            " Patch [784/1124]\n",
            " Patch [785/1124]\n",
            " Patch [786/1124]\n",
            " Patch [787/1124]\n",
            " Patch [788/1124]\n",
            " Patch [789/1124]\n",
            " Patch [790/1124]\n",
            " Patch [791/1124]\n",
            " Patch [792/1124]\n",
            " Patch [793/1124]\n",
            " Patch [794/1124]\n",
            " Patch [795/1124]\n",
            " Patch [796/1124]\n",
            " Patch [797/1124]\n",
            " Patch [798/1124]\n",
            " Patch [799/1124]\n",
            " Patch [800/1124]\n",
            " Patch [801/1124]\n",
            " Patch [802/1124]\n",
            " Patch [803/1124]\n",
            " Patch [804/1124]\n",
            " Patch [805/1124]\n",
            " Patch [806/1124]\n",
            " Patch [807/1124]\n",
            " Patch [808/1124]\n",
            " Patch [809/1124]\n",
            " Patch [810/1124]\n",
            " Patch [811/1124]\n",
            " Patch [812/1124]\n",
            " Patch [813/1124]\n",
            " Patch [814/1124]\n",
            " Patch [815/1124]\n",
            " Patch [816/1124]\n",
            " Patch [817/1124]\n",
            " Patch [818/1124]\n",
            " Patch [819/1124]\n",
            " Patch [820/1124]\n",
            " Patch [821/1124]\n",
            " Patch [822/1124]\n",
            " Patch [823/1124]\n",
            " Patch [824/1124]\n",
            " Patch [825/1124]\n",
            " Patch [826/1124]\n",
            " Patch [827/1124]\n",
            " Patch [828/1124]\n",
            " Patch [829/1124]\n",
            " Patch [830/1124]\n",
            " Patch [831/1124]\n",
            " Patch [832/1124]\n",
            " Patch [833/1124]\n",
            " Patch [834/1124]\n",
            " Patch [835/1124]\n",
            " Patch [836/1124]\n",
            " Patch [837/1124]\n",
            " Patch [838/1124]\n",
            " Patch [839/1124]\n",
            " Patch [840/1124]\n",
            " Patch [841/1124]\n",
            " Patch [842/1124]\n",
            " Patch [843/1124]\n",
            " Patch [844/1124]\n",
            " Patch [845/1124]\n",
            " Patch [846/1124]\n",
            " Patch [847/1124]\n",
            " Patch [848/1124]\n",
            " Patch [849/1124]\n",
            " Patch [850/1124]\n",
            " Patch [851/1124]\n",
            " Patch [852/1124]\n",
            " Patch [853/1124]\n",
            " Patch [854/1124]\n",
            " Patch [855/1124]\n",
            " Patch [856/1124]\n",
            " Patch [857/1124]\n",
            " Patch [858/1124]\n",
            " Patch [859/1124]\n",
            " Patch [860/1124]\n",
            " Patch [861/1124]\n",
            " Patch [862/1124]\n",
            " Patch [863/1124]\n",
            " Patch [864/1124]\n",
            " Patch [865/1124]\n",
            " Patch [866/1124]\n",
            " Patch [867/1124]\n",
            " Patch [868/1124]\n",
            " Patch [869/1124]\n",
            " Patch [870/1124]\n",
            " Patch [871/1124]\n",
            " Patch [872/1124]\n",
            " Patch [873/1124]\n",
            " Patch [874/1124]\n",
            " Patch [875/1124]\n",
            " Patch [876/1124]\n",
            " Patch [877/1124]\n",
            " Patch [878/1124]\n",
            " Patch [879/1124]\n",
            " Patch [880/1124]\n",
            " Patch [881/1124]\n",
            " Patch [882/1124]\n",
            " Patch [883/1124]\n",
            " Patch [884/1124]\n",
            " Patch [885/1124]\n",
            " Patch [886/1124]\n",
            " Patch [887/1124]\n",
            " Patch [888/1124]\n",
            " Patch [889/1124]\n",
            " Patch [890/1124]\n",
            " Patch [891/1124]\n",
            " Patch [892/1124]\n",
            " Patch [893/1124]\n",
            " Patch [894/1124]\n",
            " Patch [895/1124]\n",
            " Patch [896/1124]\n",
            " Patch [897/1124]\n",
            " Patch [898/1124]\n",
            " Patch [899/1124]\n",
            " Patch [900/1124]\n",
            " Patch [901/1124]\n",
            " Patch [902/1124]\n",
            " Patch [903/1124]\n",
            " Patch [904/1124]\n",
            " Patch [905/1124]\n",
            " Patch [906/1124]\n",
            " Patch [907/1124]\n",
            " Patch [908/1124]\n",
            " Patch [909/1124]\n",
            " Patch [910/1124]\n",
            " Patch [911/1124]\n",
            " Patch [912/1124]\n",
            " Patch [913/1124]\n",
            " Patch [914/1124]\n",
            " Patch [915/1124]\n",
            " Patch [916/1124]\n",
            " Patch [917/1124]\n",
            " Patch [918/1124]\n",
            " Patch [919/1124]\n",
            " Patch [920/1124]\n",
            " Patch [921/1124]\n",
            " Patch [922/1124]\n",
            " Patch [923/1124]\n",
            " Patch [924/1124]\n",
            " Patch [925/1124]\n",
            " Patch [926/1124]\n",
            " Patch [927/1124]\n",
            " Patch [928/1124]\n",
            " Patch [929/1124]\n",
            " Patch [930/1124]\n",
            " Patch [931/1124]\n",
            " Patch [932/1124]\n",
            " Patch [933/1124]\n",
            " Patch [934/1124]\n",
            " Patch [935/1124]\n",
            " Patch [936/1124]\n",
            " Patch [937/1124]\n",
            " Patch [938/1124]\n",
            " Patch [939/1124]\n",
            " Patch [940/1124]\n",
            " Patch [941/1124]\n",
            " Patch [942/1124]\n",
            " Patch [943/1124]\n",
            " Patch [944/1124]\n",
            " Patch [945/1124]\n",
            " Patch [946/1124]\n",
            " Patch [947/1124]\n",
            " Patch [948/1124]\n",
            " Patch [949/1124]\n",
            " Patch [950/1124]\n",
            " Patch [951/1124]\n",
            " Patch [952/1124]\n",
            " Patch [953/1124]\n",
            " Patch [954/1124]\n",
            " Patch [955/1124]\n",
            " Patch [956/1124]\n",
            " Patch [957/1124]\n",
            " Patch [958/1124]\n",
            " Patch [959/1124]\n",
            " Patch [960/1124]\n",
            " Patch [961/1124]\n",
            " Patch [962/1124]\n",
            " Patch [963/1124]\n",
            " Patch [964/1124]\n",
            " Patch [965/1124]\n",
            " Patch [966/1124]\n",
            " Patch [967/1124]\n",
            " Patch [968/1124]\n",
            " Patch [969/1124]\n",
            " Patch [970/1124]\n",
            " Patch [971/1124]\n",
            " Patch [972/1124]\n",
            " Patch [973/1124]\n",
            " Patch [974/1124]\n",
            " Patch [975/1124]\n",
            " Patch [976/1124]\n",
            " Patch [977/1124]\n",
            " Patch [978/1124]\n",
            " Patch [979/1124]\n",
            " Patch [980/1124]\n",
            " Patch [981/1124]\n",
            " Patch [982/1124]\n",
            " Patch [983/1124]\n",
            " Patch [984/1124]\n",
            " Patch [985/1124]\n",
            " Patch [986/1124]\n",
            " Patch [987/1124]\n",
            " Patch [988/1124]\n",
            " Patch [989/1124]\n",
            " Patch [990/1124]\n",
            " Patch [991/1124]\n",
            " Patch [992/1124]\n",
            " Patch [993/1124]\n",
            " Patch [994/1124]\n",
            " Patch [995/1124]\n",
            " Patch [996/1124]\n",
            " Patch [997/1124]\n",
            " Patch [998/1124]\n",
            " Patch [999/1124]\n",
            " Patch [1000/1124]\n",
            " Patch [1001/1124]\n",
            " Patch [1002/1124]\n",
            " Patch [1003/1124]\n",
            " Patch [1004/1124]\n",
            " Patch [1005/1124]\n",
            " Patch [1006/1124]\n",
            " Patch [1007/1124]\n",
            " Patch [1008/1124]\n",
            " Patch [1009/1124]\n",
            " Patch [1010/1124]\n",
            " Patch [1011/1124]\n",
            " Patch [1012/1124]\n",
            " Patch [1013/1124]\n",
            " Patch [1014/1124]\n",
            " Patch [1015/1124]\n",
            " Patch [1016/1124]\n",
            " Patch [1017/1124]\n",
            " Patch [1018/1124]\n",
            " Patch [1019/1124]\n",
            " Patch [1020/1124]\n",
            " Patch [1021/1124]\n",
            " Patch [1022/1124]\n",
            " Patch [1023/1124]\n",
            " Patch [1024/1124]\n",
            " Patch [1025/1124]\n",
            " Patch [1026/1124]\n",
            " Patch [1027/1124]\n",
            " Patch [1028/1124]\n",
            " Patch [1029/1124]\n",
            " Patch [1030/1124]\n",
            " Patch [1031/1124]\n",
            " Patch [1032/1124]\n",
            " Patch [1033/1124]\n",
            " Patch [1034/1124]\n",
            " Patch [1035/1124]\n",
            " Patch [1036/1124]\n",
            " Patch [1037/1124]\n",
            " Patch [1038/1124]\n",
            " Patch [1039/1124]\n",
            " Patch [1040/1124]\n",
            " Patch [1041/1124]\n",
            " Patch [1042/1124]\n",
            " Patch [1043/1124]\n",
            " Patch [1044/1124]\n",
            " Patch [1045/1124]\n",
            " Patch [1046/1124]\n",
            " Patch [1047/1124]\n",
            " Patch [1048/1124]\n",
            " Patch [1049/1124]\n",
            " Patch [1050/1124]\n",
            " Patch [1051/1124]\n",
            " Patch [1052/1124]\n",
            " Patch [1053/1124]\n",
            " Patch [1054/1124]\n",
            " Patch [1055/1124]\n",
            " Patch [1056/1124]\n",
            " Patch [1057/1124]\n",
            " Patch [1058/1124]\n",
            " Patch [1059/1124]\n",
            " Patch [1060/1124]\n",
            " Patch [1061/1124]\n",
            " Patch [1062/1124]\n",
            " Patch [1063/1124]\n",
            " Patch [1064/1124]\n",
            " Patch [1065/1124]\n",
            " Patch [1066/1124]\n",
            " Patch [1067/1124]\n",
            " Patch [1068/1124]\n",
            " Patch [1069/1124]\n",
            " Patch [1070/1124]\n",
            " Patch [1071/1124]\n",
            " Patch [1072/1124]\n",
            " Patch [1073/1124]\n",
            " Patch [1074/1124]\n",
            " Patch [1075/1124]\n",
            " Patch [1076/1124]\n",
            " Patch [1077/1124]\n",
            " Patch [1078/1124]\n",
            " Patch [1079/1124]\n",
            " Patch [1080/1124]\n",
            " Patch [1081/1124]\n",
            " Patch [1082/1124]\n",
            " Patch [1083/1124]\n",
            " Patch [1084/1124]\n",
            " Patch [1085/1124]\n",
            " Patch [1086/1124]\n",
            " Patch [1087/1124]\n",
            " Patch [1088/1124]\n",
            " Patch [1089/1124]\n",
            " Patch [1090/1124]\n",
            " Patch [1091/1124]\n",
            " Patch [1092/1124]\n",
            " Patch [1093/1124]\n",
            " Patch [1094/1124]\n",
            " Patch [1095/1124]\n",
            " Patch [1096/1124]\n",
            " Patch [1097/1124]\n",
            " Patch [1098/1124]\n",
            " Patch [1099/1124]\n",
            " Patch [1100/1124]\n",
            " Patch [1101/1124]\n",
            " Patch [1102/1124]\n",
            " Patch [1103/1124]\n",
            " Patch [1104/1124]\n",
            " Patch [1105/1124]\n",
            " Patch [1106/1124]\n",
            " Patch [1107/1124]\n",
            " Patch [1108/1124]\n",
            " Patch [1109/1124]\n",
            " Patch [1110/1124]\n",
            " Patch [1111/1124]\n",
            " Patch [1112/1124]\n",
            " Patch [1113/1124]\n",
            " Patch [1114/1124]\n",
            " Patch [1115/1124]\n",
            " Patch [1116/1124]\n",
            " Patch [1117/1124]\n",
            " Patch [1118/1124]\n",
            " Patch [1119/1124]\n",
            " Patch [1120/1124]\n",
            " Patch [1121/1124]\n",
            " Patch [1122/1124]\n",
            " Patch [1123/1124]\n",
            " Patch [1124/1124]Done.\n",
            "Patch extraction done for 22 slides.\n",
            "\n",
            "Tiling slide: wrote 100/45860 tiles\n",
            "Tiling slide: wrote 200/45860 tiles\n",
            "Tiling slide: wrote 300/45860 tiles\n",
            "Tiling slide: wrote 400/45860 tiles\n",
            "Tiling slide: wrote 500/45860 tiles\n",
            "Tiling slide: wrote 600/45860 tiles\n",
            "Tiling slide: wrote 700/45860 tiles\n",
            "Tiling slide: wrote 800/45860 tiles\n",
            "Tiling slide: wrote 900/45860 tiles\n",
            "Tiling slide: wrote 1000/45860 tiles\n",
            "Tiling slide: wrote 1100/45860 tiles\n",
            "Tiling slide: wrote 1200/45860 tiles\n",
            "Tiling slide: wrote 1300/45860 tiles\n",
            "Tiling slide: wrote 1400/45860 tiles\n",
            "Tiling slide: wrote 1500/45860 tiles\n",
            "Tiling slide: wrote 1600/45860 tiles\n",
            "Tiling slide: wrote 1700/45860 tiles\n",
            "Tiling slide: wrote 1800/45860 tiles\n",
            "Tiling slide: wrote 1900/45860 tiles\n",
            "Tiling slide: wrote 2000/45860 tiles\n",
            "Tiling slide: wrote 2100/45860 tiles\n",
            "Tiling slide: wrote 2200/45860 tiles\n",
            "Tiling slide: wrote 2300/45860 tiles\n",
            "Tiling slide: wrote 2400/45860 tiles\n",
            "Tiling slide: wrote 2500/45860 tiles\n",
            "Tiling slide: wrote 2600/45860 tiles\n",
            "Tiling slide: wrote 2700/45860 tiles\n",
            "Tiling slide: wrote 2800/45860 tiles\n",
            "Tiling slide: wrote 2900/45860 tiles\n",
            "Tiling slide: wrote 3000/45860 tiles\n",
            "Tiling slide: wrote 3100/45860 tiles\n",
            "Tiling slide: wrote 3200/45860 tiles\n",
            "Tiling slide: wrote 3300/45860 tiles\n",
            "Tiling slide: wrote 3400/45860 tiles\n",
            "Tiling slide: wrote 3500/45860 tiles\n",
            "Tiling slide: wrote 3600/45860 tiles\n",
            "Tiling slide: wrote 3700/45860 tiles\n",
            "Tiling slide: wrote 3800/45860 tiles\n",
            "Tiling slide: wrote 3900/45860 tiles\n",
            "Tiling slide: wrote 4000/45860 tiles\n",
            "Tiling slide: wrote 4100/45860 tiles\n",
            "Tiling slide: wrote 4200/45860 tiles\n",
            "Tiling slide: wrote 4300/45860 tiles\n",
            "Tiling slide: wrote 4400/45860 tiles\n",
            "Tiling slide: wrote 4500/45860 tiles\n",
            "Tiling slide: wrote 4600/45860 tiles\n",
            "Tiling slide: wrote 4700/45860 tiles\n",
            "Tiling slide: wrote 4800/45860 tiles\n",
            "Tiling slide: wrote 4900/45860 tiles\n",
            "Tiling slide: wrote 5000/45860 tiles\n",
            "Tiling slide: wrote 5100/45860 tiles\n",
            "Tiling slide: wrote 5200/45860 tiles\n",
            "Tiling slide: wrote 5300/45860 tiles\n",
            "Tiling slide: wrote 5400/45860 tiles\n",
            "Tiling slide: wrote 5500/45860 tiles\n",
            "Tiling slide: wrote 5600/45860 tiles\n",
            "Tiling slide: wrote 5700/45860 tiles\n",
            "Tiling slide: wrote 5800/45860 tiles\n",
            "Tiling slide: wrote 5900/45860 tiles\n",
            "Tiling slide: wrote 6000/45860 tiles\n",
            "Tiling slide: wrote 6100/45860 tiles\n",
            "Tiling slide: wrote 6200/45860 tiles\n",
            "Tiling slide: wrote 6300/45860 tiles\n",
            "Tiling slide: wrote 6400/45860 tiles\n",
            "Tiling slide: wrote 6500/45860 tiles\n",
            "Tiling slide: wrote 6600/45860 tiles\n",
            "Tiling slide: wrote 6700/45860 tiles\n",
            "Tiling slide: wrote 6800/45860 tiles\n",
            "Tiling slide: wrote 6900/45860 tiles\n",
            "Tiling slide: wrote 7000/45860 tiles\n",
            "Tiling slide: wrote 7100/45860 tiles\n",
            "Tiling slide: wrote 7200/45860 tiles\n",
            "Tiling slide: wrote 7300/45860 tiles\n",
            "Tiling slide: wrote 7400/45860 tiles\n",
            "Tiling slide: wrote 7500/45860 tiles\n",
            "Tiling slide: wrote 7600/45860 tiles\n",
            "Tiling slide: wrote 7700/45860 tiles\n",
            "Tiling slide: wrote 7800/45860 tiles\n",
            "Tiling slide: wrote 7900/45860 tiles\n",
            "Tiling slide: wrote 8000/45860 tiles\n",
            "Tiling slide: wrote 8100/45860 tiles\n",
            "Tiling slide: wrote 8200/45860 tiles\n",
            "Tiling slide: wrote 8300/45860 tiles\n",
            "Tiling slide: wrote 8400/45860 tiles\n",
            "Tiling slide: wrote 8500/45860 tiles\n",
            "Tiling slide: wrote 8600/45860 tiles\n",
            "Tiling slide: wrote 100/61697 tiles\n",
            "Tiling slide: wrote 200/61697 tiles\n",
            "Tiling slide: wrote 300/61697 tiles\n",
            "Tiling slide: wrote 400/61697 tiles\n",
            "Tiling slide: wrote 500/61697 tiles\n",
            "Tiling slide: wrote 600/61697 tiles\n",
            "Tiling slide: wrote 700/61697 tiles\n",
            "Tiling slide: wrote 800/61697 tiles\n",
            "Tiling slide: wrote 900/61697 tiles\n",
            "Tiling slide: wrote 1000/61697 tiles\n",
            "Tiling slide: wrote 1100/61697 tiles\n",
            "Tiling slide: wrote 1200/61697 tiles\n",
            "Tiling slide: wrote 1300/61697 tiles\n",
            "Tiling slide: wrote 1400/61697 tiles\n",
            "Tiling slide: wrote 1500/61697 tiles\n",
            "Tiling slide: wrote 1600/61697 tiles\n",
            "Tiling slide: wrote 1700/61697 tiles\n",
            "Tiling slide: wrote 1800/61697 tiles\n",
            "Tiling slide: wrote 1900/61697 tiles\n",
            "Tiling slide: wrote 2000/61697 tiles\n",
            "Tiling slide: wrote 2100/61697 tiles\n",
            "Tiling slide: wrote 2200/61697 tiles\n",
            "Tiling slide: wrote 2300/61697 tiles\n",
            "Tiling slide: wrote 2400/61697 tiles\n",
            "Tiling slide: wrote 2500/61697 tiles\n",
            "Tiling slide: wrote 2600/61697 tiles\n",
            "Tiling slide: wrote 2700/61697 tiles\n",
            "Tiling slide: wrote 2800/61697 tiles\n",
            "Tiling slide: wrote 2900/61697 tiles\n",
            "Tiling slide: wrote 3000/61697 tiles\n",
            "Tiling slide: wrote 3100/61697 tiles\n",
            "Tiling slide: wrote 3200/61697 tiles\n",
            "Tiling slide: wrote 3300/61697 tiles\n",
            "Tiling slide: wrote 3400/61697 tiles\n",
            "Tiling slide: wrote 3500/61697 tiles\n",
            "Tiling slide: wrote 3600/61697 tiles\n",
            "Tiling slide: wrote 3700/61697 tiles\n",
            "Tiling slide: wrote 3800/61697 tiles\n",
            "Tiling slide: wrote 3900/61697 tiles\n",
            "Tiling slide: wrote 4000/61697 tiles\n",
            "Tiling slide: wrote 4100/61697 tiles\n",
            "Tiling slide: wrote 4200/61697 tiles\n",
            "Tiling slide: wrote 4300/61697 tiles\n",
            "Tiling slide: wrote 4400/61697 tiles\n",
            "Tiling slide: wrote 4500/61697 tiles\n",
            "Tiling slide: wrote 4600/61697 tiles\n",
            "Tiling slide: wrote 4700/61697 tiles\n",
            "Tiling slide: wrote 4800/61697 tiles\n",
            "Tiling slide: wrote 4900/61697 tiles\n",
            "Tiling slide: wrote 5000/61697 tiles\n",
            "Tiling slide: wrote 5100/61697 tiles\n",
            "Tiling slide: wrote 5200/61697 tiles\n",
            "Tiling slide: wrote 5300/61697 tiles\n",
            "Tiling slide: wrote 5400/61697 tiles\n",
            "Tiling slide: wrote 5500/61697 tiles\n",
            "Tiling slide: wrote 5600/61697 tiles\n",
            "Tiling slide: wrote 5700/61697 tiles\n",
            "Tiling slide: wrote 5800/61697 tiles\n",
            "Tiling slide: wrote 5900/61697 tiles\n",
            "Tiling slide: wrote 6000/61697 tiles\n",
            "Tiling slide: wrote 6100/61697 tiles\n",
            "Tiling slide: wrote 6200/61697 tiles\n",
            "Tiling slide: wrote 6300/61697 tiles\n",
            "Tiling slide: wrote 6400/61697 tiles\n",
            "Tiling slide: wrote 6500/61697 tiles\n",
            "Tiling slide: wrote 6600/61697 tiles\n",
            "Tiling slide: wrote 6700/61697 tiles\n",
            "Tiling slide: wrote 6800/61697 tiles\n",
            "Tiling slide: wrote 6900/61697 tiles\n",
            "Tiling slide: wrote 7000/61697 tiles\n",
            "Tiling slide: wrote 7100/61697 tiles\n",
            "Tiling slide: wrote 7200/61697 tiles\n",
            "Tiling slide: wrote 7300/61697 tiles\n",
            "Tiling slide: wrote 7400/61697 tiles\n",
            "Tiling slide: wrote 7500/61697 tiles\n",
            "Tiling slide: wrote 7600/61697 tiles\n",
            "Tiling slide: wrote 7700/61697 tiles\n",
            "Tiling slide: wrote 7800/61697 tiles\n",
            "Tiling slide: wrote 7900/61697 tiles\n",
            "Tiling slide: wrote 8000/61697 tiles\n",
            "Tiling slide: wrote 8100/61697 tiles\n",
            "Tiling slide: wrote 8200/61697 tiles\n",
            "Tiling slide: wrote 8300/61697 tiles\n",
            "Tiling slide: wrote 8400/61697 tiles\n",
            "Tiling slide: wrote 8500/61697 tiles\n",
            "Tiling slide: wrote 8600/61697 tiles\n",
            "Tiling slide: wrote 8700/61697 tiles\n",
            "Tiling slide: wrote 8800/61697 tiles\n",
            "Tiling slide: wrote 8900/61697 tiles\n",
            "Tiling slide: wrote 9000/61697 tiles\n",
            "Tiling slide: wrote 9100/61697 tiles\n",
            "Tiling slide: wrote 9200/61697 tiles\n",
            "Tiling slide: wrote 9300/61697 tiles\n",
            "Tiling slide: wrote 9400/61697 tiles\n",
            "Tiling slide: wrote 9500/61697 tiles\n",
            "Tiling slide: wrote 9600/61697 tiles\n",
            "Tiling slide: wrote 9700/61697 tiles\n",
            "Tiling slide: wrote 9800/61697 tiles\n",
            "Tiling slide: wrote 9900/61697 tiles\n",
            "Tiling slide: wrote 10000/61697 tiles\n",
            "Tiling slide: wrote 10100/61697 tiles\n",
            "Tiling slide: wrote 10200/61697 tiles\n",
            "Tiling slide: wrote 10300/61697 tiles\n",
            "Tiling slide: wrote 10400/61697 tiles\n",
            "Tiling slide: wrote 10500/61697 tiles\n",
            "Tiling slide: wrote 10600/61697 tiles\n",
            "Tiling slide: wrote 10700/61697 tiles\n",
            "Tiling slide: wrote 10800/61697 tiles\n",
            "Tiling slide: wrote 10900/61697 tiles\n",
            "Tiling slide: wrote 11000/61697 tiles\n",
            "Tiling slide: wrote 11100/61697 tiles\n",
            "Tiling slide: wrote 11200/61697 tiles\n",
            "Tiling slide: wrote 11300/61697 tiles\n",
            "Tiling slide: wrote 11400/61697 tiles\n",
            "Tiling slide: wrote 11500/61697 tiles\n",
            "Tiling slide: wrote 100/19035 tiles\n",
            "Tiling slide: wrote 200/19035 tiles\n",
            "Tiling slide: wrote 300/19035 tiles\n",
            "Tiling slide: wrote 400/19035 tiles\n",
            "Tiling slide: wrote 500/19035 tiles\n",
            "Tiling slide: wrote 600/19035 tiles\n",
            "Tiling slide: wrote 700/19035 tiles\n",
            "Tiling slide: wrote 800/19035 tiles\n",
            "Tiling slide: wrote 900/19035 tiles\n",
            "Tiling slide: wrote 1000/19035 tiles\n",
            "Tiling slide: wrote 1100/19035 tiles\n",
            "Tiling slide: wrote 1200/19035 tiles\n",
            "Tiling slide: wrote 1300/19035 tiles\n",
            "Tiling slide: wrote 1400/19035 tiles\n",
            "Tiling slide: wrote 1500/19035 tiles\n",
            "Tiling slide: wrote 1600/19035 tiles\n",
            "Tiling slide: wrote 1700/19035 tiles\n",
            "Tiling slide: wrote 1800/19035 tiles\n",
            "Tiling slide: wrote 1900/19035 tiles\n",
            "Tiling slide: wrote 2000/19035 tiles\n",
            "Tiling slide: wrote 2100/19035 tiles\n",
            "Tiling slide: wrote 2200/19035 tiles\n",
            "Tiling slide: wrote 2300/19035 tiles\n",
            "Tiling slide: wrote 2400/19035 tiles\n",
            "Tiling slide: wrote 2500/19035 tiles\n",
            "Tiling slide: wrote 2600/19035 tiles\n",
            "Tiling slide: wrote 2700/19035 tiles\n",
            "Tiling slide: wrote 2800/19035 tiles\n",
            "Tiling slide: wrote 2900/19035 tiles\n",
            "Tiling slide: wrote 3000/19035 tiles\n",
            "Tiling slide: wrote 3100/19035 tiles\n",
            "Tiling slide: wrote 3200/19035 tiles\n",
            "Tiling slide: wrote 3300/19035 tiles\n",
            "Tiling slide: wrote 3400/19035 tiles\n",
            "Tiling slide: wrote 3500/19035 tiles\n",
            "Tiling slide: wrote 3600/19035 tiles\n",
            "Tiling slide: wrote 100/24946 tiles\n",
            "Tiling slide: wrote 200/24946 tiles\n",
            "Tiling slide: wrote 300/24946 tiles\n",
            "Tiling slide: wrote 400/24946 tiles\n",
            "Tiling slide: wrote 500/24946 tiles\n",
            "Tiling slide: wrote 600/24946 tiles\n",
            "Tiling slide: wrote 700/24946 tiles\n",
            "Tiling slide: wrote 800/24946 tiles\n",
            "Tiling slide: wrote 900/24946 tiles\n",
            "Tiling slide: wrote 1000/24946 tiles\n",
            "Tiling slide: wrote 1100/24946 tiles\n",
            "Tiling slide: wrote 1200/24946 tiles\n",
            "Tiling slide: wrote 1300/24946 tiles\n",
            "Tiling slide: wrote 1400/24946 tiles\n",
            "Tiling slide: wrote 1500/24946 tiles\n",
            "Tiling slide: wrote 1600/24946 tiles\n",
            "Tiling slide: wrote 1700/24946 tiles\n",
            "Tiling slide: wrote 1800/24946 tiles\n",
            "Tiling slide: wrote 1900/24946 tiles\n",
            "Tiling slide: wrote 2000/24946 tiles\n",
            "Tiling slide: wrote 2100/24946 tiles\n",
            "Tiling slide: wrote 2200/24946 tiles\n",
            "Tiling slide: wrote 2300/24946 tiles\n",
            "Tiling slide: wrote 2400/24946 tiles\n",
            "Tiling slide: wrote 2500/24946 tiles\n",
            "Tiling slide: wrote 2600/24946 tiles\n",
            "Tiling slide: wrote 2700/24946 tiles\n",
            "Tiling slide: wrote 2800/24946 tiles\n",
            "Tiling slide: wrote 2900/24946 tiles\n",
            "Tiling slide: wrote 3000/24946 tiles\n",
            "Tiling slide: wrote 3100/24946 tiles\n",
            "Tiling slide: wrote 3200/24946 tiles\n",
            "Tiling slide: wrote 3300/24946 tiles\n",
            "Tiling slide: wrote 3400/24946 tiles\n",
            "Tiling slide: wrote 3500/24946 tiles\n",
            "Tiling slide: wrote 3600/24946 tiles\n",
            "Tiling slide: wrote 3700/24946 tiles\n",
            "Tiling slide: wrote 3800/24946 tiles\n",
            "Tiling slide: wrote 3900/24946 tiles\n",
            "Tiling slide: wrote 4000/24946 tiles\n",
            "Tiling slide: wrote 4100/24946 tiles\n",
            "Tiling slide: wrote 4200/24946 tiles\n",
            "Tiling slide: wrote 4300/24946 tiles\n",
            "Tiling slide: wrote 4400/24946 tiles\n",
            "Tiling slide: wrote 4500/24946 tiles\n",
            "Tiling slide: wrote 4600/24946 tiles\n",
            "Tiling slide: wrote 100/22129 tiles\n",
            "Tiling slide: wrote 200/22129 tiles\n",
            "Tiling slide: wrote 300/22129 tiles\n",
            "Tiling slide: wrote 400/22129 tiles\n",
            "Tiling slide: wrote 500/22129 tiles\n",
            "Tiling slide: wrote 600/22129 tiles\n",
            "Tiling slide: wrote 700/22129 tiles\n",
            "Tiling slide: wrote 800/22129 tiles\n",
            "Tiling slide: wrote 900/22129 tiles\n",
            "Tiling slide: wrote 1000/22129 tiles\n",
            "Tiling slide: wrote 1100/22129 tiles\n",
            "Tiling slide: wrote 1200/22129 tiles\n",
            "Tiling slide: wrote 1300/22129 tiles\n",
            "Tiling slide: wrote 1400/22129 tiles\n",
            "Tiling slide: wrote 1500/22129 tiles\n",
            "Tiling slide: wrote 1600/22129 tiles\n",
            "Tiling slide: wrote 1700/22129 tiles\n",
            "Tiling slide: wrote 1800/22129 tiles\n",
            "Tiling slide: wrote 1900/22129 tiles\n",
            "Tiling slide: wrote 2000/22129 tiles\n",
            "Tiling slide: wrote 2100/22129 tiles\n",
            "Tiling slide: wrote 2200/22129 tiles\n",
            "Tiling slide: wrote 2300/22129 tiles\n",
            "Tiling slide: wrote 2400/22129 tiles\n",
            "Tiling slide: wrote 2500/22129 tiles\n",
            "Tiling slide: wrote 2600/22129 tiles\n",
            "Tiling slide: wrote 2700/22129 tiles\n",
            "Tiling slide: wrote 2800/22129 tiles\n",
            "Tiling slide: wrote 2900/22129 tiles\n",
            "Tiling slide: wrote 3000/22129 tiles\n",
            "Tiling slide: wrote 3100/22129 tiles\n",
            "Tiling slide: wrote 3200/22129 tiles\n",
            "Tiling slide: wrote 3300/22129 tiles\n",
            "Tiling slide: wrote 3400/22129 tiles\n",
            "Tiling slide: wrote 3500/22129 tiles\n",
            "Tiling slide: wrote 3600/22129 tiles\n",
            "Tiling slide: wrote 3700/22129 tiles\n",
            "Tiling slide: wrote 3800/22129 tiles\n",
            "Tiling slide: wrote 3900/22129 tiles\n",
            "Tiling slide: wrote 4000/22129 tiles\n",
            "Tiling slide: wrote 4100/22129 tiles\n",
            "Tiling slide: wrote 100/7784 tiles\n",
            "Tiling slide: wrote 200/7784 tiles\n",
            "Tiling slide: wrote 300/7784 tiles\n",
            "Tiling slide: wrote 400/7784 tiles\n",
            "Tiling slide: wrote 500/7784 tiles\n",
            "Tiling slide: wrote 600/7784 tiles\n",
            "Tiling slide: wrote 700/7784 tiles\n",
            "Tiling slide: wrote 800/7784 tiles\n",
            "Tiling slide: wrote 900/7784 tiles\n",
            "Tiling slide: wrote 1000/7784 tiles\n",
            "Tiling slide: wrote 1100/7784 tiles\n",
            "Tiling slide: wrote 1200/7784 tiles\n",
            "Tiling slide: wrote 1300/7784 tiles\n",
            "Tiling slide: wrote 1400/7784 tiles\n",
            "Tiling slide: wrote 100/61697 tiles\n",
            "Tiling slide: wrote 200/61697 tiles\n",
            "Tiling slide: wrote 300/61697 tiles\n",
            "Tiling slide: wrote 400/61697 tiles\n",
            "Tiling slide: wrote 500/61697 tiles\n",
            "Tiling slide: wrote 600/61697 tiles\n",
            "Tiling slide: wrote 700/61697 tiles\n",
            "Tiling slide: wrote 800/61697 tiles\n",
            "Tiling slide: wrote 900/61697 tiles\n",
            "Tiling slide: wrote 1000/61697 tiles\n",
            "Tiling slide: wrote 1100/61697 tiles\n",
            "Tiling slide: wrote 1200/61697 tiles\n",
            "Tiling slide: wrote 1300/61697 tiles\n",
            "Tiling slide: wrote 1400/61697 tiles\n",
            "Tiling slide: wrote 1500/61697 tiles\n",
            "Tiling slide: wrote 1600/61697 tiles\n",
            "Tiling slide: wrote 1700/61697 tiles\n",
            "Tiling slide: wrote 1800/61697 tiles\n",
            "Tiling slide: wrote 1900/61697 tiles\n",
            "Tiling slide: wrote 2000/61697 tiles\n",
            "Tiling slide: wrote 2100/61697 tiles\n",
            "Tiling slide: wrote 2200/61697 tiles\n",
            "Tiling slide: wrote 2300/61697 tiles\n",
            "Tiling slide: wrote 2400/61697 tiles\n",
            "Tiling slide: wrote 2500/61697 tiles\n",
            "Tiling slide: wrote 2600/61697 tiles\n",
            "Tiling slide: wrote 2700/61697 tiles\n",
            "Tiling slide: wrote 2800/61697 tiles\n",
            "Tiling slide: wrote 2900/61697 tiles\n",
            "Tiling slide: wrote 3000/61697 tiles\n",
            "Tiling slide: wrote 3100/61697 tiles\n",
            "Tiling slide: wrote 3200/61697 tiles\n",
            "Tiling slide: wrote 3300/61697 tiles\n",
            "Tiling slide: wrote 3400/61697 tiles\n",
            "Tiling slide: wrote 3500/61697 tiles\n",
            "Tiling slide: wrote 3600/61697 tiles\n",
            "Tiling slide: wrote 3700/61697 tiles\n",
            "Tiling slide: wrote 3800/61697 tiles\n",
            "Tiling slide: wrote 3900/61697 tiles\n",
            "Tiling slide: wrote 4000/61697 tiles\n",
            "Tiling slide: wrote 4100/61697 tiles\n",
            "Tiling slide: wrote 4200/61697 tiles\n",
            "Tiling slide: wrote 4300/61697 tiles\n",
            "Tiling slide: wrote 4400/61697 tiles\n",
            "Tiling slide: wrote 4500/61697 tiles\n",
            "Tiling slide: wrote 4600/61697 tiles\n",
            "Tiling slide: wrote 4700/61697 tiles\n",
            "Tiling slide: wrote 4800/61697 tiles\n",
            "Tiling slide: wrote 4900/61697 tiles\n",
            "Tiling slide: wrote 5000/61697 tiles\n",
            "Tiling slide: wrote 5100/61697 tiles\n",
            "Tiling slide: wrote 5200/61697 tiles\n",
            "Tiling slide: wrote 5300/61697 tiles\n",
            "Tiling slide: wrote 5400/61697 tiles\n",
            "Tiling slide: wrote 5500/61697 tiles\n",
            "Tiling slide: wrote 5600/61697 tiles\n",
            "Tiling slide: wrote 5700/61697 tiles\n",
            "Tiling slide: wrote 5800/61697 tiles\n",
            "Tiling slide: wrote 5900/61697 tiles\n",
            "Tiling slide: wrote 6000/61697 tiles\n",
            "Tiling slide: wrote 6100/61697 tiles\n",
            "Tiling slide: wrote 6200/61697 tiles\n",
            "Tiling slide: wrote 6300/61697 tiles\n",
            "Tiling slide: wrote 6400/61697 tiles\n",
            "Tiling slide: wrote 6500/61697 tiles\n",
            "Tiling slide: wrote 6600/61697 tiles\n",
            "Tiling slide: wrote 6700/61697 tiles\n",
            "Tiling slide: wrote 6800/61697 tiles\n",
            "Tiling slide: wrote 6900/61697 tiles\n",
            "Tiling slide: wrote 7000/61697 tiles\n",
            "Tiling slide: wrote 7100/61697 tiles\n",
            "Tiling slide: wrote 7200/61697 tiles\n",
            "Tiling slide: wrote 7300/61697 tiles\n",
            "Tiling slide: wrote 7400/61697 tiles\n",
            "Tiling slide: wrote 7500/61697 tiles\n",
            "Tiling slide: wrote 7600/61697 tiles\n",
            "Tiling slide: wrote 7700/61697 tiles\n",
            "Tiling slide: wrote 7800/61697 tiles\n",
            "Tiling slide: wrote 7900/61697 tiles\n",
            "Tiling slide: wrote 8000/61697 tiles\n",
            "Tiling slide: wrote 8100/61697 tiles\n",
            "Tiling slide: wrote 8200/61697 tiles\n",
            "Tiling slide: wrote 8300/61697 tiles\n",
            "Tiling slide: wrote 8400/61697 tiles\n",
            "Tiling slide: wrote 8500/61697 tiles\n",
            "Tiling slide: wrote 8600/61697 tiles\n",
            "Tiling slide: wrote 8700/61697 tiles\n",
            "Tiling slide: wrote 8800/61697 tiles\n",
            "Tiling slide: wrote 8900/61697 tiles\n",
            "Tiling slide: wrote 9000/61697 tiles\n",
            "Tiling slide: wrote 9100/61697 tiles\n",
            "Tiling slide: wrote 9200/61697 tiles\n",
            "Tiling slide: wrote 9300/61697 tiles\n",
            "Tiling slide: wrote 9400/61697 tiles\n",
            "Tiling slide: wrote 9500/61697 tiles\n",
            "Tiling slide: wrote 9600/61697 tiles\n",
            "Tiling slide: wrote 9700/61697 tiles\n",
            "Tiling slide: wrote 9800/61697 tiles\n",
            "Tiling slide: wrote 9900/61697 tiles\n",
            "Tiling slide: wrote 10000/61697 tiles\n",
            "Tiling slide: wrote 10100/61697 tiles\n",
            "Tiling slide: wrote 10200/61697 tiles\n",
            "Tiling slide: wrote 10300/61697 tiles\n",
            "Tiling slide: wrote 10400/61697 tiles\n",
            "Tiling slide: wrote 10500/61697 tiles\n",
            "Tiling slide: wrote 10600/61697 tiles\n",
            "Tiling slide: wrote 10700/61697 tiles\n",
            "Tiling slide: wrote 10800/61697 tiles\n",
            "Tiling slide: wrote 10900/61697 tiles\n",
            "Tiling slide: wrote 11000/61697 tiles\n",
            "Tiling slide: wrote 11100/61697 tiles\n",
            "Tiling slide: wrote 11200/61697 tiles\n",
            "Tiling slide: wrote 11300/61697 tiles\n",
            "Tiling slide: wrote 11400/61697 tiles\n",
            "Tiling slide: wrote 11500/61697 tiles\n",
            "Tiling slide: wrote 100/36498 tiles\n",
            "Tiling slide: wrote 200/36498 tiles\n",
            "Tiling slide: wrote 300/36498 tiles\n",
            "Tiling slide: wrote 400/36498 tiles\n",
            "Tiling slide: wrote 500/36498 tiles\n",
            "Tiling slide: wrote 600/36498 tiles\n",
            "Tiling slide: wrote 700/36498 tiles\n",
            "Tiling slide: wrote 800/36498 tiles\n",
            "Tiling slide: wrote 900/36498 tiles\n",
            "Tiling slide: wrote 1000/36498 tiles\n",
            "Tiling slide: wrote 1100/36498 tiles\n",
            "Tiling slide: wrote 1200/36498 tiles\n",
            "Tiling slide: wrote 1300/36498 tiles\n",
            "Tiling slide: wrote 1400/36498 tiles\n",
            "Tiling slide: wrote 1500/36498 tiles\n",
            "Tiling slide: wrote 1600/36498 tiles\n",
            "Tiling slide: wrote 1700/36498 tiles\n",
            "Tiling slide: wrote 1800/36498 tiles\n",
            "Tiling slide: wrote 1900/36498 tiles\n",
            "Tiling slide: wrote 2000/36498 tiles\n",
            "Tiling slide: wrote 2100/36498 tiles\n",
            "Tiling slide: wrote 2200/36498 tiles\n",
            "Tiling slide: wrote 2300/36498 tiles\n",
            "Tiling slide: wrote 2400/36498 tiles\n",
            "Tiling slide: wrote 2500/36498 tiles\n",
            "Tiling slide: wrote 2600/36498 tiles\n",
            "Tiling slide: wrote 2700/36498 tiles\n",
            "Tiling slide: wrote 2800/36498 tiles\n",
            "Tiling slide: wrote 2900/36498 tiles\n",
            "Tiling slide: wrote 3000/36498 tiles\n",
            "Tiling slide: wrote 3100/36498 tiles\n",
            "Tiling slide: wrote 3200/36498 tiles\n",
            "Tiling slide: wrote 3300/36498 tiles\n",
            "Tiling slide: wrote 3400/36498 tiles\n",
            "Tiling slide: wrote 3500/36498 tiles\n",
            "Tiling slide: wrote 3600/36498 tiles\n",
            "Tiling slide: wrote 3700/36498 tiles\n",
            "Tiling slide: wrote 3800/36498 tiles\n",
            "Tiling slide: wrote 3900/36498 tiles\n",
            "Tiling slide: wrote 4000/36498 tiles\n",
            "Tiling slide: wrote 4100/36498 tiles\n",
            "Tiling slide: wrote 4200/36498 tiles\n",
            "Tiling slide: wrote 4300/36498 tiles\n",
            "Tiling slide: wrote 4400/36498 tiles\n",
            "Tiling slide: wrote 4500/36498 tiles\n",
            "Tiling slide: wrote 4600/36498 tiles\n",
            "Tiling slide: wrote 4700/36498 tiles\n",
            "Tiling slide: wrote 4800/36498 tiles\n",
            "Tiling slide: wrote 4900/36498 tiles\n",
            "Tiling slide: wrote 5000/36498 tiles\n",
            "Tiling slide: wrote 5100/36498 tiles\n",
            "Tiling slide: wrote 5200/36498 tiles\n",
            "Tiling slide: wrote 5300/36498 tiles\n",
            "Tiling slide: wrote 5400/36498 tiles\n",
            "Tiling slide: wrote 5500/36498 tiles\n",
            "Tiling slide: wrote 5600/36498 tiles\n",
            "Tiling slide: wrote 5700/36498 tiles\n",
            "Tiling slide: wrote 5800/36498 tiles\n",
            "Tiling slide: wrote 5900/36498 tiles\n",
            "Tiling slide: wrote 6000/36498 tiles\n",
            "Tiling slide: wrote 6100/36498 tiles\n",
            "Tiling slide: wrote 6200/36498 tiles\n",
            "Tiling slide: wrote 6300/36498 tiles\n",
            "Tiling slide: wrote 6400/36498 tiles\n",
            "Tiling slide: wrote 6500/36498 tiles\n",
            "Tiling slide: wrote 6600/36498 tiles\n",
            "Tiling slide: wrote 6700/36498 tiles\n",
            "Tiling slide: wrote 6800/36498 tiles\n",
            "Tiling slide: wrote 100/60952 tiles\n",
            "Tiling slide: wrote 200/60952 tiles\n",
            "Tiling slide: wrote 300/60952 tiles\n",
            "Tiling slide: wrote 400/60952 tiles\n",
            "Tiling slide: wrote 500/60952 tiles\n",
            "Tiling slide: wrote 600/60952 tiles\n",
            "Tiling slide: wrote 700/60952 tiles\n",
            "Tiling slide: wrote 800/60952 tiles\n",
            "Tiling slide: wrote 900/60952 tiles\n",
            "Tiling slide: wrote 1000/60952 tiles\n",
            "Tiling slide: wrote 1100/60952 tiles\n",
            "Tiling slide: wrote 1200/60952 tiles\n",
            "Tiling slide: wrote 1300/60952 tiles\n",
            "Tiling slide: wrote 1400/60952 tiles\n",
            "Tiling slide: wrote 1500/60952 tiles\n",
            "Tiling slide: wrote 1600/60952 tiles\n",
            "Tiling slide: wrote 1700/60952 tiles\n",
            "Tiling slide: wrote 1800/60952 tiles\n",
            "Tiling slide: wrote 1900/60952 tiles\n",
            "Tiling slide: wrote 2000/60952 tiles\n",
            "Tiling slide: wrote 2100/60952 tiles\n",
            "Tiling slide: wrote 2200/60952 tiles\n",
            "Tiling slide: wrote 2300/60952 tiles\n",
            "Tiling slide: wrote 2400/60952 tiles\n",
            "Tiling slide: wrote 2500/60952 tiles\n",
            "Tiling slide: wrote 2600/60952 tiles\n",
            "Tiling slide: wrote 2700/60952 tiles\n",
            "Tiling slide: wrote 2800/60952 tiles\n",
            "Tiling slide: wrote 2900/60952 tiles\n",
            "Tiling slide: wrote 3000/60952 tiles\n",
            "Tiling slide: wrote 3100/60952 tiles\n",
            "Tiling slide: wrote 3200/60952 tiles\n",
            "Tiling slide: wrote 3300/60952 tiles\n",
            "Tiling slide: wrote 3400/60952 tiles\n",
            "Tiling slide: wrote 3500/60952 tiles\n",
            "Tiling slide: wrote 3600/60952 tiles\n",
            "Tiling slide: wrote 3700/60952 tiles\n",
            "Tiling slide: wrote 3800/60952 tiles\n",
            "Tiling slide: wrote 3900/60952 tiles\n",
            "Tiling slide: wrote 4000/60952 tiles\n",
            "Tiling slide: wrote 4100/60952 tiles\n",
            "Tiling slide: wrote 4200/60952 tiles\n",
            "Tiling slide: wrote 4300/60952 tiles\n",
            "Tiling slide: wrote 4400/60952 tiles\n",
            "Tiling slide: wrote 4500/60952 tiles\n",
            "Tiling slide: wrote 4600/60952 tiles\n",
            "Tiling slide: wrote 4700/60952 tiles\n",
            "Tiling slide: wrote 4800/60952 tiles\n",
            "Tiling slide: wrote 4900/60952 tiles\n",
            "Tiling slide: wrote 5000/60952 tiles\n",
            "Tiling slide: wrote 5100/60952 tiles\n",
            "Tiling slide: wrote 5200/60952 tiles\n",
            "Tiling slide: wrote 5300/60952 tiles\n",
            "Tiling slide: wrote 5400/60952 tiles\n",
            "Tiling slide: wrote 5500/60952 tiles\n",
            "Tiling slide: wrote 5600/60952 tiles\n",
            "Tiling slide: wrote 5700/60952 tiles\n",
            "Tiling slide: wrote 5800/60952 tiles\n",
            "Tiling slide: wrote 5900/60952 tiles\n",
            "Tiling slide: wrote 6000/60952 tiles\n",
            "Tiling slide: wrote 6100/60952 tiles\n",
            "Tiling slide: wrote 6200/60952 tiles\n",
            "Tiling slide: wrote 6300/60952 tiles\n",
            "Tiling slide: wrote 6400/60952 tiles\n",
            "Tiling slide: wrote 6500/60952 tiles\n",
            "Tiling slide: wrote 6600/60952 tiles\n",
            "Tiling slide: wrote 6700/60952 tiles\n",
            "Tiling slide: wrote 6800/60952 tiles\n",
            "Tiling slide: wrote 6900/60952 tiles\n",
            "Tiling slide: wrote 7000/60952 tiles\n",
            "Tiling slide: wrote 7100/60952 tiles\n",
            "Tiling slide: wrote 7200/60952 tiles\n",
            "Tiling slide: wrote 7300/60952 tiles\n",
            "Tiling slide: wrote 7400/60952 tiles\n",
            "Tiling slide: wrote 7500/60952 tiles\n",
            "Tiling slide: wrote 7600/60952 tiles\n",
            "Tiling slide: wrote 7700/60952 tiles\n",
            "Tiling slide: wrote 7800/60952 tiles\n",
            "Tiling slide: wrote 7900/60952 tiles\n",
            "Tiling slide: wrote 8000/60952 tiles\n",
            "Tiling slide: wrote 8100/60952 tiles\n",
            "Tiling slide: wrote 8200/60952 tiles\n",
            "Tiling slide: wrote 8300/60952 tiles\n",
            "Tiling slide: wrote 8400/60952 tiles\n",
            "Tiling slide: wrote 8500/60952 tiles\n",
            "Tiling slide: wrote 8600/60952 tiles\n",
            "Tiling slide: wrote 8700/60952 tiles\n",
            "Tiling slide: wrote 8800/60952 tiles\n",
            "Tiling slide: wrote 8900/60952 tiles\n",
            "Tiling slide: wrote 9000/60952 tiles\n",
            "Tiling slide: wrote 9100/60952 tiles\n",
            "Tiling slide: wrote 9200/60952 tiles\n",
            "Tiling slide: wrote 9300/60952 tiles\n",
            "Tiling slide: wrote 9400/60952 tiles\n",
            "Tiling slide: wrote 9500/60952 tiles\n",
            "Tiling slide: wrote 9600/60952 tiles\n",
            "Tiling slide: wrote 9700/60952 tiles\n",
            "Tiling slide: wrote 9800/60952 tiles\n",
            "Tiling slide: wrote 9900/60952 tiles\n",
            "Tiling slide: wrote 10000/60952 tiles\n",
            "Tiling slide: wrote 10100/60952 tiles\n",
            "Tiling slide: wrote 10200/60952 tiles\n",
            "Tiling slide: wrote 10300/60952 tiles\n",
            "Tiling slide: wrote 10400/60952 tiles\n",
            "Tiling slide: wrote 10500/60952 tiles\n",
            "Tiling slide: wrote 10600/60952 tiles\n",
            "Tiling slide: wrote 10700/60952 tiles\n",
            "Tiling slide: wrote 10800/60952 tiles\n",
            "Tiling slide: wrote 10900/60952 tiles\n",
            "Tiling slide: wrote 11000/60952 tiles\n",
            "Tiling slide: wrote 11100/60952 tiles\n",
            "Tiling slide: wrote 11200/60952 tiles\n",
            "Tiling slide: wrote 11300/60952 tiles\n",
            "Tiling slide: wrote 11400/60952 tiles\n",
            "Tiling slide: wrote 100/135825 tiles\n",
            "Tiling slide: wrote 200/135825 tiles\n",
            "Tiling slide: wrote 300/135825 tiles\n",
            "Tiling slide: wrote 400/135825 tiles\n",
            "Tiling slide: wrote 500/135825 tiles\n",
            "Tiling slide: wrote 600/135825 tiles\n",
            "Tiling slide: wrote 700/135825 tiles\n",
            "Tiling slide: wrote 800/135825 tiles\n",
            "Tiling slide: wrote 900/135825 tiles\n",
            "Tiling slide: wrote 1000/135825 tiles\n",
            "Tiling slide: wrote 1100/135825 tiles\n",
            "Tiling slide: wrote 1200/135825 tiles\n",
            "Tiling slide: wrote 1300/135825 tiles\n",
            "Tiling slide: wrote 1400/135825 tiles\n",
            "Tiling slide: wrote 1500/135825 tiles\n",
            "Tiling slide: wrote 1600/135825 tiles\n",
            "Tiling slide: wrote 1700/135825 tiles\n",
            "Tiling slide: wrote 1800/135825 tiles\n",
            "Tiling slide: wrote 1900/135825 tiles\n",
            "Tiling slide: wrote 2000/135825 tiles\n",
            "Tiling slide: wrote 2100/135825 tiles\n",
            "Tiling slide: wrote 2200/135825 tiles\n",
            "Tiling slide: wrote 2300/135825 tiles\n",
            "Tiling slide: wrote 2400/135825 tiles\n",
            "Tiling slide: wrote 2500/135825 tiles\n",
            "Tiling slide: wrote 2600/135825 tiles\n",
            "Tiling slide: wrote 2700/135825 tiles\n",
            "Tiling slide: wrote 2800/135825 tiles\n",
            "Tiling slide: wrote 2900/135825 tiles\n",
            "Tiling slide: wrote 3000/135825 tiles\n",
            "Tiling slide: wrote 3100/135825 tiles\n",
            "Tiling slide: wrote 3200/135825 tiles\n",
            "Tiling slide: wrote 3300/135825 tiles\n",
            "Tiling slide: wrote 3400/135825 tiles\n",
            "Tiling slide: wrote 3500/135825 tiles\n",
            "Tiling slide: wrote 3600/135825 tiles\n",
            "Tiling slide: wrote 3700/135825 tiles\n",
            "Tiling slide: wrote 3800/135825 tiles\n",
            "Tiling slide: wrote 3900/135825 tiles\n",
            "Tiling slide: wrote 4000/135825 tiles\n",
            "Tiling slide: wrote 4100/135825 tiles\n",
            "Tiling slide: wrote 4200/135825 tiles\n",
            "Tiling slide: wrote 4300/135825 tiles\n",
            "Tiling slide: wrote 4400/135825 tiles\n",
            "Tiling slide: wrote 4500/135825 tiles\n",
            "Tiling slide: wrote 4600/135825 tiles\n",
            "Tiling slide: wrote 4700/135825 tiles\n",
            "Tiling slide: wrote 4800/135825 tiles\n",
            "Tiling slide: wrote 4900/135825 tiles\n",
            "Tiling slide: wrote 5000/135825 tiles\n",
            "Tiling slide: wrote 5100/135825 tiles\n",
            "Tiling slide: wrote 5200/135825 tiles\n",
            "Tiling slide: wrote 5300/135825 tiles\n",
            "Tiling slide: wrote 5400/135825 tiles\n",
            "Tiling slide: wrote 5500/135825 tiles\n",
            "Tiling slide: wrote 5600/135825 tiles\n",
            "Tiling slide: wrote 5700/135825 tiles\n",
            "Tiling slide: wrote 5800/135825 tiles\n",
            "Tiling slide: wrote 5900/135825 tiles\n",
            "Tiling slide: wrote 6000/135825 tiles\n",
            "Tiling slide: wrote 6100/135825 tiles\n",
            "Tiling slide: wrote 6200/135825 tiles\n",
            "Tiling slide: wrote 6300/135825 tiles\n",
            "Tiling slide: wrote 6400/135825 tiles\n",
            "Tiling slide: wrote 6500/135825 tiles\n",
            "Tiling slide: wrote 6600/135825 tiles\n",
            "Tiling slide: wrote 6700/135825 tiles\n",
            "Tiling slide: wrote 6800/135825 tiles\n",
            "Tiling slide: wrote 6900/135825 tiles\n",
            "Tiling slide: wrote 7000/135825 tiles\n",
            "Tiling slide: wrote 7100/135825 tiles\n",
            "Tiling slide: wrote 7200/135825 tiles\n",
            "Tiling slide: wrote 7300/135825 tiles\n",
            "Tiling slide: wrote 7400/135825 tiles\n",
            "Tiling slide: wrote 7500/135825 tiles\n",
            "Tiling slide: wrote 7600/135825 tiles\n",
            "Tiling slide: wrote 7700/135825 tiles\n",
            "Tiling slide: wrote 7800/135825 tiles\n",
            "Tiling slide: wrote 7900/135825 tiles\n",
            "Tiling slide: wrote 8000/135825 tiles\n",
            "Tiling slide: wrote 8100/135825 tiles\n",
            "Tiling slide: wrote 8200/135825 tiles\n",
            "Tiling slide: wrote 8300/135825 tiles\n",
            "Tiling slide: wrote 8400/135825 tiles\n",
            "Tiling slide: wrote 8500/135825 tiles\n",
            "Tiling slide: wrote 8600/135825 tiles\n",
            "Tiling slide: wrote 8700/135825 tiles\n",
            "Tiling slide: wrote 8800/135825 tiles\n",
            "Tiling slide: wrote 8900/135825 tiles\n",
            "Tiling slide: wrote 9000/135825 tiles\n",
            "Tiling slide: wrote 9100/135825 tiles\n",
            "Tiling slide: wrote 9200/135825 tiles\n",
            "Tiling slide: wrote 9300/135825 tiles\n",
            "Tiling slide: wrote 9400/135825 tiles\n",
            "Tiling slide: wrote 9500/135825 tiles\n",
            "Tiling slide: wrote 9600/135825 tiles\n",
            "Tiling slide: wrote 9700/135825 tiles\n",
            "Tiling slide: wrote 9800/135825 tiles\n",
            "Tiling slide: wrote 9900/135825 tiles\n",
            "Tiling slide: wrote 10000/135825 tiles\n",
            "Tiling slide: wrote 10100/135825 tiles\n",
            "Tiling slide: wrote 10200/135825 tiles\n",
            "Tiling slide: wrote 10300/135825 tiles\n",
            "Tiling slide: wrote 10400/135825 tiles\n",
            "Tiling slide: wrote 10500/135825 tiles\n",
            "Tiling slide: wrote 10600/135825 tiles\n",
            "Tiling slide: wrote 10700/135825 tiles\n",
            "Tiling slide: wrote 10800/135825 tiles\n",
            "Tiling slide: wrote 10900/135825 tiles\n",
            "Tiling slide: wrote 11000/135825 tiles\n",
            "Tiling slide: wrote 11100/135825 tiles\n",
            "Tiling slide: wrote 11200/135825 tiles\n",
            "Tiling slide: wrote 11300/135825 tiles\n",
            "Tiling slide: wrote 11400/135825 tiles\n",
            "Tiling slide: wrote 11500/135825 tiles\n",
            "Tiling slide: wrote 11600/135825 tiles\n",
            "Tiling slide: wrote 11700/135825 tiles\n",
            "Tiling slide: wrote 11800/135825 tiles\n",
            "Tiling slide: wrote 11900/135825 tiles\n",
            "Tiling slide: wrote 12000/135825 tiles\n",
            "Tiling slide: wrote 12100/135825 tiles\n",
            "Tiling slide: wrote 12200/135825 tiles\n",
            "Tiling slide: wrote 12300/135825 tiles\n",
            "Tiling slide: wrote 12400/135825 tiles\n",
            "Tiling slide: wrote 12500/135825 tiles\n",
            "Tiling slide: wrote 12600/135825 tiles\n",
            "Tiling slide: wrote 12700/135825 tiles\n",
            "Tiling slide: wrote 12800/135825 tiles\n",
            "Tiling slide: wrote 12900/135825 tiles\n",
            "Tiling slide: wrote 13000/135825 tiles\n",
            "Tiling slide: wrote 13100/135825 tiles\n",
            "Tiling slide: wrote 13200/135825 tiles\n",
            "Tiling slide: wrote 13300/135825 tiles\n",
            "Tiling slide: wrote 13400/135825 tiles\n",
            "Tiling slide: wrote 13500/135825 tiles\n",
            "Tiling slide: wrote 13600/135825 tiles\n",
            "Tiling slide: wrote 13700/135825 tiles\n",
            "Tiling slide: wrote 13800/135825 tiles\n",
            "Tiling slide: wrote 13900/135825 tiles\n",
            "Tiling slide: wrote 14000/135825 tiles\n",
            "Tiling slide: wrote 14100/135825 tiles\n",
            "Tiling slide: wrote 14200/135825 tiles\n",
            "Tiling slide: wrote 14300/135825 tiles\n",
            "Tiling slide: wrote 14400/135825 tiles\n",
            "Tiling slide: wrote 14500/135825 tiles\n",
            "Tiling slide: wrote 14600/135825 tiles\n",
            "Tiling slide: wrote 14700/135825 tiles\n",
            "Tiling slide: wrote 14800/135825 tiles\n",
            "Tiling slide: wrote 14900/135825 tiles\n",
            "Tiling slide: wrote 15000/135825 tiles\n",
            "Tiling slide: wrote 15100/135825 tiles\n",
            "Tiling slide: wrote 15200/135825 tiles\n",
            "Tiling slide: wrote 15300/135825 tiles\n",
            "Tiling slide: wrote 15400/135825 tiles\n",
            "Tiling slide: wrote 15500/135825 tiles\n",
            "Tiling slide: wrote 15600/135825 tiles\n",
            "Tiling slide: wrote 15700/135825 tiles\n",
            "Tiling slide: wrote 15800/135825 tiles\n",
            "Tiling slide: wrote 15900/135825 tiles\n",
            "Tiling slide: wrote 16000/135825 tiles\n",
            "Tiling slide: wrote 16100/135825 tiles\n",
            "Tiling slide: wrote 16200/135825 tiles\n",
            "Tiling slide: wrote 16300/135825 tiles\n",
            "Tiling slide: wrote 16400/135825 tiles\n",
            "Tiling slide: wrote 16500/135825 tiles\n",
            "Tiling slide: wrote 16600/135825 tiles\n",
            "Tiling slide: wrote 16700/135825 tiles\n",
            "Tiling slide: wrote 16800/135825 tiles\n",
            "Tiling slide: wrote 16900/135825 tiles\n",
            "Tiling slide: wrote 17000/135825 tiles\n",
            "Tiling slide: wrote 17100/135825 tiles\n",
            "Tiling slide: wrote 17200/135825 tiles\n",
            "Tiling slide: wrote 17300/135825 tiles\n",
            "Tiling slide: wrote 17400/135825 tiles\n",
            "Tiling slide: wrote 17500/135825 tiles\n",
            "Tiling slide: wrote 17600/135825 tiles\n",
            "Tiling slide: wrote 17700/135825 tiles\n",
            "Tiling slide: wrote 17800/135825 tiles\n",
            "Tiling slide: wrote 17900/135825 tiles\n",
            "Tiling slide: wrote 18000/135825 tiles\n",
            "Tiling slide: wrote 18100/135825 tiles\n",
            "Tiling slide: wrote 18200/135825 tiles\n",
            "Tiling slide: wrote 18300/135825 tiles\n",
            "Tiling slide: wrote 18400/135825 tiles\n",
            "Tiling slide: wrote 18500/135825 tiles\n",
            "Tiling slide: wrote 18600/135825 tiles\n",
            "Tiling slide: wrote 18700/135825 tiles\n",
            "Tiling slide: wrote 18800/135825 tiles\n",
            "Tiling slide: wrote 18900/135825 tiles\n",
            "Tiling slide: wrote 19000/135825 tiles\n",
            "Tiling slide: wrote 19100/135825 tiles\n",
            "Tiling slide: wrote 19200/135825 tiles\n",
            "Tiling slide: wrote 19300/135825 tiles\n",
            "Tiling slide: wrote 19400/135825 tiles\n",
            "Tiling slide: wrote 19500/135825 tiles\n",
            "Tiling slide: wrote 19600/135825 tiles\n",
            "Tiling slide: wrote 19700/135825 tiles\n",
            "Tiling slide: wrote 19800/135825 tiles\n",
            "Tiling slide: wrote 19900/135825 tiles\n",
            "Tiling slide: wrote 20000/135825 tiles\n",
            "Tiling slide: wrote 20100/135825 tiles\n",
            "Tiling slide: wrote 20200/135825 tiles\n",
            "Tiling slide: wrote 20300/135825 tiles\n",
            "Tiling slide: wrote 20400/135825 tiles\n",
            "Tiling slide: wrote 20500/135825 tiles\n",
            "Tiling slide: wrote 20600/135825 tiles\n",
            "Tiling slide: wrote 20700/135825 tiles\n",
            "Tiling slide: wrote 20800/135825 tiles\n",
            "Tiling slide: wrote 20900/135825 tiles\n",
            "Tiling slide: wrote 21000/135825 tiles\n",
            "Tiling slide: wrote 21100/135825 tiles\n",
            "Tiling slide: wrote 21200/135825 tiles\n",
            "Tiling slide: wrote 21300/135825 tiles\n",
            "Tiling slide: wrote 21400/135825 tiles\n",
            "Tiling slide: wrote 21500/135825 tiles\n",
            "Tiling slide: wrote 21600/135825 tiles\n",
            "Tiling slide: wrote 21700/135825 tiles\n",
            "Tiling slide: wrote 21800/135825 tiles\n",
            "Tiling slide: wrote 21900/135825 tiles\n",
            "Tiling slide: wrote 22000/135825 tiles\n",
            "Tiling slide: wrote 22100/135825 tiles\n",
            "Tiling slide: wrote 22200/135825 tiles\n",
            "Tiling slide: wrote 22300/135825 tiles\n",
            "Tiling slide: wrote 22400/135825 tiles\n",
            "Tiling slide: wrote 22500/135825 tiles\n",
            "Tiling slide: wrote 22600/135825 tiles\n",
            "Tiling slide: wrote 22700/135825 tiles\n",
            "Tiling slide: wrote 22800/135825 tiles\n",
            "Tiling slide: wrote 22900/135825 tiles\n",
            "Tiling slide: wrote 23000/135825 tiles\n",
            "Tiling slide: wrote 23100/135825 tiles\n",
            "Tiling slide: wrote 23200/135825 tiles\n",
            "Tiling slide: wrote 23300/135825 tiles\n",
            "Tiling slide: wrote 23400/135825 tiles\n",
            "Tiling slide: wrote 23500/135825 tiles\n",
            "Tiling slide: wrote 23600/135825 tiles\n",
            "Tiling slide: wrote 23700/135825 tiles\n",
            "Tiling slide: wrote 23800/135825 tiles\n",
            "Tiling slide: wrote 23900/135825 tiles\n",
            "Tiling slide: wrote 24000/135825 tiles\n",
            "Tiling slide: wrote 24100/135825 tiles\n",
            "Tiling slide: wrote 24200/135825 tiles\n",
            "Tiling slide: wrote 24300/135825 tiles\n",
            "Tiling slide: wrote 24400/135825 tiles\n",
            "Tiling slide: wrote 24500/135825 tiles\n",
            "Tiling slide: wrote 24600/135825 tiles\n",
            "Tiling slide: wrote 24700/135825 tiles\n",
            "Tiling slide: wrote 24800/135825 tiles\n",
            "Tiling slide: wrote 24900/135825 tiles\n",
            "Tiling slide: wrote 25000/135825 tiles\n",
            "Tiling slide: wrote 25100/135825 tiles\n",
            "Tiling slide: wrote 25200/135825 tiles\n",
            "Tiling slide: wrote 25300/135825 tiles\n",
            "Tiling slide: wrote 25400/135825 tiles\n",
            "Tiling slide: wrote 100/99618 tiles\n",
            "Tiling slide: wrote 200/99618 tiles\n",
            "Tiling slide: wrote 300/99618 tiles\n",
            "Tiling slide: wrote 400/99618 tiles\n",
            "Tiling slide: wrote 500/99618 tiles\n",
            "Tiling slide: wrote 600/99618 tiles\n",
            "Tiling slide: wrote 700/99618 tiles\n",
            "Tiling slide: wrote 800/99618 tiles\n",
            "Tiling slide: wrote 900/99618 tiles\n",
            "Tiling slide: wrote 1000/99618 tiles\n",
            "Tiling slide: wrote 1100/99618 tiles\n",
            "Tiling slide: wrote 1200/99618 tiles\n",
            "Tiling slide: wrote 1300/99618 tiles\n",
            "Tiling slide: wrote 1400/99618 tiles\n",
            "Tiling slide: wrote 1500/99618 tiles\n",
            "Tiling slide: wrote 1600/99618 tiles\n",
            "Tiling slide: wrote 1700/99618 tiles\n",
            "Tiling slide: wrote 1800/99618 tiles\n",
            "Tiling slide: wrote 1900/99618 tiles\n",
            "Tiling slide: wrote 2000/99618 tiles\n",
            "Tiling slide: wrote 2100/99618 tiles\n",
            "Tiling slide: wrote 2200/99618 tiles\n",
            "Tiling slide: wrote 2300/99618 tiles\n",
            "Tiling slide: wrote 2400/99618 tiles\n",
            "Tiling slide: wrote 2500/99618 tiles\n",
            "Tiling slide: wrote 2600/99618 tiles\n",
            "Tiling slide: wrote 2700/99618 tiles\n",
            "Tiling slide: wrote 2800/99618 tiles\n",
            "Tiling slide: wrote 2900/99618 tiles\n",
            "Tiling slide: wrote 3000/99618 tiles\n",
            "Tiling slide: wrote 3100/99618 tiles\n",
            "Tiling slide: wrote 3200/99618 tiles\n",
            "Tiling slide: wrote 3300/99618 tiles\n",
            "Tiling slide: wrote 3400/99618 tiles\n",
            "Tiling slide: wrote 3500/99618 tiles\n",
            "Tiling slide: wrote 3600/99618 tiles\n",
            "Tiling slide: wrote 3700/99618 tiles\n",
            "Tiling slide: wrote 3800/99618 tiles\n",
            "Tiling slide: wrote 3900/99618 tiles\n",
            "Tiling slide: wrote 4000/99618 tiles\n",
            "Tiling slide: wrote 4100/99618 tiles\n",
            "Tiling slide: wrote 4200/99618 tiles\n",
            "Tiling slide: wrote 4300/99618 tiles\n",
            "Tiling slide: wrote 4400/99618 tiles\n",
            "Tiling slide: wrote 4500/99618 tiles\n",
            "Tiling slide: wrote 4600/99618 tiles\n",
            "Tiling slide: wrote 4700/99618 tiles\n",
            "Tiling slide: wrote 4800/99618 tiles\n",
            "Tiling slide: wrote 4900/99618 tiles\n",
            "Tiling slide: wrote 5000/99618 tiles\n",
            "Tiling slide: wrote 5100/99618 tiles\n",
            "Tiling slide: wrote 5200/99618 tiles\n",
            "Tiling slide: wrote 5300/99618 tiles\n",
            "Tiling slide: wrote 5400/99618 tiles\n",
            "Tiling slide: wrote 5500/99618 tiles\n",
            "Tiling slide: wrote 5600/99618 tiles\n",
            "Tiling slide: wrote 5700/99618 tiles\n",
            "Tiling slide: wrote 5800/99618 tiles\n",
            "Tiling slide: wrote 5900/99618 tiles\n",
            "Tiling slide: wrote 6000/99618 tiles\n",
            "Tiling slide: wrote 6100/99618 tiles\n",
            "Tiling slide: wrote 6200/99618 tiles\n",
            "Tiling slide: wrote 6300/99618 tiles\n",
            "Tiling slide: wrote 6400/99618 tiles\n",
            "Tiling slide: wrote 6500/99618 tiles\n",
            "Tiling slide: wrote 6600/99618 tiles\n",
            "Tiling slide: wrote 6700/99618 tiles\n",
            "Tiling slide: wrote 6800/99618 tiles\n",
            "Tiling slide: wrote 6900/99618 tiles\n",
            "Tiling slide: wrote 7000/99618 tiles\n",
            "Tiling slide: wrote 7100/99618 tiles\n",
            "Tiling slide: wrote 7200/99618 tiles\n",
            "Tiling slide: wrote 7300/99618 tiles\n",
            "Tiling slide: wrote 7400/99618 tiles\n",
            "Tiling slide: wrote 7500/99618 tiles\n",
            "Tiling slide: wrote 7600/99618 tiles\n",
            "Tiling slide: wrote 7700/99618 tiles\n",
            "Tiling slide: wrote 7800/99618 tiles\n",
            "Tiling slide: wrote 7900/99618 tiles\n",
            "Tiling slide: wrote 8000/99618 tiles\n",
            "Tiling slide: wrote 8100/99618 tiles\n",
            "Tiling slide: wrote 8200/99618 tiles\n",
            "Tiling slide: wrote 8300/99618 tiles\n",
            "Tiling slide: wrote 8400/99618 tiles\n",
            "Tiling slide: wrote 8500/99618 tiles\n",
            "Tiling slide: wrote 8600/99618 tiles\n",
            "Tiling slide: wrote 8700/99618 tiles\n",
            "Tiling slide: wrote 8800/99618 tiles\n",
            "Tiling slide: wrote 8900/99618 tiles\n",
            "Tiling slide: wrote 9000/99618 tiles\n",
            "Tiling slide: wrote 9100/99618 tiles\n",
            "Tiling slide: wrote 9200/99618 tiles\n",
            "Tiling slide: wrote 9300/99618 tiles\n",
            "Tiling slide: wrote 9400/99618 tiles\n",
            "Tiling slide: wrote 9500/99618 tiles\n",
            "Tiling slide: wrote 9600/99618 tiles\n",
            "Tiling slide: wrote 9700/99618 tiles\n",
            "Tiling slide: wrote 9800/99618 tiles\n",
            "Tiling slide: wrote 9900/99618 tiles\n",
            "Tiling slide: wrote 10000/99618 tiles\n",
            "Tiling slide: wrote 10100/99618 tiles\n",
            "Tiling slide: wrote 10200/99618 tiles\n",
            "Tiling slide: wrote 10300/99618 tiles\n",
            "Tiling slide: wrote 10400/99618 tiles\n",
            "Tiling slide: wrote 10500/99618 tiles\n",
            "Tiling slide: wrote 10600/99618 tiles\n",
            "Tiling slide: wrote 10700/99618 tiles\n",
            "Tiling slide: wrote 10800/99618 tiles\n",
            "Tiling slide: wrote 10900/99618 tiles\n",
            "Tiling slide: wrote 11000/99618 tiles\n",
            "Tiling slide: wrote 11100/99618 tiles\n",
            "Tiling slide: wrote 11200/99618 tiles\n",
            "Tiling slide: wrote 11300/99618 tiles\n",
            "Tiling slide: wrote 11400/99618 tiles\n",
            "Tiling slide: wrote 11500/99618 tiles\n",
            "Tiling slide: wrote 11600/99618 tiles\n",
            "Tiling slide: wrote 11700/99618 tiles\n",
            "Tiling slide: wrote 11800/99618 tiles\n",
            "Tiling slide: wrote 11900/99618 tiles\n",
            "Tiling slide: wrote 12000/99618 tiles\n",
            "Tiling slide: wrote 12100/99618 tiles\n",
            "Tiling slide: wrote 12200/99618 tiles\n",
            "Tiling slide: wrote 12300/99618 tiles\n",
            "Tiling slide: wrote 12400/99618 tiles\n",
            "Tiling slide: wrote 12500/99618 tiles\n",
            "Tiling slide: wrote 12600/99618 tiles\n",
            "Tiling slide: wrote 12700/99618 tiles\n",
            "Tiling slide: wrote 12800/99618 tiles\n",
            "Tiling slide: wrote 12900/99618 tiles\n",
            "Tiling slide: wrote 13000/99618 tiles\n",
            "Tiling slide: wrote 13100/99618 tiles\n",
            "Tiling slide: wrote 13200/99618 tiles\n",
            "Tiling slide: wrote 13300/99618 tiles\n",
            "Tiling slide: wrote 13400/99618 tiles\n",
            "Tiling slide: wrote 13500/99618 tiles\n",
            "Tiling slide: wrote 13600/99618 tiles\n",
            "Tiling slide: wrote 13700/99618 tiles\n",
            "Tiling slide: wrote 13800/99618 tiles\n",
            "Tiling slide: wrote 13900/99618 tiles\n",
            "Tiling slide: wrote 14000/99618 tiles\n",
            "Tiling slide: wrote 14100/99618 tiles\n",
            "Tiling slide: wrote 14200/99618 tiles\n",
            "Tiling slide: wrote 14300/99618 tiles\n",
            "Tiling slide: wrote 14400/99618 tiles\n",
            "Tiling slide: wrote 14500/99618 tiles\n",
            "Tiling slide: wrote 14600/99618 tiles\n",
            "Tiling slide: wrote 14700/99618 tiles\n",
            "Tiling slide: wrote 14800/99618 tiles\n",
            "Tiling slide: wrote 14900/99618 tiles\n",
            "Tiling slide: wrote 15000/99618 tiles\n",
            "Tiling slide: wrote 15100/99618 tiles\n",
            "Tiling slide: wrote 15200/99618 tiles\n",
            "Tiling slide: wrote 15300/99618 tiles\n",
            "Tiling slide: wrote 15400/99618 tiles\n",
            "Tiling slide: wrote 15500/99618 tiles\n",
            "Tiling slide: wrote 15600/99618 tiles\n",
            "Tiling slide: wrote 15700/99618 tiles\n",
            "Tiling slide: wrote 15800/99618 tiles\n",
            "Tiling slide: wrote 15900/99618 tiles\n",
            "Tiling slide: wrote 16000/99618 tiles\n",
            "Tiling slide: wrote 16100/99618 tiles\n",
            "Tiling slide: wrote 16200/99618 tiles\n",
            "Tiling slide: wrote 16300/99618 tiles\n",
            "Tiling slide: wrote 16400/99618 tiles\n",
            "Tiling slide: wrote 16500/99618 tiles\n",
            "Tiling slide: wrote 16600/99618 tiles\n",
            "Tiling slide: wrote 16700/99618 tiles\n",
            "Tiling slide: wrote 16800/99618 tiles\n",
            "Tiling slide: wrote 16900/99618 tiles\n",
            "Tiling slide: wrote 17000/99618 tiles\n",
            "Tiling slide: wrote 17100/99618 tiles\n",
            "Tiling slide: wrote 17200/99618 tiles\n",
            "Tiling slide: wrote 17300/99618 tiles\n",
            "Tiling slide: wrote 17400/99618 tiles\n",
            "Tiling slide: wrote 17500/99618 tiles\n",
            "Tiling slide: wrote 17600/99618 tiles\n",
            "Tiling slide: wrote 17700/99618 tiles\n",
            "Tiling slide: wrote 17800/99618 tiles\n",
            "Tiling slide: wrote 17900/99618 tiles\n",
            "Tiling slide: wrote 18000/99618 tiles\n",
            "Tiling slide: wrote 18100/99618 tiles\n",
            "Tiling slide: wrote 18200/99618 tiles\n",
            "Tiling slide: wrote 18300/99618 tiles\n",
            "Tiling slide: wrote 18400/99618 tiles\n",
            "Tiling slide: wrote 18500/99618 tiles\n",
            "Tiling slide: wrote 18600/99618 tiles\n",
            "Tiling slide: wrote 100/25487 tiles\n",
            "Tiling slide: wrote 200/25487 tiles\n",
            "Tiling slide: wrote 300/25487 tiles\n",
            "Tiling slide: wrote 400/25487 tiles\n",
            "Tiling slide: wrote 500/25487 tiles\n",
            "Tiling slide: wrote 600/25487 tiles\n",
            "Tiling slide: wrote 700/25487 tiles\n",
            "Tiling slide: wrote 800/25487 tiles\n",
            "Tiling slide: wrote 900/25487 tiles\n",
            "Tiling slide: wrote 1000/25487 tiles\n",
            "Tiling slide: wrote 1100/25487 tiles\n",
            "Tiling slide: wrote 1200/25487 tiles\n",
            "Tiling slide: wrote 1300/25487 tiles\n",
            "Tiling slide: wrote 1400/25487 tiles\n",
            "Tiling slide: wrote 1500/25487 tiles\n",
            "Tiling slide: wrote 1600/25487 tiles\n",
            "Tiling slide: wrote 1700/25487 tiles\n",
            "Tiling slide: wrote 1800/25487 tiles\n",
            "Tiling slide: wrote 1900/25487 tiles\n",
            "Tiling slide: wrote 2000/25487 tiles\n",
            "Tiling slide: wrote 2100/25487 tiles\n",
            "Tiling slide: wrote 2200/25487 tiles\n",
            "Tiling slide: wrote 2300/25487 tiles\n",
            "Tiling slide: wrote 2400/25487 tiles\n",
            "Tiling slide: wrote 2500/25487 tiles\n",
            "Tiling slide: wrote 2600/25487 tiles\n",
            "Tiling slide: wrote 2700/25487 tiles\n",
            "Tiling slide: wrote 2800/25487 tiles\n",
            "Tiling slide: wrote 2900/25487 tiles\n",
            "Tiling slide: wrote 3000/25487 tiles\n",
            "Tiling slide: wrote 3100/25487 tiles\n",
            "Tiling slide: wrote 3200/25487 tiles\n",
            "Tiling slide: wrote 3300/25487 tiles\n",
            "Tiling slide: wrote 3400/25487 tiles\n",
            "Tiling slide: wrote 3500/25487 tiles\n",
            "Tiling slide: wrote 3600/25487 tiles\n",
            "Tiling slide: wrote 3700/25487 tiles\n",
            "Tiling slide: wrote 3800/25487 tiles\n",
            "Tiling slide: wrote 3900/25487 tiles\n",
            "Tiling slide: wrote 4000/25487 tiles\n",
            "Tiling slide: wrote 4100/25487 tiles\n",
            "Tiling slide: wrote 4200/25487 tiles\n",
            "Tiling slide: wrote 4300/25487 tiles\n",
            "Tiling slide: wrote 4400/25487 tiles\n",
            "Tiling slide: wrote 4500/25487 tiles\n",
            "Tiling slide: wrote 4600/25487 tiles\n",
            "Tiling slide: wrote 4700/25487 tiles\n",
            "Tiling slide: wrote 4800/25487 tiles\n",
            "Tiling slide: wrote 100/54504 tiles\n",
            "Tiling slide: wrote 200/54504 tiles\n",
            "Tiling slide: wrote 300/54504 tiles\n",
            "Tiling slide: wrote 400/54504 tiles\n",
            "Tiling slide: wrote 500/54504 tiles\n",
            "Tiling slide: wrote 600/54504 tiles\n",
            "Tiling slide: wrote 700/54504 tiles\n",
            "Tiling slide: wrote 800/54504 tiles\n",
            "Tiling slide: wrote 900/54504 tiles\n",
            "Tiling slide: wrote 1000/54504 tiles\n",
            "Tiling slide: wrote 1100/54504 tiles\n",
            "Tiling slide: wrote 1200/54504 tiles\n",
            "Tiling slide: wrote 1300/54504 tiles\n",
            "Tiling slide: wrote 1400/54504 tiles\n",
            "Tiling slide: wrote 1500/54504 tiles\n",
            "Tiling slide: wrote 1600/54504 tiles\n",
            "Tiling slide: wrote 1700/54504 tiles\n",
            "Tiling slide: wrote 1800/54504 tiles\n",
            "Tiling slide: wrote 1900/54504 tiles\n",
            "Tiling slide: wrote 2000/54504 tiles\n",
            "Tiling slide: wrote 2100/54504 tiles\n",
            "Tiling slide: wrote 2200/54504 tiles\n",
            "Tiling slide: wrote 2300/54504 tiles\n",
            "Tiling slide: wrote 2400/54504 tiles\n",
            "Tiling slide: wrote 2500/54504 tiles\n",
            "Tiling slide: wrote 2600/54504 tiles\n",
            "Tiling slide: wrote 2700/54504 tiles\n",
            "Tiling slide: wrote 2800/54504 tiles\n",
            "Tiling slide: wrote 2900/54504 tiles\n",
            "Tiling slide: wrote 3000/54504 tiles\n",
            "Tiling slide: wrote 3100/54504 tiles\n",
            "Tiling slide: wrote 3200/54504 tiles\n",
            "Tiling slide: wrote 3300/54504 tiles\n",
            "Tiling slide: wrote 3400/54504 tiles\n",
            "Tiling slide: wrote 3500/54504 tiles\n",
            "Tiling slide: wrote 3600/54504 tiles\n",
            "Tiling slide: wrote 3700/54504 tiles\n",
            "Tiling slide: wrote 3800/54504 tiles\n",
            "Tiling slide: wrote 3900/54504 tiles\n",
            "Tiling slide: wrote 4000/54504 tiles\n",
            "Tiling slide: wrote 4100/54504 tiles\n",
            "Tiling slide: wrote 4200/54504 tiles\n",
            "Tiling slide: wrote 4300/54504 tiles\n",
            "Tiling slide: wrote 4400/54504 tiles\n",
            "Tiling slide: wrote 4500/54504 tiles\n",
            "Tiling slide: wrote 4600/54504 tiles\n",
            "Tiling slide: wrote 4700/54504 tiles\n",
            "Tiling slide: wrote 4800/54504 tiles\n",
            "Tiling slide: wrote 4900/54504 tiles\n",
            "Tiling slide: wrote 5000/54504 tiles\n",
            "Tiling slide: wrote 5100/54504 tiles\n",
            "Tiling slide: wrote 5200/54504 tiles\n",
            "Tiling slide: wrote 5300/54504 tiles\n",
            "Tiling slide: wrote 5400/54504 tiles\n",
            "Tiling slide: wrote 5500/54504 tiles\n",
            "Tiling slide: wrote 5600/54504 tiles\n",
            "Tiling slide: wrote 5700/54504 tiles\n",
            "Tiling slide: wrote 5800/54504 tiles\n",
            "Tiling slide: wrote 5900/54504 tiles\n",
            "Tiling slide: wrote 6000/54504 tiles\n",
            "Tiling slide: wrote 6100/54504 tiles\n",
            "Tiling slide: wrote 6200/54504 tiles\n",
            "Tiling slide: wrote 6300/54504 tiles\n",
            "Tiling slide: wrote 6400/54504 tiles\n",
            "Tiling slide: wrote 6500/54504 tiles\n",
            "Tiling slide: wrote 6600/54504 tiles\n",
            "Tiling slide: wrote 6700/54504 tiles\n",
            "Tiling slide: wrote 6800/54504 tiles\n",
            "Tiling slide: wrote 6900/54504 tiles\n",
            "Tiling slide: wrote 7000/54504 tiles\n",
            "Tiling slide: wrote 7100/54504 tiles\n",
            "Tiling slide: wrote 7200/54504 tiles\n",
            "Tiling slide: wrote 7300/54504 tiles\n",
            "Tiling slide: wrote 7400/54504 tiles\n",
            "Tiling slide: wrote 7500/54504 tiles\n",
            "Tiling slide: wrote 7600/54504 tiles\n",
            "Tiling slide: wrote 7700/54504 tiles\n",
            "Tiling slide: wrote 7800/54504 tiles\n",
            "Tiling slide: wrote 7900/54504 tiles\n",
            "Tiling slide: wrote 8000/54504 tiles\n",
            "Tiling slide: wrote 8100/54504 tiles\n",
            "Tiling slide: wrote 8200/54504 tiles\n",
            "Tiling slide: wrote 8300/54504 tiles\n",
            "Tiling slide: wrote 8400/54504 tiles\n",
            "Tiling slide: wrote 8500/54504 tiles\n",
            "Tiling slide: wrote 8600/54504 tiles\n",
            "Tiling slide: wrote 8700/54504 tiles\n",
            "Tiling slide: wrote 8800/54504 tiles\n",
            "Tiling slide: wrote 8900/54504 tiles\n",
            "Tiling slide: wrote 9000/54504 tiles\n",
            "Tiling slide: wrote 9100/54504 tiles\n",
            "Tiling slide: wrote 9200/54504 tiles\n",
            "Tiling slide: wrote 9300/54504 tiles\n",
            "Tiling slide: wrote 9400/54504 tiles\n",
            "Tiling slide: wrote 9500/54504 tiles\n",
            "Tiling slide: wrote 9600/54504 tiles\n",
            "Tiling slide: wrote 9700/54504 tiles\n",
            "Tiling slide: wrote 9800/54504 tiles\n",
            "Tiling slide: wrote 9900/54504 tiles\n",
            "Tiling slide: wrote 10000/54504 tiles\n",
            "Tiling slide: wrote 10100/54504 tiles\n",
            "Tiling slide: wrote 10200/54504 tiles\n",
            "Tiling slide: wrote 100/21725 tiles\n",
            "Tiling slide: wrote 200/21725 tiles\n",
            "Tiling slide: wrote 300/21725 tiles\n",
            "Tiling slide: wrote 400/21725 tiles\n",
            "Tiling slide: wrote 500/21725 tiles\n",
            "Tiling slide: wrote 600/21725 tiles\n",
            "Tiling slide: wrote 700/21725 tiles\n",
            "Tiling slide: wrote 800/21725 tiles\n",
            "Tiling slide: wrote 900/21725 tiles\n",
            "Tiling slide: wrote 1000/21725 tiles\n",
            "Tiling slide: wrote 1100/21725 tiles\n",
            "Tiling slide: wrote 1200/21725 tiles\n",
            "Tiling slide: wrote 1300/21725 tiles\n",
            "Tiling slide: wrote 1400/21725 tiles\n",
            "Tiling slide: wrote 1500/21725 tiles\n",
            "Tiling slide: wrote 1600/21725 tiles\n",
            "Tiling slide: wrote 1700/21725 tiles\n",
            "Tiling slide: wrote 1800/21725 tiles\n",
            "Tiling slide: wrote 1900/21725 tiles\n",
            "Tiling slide: wrote 2000/21725 tiles\n",
            "Tiling slide: wrote 2100/21725 tiles\n",
            "Tiling slide: wrote 2200/21725 tiles\n",
            "Tiling slide: wrote 2300/21725 tiles\n",
            "Tiling slide: wrote 2400/21725 tiles\n",
            "Tiling slide: wrote 2500/21725 tiles\n",
            "Tiling slide: wrote 2600/21725 tiles\n",
            "Tiling slide: wrote 2700/21725 tiles\n",
            "Tiling slide: wrote 2800/21725 tiles\n",
            "Tiling slide: wrote 2900/21725 tiles\n",
            "Tiling slide: wrote 3000/21725 tiles\n",
            "Tiling slide: wrote 3100/21725 tiles\n",
            "Tiling slide: wrote 3200/21725 tiles\n",
            "Tiling slide: wrote 3300/21725 tiles\n",
            "Tiling slide: wrote 3400/21725 tiles\n",
            "Tiling slide: wrote 3500/21725 tiles\n",
            "Tiling slide: wrote 3600/21725 tiles\n",
            "Tiling slide: wrote 3700/21725 tiles\n",
            "Tiling slide: wrote 3800/21725 tiles\n",
            "Tiling slide: wrote 3900/21725 tiles\n",
            "Tiling slide: wrote 4000/21725 tiles\n",
            "Tiling slide: wrote 100/62989 tiles\n",
            "Tiling slide: wrote 200/62989 tiles\n",
            "Tiling slide: wrote 300/62989 tiles\n",
            "Tiling slide: wrote 400/62989 tiles\n",
            "Tiling slide: wrote 500/62989 tiles\n",
            "Tiling slide: wrote 600/62989 tiles\n",
            "Tiling slide: wrote 700/62989 tiles\n",
            "Tiling slide: wrote 800/62989 tiles\n",
            "Tiling slide: wrote 900/62989 tiles\n",
            "Tiling slide: wrote 1000/62989 tiles\n",
            "Tiling slide: wrote 1100/62989 tiles\n",
            "Tiling slide: wrote 1200/62989 tiles\n",
            "Tiling slide: wrote 1300/62989 tiles\n",
            "Tiling slide: wrote 1400/62989 tiles\n",
            "Tiling slide: wrote 1500/62989 tiles\n",
            "Tiling slide: wrote 1600/62989 tiles\n",
            "Tiling slide: wrote 1700/62989 tiles\n",
            "Tiling slide: wrote 1800/62989 tiles\n",
            "Tiling slide: wrote 1900/62989 tiles\n",
            "Tiling slide: wrote 2000/62989 tiles\n",
            "Tiling slide: wrote 2100/62989 tiles\n",
            "Tiling slide: wrote 2200/62989 tiles\n",
            "Tiling slide: wrote 2300/62989 tiles\n",
            "Tiling slide: wrote 2400/62989 tiles\n",
            "Tiling slide: wrote 2500/62989 tiles\n",
            "Tiling slide: wrote 2600/62989 tiles\n",
            "Tiling slide: wrote 2700/62989 tiles\n",
            "Tiling slide: wrote 2800/62989 tiles\n",
            "Tiling slide: wrote 2900/62989 tiles\n",
            "Tiling slide: wrote 3000/62989 tiles\n",
            "Tiling slide: wrote 3100/62989 tiles\n",
            "Tiling slide: wrote 3200/62989 tiles\n",
            "Tiling slide: wrote 3300/62989 tiles\n",
            "Tiling slide: wrote 3400/62989 tiles\n",
            "Tiling slide: wrote 3500/62989 tiles\n",
            "Tiling slide: wrote 3600/62989 tiles\n",
            "Tiling slide: wrote 3700/62989 tiles\n",
            "Tiling slide: wrote 3800/62989 tiles\n",
            "Tiling slide: wrote 3900/62989 tiles\n",
            "Tiling slide: wrote 4000/62989 tiles\n",
            "Tiling slide: wrote 4100/62989 tiles\n",
            "Tiling slide: wrote 4200/62989 tiles\n",
            "Tiling slide: wrote 4300/62989 tiles\n",
            "Tiling slide: wrote 4400/62989 tiles\n",
            "Tiling slide: wrote 4500/62989 tiles\n",
            "Tiling slide: wrote 4600/62989 tiles\n",
            "Tiling slide: wrote 4700/62989 tiles\n",
            "Tiling slide: wrote 4800/62989 tiles\n",
            "Tiling slide: wrote 4900/62989 tiles\n",
            "Tiling slide: wrote 5000/62989 tiles\n",
            "Tiling slide: wrote 5100/62989 tiles\n",
            "Tiling slide: wrote 5200/62989 tiles\n",
            "Tiling slide: wrote 5300/62989 tiles\n",
            "Tiling slide: wrote 5400/62989 tiles\n",
            "Tiling slide: wrote 5500/62989 tiles\n",
            "Tiling slide: wrote 5600/62989 tiles\n",
            "Tiling slide: wrote 5700/62989 tiles\n",
            "Tiling slide: wrote 5800/62989 tiles\n",
            "Tiling slide: wrote 5900/62989 tiles\n",
            "Tiling slide: wrote 6000/62989 tiles\n",
            "Tiling slide: wrote 6100/62989 tiles\n",
            "Tiling slide: wrote 6200/62989 tiles\n",
            "Tiling slide: wrote 6300/62989 tiles\n",
            "Tiling slide: wrote 6400/62989 tiles\n",
            "Tiling slide: wrote 6500/62989 tiles\n",
            "Tiling slide: wrote 6600/62989 tiles\n",
            "Tiling slide: wrote 6700/62989 tiles\n",
            "Tiling slide: wrote 6800/62989 tiles\n",
            "Tiling slide: wrote 6900/62989 tiles\n",
            "Tiling slide: wrote 7000/62989 tiles\n",
            "Tiling slide: wrote 7100/62989 tiles\n",
            "Tiling slide: wrote 7200/62989 tiles\n",
            "Tiling slide: wrote 7300/62989 tiles\n",
            "Tiling slide: wrote 7400/62989 tiles\n",
            "Tiling slide: wrote 7500/62989 tiles\n",
            "Tiling slide: wrote 7600/62989 tiles\n",
            "Tiling slide: wrote 7700/62989 tiles\n",
            "Tiling slide: wrote 7800/62989 tiles\n",
            "Tiling slide: wrote 7900/62989 tiles\n",
            "Tiling slide: wrote 8000/62989 tiles\n",
            "Tiling slide: wrote 8100/62989 tiles\n",
            "Tiling slide: wrote 8200/62989 tiles\n",
            "Tiling slide: wrote 8300/62989 tiles\n",
            "Tiling slide: wrote 8400/62989 tiles\n",
            "Tiling slide: wrote 8500/62989 tiles\n",
            "Tiling slide: wrote 8600/62989 tiles\n",
            "Tiling slide: wrote 8700/62989 tiles\n",
            "Tiling slide: wrote 8800/62989 tiles\n",
            "Tiling slide: wrote 8900/62989 tiles\n",
            "Tiling slide: wrote 9000/62989 tiles\n",
            "Tiling slide: wrote 9100/62989 tiles\n",
            "Tiling slide: wrote 9200/62989 tiles\n",
            "Tiling slide: wrote 9300/62989 tiles\n",
            "Tiling slide: wrote 9400/62989 tiles\n",
            "Tiling slide: wrote 9500/62989 tiles\n",
            "Tiling slide: wrote 9600/62989 tiles\n",
            "Tiling slide: wrote 9700/62989 tiles\n",
            "Tiling slide: wrote 9800/62989 tiles\n",
            "Tiling slide: wrote 9900/62989 tiles\n",
            "Tiling slide: wrote 10000/62989 tiles\n",
            "Tiling slide: wrote 10100/62989 tiles\n",
            "Tiling slide: wrote 10200/62989 tiles\n",
            "Tiling slide: wrote 10300/62989 tiles\n",
            "Tiling slide: wrote 10400/62989 tiles\n",
            "Tiling slide: wrote 10500/62989 tiles\n",
            "Tiling slide: wrote 10600/62989 tiles\n",
            "Tiling slide: wrote 10700/62989 tiles\n",
            "Tiling slide: wrote 10800/62989 tiles\n",
            "Tiling slide: wrote 10900/62989 tiles\n",
            "Tiling slide: wrote 11000/62989 tiles\n",
            "Tiling slide: wrote 11100/62989 tiles\n",
            "Tiling slide: wrote 11200/62989 tiles\n",
            "Tiling slide: wrote 11300/62989 tiles\n",
            "Tiling slide: wrote 11400/62989 tiles\n",
            "Tiling slide: wrote 11500/62989 tiles\n",
            "Tiling slide: wrote 11600/62989 tiles\n",
            "Tiling slide: wrote 11700/62989 tiles\n",
            "Tiling slide: wrote 11800/62989 tiles\n",
            "Tiling slide: wrote 100/61697 tiles\n",
            "Tiling slide: wrote 200/61697 tiles\n",
            "Tiling slide: wrote 300/61697 tiles\n",
            "Tiling slide: wrote 400/61697 tiles\n",
            "Tiling slide: wrote 500/61697 tiles\n",
            "Tiling slide: wrote 600/61697 tiles\n",
            "Tiling slide: wrote 700/61697 tiles\n",
            "Tiling slide: wrote 800/61697 tiles\n",
            "Tiling slide: wrote 900/61697 tiles\n",
            "Tiling slide: wrote 1000/61697 tiles\n",
            "Tiling slide: wrote 1100/61697 tiles\n",
            "Tiling slide: wrote 1200/61697 tiles\n",
            "Tiling slide: wrote 1300/61697 tiles\n",
            "Tiling slide: wrote 1400/61697 tiles\n",
            "Tiling slide: wrote 1500/61697 tiles\n",
            "Tiling slide: wrote 1600/61697 tiles\n",
            "Tiling slide: wrote 1700/61697 tiles\n",
            "Tiling slide: wrote 1800/61697 tiles\n",
            "Tiling slide: wrote 1900/61697 tiles\n",
            "Tiling slide: wrote 2000/61697 tiles\n",
            "Tiling slide: wrote 2100/61697 tiles\n",
            "Tiling slide: wrote 2200/61697 tiles\n",
            "Tiling slide: wrote 2300/61697 tiles\n",
            "Tiling slide: wrote 2400/61697 tiles\n",
            "Tiling slide: wrote 2500/61697 tiles\n",
            "Tiling slide: wrote 2600/61697 tiles\n",
            "Tiling slide: wrote 2700/61697 tiles\n",
            "Tiling slide: wrote 2800/61697 tiles\n",
            "Tiling slide: wrote 2900/61697 tiles\n",
            "Tiling slide: wrote 3000/61697 tiles\n",
            "Tiling slide: wrote 3100/61697 tiles\n",
            "Tiling slide: wrote 3200/61697 tiles\n",
            "Tiling slide: wrote 3300/61697 tiles\n",
            "Tiling slide: wrote 3400/61697 tiles\n",
            "Tiling slide: wrote 3500/61697 tiles\n",
            "Tiling slide: wrote 3600/61697 tiles\n",
            "Tiling slide: wrote 3700/61697 tiles\n",
            "Tiling slide: wrote 3800/61697 tiles\n",
            "Tiling slide: wrote 3900/61697 tiles\n",
            "Tiling slide: wrote 4000/61697 tiles\n",
            "Tiling slide: wrote 4100/61697 tiles\n",
            "Tiling slide: wrote 4200/61697 tiles\n",
            "Tiling slide: wrote 4300/61697 tiles\n",
            "Tiling slide: wrote 4400/61697 tiles\n",
            "Tiling slide: wrote 4500/61697 tiles\n",
            "Tiling slide: wrote 4600/61697 tiles\n",
            "Tiling slide: wrote 4700/61697 tiles\n",
            "Tiling slide: wrote 4800/61697 tiles\n",
            "Tiling slide: wrote 4900/61697 tiles\n",
            "Tiling slide: wrote 5000/61697 tiles\n",
            "Tiling slide: wrote 5100/61697 tiles\n",
            "Tiling slide: wrote 5200/61697 tiles\n",
            "Tiling slide: wrote 5300/61697 tiles\n",
            "Tiling slide: wrote 5400/61697 tiles\n",
            "Tiling slide: wrote 5500/61697 tiles\n",
            "Tiling slide: wrote 5600/61697 tiles\n",
            "Tiling slide: wrote 5700/61697 tiles\n",
            "Tiling slide: wrote 5800/61697 tiles\n",
            "Tiling slide: wrote 5900/61697 tiles\n",
            "Tiling slide: wrote 6000/61697 tiles\n",
            "Tiling slide: wrote 6100/61697 tiles\n",
            "Tiling slide: wrote 6200/61697 tiles\n",
            "Tiling slide: wrote 6300/61697 tiles\n",
            "Tiling slide: wrote 6400/61697 tiles\n",
            "Tiling slide: wrote 6500/61697 tiles\n",
            "Tiling slide: wrote 6600/61697 tiles\n",
            "Tiling slide: wrote 6700/61697 tiles\n",
            "Tiling slide: wrote 6800/61697 tiles\n",
            "Tiling slide: wrote 6900/61697 tiles\n",
            "Tiling slide: wrote 7000/61697 tiles\n",
            "Tiling slide: wrote 7100/61697 tiles\n",
            "Tiling slide: wrote 7200/61697 tiles\n",
            "Tiling slide: wrote 7300/61697 tiles\n",
            "Tiling slide: wrote 7400/61697 tiles\n",
            "Tiling slide: wrote 7500/61697 tiles\n",
            "Tiling slide: wrote 7600/61697 tiles\n",
            "Tiling slide: wrote 7700/61697 tiles\n",
            "Tiling slide: wrote 7800/61697 tiles\n",
            "Tiling slide: wrote 7900/61697 tiles\n",
            "Tiling slide: wrote 8000/61697 tiles\n",
            "Tiling slide: wrote 8100/61697 tiles\n",
            "Tiling slide: wrote 8200/61697 tiles\n",
            "Tiling slide: wrote 8300/61697 tiles\n",
            "Tiling slide: wrote 8400/61697 tiles\n",
            "Tiling slide: wrote 8500/61697 tiles\n",
            "Tiling slide: wrote 8600/61697 tiles\n",
            "Tiling slide: wrote 8700/61697 tiles\n",
            "Tiling slide: wrote 8800/61697 tiles\n",
            "Tiling slide: wrote 8900/61697 tiles\n",
            "Tiling slide: wrote 9000/61697 tiles\n",
            "Tiling slide: wrote 9100/61697 tiles\n",
            "Tiling slide: wrote 9200/61697 tiles\n",
            "Tiling slide: wrote 9300/61697 tiles\n",
            "Tiling slide: wrote 9400/61697 tiles\n",
            "Tiling slide: wrote 9500/61697 tiles\n",
            "Tiling slide: wrote 9600/61697 tiles\n",
            "Tiling slide: wrote 9700/61697 tiles\n",
            "Tiling slide: wrote 9800/61697 tiles\n",
            "Tiling slide: wrote 9900/61697 tiles\n",
            "Tiling slide: wrote 10000/61697 tiles\n",
            "Tiling slide: wrote 10100/61697 tiles\n",
            "Tiling slide: wrote 10200/61697 tiles\n",
            "Tiling slide: wrote 10300/61697 tiles\n",
            "Tiling slide: wrote 10400/61697 tiles\n",
            "Tiling slide: wrote 10500/61697 tiles\n",
            "Tiling slide: wrote 10600/61697 tiles\n",
            "Tiling slide: wrote 10700/61697 tiles\n",
            "Tiling slide: wrote 10800/61697 tiles\n",
            "Tiling slide: wrote 10900/61697 tiles\n",
            "Tiling slide: wrote 11000/61697 tiles\n",
            "Tiling slide: wrote 11100/61697 tiles\n",
            "Tiling slide: wrote 11200/61697 tiles\n",
            "Tiling slide: wrote 11300/61697 tiles\n",
            "Tiling slide: wrote 11400/61697 tiles\n",
            "Tiling slide: wrote 11500/61697 tiles\n",
            "Tiling slide: wrote 100/37044 tiles\n",
            "Tiling slide: wrote 200/37044 tiles\n",
            "Tiling slide: wrote 300/37044 tiles\n",
            "Tiling slide: wrote 400/37044 tiles\n",
            "Tiling slide: wrote 500/37044 tiles\n",
            "Tiling slide: wrote 600/37044 tiles\n",
            "Tiling slide: wrote 700/37044 tiles\n",
            "Tiling slide: wrote 800/37044 tiles\n",
            "Tiling slide: wrote 900/37044 tiles\n",
            "Tiling slide: wrote 1000/37044 tiles\n",
            "Tiling slide: wrote 1100/37044 tiles\n",
            "Tiling slide: wrote 1200/37044 tiles\n",
            "Tiling slide: wrote 1300/37044 tiles\n",
            "Tiling slide: wrote 1400/37044 tiles\n",
            "Tiling slide: wrote 1500/37044 tiles\n",
            "Tiling slide: wrote 1600/37044 tiles\n",
            "Tiling slide: wrote 1700/37044 tiles\n",
            "Tiling slide: wrote 1800/37044 tiles\n",
            "Tiling slide: wrote 1900/37044 tiles\n",
            "Tiling slide: wrote 2000/37044 tiles\n",
            "Tiling slide: wrote 2100/37044 tiles\n",
            "Tiling slide: wrote 2200/37044 tiles\n",
            "Tiling slide: wrote 2300/37044 tiles\n",
            "Tiling slide: wrote 2400/37044 tiles\n",
            "Tiling slide: wrote 2500/37044 tiles\n",
            "Tiling slide: wrote 2600/37044 tiles\n",
            "Tiling slide: wrote 2700/37044 tiles\n",
            "Tiling slide: wrote 2800/37044 tiles\n",
            "Tiling slide: wrote 2900/37044 tiles\n",
            "Tiling slide: wrote 3000/37044 tiles\n",
            "Tiling slide: wrote 3100/37044 tiles\n",
            "Tiling slide: wrote 3200/37044 tiles\n",
            "Tiling slide: wrote 3300/37044 tiles\n",
            "Tiling slide: wrote 3400/37044 tiles\n",
            "Tiling slide: wrote 3500/37044 tiles\n",
            "Tiling slide: wrote 3600/37044 tiles\n",
            "Tiling slide: wrote 3700/37044 tiles\n",
            "Tiling slide: wrote 3800/37044 tiles\n",
            "Tiling slide: wrote 3900/37044 tiles\n",
            "Tiling slide: wrote 4000/37044 tiles\n",
            "Tiling slide: wrote 4100/37044 tiles\n",
            "Tiling slide: wrote 4200/37044 tiles\n",
            "Tiling slide: wrote 4300/37044 tiles\n",
            "Tiling slide: wrote 4400/37044 tiles\n",
            "Tiling slide: wrote 4500/37044 tiles\n",
            "Tiling slide: wrote 4600/37044 tiles\n",
            "Tiling slide: wrote 4700/37044 tiles\n",
            "Tiling slide: wrote 4800/37044 tiles\n",
            "Tiling slide: wrote 4900/37044 tiles\n",
            "Tiling slide: wrote 5000/37044 tiles\n",
            "Tiling slide: wrote 5100/37044 tiles\n",
            "Tiling slide: wrote 5200/37044 tiles\n",
            "Tiling slide: wrote 5300/37044 tiles\n",
            "Tiling slide: wrote 5400/37044 tiles\n",
            "Tiling slide: wrote 5500/37044 tiles\n",
            "Tiling slide: wrote 5600/37044 tiles\n",
            "Tiling slide: wrote 5700/37044 tiles\n",
            "Tiling slide: wrote 5800/37044 tiles\n",
            "Tiling slide: wrote 5900/37044 tiles\n",
            "Tiling slide: wrote 6000/37044 tiles\n",
            "Tiling slide: wrote 6100/37044 tiles\n",
            "Tiling slide: wrote 6200/37044 tiles\n",
            "Tiling slide: wrote 6300/37044 tiles\n",
            "Tiling slide: wrote 6400/37044 tiles\n",
            "Tiling slide: wrote 6500/37044 tiles\n",
            "Tiling slide: wrote 6600/37044 tiles\n",
            "Tiling slide: wrote 6700/37044 tiles\n",
            "Tiling slide: wrote 6800/37044 tiles\n",
            "Tiling slide: wrote 6900/37044 tiles\n",
            "Tiling slide: wrote 100/65548 tiles\n",
            "Tiling slide: wrote 200/65548 tiles\n",
            "Tiling slide: wrote 300/65548 tiles\n",
            "Tiling slide: wrote 400/65548 tiles\n",
            "Tiling slide: wrote 500/65548 tiles\n",
            "Tiling slide: wrote 600/65548 tiles\n",
            "Tiling slide: wrote 700/65548 tiles\n",
            "Tiling slide: wrote 800/65548 tiles\n",
            "Tiling slide: wrote 900/65548 tiles\n",
            "Tiling slide: wrote 1000/65548 tiles\n",
            "Tiling slide: wrote 1100/65548 tiles\n",
            "Tiling slide: wrote 1200/65548 tiles\n",
            "Tiling slide: wrote 1300/65548 tiles\n",
            "Tiling slide: wrote 1400/65548 tiles\n",
            "Tiling slide: wrote 1500/65548 tiles\n",
            "Tiling slide: wrote 1600/65548 tiles\n",
            "Tiling slide: wrote 1700/65548 tiles\n",
            "Tiling slide: wrote 1800/65548 tiles\n",
            "Tiling slide: wrote 1900/65548 tiles\n",
            "Tiling slide: wrote 2000/65548 tiles\n",
            "Tiling slide: wrote 2100/65548 tiles\n",
            "Tiling slide: wrote 2200/65548 tiles\n",
            "Tiling slide: wrote 2300/65548 tiles\n",
            "Tiling slide: wrote 2400/65548 tiles\n",
            "Tiling slide: wrote 2500/65548 tiles\n",
            "Tiling slide: wrote 2600/65548 tiles\n",
            "Tiling slide: wrote 2700/65548 tiles\n",
            "Tiling slide: wrote 2800/65548 tiles\n",
            "Tiling slide: wrote 2900/65548 tiles\n",
            "Tiling slide: wrote 3000/65548 tiles\n",
            "Tiling slide: wrote 3100/65548 tiles\n",
            "Tiling slide: wrote 3200/65548 tiles\n",
            "Tiling slide: wrote 3300/65548 tiles\n",
            "Tiling slide: wrote 3400/65548 tiles\n",
            "Tiling slide: wrote 3500/65548 tiles\n",
            "Tiling slide: wrote 3600/65548 tiles\n",
            "Tiling slide: wrote 3700/65548 tiles\n",
            "Tiling slide: wrote 3800/65548 tiles\n",
            "Tiling slide: wrote 3900/65548 tiles\n",
            "Tiling slide: wrote 4000/65548 tiles\n",
            "Tiling slide: wrote 4100/65548 tiles\n",
            "Tiling slide: wrote 4200/65548 tiles\n",
            "Tiling slide: wrote 4300/65548 tiles\n",
            "Tiling slide: wrote 4400/65548 tiles\n",
            "Tiling slide: wrote 4500/65548 tiles\n",
            "Tiling slide: wrote 4600/65548 tiles\n",
            "Tiling slide: wrote 4700/65548 tiles\n",
            "Tiling slide: wrote 4800/65548 tiles\n",
            "Tiling slide: wrote 4900/65548 tiles\n",
            "Tiling slide: wrote 5000/65548 tiles\n",
            "Tiling slide: wrote 5100/65548 tiles\n",
            "Tiling slide: wrote 5200/65548 tiles\n",
            "Tiling slide: wrote 5300/65548 tiles\n",
            "Tiling slide: wrote 5400/65548 tiles\n",
            "Tiling slide: wrote 5500/65548 tiles\n",
            "Tiling slide: wrote 5600/65548 tiles\n",
            "Tiling slide: wrote 5700/65548 tiles\n",
            "Tiling slide: wrote 5800/65548 tiles\n",
            "Tiling slide: wrote 5900/65548 tiles\n",
            "Tiling slide: wrote 6000/65548 tiles\n",
            "Tiling slide: wrote 6100/65548 tiles\n",
            "Tiling slide: wrote 6200/65548 tiles\n",
            "Tiling slide: wrote 6300/65548 tiles\n",
            "Tiling slide: wrote 6400/65548 tiles\n",
            "Tiling slide: wrote 6500/65548 tiles\n",
            "Tiling slide: wrote 6600/65548 tiles\n",
            "Tiling slide: wrote 6700/65548 tiles\n",
            "Tiling slide: wrote 6800/65548 tiles\n",
            "Tiling slide: wrote 6900/65548 tiles\n",
            "Tiling slide: wrote 7000/65548 tiles\n",
            "Tiling slide: wrote 7100/65548 tiles\n",
            "Tiling slide: wrote 7200/65548 tiles\n",
            "Tiling slide: wrote 7300/65548 tiles\n",
            "Tiling slide: wrote 7400/65548 tiles\n",
            "Tiling slide: wrote 7500/65548 tiles\n",
            "Tiling slide: wrote 7600/65548 tiles\n",
            "Tiling slide: wrote 7700/65548 tiles\n",
            "Tiling slide: wrote 7800/65548 tiles\n",
            "Tiling slide: wrote 7900/65548 tiles\n",
            "Tiling slide: wrote 8000/65548 tiles\n",
            "Tiling slide: wrote 8100/65548 tiles\n",
            "Tiling slide: wrote 8200/65548 tiles\n",
            "Tiling slide: wrote 8300/65548 tiles\n",
            "Tiling slide: wrote 8400/65548 tiles\n",
            "Tiling slide: wrote 8500/65548 tiles\n",
            "Tiling slide: wrote 8600/65548 tiles\n",
            "Tiling slide: wrote 8700/65548 tiles\n",
            "Tiling slide: wrote 8800/65548 tiles\n",
            "Tiling slide: wrote 8900/65548 tiles\n",
            "Tiling slide: wrote 9000/65548 tiles\n",
            "Tiling slide: wrote 9100/65548 tiles\n",
            "Tiling slide: wrote 9200/65548 tiles\n",
            "Tiling slide: wrote 9300/65548 tiles\n",
            "Tiling slide: wrote 9400/65548 tiles\n",
            "Tiling slide: wrote 9500/65548 tiles\n",
            "Tiling slide: wrote 9600/65548 tiles\n",
            "Tiling slide: wrote 9700/65548 tiles\n",
            "Tiling slide: wrote 9800/65548 tiles\n",
            "Tiling slide: wrote 9900/65548 tiles\n",
            "Tiling slide: wrote 10000/65548 tiles\n",
            "Tiling slide: wrote 10100/65548 tiles\n",
            "Tiling slide: wrote 10200/65548 tiles\n",
            "Tiling slide: wrote 10300/65548 tiles\n",
            "Tiling slide: wrote 10400/65548 tiles\n",
            "Tiling slide: wrote 10500/65548 tiles\n",
            "Tiling slide: wrote 10600/65548 tiles\n",
            "Tiling slide: wrote 10700/65548 tiles\n",
            "Tiling slide: wrote 10800/65548 tiles\n",
            "Tiling slide: wrote 10900/65548 tiles\n",
            "Tiling slide: wrote 11000/65548 tiles\n",
            "Tiling slide: wrote 11100/65548 tiles\n",
            "Tiling slide: wrote 11200/65548 tiles\n",
            "Tiling slide: wrote 11300/65548 tiles\n",
            "Tiling slide: wrote 11400/65548 tiles\n",
            "Tiling slide: wrote 11500/65548 tiles\n",
            "Tiling slide: wrote 11600/65548 tiles\n",
            "Tiling slide: wrote 11700/65548 tiles\n",
            "Tiling slide: wrote 11800/65548 tiles\n",
            "Tiling slide: wrote 11900/65548 tiles\n",
            "Tiling slide: wrote 12000/65548 tiles\n",
            "Tiling slide: wrote 12100/65548 tiles\n",
            "Tiling slide: wrote 12200/65548 tiles\n",
            "Tiling slide: wrote 100/34414 tiles\n",
            "Tiling slide: wrote 200/34414 tiles\n",
            "Tiling slide: wrote 300/34414 tiles\n",
            "Tiling slide: wrote 400/34414 tiles\n",
            "Tiling slide: wrote 500/34414 tiles\n",
            "Tiling slide: wrote 600/34414 tiles\n",
            "Tiling slide: wrote 700/34414 tiles\n",
            "Tiling slide: wrote 800/34414 tiles\n",
            "Tiling slide: wrote 900/34414 tiles\n",
            "Tiling slide: wrote 1000/34414 tiles\n",
            "Tiling slide: wrote 1100/34414 tiles\n",
            "Tiling slide: wrote 1200/34414 tiles\n",
            "Tiling slide: wrote 1300/34414 tiles\n",
            "Tiling slide: wrote 1400/34414 tiles\n",
            "Tiling slide: wrote 1500/34414 tiles\n",
            "Tiling slide: wrote 1600/34414 tiles\n",
            "Tiling slide: wrote 1700/34414 tiles\n",
            "Tiling slide: wrote 1800/34414 tiles\n",
            "Tiling slide: wrote 1900/34414 tiles\n",
            "Tiling slide: wrote 2000/34414 tiles\n",
            "Tiling slide: wrote 2100/34414 tiles\n",
            "Tiling slide: wrote 2200/34414 tiles\n",
            "Tiling slide: wrote 2300/34414 tiles\n",
            "Tiling slide: wrote 2400/34414 tiles\n",
            "Tiling slide: wrote 2500/34414 tiles\n",
            "Tiling slide: wrote 2600/34414 tiles\n",
            "Tiling slide: wrote 2700/34414 tiles\n",
            "Tiling slide: wrote 2800/34414 tiles\n",
            "Tiling slide: wrote 2900/34414 tiles\n",
            "Tiling slide: wrote 3000/34414 tiles\n",
            "Tiling slide: wrote 3100/34414 tiles\n",
            "Tiling slide: wrote 3200/34414 tiles\n",
            "Tiling slide: wrote 3300/34414 tiles\n",
            "Tiling slide: wrote 3400/34414 tiles\n",
            "Tiling slide: wrote 3500/34414 tiles\n",
            "Tiling slide: wrote 3600/34414 tiles\n",
            "Tiling slide: wrote 3700/34414 tiles\n",
            "Tiling slide: wrote 3800/34414 tiles\n",
            "Tiling slide: wrote 3900/34414 tiles\n",
            "Tiling slide: wrote 4000/34414 tiles\n",
            "Tiling slide: wrote 4100/34414 tiles\n",
            "Tiling slide: wrote 4200/34414 tiles\n",
            "Tiling slide: wrote 4300/34414 tiles\n",
            "Tiling slide: wrote 4400/34414 tiles\n",
            "Tiling slide: wrote 4500/34414 tiles\n",
            "Tiling slide: wrote 4600/34414 tiles\n",
            "Tiling slide: wrote 4700/34414 tiles\n",
            "Tiling slide: wrote 4800/34414 tiles\n",
            "Tiling slide: wrote 4900/34414 tiles\n",
            "Tiling slide: wrote 5000/34414 tiles\n",
            "Tiling slide: wrote 5100/34414 tiles\n",
            "Tiling slide: wrote 5200/34414 tiles\n",
            "Tiling slide: wrote 5300/34414 tiles\n",
            "Tiling slide: wrote 5400/34414 tiles\n",
            "Tiling slide: wrote 5500/34414 tiles\n",
            "Tiling slide: wrote 5600/34414 tiles\n",
            "Tiling slide: wrote 5700/34414 tiles\n",
            "Tiling slide: wrote 5800/34414 tiles\n",
            "Tiling slide: wrote 5900/34414 tiles\n",
            "Tiling slide: wrote 6000/34414 tiles\n",
            "Tiling slide: wrote 6100/34414 tiles\n",
            "Tiling slide: wrote 6200/34414 tiles\n",
            "Tiling slide: wrote 6300/34414 tiles\n",
            "Tiling slide: wrote 6400/34414 tiles\n",
            "Tiling slide: wrote 100/89866 tiles\n",
            "Tiling slide: wrote 200/89866 tiles\n",
            "Tiling slide: wrote 300/89866 tiles\n",
            "Tiling slide: wrote 400/89866 tiles\n",
            "Tiling slide: wrote 500/89866 tiles\n",
            "Tiling slide: wrote 600/89866 tiles\n",
            "Tiling slide: wrote 700/89866 tiles\n",
            "Tiling slide: wrote 800/89866 tiles\n",
            "Tiling slide: wrote 900/89866 tiles\n",
            "Tiling slide: wrote 1000/89866 tiles\n",
            "Tiling slide: wrote 1100/89866 tiles\n",
            "Tiling slide: wrote 1200/89866 tiles\n",
            "Tiling slide: wrote 1300/89866 tiles\n",
            "Tiling slide: wrote 1400/89866 tiles\n",
            "Tiling slide: wrote 1500/89866 tiles\n",
            "Tiling slide: wrote 1600/89866 tiles\n",
            "Tiling slide: wrote 1700/89866 tiles\n",
            "Tiling slide: wrote 1800/89866 tiles\n",
            "Tiling slide: wrote 1900/89866 tiles\n",
            "Tiling slide: wrote 2000/89866 tiles\n",
            "Tiling slide: wrote 2100/89866 tiles\n",
            "Tiling slide: wrote 2200/89866 tiles\n",
            "Tiling slide: wrote 2300/89866 tiles\n",
            "Tiling slide: wrote 2400/89866 tiles\n",
            "Tiling slide: wrote 2500/89866 tiles\n",
            "Tiling slide: wrote 2600/89866 tiles\n",
            "Tiling slide: wrote 2700/89866 tiles\n",
            "Tiling slide: wrote 2800/89866 tiles\n",
            "Tiling slide: wrote 2900/89866 tiles\n",
            "Tiling slide: wrote 3000/89866 tiles\n",
            "Tiling slide: wrote 3100/89866 tiles\n",
            "Tiling slide: wrote 3200/89866 tiles\n",
            "Tiling slide: wrote 3300/89866 tiles\n",
            "Tiling slide: wrote 3400/89866 tiles\n",
            "Tiling slide: wrote 3500/89866 tiles\n",
            "Tiling slide: wrote 3600/89866 tiles\n",
            "Tiling slide: wrote 3700/89866 tiles\n",
            "Tiling slide: wrote 3800/89866 tiles\n",
            "Tiling slide: wrote 3900/89866 tiles\n",
            "Tiling slide: wrote 4000/89866 tiles\n",
            "Tiling slide: wrote 4100/89866 tiles\n",
            "Tiling slide: wrote 4200/89866 tiles\n",
            "Tiling slide: wrote 4300/89866 tiles\n",
            "Tiling slide: wrote 4400/89866 tiles\n",
            "Tiling slide: wrote 4500/89866 tiles\n",
            "Tiling slide: wrote 4600/89866 tiles\n",
            "Tiling slide: wrote 4700/89866 tiles\n",
            "Tiling slide: wrote 4800/89866 tiles\n",
            "Tiling slide: wrote 4900/89866 tiles\n",
            "Tiling slide: wrote 5000/89866 tiles\n",
            "Tiling slide: wrote 5100/89866 tiles\n",
            "Tiling slide: wrote 5200/89866 tiles\n",
            "Tiling slide: wrote 5300/89866 tiles\n",
            "Tiling slide: wrote 5400/89866 tiles\n",
            "Tiling slide: wrote 5500/89866 tiles\n",
            "Tiling slide: wrote 5600/89866 tiles\n",
            "Tiling slide: wrote 5700/89866 tiles\n",
            "Tiling slide: wrote 5800/89866 tiles\n",
            "Tiling slide: wrote 5900/89866 tiles\n",
            "Tiling slide: wrote 6000/89866 tiles\n",
            "Tiling slide: wrote 6100/89866 tiles\n",
            "Tiling slide: wrote 6200/89866 tiles\n",
            "Tiling slide: wrote 6300/89866 tiles\n",
            "Tiling slide: wrote 6400/89866 tiles\n",
            "Tiling slide: wrote 6500/89866 tiles\n",
            "Tiling slide: wrote 6600/89866 tiles\n",
            "Tiling slide: wrote 6700/89866 tiles\n",
            "Tiling slide: wrote 6800/89866 tiles\n",
            "Tiling slide: wrote 6900/89866 tiles\n",
            "Tiling slide: wrote 7000/89866 tiles\n",
            "Tiling slide: wrote 7100/89866 tiles\n",
            "Tiling slide: wrote 7200/89866 tiles\n",
            "Tiling slide: wrote 7300/89866 tiles\n",
            "Tiling slide: wrote 7400/89866 tiles\n",
            "Tiling slide: wrote 7500/89866 tiles\n",
            "Tiling slide: wrote 7600/89866 tiles\n",
            "Tiling slide: wrote 7700/89866 tiles\n",
            "Tiling slide: wrote 7800/89866 tiles\n",
            "Tiling slide: wrote 7900/89866 tiles\n",
            "Tiling slide: wrote 8000/89866 tiles\n",
            "Tiling slide: wrote 8100/89866 tiles\n",
            "Tiling slide: wrote 8200/89866 tiles\n",
            "Tiling slide: wrote 8300/89866 tiles\n",
            "Tiling slide: wrote 8400/89866 tiles\n",
            "Tiling slide: wrote 8500/89866 tiles\n",
            "Tiling slide: wrote 8600/89866 tiles\n",
            "Tiling slide: wrote 8700/89866 tiles\n",
            "Tiling slide: wrote 8800/89866 tiles\n",
            "Tiling slide: wrote 8900/89866 tiles\n",
            "Tiling slide: wrote 9000/89866 tiles\n",
            "Tiling slide: wrote 9100/89866 tiles\n",
            "Tiling slide: wrote 9200/89866 tiles\n",
            "Tiling slide: wrote 9300/89866 tiles\n",
            "Tiling slide: wrote 9400/89866 tiles\n",
            "Tiling slide: wrote 9500/89866 tiles\n",
            "Tiling slide: wrote 9600/89866 tiles\n",
            "Tiling slide: wrote 9700/89866 tiles\n",
            "Tiling slide: wrote 9800/89866 tiles\n",
            "Tiling slide: wrote 9900/89866 tiles\n",
            "Tiling slide: wrote 10000/89866 tiles\n",
            "Tiling slide: wrote 10100/89866 tiles\n",
            "Tiling slide: wrote 10200/89866 tiles\n",
            "Tiling slide: wrote 10300/89866 tiles\n",
            "Tiling slide: wrote 10400/89866 tiles\n",
            "Tiling slide: wrote 10500/89866 tiles\n",
            "Tiling slide: wrote 10600/89866 tiles\n",
            "Tiling slide: wrote 10700/89866 tiles\n",
            "Tiling slide: wrote 10800/89866 tiles\n",
            "Tiling slide: wrote 10900/89866 tiles\n",
            "Tiling slide: wrote 11000/89866 tiles\n",
            "Tiling slide: wrote 11100/89866 tiles\n",
            "Tiling slide: wrote 11200/89866 tiles\n",
            "Tiling slide: wrote 11300/89866 tiles\n",
            "Tiling slide: wrote 11400/89866 tiles\n",
            "Tiling slide: wrote 11500/89866 tiles\n",
            "Tiling slide: wrote 11600/89866 tiles\n",
            "Tiling slide: wrote 11700/89866 tiles\n",
            "Tiling slide: wrote 11800/89866 tiles\n",
            "Tiling slide: wrote 11900/89866 tiles\n",
            "Tiling slide: wrote 12000/89866 tiles\n",
            "Tiling slide: wrote 12100/89866 tiles\n",
            "Tiling slide: wrote 12200/89866 tiles\n",
            "Tiling slide: wrote 12300/89866 tiles\n",
            "Tiling slide: wrote 12400/89866 tiles\n",
            "Tiling slide: wrote 12500/89866 tiles\n",
            "Tiling slide: wrote 12600/89866 tiles\n",
            "Tiling slide: wrote 12700/89866 tiles\n",
            "Tiling slide: wrote 12800/89866 tiles\n",
            "Tiling slide: wrote 12900/89866 tiles\n",
            "Tiling slide: wrote 13000/89866 tiles\n",
            "Tiling slide: wrote 13100/89866 tiles\n",
            "Tiling slide: wrote 13200/89866 tiles\n",
            "Tiling slide: wrote 13300/89866 tiles\n",
            "Tiling slide: wrote 13400/89866 tiles\n",
            "Tiling slide: wrote 13500/89866 tiles\n",
            "Tiling slide: wrote 13600/89866 tiles\n",
            "Tiling slide: wrote 13700/89866 tiles\n",
            "Tiling slide: wrote 13800/89866 tiles\n",
            "Tiling slide: wrote 13900/89866 tiles\n",
            "Tiling slide: wrote 14000/89866 tiles\n",
            "Tiling slide: wrote 14100/89866 tiles\n",
            "Tiling slide: wrote 14200/89866 tiles\n",
            "Tiling slide: wrote 14300/89866 tiles\n",
            "Tiling slide: wrote 14400/89866 tiles\n",
            "Tiling slide: wrote 14500/89866 tiles\n",
            "Tiling slide: wrote 14600/89866 tiles\n",
            "Tiling slide: wrote 14700/89866 tiles\n",
            "Tiling slide: wrote 14800/89866 tiles\n",
            "Tiling slide: wrote 14900/89866 tiles\n",
            "Tiling slide: wrote 15000/89866 tiles\n",
            "Tiling slide: wrote 15100/89866 tiles\n",
            "Tiling slide: wrote 15200/89866 tiles\n",
            "Tiling slide: wrote 15300/89866 tiles\n",
            "Tiling slide: wrote 15400/89866 tiles\n",
            "Tiling slide: wrote 15500/89866 tiles\n",
            "Tiling slide: wrote 15600/89866 tiles\n",
            "Tiling slide: wrote 15700/89866 tiles\n",
            "Tiling slide: wrote 15800/89866 tiles\n",
            "Tiling slide: wrote 15900/89866 tiles\n",
            "Tiling slide: wrote 16000/89866 tiles\n",
            "Tiling slide: wrote 16100/89866 tiles\n",
            "Tiling slide: wrote 16200/89866 tiles\n",
            "Tiling slide: wrote 16300/89866 tiles\n",
            "Tiling slide: wrote 16400/89866 tiles\n",
            "Tiling slide: wrote 16500/89866 tiles\n",
            "Tiling slide: wrote 16600/89866 tiles\n",
            "Tiling slide: wrote 16700/89866 tiles\n",
            "Tiling slide: wrote 16800/89866 tiles\n",
            "Tiling slide: wrote 100/83919 tiles\n",
            "Tiling slide: wrote 200/83919 tiles\n",
            "Tiling slide: wrote 300/83919 tiles\n",
            "Tiling slide: wrote 400/83919 tiles\n",
            "Tiling slide: wrote 500/83919 tiles\n",
            "Tiling slide: wrote 600/83919 tiles\n",
            "Tiling slide: wrote 700/83919 tiles\n",
            "Tiling slide: wrote 800/83919 tiles\n",
            "Tiling slide: wrote 900/83919 tiles\n",
            "Tiling slide: wrote 1000/83919 tiles\n",
            "Tiling slide: wrote 1100/83919 tiles\n",
            "Tiling slide: wrote 1200/83919 tiles\n",
            "Tiling slide: wrote 1300/83919 tiles\n",
            "Tiling slide: wrote 1400/83919 tiles\n",
            "Tiling slide: wrote 1500/83919 tiles\n",
            "Tiling slide: wrote 1600/83919 tiles\n",
            "Tiling slide: wrote 1700/83919 tiles\n",
            "Tiling slide: wrote 1800/83919 tiles\n",
            "Tiling slide: wrote 1900/83919 tiles\n",
            "Tiling slide: wrote 2000/83919 tiles\n",
            "Tiling slide: wrote 2100/83919 tiles\n",
            "Tiling slide: wrote 2200/83919 tiles\n",
            "Tiling slide: wrote 2300/83919 tiles\n",
            "Tiling slide: wrote 2400/83919 tiles\n",
            "Tiling slide: wrote 2500/83919 tiles\n",
            "Tiling slide: wrote 2600/83919 tiles\n",
            "Tiling slide: wrote 2700/83919 tiles\n",
            "Tiling slide: wrote 2800/83919 tiles\n",
            "Tiling slide: wrote 2900/83919 tiles\n",
            "Tiling slide: wrote 3000/83919 tiles\n",
            "Tiling slide: wrote 3100/83919 tiles\n",
            "Tiling slide: wrote 3200/83919 tiles\n",
            "Tiling slide: wrote 3300/83919 tiles\n",
            "Tiling slide: wrote 3400/83919 tiles\n",
            "Tiling slide: wrote 3500/83919 tiles\n",
            "Tiling slide: wrote 3600/83919 tiles\n",
            "Tiling slide: wrote 3700/83919 tiles\n",
            "Tiling slide: wrote 3800/83919 tiles\n",
            "Tiling slide: wrote 3900/83919 tiles\n",
            "Tiling slide: wrote 4000/83919 tiles\n",
            "Tiling slide: wrote 4100/83919 tiles\n",
            "Tiling slide: wrote 4200/83919 tiles\n",
            "Tiling slide: wrote 4300/83919 tiles\n",
            "Tiling slide: wrote 4400/83919 tiles\n",
            "Tiling slide: wrote 4500/83919 tiles\n",
            "Tiling slide: wrote 4600/83919 tiles\n",
            "Tiling slide: wrote 4700/83919 tiles\n",
            "Tiling slide: wrote 4800/83919 tiles\n",
            "Tiling slide: wrote 4900/83919 tiles\n",
            "Tiling slide: wrote 5000/83919 tiles\n",
            "Tiling slide: wrote 5100/83919 tiles\n",
            "Tiling slide: wrote 5200/83919 tiles\n",
            "Tiling slide: wrote 5300/83919 tiles\n",
            "Tiling slide: wrote 5400/83919 tiles\n",
            "Tiling slide: wrote 5500/83919 tiles\n",
            "Tiling slide: wrote 5600/83919 tiles\n",
            "Tiling slide: wrote 5700/83919 tiles\n",
            "Tiling slide: wrote 5800/83919 tiles\n",
            "Tiling slide: wrote 5900/83919 tiles\n",
            "Tiling slide: wrote 6000/83919 tiles\n",
            "Tiling slide: wrote 6100/83919 tiles\n",
            "Tiling slide: wrote 6200/83919 tiles\n",
            "Tiling slide: wrote 6300/83919 tiles\n",
            "Tiling slide: wrote 6400/83919 tiles\n",
            "Tiling slide: wrote 6500/83919 tiles\n",
            "Tiling slide: wrote 6600/83919 tiles\n",
            "Tiling slide: wrote 6700/83919 tiles\n",
            "Tiling slide: wrote 6800/83919 tiles\n",
            "Tiling slide: wrote 6900/83919 tiles\n",
            "Tiling slide: wrote 7000/83919 tiles\n",
            "Tiling slide: wrote 7100/83919 tiles\n",
            "Tiling slide: wrote 7200/83919 tiles\n",
            "Tiling slide: wrote 7300/83919 tiles\n",
            "Tiling slide: wrote 7400/83919 tiles\n",
            "Tiling slide: wrote 7500/83919 tiles\n",
            "Tiling slide: wrote 7600/83919 tiles\n",
            "Tiling slide: wrote 7700/83919 tiles\n",
            "Tiling slide: wrote 7800/83919 tiles\n",
            "Tiling slide: wrote 7900/83919 tiles\n",
            "Tiling slide: wrote 8000/83919 tiles\n",
            "Tiling slide: wrote 8100/83919 tiles\n",
            "Tiling slide: wrote 8200/83919 tiles\n",
            "Tiling slide: wrote 8300/83919 tiles\n",
            "Tiling slide: wrote 8400/83919 tiles\n",
            "Tiling slide: wrote 8500/83919 tiles\n",
            "Tiling slide: wrote 8600/83919 tiles\n",
            "Tiling slide: wrote 8700/83919 tiles\n",
            "Tiling slide: wrote 8800/83919 tiles\n",
            "Tiling slide: wrote 8900/83919 tiles\n",
            "Tiling slide: wrote 9000/83919 tiles\n",
            "Tiling slide: wrote 9100/83919 tiles\n",
            "Tiling slide: wrote 9200/83919 tiles\n",
            "Tiling slide: wrote 9300/83919 tiles\n",
            "Tiling slide: wrote 9400/83919 tiles\n",
            "Tiling slide: wrote 9500/83919 tiles\n",
            "Tiling slide: wrote 9600/83919 tiles\n",
            "Tiling slide: wrote 9700/83919 tiles\n",
            "Tiling slide: wrote 9800/83919 tiles\n",
            "Tiling slide: wrote 9900/83919 tiles\n",
            "Tiling slide: wrote 10000/83919 tiles\n",
            "Tiling slide: wrote 10100/83919 tiles\n",
            "Tiling slide: wrote 10200/83919 tiles\n",
            "Tiling slide: wrote 10300/83919 tiles\n",
            "Tiling slide: wrote 10400/83919 tiles\n",
            "Tiling slide: wrote 10500/83919 tiles\n",
            "Tiling slide: wrote 10600/83919 tiles\n",
            "Tiling slide: wrote 10700/83919 tiles\n",
            "Tiling slide: wrote 10800/83919 tiles\n",
            "Tiling slide: wrote 10900/83919 tiles\n",
            "Tiling slide: wrote 11000/83919 tiles\n",
            "Tiling slide: wrote 11100/83919 tiles\n",
            "Tiling slide: wrote 11200/83919 tiles\n",
            "Tiling slide: wrote 11300/83919 tiles\n",
            "Tiling slide: wrote 11400/83919 tiles\n",
            "Tiling slide: wrote 11500/83919 tiles\n",
            "Tiling slide: wrote 11600/83919 tiles\n",
            "Tiling slide: wrote 11700/83919 tiles\n",
            "Tiling slide: wrote 11800/83919 tiles\n",
            "Tiling slide: wrote 11900/83919 tiles\n",
            "Tiling slide: wrote 12000/83919 tiles\n",
            "Tiling slide: wrote 12100/83919 tiles\n",
            "Tiling slide: wrote 12200/83919 tiles\n",
            "Tiling slide: wrote 12300/83919 tiles\n",
            "Tiling slide: wrote 12400/83919 tiles\n",
            "Tiling slide: wrote 12500/83919 tiles\n",
            "Tiling slide: wrote 12600/83919 tiles\n",
            "Tiling slide: wrote 12700/83919 tiles\n",
            "Tiling slide: wrote 12800/83919 tiles\n",
            "Tiling slide: wrote 12900/83919 tiles\n",
            "Tiling slide: wrote 13000/83919 tiles\n",
            "Tiling slide: wrote 13100/83919 tiles\n",
            "Tiling slide: wrote 13200/83919 tiles\n",
            "Tiling slide: wrote 13300/83919 tiles\n",
            "Tiling slide: wrote 13400/83919 tiles\n",
            "Tiling slide: wrote 13500/83919 tiles\n",
            "Tiling slide: wrote 13600/83919 tiles\n",
            "Tiling slide: wrote 13700/83919 tiles\n",
            "Tiling slide: wrote 13800/83919 tiles\n",
            "Tiling slide: wrote 13900/83919 tiles\n",
            "Tiling slide: wrote 14000/83919 tiles\n",
            "Tiling slide: wrote 14100/83919 tiles\n",
            "Tiling slide: wrote 14200/83919 tiles\n",
            "Tiling slide: wrote 14300/83919 tiles\n",
            "Tiling slide: wrote 14400/83919 tiles\n",
            "Tiling slide: wrote 14500/83919 tiles\n",
            "Tiling slide: wrote 14600/83919 tiles\n",
            "Tiling slide: wrote 14700/83919 tiles\n",
            "Tiling slide: wrote 14800/83919 tiles\n",
            "Tiling slide: wrote 14900/83919 tiles\n",
            "Tiling slide: wrote 15000/83919 tiles\n",
            "Tiling slide: wrote 15100/83919 tiles\n",
            "Tiling slide: wrote 15200/83919 tiles\n",
            "Tiling slide: wrote 15300/83919 tiles\n",
            "Tiling slide: wrote 15400/83919 tiles\n",
            "Tiling slide: wrote 15500/83919 tiles\n",
            "Tiling slide: wrote 15600/83919 tiles\n",
            "Tiling slide: wrote 15700/83919 tiles\n",
            "Tiling slide: wrote 100/28076 tiles\n",
            "Tiling slide: wrote 200/28076 tiles\n",
            "Tiling slide: wrote 300/28076 tiles\n",
            "Tiling slide: wrote 400/28076 tiles\n",
            "Tiling slide: wrote 500/28076 tiles\n",
            "Tiling slide: wrote 600/28076 tiles\n",
            "Tiling slide: wrote 700/28076 tiles\n",
            "Tiling slide: wrote 800/28076 tiles\n",
            "Tiling slide: wrote 900/28076 tiles\n",
            "Tiling slide: wrote 1000/28076 tiles\n",
            "Tiling slide: wrote 1100/28076 tiles\n",
            "Tiling slide: wrote 1200/28076 tiles\n",
            "Tiling slide: wrote 1300/28076 tiles\n",
            "Tiling slide: wrote 1400/28076 tiles\n",
            "Tiling slide: wrote 1500/28076 tiles\n",
            "Tiling slide: wrote 1600/28076 tiles\n",
            "Tiling slide: wrote 1700/28076 tiles\n",
            "Tiling slide: wrote 1800/28076 tiles\n",
            "Tiling slide: wrote 1900/28076 tiles\n",
            "Tiling slide: wrote 2000/28076 tiles\n",
            "Tiling slide: wrote 2100/28076 tiles\n",
            "Tiling slide: wrote 2200/28076 tiles\n",
            "Tiling slide: wrote 2300/28076 tiles\n",
            "Tiling slide: wrote 2400/28076 tiles\n",
            "Tiling slide: wrote 2500/28076 tiles\n",
            "Tiling slide: wrote 2600/28076 tiles\n",
            "Tiling slide: wrote 2700/28076 tiles\n",
            "Tiling slide: wrote 2800/28076 tiles\n",
            "Tiling slide: wrote 2900/28076 tiles\n",
            "Tiling slide: wrote 3000/28076 tiles\n",
            "Tiling slide: wrote 3100/28076 tiles\n",
            "Tiling slide: wrote 3200/28076 tiles\n",
            "Tiling slide: wrote 3300/28076 tiles\n",
            "Tiling slide: wrote 3400/28076 tiles\n",
            "Tiling slide: wrote 3500/28076 tiles\n",
            "Tiling slide: wrote 3600/28076 tiles\n",
            "Tiling slide: wrote 3700/28076 tiles\n",
            "Tiling slide: wrote 3800/28076 tiles\n",
            "Tiling slide: wrote 3900/28076 tiles\n",
            "Tiling slide: wrote 4000/28076 tiles\n",
            "Tiling slide: wrote 4100/28076 tiles\n",
            "Tiling slide: wrote 4200/28076 tiles\n",
            "Tiling slide: wrote 4300/28076 tiles\n",
            "Tiling slide: wrote 4400/28076 tiles\n",
            "Tiling slide: wrote 4500/28076 tiles\n",
            "Tiling slide: wrote 4600/28076 tiles\n",
            "Tiling slide: wrote 4700/28076 tiles\n",
            "Tiling slide: wrote 4800/28076 tiles\n",
            "Tiling slide: wrote 4900/28076 tiles\n",
            "Tiling slide: wrote 5000/28076 tiles\n",
            "Tiling slide: wrote 5100/28076 tiles\n",
            "Tiling slide: wrote 5200/28076 tiles\n",
            "Tiling slide: wrote 5300/28076 tiles\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import gc\n",
        "\n",
        "def free_memory():\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()    # Libera la cache della GPU\n",
        "        torch.cuda.ipc_collect()    # Raccoglie la memoria non piÃ¹ usata dalla GPU\n",
        "    gc.collect()                    # Libera la RAM\n",
        "\n",
        "free_memory()"
      ],
      "metadata": {
        "id": "1qqJyNfbrFaE"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!conda run -n dsmil pip install tensorboard"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waJULj3i5vPW",
        "outputId": "de42e89d-9c6a-475d-f395-16d1eefd6b82"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorboard in /usr/local/envs/dsmil/lib/python3.13/site-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/envs/dsmil/lib/python3.13/site-packages (from tensorboard) (2.3.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/envs/dsmil/lib/python3.13/site-packages (from tensorboard) (1.73.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/envs/dsmil/lib/python3.13/site-packages (from tensorboard) (3.8.2)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/envs/dsmil/lib/python3.13/site-packages (from tensorboard) (2.3.1)\n",
            "Requirement already satisfied: packaging in /usr/local/envs/dsmil/lib/python3.13/site-packages (from tensorboard) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/envs/dsmil/lib/python3.13/site-packages (from tensorboard) (6.31.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/envs/dsmil/lib/python3.13/site-packages (from tensorboard) (72.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/envs/dsmil/lib/python3.13/site-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/envs/dsmil/lib/python3.13/site-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/envs/dsmil/lib/python3.13/site-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/envs/dsmil/lib/python3.13/site-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  # Train an embedder SIMClr\n",
        "  %cd /content/dsmil-wsi/simclr\n",
        "  !MPLBACKEND=Agg conda run -n dsmil python run.py --dataset=ndpi_files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHhgK_OX5Wh6",
        "outputId": "65bafbd0-31ac-4b6a-8904-bb6f649b0e08"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/dsmil-wsi/simclr\n",
            "Please install apex for mixed precision training from: https://github.com/NVIDIA/apex\n",
            "Running on: cuda\n",
            "Feature extractor: resnet18\n",
            "ResNetSimCLR(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (4): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (5): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (6): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (7): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      )\n",
            "    )\n",
            "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  )\n",
            "  (l1): Linear(in_features=512, out_features=512, bias=True)\n",
            "  (l2): Linear(in_features=512, out_features=256, bias=True)\n",
            ")\n",
            "Loaded pretrained ResNet-18 weights successfully.\n",
            "\n",
            "/usr/local/envs/dsmil/lib/python3.13/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/dsmil/lib/python3.13/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/envs/dsmil/lib/python3.13/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/dsmil-wsi/simclr/run.py\", line 41, in <module>\n",
            "    main()\n",
            "    ~~~~^^\n",
            "  File \"/content/dsmil-wsi/simclr/run.py\", line 37, in main\n",
            "    simclr.train()\n",
            "    ~~~~~~~~~~~~^^\n",
            "  File \"/content/dsmil-wsi/simclr/simclr.py\", line 118, in train\n",
            "    valid_loss = self._validate(model, valid_loader)\n",
            "  File \"/content/dsmil-wsi/simclr/simclr.py\", line 161, in _validate\n",
            "    for (xis, xjs) in valid_loader:\n",
            "                      ^^^^^^^^^^^^\n",
            "  File \"/usr/local/envs/dsmil/lib/python3.13/site-packages/torch/utils/data/dataloader.py\", line 733, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/envs/dsmil/lib/python3.13/site-packages/torch/utils/data/dataloader.py\", line 789, in _next_data\n",
            "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
            "  File \"/usr/local/envs/dsmil/lib/python3.13/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "            ~~~~~~~~~~~~^^^^^\n",
            "  File \"/content/dsmil-wsi/simclr/data_aug/dataset_wrapper.py\", line 21, in __getitem__\n",
            "    img = Image.open(temp_path)\n",
            "  File \"/usr/local/envs/dsmil/lib/python3.13/site-packages/PIL/Image.py\", line 3532, in open\n",
            "    raise UnidentifiedImageError(msg)\n",
            "PIL.UnidentifiedImageError: cannot identify image file '../WSI/ndpi_files/single/E/M-111/65_113.jpeg'\n",
            "\n",
            "ERROR conda.cli.main_run:execute(125): `conda run python run.py --dataset=ndpi_files` failed. (See above for error)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import requests\n",
        "import json\n",
        "\n",
        "# Your Zenodo access token here\n",
        "ACCESS_TOKEN = 'uVSb7icJqT9efPM71KYgviJ50r7eML9ynei2q7hDkedVlFrf8fBsr9lFaJ3O'  # <-- Put your token here\n",
        "\n",
        "# Folder you want to zip and upload\n",
        "folder_dest = '/content/dsmil-wsi/WSI/ndpi_files/single'\n",
        "\n",
        "# 1. Create ZIP archive of folder, maintaining structure\n",
        "def create_zip_archive(folder_path, zip_name=None):\n",
        "    if zip_name is None:\n",
        "        zip_name = f\"{os.path.basename(folder_path)}.zip\"\n",
        "\n",
        "    print(f\"ðŸ—œï¸ Creating ZIP archive: {zip_name}\")\n",
        "    with zipfile.ZipFile(zip_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for root, dirs, files in os.walk(folder_path):\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                arc_name = os.path.relpath(file_path, os.path.dirname(folder_path))\n",
        "                zipf.write(file_path, arc_name)\n",
        "                print(f\"  ðŸ“ Added: {arc_name}\")\n",
        "\n",
        "    zip_size = os.path.getsize(zip_name)\n",
        "    print(f\"âœ… Archive created: {zip_name} ({zip_size/1024/1024:.2f} MB)\")\n",
        "    return zip_name\n",
        "\n",
        "\n",
        "# 2. Create a new Zenodo deposition (dataset)\n",
        "def create_deposition(title):\n",
        "    url = 'https://zenodo.org/api/deposit/depositions'\n",
        "    headers = {\"Content-Type\": \"application/json\"}\n",
        "    params = {'access_token': ACCESS_TOKEN}\n",
        "\n",
        "    data = {\n",
        "        'metadata': {\n",
        "            'title': title,\n",
        "            'upload_type': 'dataset',\n",
        "            'description': 'Working on DSMIL patch extraction dataset',\n",
        "            'creators': [{'name': 'Raf-Tony-Luca'}]\n",
        "        }\n",
        "    }\n",
        "\n",
        "    response = requests.post(url, params=params, data=json.dumps(data), headers=headers)\n",
        "    response.raise_for_status()\n",
        "    return response.json()\n",
        "\n",
        "\n",
        "# 3. Upload the ZIP file to the Zenodo bucket URL\n",
        "def upload_file(deposition_id, file_path):\n",
        "    url = f'https://zenodo.org/api/deposit/depositions/{deposition_id}'\n",
        "    params = {'access_token': ACCESS_TOKEN}\n",
        "    r = requests.get(url, params=params)\n",
        "    r.raise_for_status()\n",
        "    bucket_url = r.json()[\"links\"][\"bucket\"]\n",
        "\n",
        "    filename = os.path.basename(file_path)\n",
        "    with open(file_path, \"rb\") as fp:\n",
        "        r = requests.put(f\"{bucket_url}/{filename}\", data=fp, params=params)\n",
        "        r.raise_for_status()\n",
        "    print(f\"âœ… File {filename} uploaded successfully.\")\n",
        "    return r.json()\n",
        "\n",
        "\n",
        "# 4. Publish the deposition (make it public)\n",
        "def publish_deposition(deposition_id):\n",
        "    url = f'https://zenodo.org/api/deposit/depositions/{deposition_id}/actions/publish'\n",
        "    params = {'access_token': ACCESS_TOKEN}\n",
        "    r = requests.post(url, params=params)\n",
        "    r.raise_for_status()\n",
        "    print(\"âœ… Deposition published successfully.\")\n",
        "    return r.json()\n",
        "\n",
        "\n",
        "# --- Main flow ---\n",
        "\n",
        "# Change dir if you want, here just for context\n",
        "os.chdir('/content/dsmil-wsi')\n",
        "\n",
        "zip_filename = 'WSI_single.zip'\n",
        "\n",
        "# Create ZIP archive\n",
        "zip_path = create_zip_archive(folder_dest, zip_filename)\n",
        "\n",
        "# Create deposition\n",
        "print(\"Creating Zenodo deposition...\")\n",
        "deposition = create_deposition(\"DSMIL_patch_extraction_single\")\n",
        "deposition_id = deposition['id']\n",
        "\n",
        "# Upload file\n",
        "print(f\"Uploading file to deposition ID: {deposition_id} ...\")\n",
        "upload_result = upload_file(deposition_id, zip_path)\n",
        "\n",
        "# Publish dataset\n",
        "print(\"Publishing dataset on Zenodo...\")\n",
        "publication = publish_deposition(deposition_id)\n",
        "\n",
        "print(f\"ðŸŽ‰ Dataset published! DOI: {publication['doi']}\")\n",
        "print(f\"ðŸŒ URL: {publication['links']['record_html']}\")\n"
      ],
      "metadata": {
        "id": "L5aLNIKPIyNC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09d1f669-df23-4794-daa7-bf95f7c4cf54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mOutput streaming troncato alle ultime 5000 righe.\u001b[0m\n",
            "  ðŸ“ Added: single/S/M-86/60_47.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/42_154.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/49_88.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/35_100.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/52_81.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/111_164.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/160_122.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/60_40.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/24_148.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/182_152.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/15_74.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/133_76.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/82_84.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/10_48.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/131_60.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/120_154.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/104_111.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/41_37.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/43_49.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/111_189.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/144_167.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/79_113.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/164_98.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/115_120.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/60_36.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/66_180.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/91_100.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/27_40.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/97_114.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/67_111.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/35_103.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/153_97.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/168_144.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/139_167.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/27_125.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/75_29.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/41_99.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/32_72.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/34_149.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/117_176.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/21_102.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/149_96.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/130_158.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/41_74.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/92_108.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/94_153.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/129_106.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/55_76.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/73_91.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_52.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/159_158.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/120_158.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/74_85.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/54_20.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_31.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/37_201.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/39_88.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/178_149.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/79_152.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_108.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/52_105.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/157_87.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/107_200.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/35_149.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/163_147.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/44_187.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/21_38.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/41_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/47_104.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/75_56.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/134_140.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/85_97.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/173_124.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/54_54.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/110_114.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/174_125.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/36_139.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/36_44.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/49_134.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/86_68.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/111_33.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/145_174.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/136_137.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/43_78.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_177.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/15_99.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/156_165.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/20_70.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/72_138.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/91_162.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/106_141.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/72_47.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/143_168.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/162_60.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/85_98.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/47_98.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/99_97.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/65_79.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/18_59.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/130_146.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/34_80.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/36_84.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/98_198.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_189.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/101_45.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/165_138.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/141_98.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/18_98.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/127_135.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/67_86.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/137_179.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/20_48.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/174_169.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/14_111.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/146_72.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/90_49.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/23_52.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/79_34.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/49_51.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/86_106.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/87_153.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/39_54.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/124_69.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_85.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/109_114.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/85_44.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/97_155.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/127_79.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/19_41.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/123_196.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/178_161.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/89_69.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/126_166.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/82_38.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/107_142.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/110_140.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/45_26.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/68_51.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/84_51.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/123_137.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/145_70.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/153_159.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/19_63.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/114_79.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/90_171.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/96_95.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/72_79.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_193.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/114_40.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/163_148.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/49_203.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/102_199.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/173_168.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/36_198.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/32_26.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/67_83.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/18_93.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/92_50.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/75_28.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/114_85.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/132_192.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/118_63.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/63_89.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/135_137.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/152_145.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/76_50.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/89_191.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/50_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/129_143.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/32_55.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/114_75.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/129_139.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/176_152.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/67_29.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/139_92.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/87_80.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_35.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/30_37.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/50_44.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/179_167.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/78_97.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/13_33.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/86_48.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/63_59.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/113_75.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/107_188.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/34_112.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/112_102.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/118_72.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_127.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/116_135.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/28_195.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/42_18.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/86_155.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/43_55.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/59_71.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/79_49.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/32_58.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/48_117.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/30_20.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/100_197.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/56_187.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/141_85.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/127_93.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/125_146.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/52_50.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/42_100.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/116_75.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/46_99.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_79.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/65_80.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/63_95.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/133_166.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/61_60.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/35_82.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/161_162.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/126_145.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/79_116.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/54_19.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/48_135.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/48_124.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/36_155.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/118_109.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/130_145.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/42_60.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/33_55.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/86_51.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/109_39.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/81_114.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/48_90.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/56_119.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/33_15.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/41_153.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/30_127.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/159_172.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/39_183.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/24_60.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/45_98.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/54_85.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/52_58.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/170_143.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_121.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/63_100.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/28_116.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/61_64.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/97_45.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/36_121.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/114_187.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/39_25.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/90_74.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/111_104.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/174_156.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/84_54.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/116_114.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/23_91.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/56_92.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/50_100.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/88_164.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/116_59.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/76_117.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/32_191.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/51_98.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/145_160.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/80_73.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/41_77.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/42_91.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/76_27.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/81_75.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/86_151.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/47_113.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/75_100.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/133_165.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/100_45.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/101_164.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/166_158.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/35_35.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/148_163.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/134_94.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/116_136.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/55_80.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/113_149.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/55_199.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/161_153.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/139_166.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/16_104.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/92_158.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/123_136.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/46_50.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/69_111.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/152_170.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/9_48.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/30_32.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/13_38.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/130_131.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/165_137.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/44_80.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/50_197.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/18_96.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/155_142.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/74_88.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/112_123.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/45_136.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/154_91.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/111_102.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/61_139.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/125_70.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/104_155.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/119_193.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/40_44.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/38_124.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/80_174.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/53_52.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/47_189.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/87_112.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/23_32.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/160_176.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/106_39.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/90_192.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/17_49.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/80_51.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/26_27.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/122_206.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/46_192.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/86_114.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/166_53.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/121_114.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/100_162.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/17_75.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/60_156.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/174_148.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/81_51.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/40_32.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/134_110.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/28_110.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/129_104.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/115_93.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/162_109.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/114_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/80_60.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/66_77.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/163_44.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/42_71.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/51_183.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/85_72.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/38_87.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/26_84.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/25_26.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/100_158.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/68_141.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/126_150.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/27_94.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/120_120.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/146_184.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/76_89.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/19_61.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/13_53.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/25_86.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/61_181.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/153_106.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/125_130.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/47_81.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/158_167.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/67_33.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/69_44.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/74_106.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/85_173.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/44_97.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/93_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/132_157.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/41_94.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/52_63.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/60_70.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/72_193.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/13_98.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/135_108.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/50_182.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/126_51.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/76_44.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/39_75.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/39_39.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/28_31.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/118_174.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/86_63.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/166_170.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/80_189.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/86_95.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/107_49.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/101_158.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/152_148.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/93_108.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/114_151.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/64_28.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/92_165.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/133_160.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/131_202.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/63_47.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/45_115.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/75_102.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_175.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/50_189.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/63_31.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/126_179.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/79_187.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/23_103.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/41_103.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/20_106.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/183_150.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/60_34.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/47_117.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/66_151.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_87.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/109_126.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/74_102.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/28_46.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/8_44.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/112_174.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/158_117.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/39_200.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/21_36.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/83_28.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/17_79.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/122_66.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/87_99.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/128_181.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/84_114.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/70_115.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/44_137.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/22_23.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/144_180.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/57_95.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/75_115.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/159_179.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/63_180.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/123_153.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/156_151.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/36_99.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/164_95.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/144_164.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/45_61.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/26_35.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/66_63.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/124_95.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/34_105.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/156_149.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/16_75.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/150_84.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/88_83.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/17_95.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/158_179.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/110_184.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/36_36.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/158_162.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/40_19.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/161_115.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/80_59.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/81_181.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/39_96.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/136_112.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/10_42.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/163_164.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/20_143.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/141_150.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/130_153.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/67_34.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/89_58.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_80.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/112_120.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/51_42.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/40_15.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/111_191.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/177_174.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/22_35.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/143_175.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/67_69.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/83_87.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/59_37.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/126_128.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/164_159.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/44_38.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/73_111.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_161.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/156_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/36_30.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/88_181.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/72_78.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/53_110.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/30_99.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/166_144.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/54_78.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/98_117.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_94.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/90_112.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/42_102.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_48.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/106_105.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/77_51.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/94_41.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/24_191.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/32_100.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/177_163.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/74_110.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/66_91.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/67_181.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/111_163.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/14_58.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/13_36.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/141_108.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/79_180.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/119_176.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/108_109.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/174_147.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_120.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/104_45.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/119_65.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/158_52.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/37_53.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/112_42.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/159_165.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/63_103.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/122_128.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/54_102.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/86_61.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/59_107.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/63_76.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/76_148.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/33_157.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/5_49.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/91_62.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/81_183.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/74_108.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/132_93.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/92_157.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/15_53.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/136_163.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/124_207.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/52_45.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/36_66.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/17_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/21_75.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/88_123.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/131_93.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/92_155.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/106_112.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/105_144.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/15_113.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/17_37.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/81_184.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/147_168.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/63_178.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/170_153.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/64_180.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/60_98.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/119_153.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/138_80.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/75_94.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/146_69.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/67_113.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/123_141.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/36_14.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/52_196.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/54_60.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/21_45.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/50_78.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/122_186.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/37_47.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_83.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/17_69.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/132_153.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/117_118.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/154_60.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/71_137.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/163_55.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/40_185.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/78_161.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/130_162.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/157_178.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/32_111.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/116_61.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/84_86.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/51_122.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/46_96.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/109_181.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/83_53.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/49_83.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/71_60.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/140_77.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/40_154.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/22_90.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/53_185.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/48_107.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/49_135.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/124_104.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/136_188.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/40_121.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/177_153.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_109.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/48_100.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/66_75.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/35_119.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/122_148.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/13_58.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/90_153.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/25_119.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/23_193.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/118_137.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_37.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/68_62.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/123_185.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/64_143.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/89_98.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/83_149.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/57_115.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/56_103.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/127_74.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/85_45.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/161_158.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/130_149.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/114_112.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/57_181.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/117_175.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/27_149.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_190.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/95_113.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/61_65.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/38_15.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/41_118.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/90_150.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/134_166.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/23_57.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/22_53.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/163_167.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/113_137.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/154_84.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/154_180.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/80_53.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/7_47.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/133_77.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/41_193.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_57.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/122_132.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/167_166.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/164_84.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/88_190.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/28_20.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/90_161.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/117_152.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/69_139.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_45.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/30_54.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/160_147.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/146_176.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/151_166.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/50_93.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/121_176.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/39_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/26_144.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/10_35.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/67_51.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/162_123.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/110_125.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/84_170.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/159_97.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/65_74.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/169_152.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/156_178.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/54_75.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/171_158.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/123_204.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/130_173.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/50_52.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/49_47.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/104_185.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/38_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/51_76.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/32_19.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/146_170.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/54_199.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/165_151.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/143_161.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/147_75.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/83_83.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/74_174.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/161_166.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/23_54.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/53_73.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/90_63.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/120_171.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_73.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/160_81.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/65_52.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/118_188.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/87_46.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/66_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/105_163.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/124_172.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/14_43.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/84_115.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/135_204.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/92_172.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/104_200.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/83_58.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/36_69.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/66_182.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/34_181.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/159_83.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/41_40.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/75_90.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/63_54.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/131_165.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/157_82.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/106_156.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/157_172.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/170_150.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/27_52.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/138_145.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/134_180.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/57_48.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/82_28.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/146_144.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/132_191.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/135_166.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_92.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/92_185.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/140_167.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/114_76.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/33_23.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/43_30.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_95.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_107.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/97_151.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_29.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/24_106.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/54_45.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/64_81.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/91_91.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/27_88.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/38_182.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/160_107.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/82_75.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/17_65.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/101_162.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/123_172.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/60_119.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_30.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/79_106.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/163_151.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/75_82.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/87_54.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/87_173.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/122_133.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/153_87.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/74_116.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/35_151.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/49_22.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/111_192.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/108_36.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/20_56.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/19_91.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/162_157.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_60.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/47_72.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/80_181.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/90_103.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/25_200.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/60_182.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/151_156.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/47_186.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/74_100.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/26_188.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/71_81.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/134_86.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/22_84.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_114.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/25_91.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/116_100.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/160_138.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/103_155.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_117.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/17_45.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/123_96.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/22_45.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/104_180.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/118_138.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/57_79.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/28_74.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/131_141.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/109_154.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/42_55.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/6_54.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/57_178.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/131_201.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/121_186.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/137_149.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/86_94.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/129_196.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/134_146.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/162_176.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/89_105.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/36_83.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/39_56.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_143.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/140_168.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/27_68.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/109_115.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/135_188.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/67_143.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/10_36.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/110_106.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/86_47.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/35_201.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/133_156.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/98_99.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/79_27.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/44_45.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/70_110.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/127_204.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/115_117.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/124_190.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/69_81.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/161_147.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/137_189.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/26_116.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/28_189.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/103_82.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/160_83.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/80_39.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/79_84.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/89_170.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_33.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/68_74.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/24_51.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/21_69.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/36_119.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/180_141.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/128_169.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/134_168.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/131_171.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/111_152.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/129_81.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/108_186.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/92_92.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/124_202.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/79_186.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/125_187.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/43_47.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/83_151.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/115_151.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/156_171.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/152_108.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/114_188.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/45_78.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/102_109.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/94_166.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/128_150.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/124_129.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/129_161.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/16_86.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/34_185.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/63_116.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/35_42.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/144_108.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/33_193.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/54_68.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/163_84.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/149_141.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_67.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/100_151.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/95_184.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/181_140.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/145_82.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/112_189.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_79.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/59_180.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/167_149.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/85_153.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/36_93.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/75_113.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/126_63.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/45_36.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/152_158.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/85_107.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/26_26.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/22_47.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/43_114.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/33_116.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/97_115.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/132_181.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/40_152.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/82_24.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/169_147.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_84.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_51.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/37_67.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_187.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/91_55.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/25_188.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/43_113.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/178_145.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/57_102.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/101_155.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/161_150.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/133_93.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/125_127.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/122_80.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/101_99.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/87_70.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/151_170.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/35_138.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/73_186.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/22_100.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/127_98.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/69_34.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/84_104.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/15_109.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/59_177.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/70_105.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/63_44.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/61_44.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/102_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/87_113.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/71_91.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/42_32.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/165_95.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/75_177.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/95_104.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/49_40.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/147_144.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/61_31.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/121_95.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/66_95.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/34_141.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/82_87.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/75_179.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/59_135.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/24_20.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/90_156.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/98_152.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/88_75.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/98_200.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/81_58.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/39_117.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/108_34.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/158_47.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/27_39.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/43_23.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/88_46.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/82_58.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/34_192.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/168_162.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/114_164.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/144_147.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/130_137.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/67_174.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/84_88.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/43_84.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/148_143.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/128_203.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/171_171.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/182_142.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_47.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/49_185.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/17_100.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/165_177.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/137_112.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/131_88.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/22_58.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/78_188.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/77_106.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/154_141.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_72.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/131_204.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/11_53.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/84_84.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/123_152.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/87_56.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/75_60.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/156_123.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/173_157.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/134_85.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_92.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/43_96.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/123_84.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/11_39.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_105.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/137_100.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/25_67.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/43_20.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/14_103.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/134_142.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/24_44.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/131_136.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/76_180.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/69_76.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/165_50.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/87_75.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/60_55.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/92_171.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/51_103.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/23_93.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/38_185.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/102_155.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/141_175.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/7_41.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/169_163.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/149_179.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/111_158.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/50_112.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/122_63.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/155_59.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/136_181.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/157_93.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/95_154.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/88_167.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/56_79.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/41_81.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/160_148.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/114_74.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_182.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/106_118.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/117_83.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/102_190.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/123_82.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/86_90.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/69_150.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/121_140.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/125_111.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/114_154.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/87_155.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/169_162.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/21_106.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_71.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/154_52.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_149.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/61_191.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/128_153.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/133_169.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/24_189.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/175_145.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/138_92.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/8_50.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/138_75.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/128_87.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/95_47.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/57_191.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/153_54.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/94_167.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/96_152.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/11_48.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/112_104.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/142_94.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/43_35.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/56_36.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/36_187.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/10_58.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/159_86.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/28_79.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/61_187.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/37_20.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/160_93.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/71_152.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/161_59.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/33_86.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/117_111.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/172_154.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/156_45.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/26_46.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/112_165.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/72_52.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/49_81.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/37_99.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/33_146.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/54_92.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/96_99.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/117_166.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/130_134.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/63_173.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/176_171.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/141_179.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/122_92.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/117_122.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/38_191.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/57_188.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/81_46.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/64_94.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/69_84.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/81_24.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/71_84.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/71_143.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/130_155.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/17_61.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/37_192.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/182_124.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/38_156.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/38_91.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/35_97.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/56_60.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/35_59.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/94_97.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/32_144.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/11_103.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/155_163.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/78_109.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/122_113.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/104_109.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/166_51.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/68_174.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/20_79.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/162_59.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_66.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/13_113.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/167_150.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/159_167.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/28_38.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/92_97.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/67_142.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/89_110.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/75_30.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/13_35.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/50_81.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/142_95.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/75_71.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/132_137.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/119_96.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/102_96.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/145_98.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/126_207.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/65_36.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/171_164.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/153_142.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/50_64.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/45_96.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/44_61.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/159_141.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/161_116.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/104_91.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/113_174.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/156_105.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/155_98.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/50_74.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/130_174.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/73_58.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/128_163.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/35_122.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/144_146.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/87_90.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/79_79.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/51_37.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/79_32.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/146_95.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/43_42.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/76_171.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/41_138.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/81_188.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/76_154.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/53_51.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/80_58.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/103_117.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/134_52.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/74_63.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/68_102.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/38_195.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/77_42.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/34_102.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/71_106.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/25_21.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/56_105.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/46_57.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/69_99.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/159_122.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/14_62.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/88_67.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/52_82.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/118_147.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/41_115.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/59_42.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/55_44.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/135_177.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/117_195.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/10_60.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/28_67.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/117_114.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/73_116.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/39_196.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/122_192.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/127_186.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/60_89.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/148_171.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/157_154.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/88_58.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/51_66.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/164_153.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/20_78.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/164_173.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/162_168.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/54_63.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/151_54.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/151_100.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/96_113.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/158_63.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/138_144.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/119_191.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/172_145.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/47_134.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/4_51.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/89_193.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/129_191.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/89_95.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/152_91.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/43_115.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/151_88.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/92_114.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_65.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/155_138.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/44_72.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/110_115.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/25_100.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/114_155.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/38_125.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/130_135.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/123_166.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/182_158.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/26_92.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/57_117.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/118_118.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/124_111.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/10_47.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/87_164.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/79_42.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/71_119.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/82_186.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/104_113.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/44_71.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/132_203.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_17.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/164_144.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/78_75.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/39_187.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/32_185.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/75_183.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/77_72.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/86_150.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/110_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/155_65.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/93_157.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/159_104.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/151_159.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/96_154.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/115_115.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/165_147.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/13_34.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/90_53.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/158_92.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/161_71.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/19_77.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/75_108.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/109_196.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/91_187.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/169_143.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_109.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/74_142.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/90_172.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/113_177.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/66_87.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/87_180.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/128_110.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/113_189.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/41_106.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/127_200.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/140_93.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/68_31.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/16_43.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/127_84.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/18_80.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/87_168.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/93_106.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/132_186.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/28_196.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/52_87.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/134_149.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/38_152.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/106_176.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/87_192.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/122_137.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/112_135.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/52_77.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/130_150.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/66_184.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/14_42.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/22_36.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/168_167.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/17_111.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/139_95.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/86_41.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/115_107.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/170_169.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/53_80.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/176_138.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/40_156.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/34_69.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/72_83.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/63_74.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/114_189.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/160_114.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/97_152.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_41.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/135_150.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/95_151.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/154_82.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/79_25.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/32_106.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/86_192.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/93_40.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/174_170.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/50_90.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/36_191.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/16_69.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/157_158.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/128_127.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/112_28.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/124_60.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/159_87.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/116_115.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/40_31.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/70_179.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/83_109.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/53_190.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/124_153.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/163_163.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/95_115.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/30_199.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/32_140.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/148_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/152_168.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/45_73.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/66_28.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/163_140.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/145_186.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/41_91.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/37_183.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/160_89.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/14_38.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/53_97.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/73_185.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/121_78.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/159_123.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/72_185.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/75_88.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/136_94.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/30_52.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/73_180.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/80_77.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/63_57.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/140_105.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/22_78.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/32_198.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/132_59.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/33_195.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/102_200.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/154_148.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/84_96.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/74_77.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/66_190.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/23_22.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_115.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/142_105.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/128_131.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/70_85.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/19_99.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/147_179.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/91_193.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/64_112.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/56_158.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/115_97.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/134_200.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/144_71.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/152_87.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/136_138.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/32_145.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_62.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/38_141.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/48_28.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/77_112.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/110_154.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/125_141.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/36_94.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/27_96.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/159_150.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/165_161.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/34_22.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/163_59.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/45_57.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/154_53.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/136_187.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/30_17.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/88_72.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/25_55.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/91_111.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/114_99.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/46_196.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_105.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/93_155.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/27_199.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/22_108.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/28_23.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/27_31.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/47_23.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/36_104.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/18_49.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/81_34.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/49_159.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/120_97.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/46_73.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/44_55.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/154_170.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/51_55.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/108_30.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/59_113.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/35_20.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/83_180.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/92_152.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/171_155.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/80_116.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/22_146.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/6_52.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/67_192.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/134_107.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/40_120.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/113_200.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/38_93.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/77_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/21_68.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/28_52.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/19_38.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/23_104.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/83_31.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/131_90.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/80_72.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/181_153.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/124_206.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/65_47.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/54_58.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/52_38.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/119_138.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/35_53.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/159_166.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/160_123.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/43_155.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/79_155.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/181_154.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/23_121.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/151_94.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/43_95.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/86_80.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/93_173.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/23_47.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/75_175.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/26_33.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/161_103.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/44_78.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/103_44.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/113_152.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/77_95.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/132_80.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_76.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/91_109.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/129_99.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/75_78.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/159_168.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/154_146.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/37_31.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/73_90.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/44_141.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/17_55.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/26_56.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/39_48.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/30_121.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/61_119.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/25_105.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/81_182.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/167_176.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/73_64.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/10_39.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/66_176.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/72_153.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/84_42.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_55.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/68_48.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/74_50.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_72.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/64_56.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/34_190.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/182_155.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/66_144.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/49_190.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/126_208.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/125_147.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/123_143.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/153_169.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/39_192.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/108_99.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/87_119.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/119_190.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/64_29.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/123_133.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/78_87.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/101_105.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/35_73.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/61_94.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_55.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/136_144.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/79_161.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/32_193.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/54_186.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/26_93.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/65_40.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/44_23.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/147_143.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/38_50.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/18_57.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/36_200.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/41_30.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/72_39.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/89_151.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/123_191.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/82_149.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/21_60.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/40_17.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/49_39.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/37_42.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/61_180.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/129_58.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/52_112.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/158_86.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/145_140.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/163_81.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/72_45.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/160_153.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/103_113.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/179_149.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/37_93.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/122_176.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/36_15.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/174_150.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/91_108.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/87_87.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/167_172.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/121_144.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/40_58.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/122_155.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/72_186.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/43_76.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/83_37.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/42_95.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/135_109.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/14_113.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/138_102.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/20_62.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/94_99.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/43_28.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/56_190.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/167_114.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/27_76.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/20_49.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/214_5.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/38_52.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/126_91.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/158_51.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/101_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/142_152.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/121_191.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/78_170.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/81_107.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/27_150.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/57_67.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_94.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/70_151.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/146_161.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/132_177.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/131_109.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/63_191.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/106_36.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/89_89.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/46_76.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/108_114.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/131_168.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/128_204.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/35_15.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/142_108.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/32_142.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/147_141.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/6_48.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/72_28.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/69_172.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/42_103.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/165_56.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/33_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/41_190.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/162_172.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/64_115.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/175_147.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/112_32.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/37_50.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/146_180.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/101_148.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/27_26.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/155_53.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/123_190.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/77_196.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/39_92.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/70_182.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/178_135.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/122_153.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/74_57.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/33_74.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_194.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/26_94.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/81_118.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/38_89.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/83_114.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/122_96.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_158.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/130_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/143_170.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/136_174.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/42_85.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/132_82.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/146_73.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/143_107.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/117_76.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/75_47.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/102_108.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/119_97.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/56_104.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/86_56.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/125_179.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/131_157.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/78_176.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/17_112.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/9_40.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/120_73.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/57_73.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/37_71.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/83_52.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/145_170.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/47_74.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/155_149.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/104_121.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/53_17.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/112_105.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_186.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/134_108.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/161_52.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/34_189.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/165_174.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/56_57.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/141_95.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/120_127.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/35_29.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/101_163.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/105_182.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/99_197.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/98_40.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/23_113.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/53_103.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_112.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/89_155.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/52_24.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/137_187.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/119_92.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/85_95.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/177_156.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/73_74.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/36_95.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/127_96.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/5_50.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_93.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/57_121.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/37_15.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_94.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/168_173.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/104_176.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/33_147.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/126_140.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/120_87.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/92_45.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/92_46.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/104_150.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/69_88.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/126_74.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/160_48.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_43.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/118_194.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/163_145.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/124_89.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/32_155.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/103_185.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/33_138.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/148_153.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/77_84.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/9_52.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/20_41.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/91_160.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/168_164.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/21_66.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/83_47.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/78_34.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/36_108.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/94_95.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/176_147.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/131_92.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/180_150.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/154_108.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/86_49.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_72.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/163_80.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/109_163.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/16_80.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/42_104.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/130_88.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/138_143.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/38_187.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/27_146.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/169_161.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/51_112.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/77_80.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/73_138.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/162_149.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/159_145.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/149_158.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/27_87.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/95_164.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/19_107.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/60_93.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/148_168.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/57_175.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/120_145.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/144_171.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/35_31.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/113_45.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/44_134.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/157_142.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/178_157.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/113_141.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/100_110.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/77_111.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/109_160.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/51_50.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/119_119.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/168_143.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/78_153.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/81_23.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/86_189.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/143_171.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/118_155.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/18_99.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/117_72.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_34.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/21_99.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/79_64.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/84_76.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_97.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/37_95.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/16_112.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/150_182.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/87_71.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/182_122.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/83_154.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/17_71.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/159_47.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/43_201.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/24_196.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/47_57.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/9_36.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/61_54.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/104_46.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/169_177.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/9_58.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/128_64.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/130_199.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/114_36.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/49_119.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/141_152.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/36_156.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/122_140.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/63_158.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/139_150.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/144_182.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/150_157.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/25_187.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/40_74.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_89.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/27_183.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/68_137.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/77_177.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/159_44.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/177_134.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/23_196.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/26_70.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/41_71.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/50_71.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/70_116.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/148_97.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/37_78.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/75_95.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/50_45.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_24.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/161_43.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/26_85.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/55_186.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/76_25.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/92_167.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/103_88.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/22_88.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_199.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/158_119.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/40_26.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/109_184.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/37_85.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/96_43.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/25_44.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/113_151.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/55_48.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/33_81.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/59_53.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/164_54.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/123_144.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/21_73.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/76_192.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/16_55.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/20_84.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/105_181.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/161_65.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/56_113.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/56_39.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/78_181.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/106_181.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/136_165.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/104_38.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/25_59.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/38_81.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/126_86.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/130_110.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/92_112.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/138_170.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/123_76.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/161_173.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/25_47.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_90.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/93_104.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/125_133.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_32.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/43_53.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/16_64.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/17_113.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/159_154.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/54_66.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/106_103.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/104_88.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/102_188.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/52_182.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/128_162.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/165_117.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/149_178.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/120_83.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/172_161.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/38_139.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/75_25.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/22_55.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/96_46.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/22_89.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/25_194.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/37_57.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/71_151.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/137_152.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/56_41.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/71_134.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/133_60.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/6_49.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_20.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/76_173.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/75_112.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/105_196.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/65_69.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/118_156.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/32_80.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/107_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/40_93.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/47_42.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/34_15.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/144_83.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/166_154.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/60_92.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/156_163.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/39_89.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/83_54.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/9_35.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/126_73.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/114_146.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/24_104.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/168_152.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/18_87.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/65_37.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/33_104.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/87_176.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/8_59.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/82_148.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/121_68.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/116_99.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/10_55.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/65_190.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_93.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/59_199.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/47_136.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/56_31.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/154_156.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/108_33.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/26_57.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/96_178.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/76_78.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/129_142.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/134_89.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/45_186.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/148_146.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/63_182.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/175_153.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/153_122.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/156_56.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/30_141.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/60_204.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/13_52.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/51_179.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/148_147.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/25_82.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/117_159.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/28_18.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/179_146.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/172_144.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/54_119.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/115_121.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/115_94.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/89_63.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/21_40.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/22_69.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/60_180.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/71_187.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/153_124.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/116_145.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/162_91.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/37_195.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/137_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/27_140.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/78_65.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/30_80.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/12_94.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/69_82.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/20_59.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/23_85.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/143_142.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/38_48.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/19_100.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/126_80.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/154_144.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/88_112.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/98_159.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/67_112.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/77_57.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/176_153.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/146_182.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/12_92.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/22_85.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/79_61.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/144_140.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/128_83.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/97_154.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/148_167.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/11_51.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/89_80.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/87_161.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/147_174.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/161_164.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/38_31.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/111_38.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/51_91.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/132_89.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/59_59.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/101_178.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/52_115.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/155_159.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/130_111.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/85_118.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_124.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/161_175.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/150_96.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/162_124.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/98_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/12_75.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/138_152.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/67_90.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/37_189.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/132_140.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/57_20.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/71_175.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/43_51.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/77_114.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/34_145.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/40_56.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/182_140.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/98_154.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/85_175.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/88_175.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_88.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/144_82.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/135_94.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/127_144.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/77_82.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/171_152.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/34_79.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/33_130.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/68_80.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/120_78.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/61_89.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/60_73.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/34_110.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/53_24.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/55_115.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_126.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/30_142.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/89_99.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/162_147.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/17_93.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/37_185.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/94_168.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/88_52.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/8_40.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/149_171.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/27_91.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/38_106.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/131_139.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/142_140.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/100_155.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/143_148.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/63_50.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/173_156.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/71_136.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/52_68.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/111_148.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/35_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/47_106.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/38_192.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/57_54.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/51_23.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/67_32.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/117_133.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/115_184.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/154_169.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/155_168.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/68_153.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/159_90.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/68_99.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/37_98.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/122_204.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/148_161.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/124_136.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/131_188.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/19_47.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/54_38.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/64_65.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/69_75.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/125_94.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/117_129.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/61_69.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/77_69.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/163_48.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/148_162.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/70_53.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/37_28.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/47_65.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/134_90.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/22_148.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/120_175.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/18_88.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/134_81.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/53_44.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/41_35.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/139_77.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/116_76.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/67_41.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/51_49.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/172_152.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/61_108.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/15_75.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/47_158.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/107_183.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/160_162.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/55_40.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/146_104.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/53_46.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/85_88.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/130_151.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/129_109.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/46_109.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/181_158.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/163_90.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/179_121.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/106_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/13_112.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/52_92.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_22.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/105_183.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/97_159.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/102_107.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/81_162.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/104_194.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/28_25.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/159_152.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/28_69.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/139_102.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/51_80.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/125_155.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/69_58.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/10_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/57_177.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/42_30.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/14_47.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/82_43.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/45_29.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/113_139.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/99_42.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/32_27.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/67_100.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/130_179.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/70_77.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/72_46.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/34_152.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/32_199.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/43_109.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/38_99.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/47_190.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/80_173.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/68_82.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/71_179.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/61_79.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/52_198.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/80_71.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/119_192.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/78_78.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/156_174.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/99_107.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/36_79.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/53_192.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/57_18.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/68_152.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/36_129.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_88.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/110_182.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/66_110.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/82_182.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/14_70.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/64_49.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/89_87.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/78_25.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/32_76.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_114.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/81_42.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_174.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/15_96.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/131_154.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/109_120.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/139_165.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/12_55.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/164_142.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/136_87.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/179_148.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/95_186.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/131_153.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/112_124.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/124_64.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/131_85.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/127_66.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/38_115.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/118_141.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/28_22.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/165_112.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/60_179.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/80_31.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/53_49.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/101_43.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/109_146.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/46_113.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/175_124.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/55_117.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/124_189.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/56_87.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/120_91.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/110_118.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/74_109.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/165_57.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/34_27.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/104_102.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/26_40.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/130_185.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/144_183.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/22_67.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/135_93.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/49_57.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_52.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_60.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/179_154.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/149_108.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/43_190.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/109_180.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/79_104.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/179_122.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/93_46.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/108_144.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/109_40.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/132_206.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/112_144.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/40_40.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/121_187.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/170_178.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/55_51.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/163_118.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/47_120.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/57_135.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/37_113.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/179_165.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/158_99.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/30_47.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/19_89.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/172_122.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/179_140.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/75_154.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/55_97.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/35_72.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/113_202.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/115_116.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/95_162.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/132_150.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/59_41.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/68_151.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/117_158.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/99_96.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/21_96.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/35_116.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/114_185.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/170_164.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/99_157.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/21_76.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/150_153.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/48_49.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/127_57.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/164_161.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/135_170.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/138_151.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/56_42.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/142_78.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/132_163.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/19_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/103_145.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/26_34.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/70_178.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/34_183.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/166_171.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/27_27.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/127_108.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/115_85.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/106_182.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/176_133.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/137_168.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/100_113.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/55_14.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/137_94.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/84_111.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/71_138.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/87_40.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/72_59.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/71_71.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/77_96.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/146_174.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/14_98.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/128_133.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/64_139.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/154_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/48_198.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/108_108.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/44_82.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/34_75.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/96_56.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/109_34.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/47_122.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/96_153.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/183_159.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/162_166.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/153_91.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/101_46.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/103_198.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/84_116.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/125_72.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/37_104.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/148_151.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/24_75.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/35_107.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/163_170.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_70.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/19_102.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/85_111.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/39_73.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/162_139.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/37_80.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/163_149.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/74_95.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/91_104.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/23_198.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/84_97.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/111_174.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/41_136.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/107_157.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/123_98.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/127_195.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_70.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/50_103.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/132_147.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/28_143.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/20_76.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/56_21.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/57_156.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/55_47.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/125_47.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/69_171.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/46_92.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/54_191.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/68_189.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/158_164.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/133_85.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/104_107.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/146_147.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/116_112.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/26_117.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/21_94.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/23_23.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_77.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/105_180.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/38_76.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/52_188.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/30_29.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/101_161.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/56_14.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/141_94.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/105_158.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/56_109.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/125_169.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/20_92.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/109_162.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/91_200.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/157_139.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/169_157.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_185.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/117_80.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/95_169.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/97_97.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/138_175.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/75_50.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/151_56.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/139_146.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/145_78.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/106_185.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/140_92.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/127_149.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/53_37.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/78_31.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/35_95.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/75_107.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/26_89.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/39_190.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/114_38.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/49_124.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/182_123.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/27_20.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/102_151.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/53_77.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/127_75.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/132_144.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/67_176.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/75_184.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/44_196.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/154_178.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/68_76.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_152.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/104_190.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/174_168.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/113_114.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/64_111.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/19_98.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/79_69.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/71_41.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/143_182.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/79_78.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/20_74.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/160_57.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/76_30.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/83_65.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/162_82.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/30_76.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/23_61.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/78_77.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/19_109.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/123_197.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/137_76.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/130_67.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/38_144.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/177_165.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/127_56.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/149_163.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/166_56.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/115_156.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/124_135.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/122_62.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/15_91.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/144_103.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/120_95.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/34_120.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/59_49.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/22_42.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/114_173.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/155_50.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_93.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/147_72.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/74_37.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/42_156.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_150.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/134_205.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/32_102.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/27_148.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/129_173.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/110_109.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/165_179.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/48_95.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/130_109.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/149_180.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/79_150.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/167_155.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/114_171.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/95_171.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/15_104.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/92_186.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/131_105.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/143_71.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/160_166.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/26_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/135_92.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/111_188.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/105_121.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/50_87.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/124_195.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/35_183.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/121_190.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/131_138.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/123_174.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_113.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/43_73.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/129_65.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/74_27.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/34_18.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/88_178.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/42_72.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/143_100.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/43_185.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/132_86.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/157_165.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/123_74.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/149_174.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/52_44.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/17_41.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/79_148.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/83_25.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/8_54.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/132_162.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/23_68.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/54_118.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/94_104.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/111_197.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/177_173.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/61_156.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/165_84.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/116_110.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/53_61.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/143_105.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_103.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/26_111.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/82_53.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/143_172.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/74_120.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/50_105.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/41_119.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/61_29.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/142_148.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/44_139.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/139_81.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/108_146.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/113_99.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/183_142.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/84_61.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/17_73.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/51_95.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/168_148.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/169_126.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/126_127.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/160_55.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/92_44.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/35_69.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/94_164.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/114_181.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/145_166.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/72_90.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/73_108.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/166_147.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/78_185.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/143_89.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/35_188.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/125_77.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/109_194.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/28_148.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/111_144.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/99_109.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/65_87.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/59_62.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/67_43.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/118_180.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/56_186.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/32_21.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/166_177.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/141_148.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/123_91.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/88_97.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/59_31.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/75_42.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_96.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/47_51.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/88_84.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/50_88.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/79_183.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/160_47.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/84_172.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/63_99.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/183_153.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/90_90.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/89_86.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/42_138.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/130_181.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/101_159.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/40_142.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/91_76.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/57_39.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/14_92.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/49_69.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/118_62.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/137_150.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/153_141.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/168_176.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/125_88.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/137_82.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/160_163.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/134_189.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/138_167.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/94_110.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/41_117.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/22_96.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/96_167.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/125_173.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/81_44.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/71_40.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/38_118.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/114_180.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/117_181.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/107_117.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/122_97.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/105_147.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/100_161.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/36_82.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/45_103.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/56_85.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/36_16.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/63_61.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/65_44.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/166_82.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/126_188.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/9_47.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/159_109.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/64_183.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/83_150.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/28_126.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/36_74.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/93_171.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/41_82.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/135_103.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/16_68.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/131_58.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/148_176.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/121_146.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/38_78.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/152_152.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/32_186.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/37_140.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/117_189.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/59_48.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/166_113.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/22_105.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/77_197.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/73_134.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/46_95.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/30_34.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/164_160.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/127_189.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/55_50.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/20_111.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/75_96.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/27_45.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/175_170.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/54_93.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/21_111.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/132_92.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/30_90.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/12_41.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/74_182.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/122_139.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/87_47.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/51_83.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/126_90.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/109_153.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/132_161.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/74_52.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/69_68.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/149_109.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/41_61.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/167_160.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/44_44.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/59_97.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/177_152.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/90_170.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/120_65.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/66_186.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/37_18.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_119.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/52_93.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/140_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/25_99.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/158_43.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/157_44.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/79_88.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/174_124.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_86.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/117_77.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_185.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/42_121.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/17_54.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/43_80.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/101_121.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/159_173.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/82_89.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/90_152.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/176_158.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/127_65.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/67_85.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/90_93.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_90.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_40.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/24_30.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/40_194.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/128_186.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/82_181.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/41_157.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/57_180.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/12_73.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/167_147.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/66_181.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/150_107.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/48_48.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/35_57.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/57_198.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/32_104.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/120_194.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/134_96.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/138_78.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/168_177.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/131_79.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/137_88.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/64_31.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/178_160.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/64_46.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/41_42.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/163_159.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/132_139.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/83_112.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/67_184.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/93_55.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/46_107.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/75_76.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/134_145.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/183_121.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/124_184.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/111_157.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/30_71.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/125_82.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/65_186.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/43_112.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/25_58.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/14_90.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/51_113.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/54_73.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/104_151.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/142_166.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/143_90.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/149_85.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/69_51.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/118_89.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/145_175.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/57_109.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/45_69.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/80_55.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/126_68.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/124_128.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/37_90.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/142_151.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/110_27.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/112_121.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/57_159.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/85_81.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/83_174.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/115_138.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/36_53.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/14_35.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/46_110.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/98_112.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/172_125.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/130_105.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/109_164.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/140_175.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/44_81.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/50_186.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/27_107.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_72.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/113_140.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/152_166.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_89.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/163_162.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/28_183.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/121_113.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/69_108.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/142_167.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/54_83.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/17_53.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/118_59.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/131_110.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/57_36.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/64_187.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/88_179.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/124_63.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/27_189.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/57_105.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/93_95.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/47_20.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/127_133.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/82_48.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/166_174.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/129_207.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/111_139.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/70_46.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/127_125.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/69_31.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/99_180.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/155_116.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/125_181.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/123_156.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/75_138.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/75_196.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/30_82.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/40_102.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/159_160.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/181_122.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/36_42.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/53_45.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/118_135.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/66_178.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/72_183.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_58.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/32_42.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/130_107.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/138_150.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_25.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/116_139.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/150_169.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/68_94.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/50_198.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/47_89.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/30_89.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/102_197.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/69_113.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/119_187.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/136_176.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/93_47.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/128_179.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/161_83.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/144_109.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/145_102.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/183_124.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/53_99.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/101_112.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/164_109.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/103_157.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/74_180.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/155_90.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/146_166.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/32_152.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/56_134.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/53_112.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/168_123.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/32_200.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_117.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/153_85.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/151_145.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_104.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/46_74.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/176_170.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/128_58.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/17_109.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_79.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/72_27.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/27_100.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/114_106.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/45_74.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/143_143.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/112_162.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/52_41.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/89_77.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/113_138.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/91_60.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/150_87.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/158_152.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/25_24.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/179_151.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/65_67.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/61_99.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/118_64.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/39_126.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/69_107.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/65_174.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/35_28.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/71_112.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/74_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/21_103.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/37_55.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/59_200.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/121_109.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/39_15.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/87_175.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/48_23.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/95_44.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/87_82.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/168_115.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/63_109.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_84.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/177_136.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/50_65.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/148_181.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_22.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/11_50.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/37_125.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/15_112.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/60_71.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_67.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/129_85.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/33_190.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/99_198.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/109_29.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/129_138.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/108_112.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/156_122.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/158_118.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/155_172.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/121_110.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/13_77.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/128_187.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/109_159.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/18_94.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/146_146.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/28_120.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/54_198.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/69_42.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/104_187.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/85_48.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_87.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/17_58.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/32_81.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/138_76.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/56_65.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/102_47.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/46_82.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/61_204.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/24_107.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/44_53.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/113_36.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/51_118.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/147_162.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/153_150.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/179_142.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/24_74.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/50_204.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/152_181.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/126_185.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/153_86.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/92_103.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/74_39.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/40_73.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/89_120.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/112_44.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/150_143.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/89_157.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/143_103.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_147.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/48_120.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/68_142.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/120_89.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/117_74.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/161_163.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/105_149.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/53_120.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/49_199.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/172_165.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/130_78.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/133_189.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_47.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/147_156.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/80_75.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/94_94.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/54_50.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/73_105.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/86_119.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/90_154.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/34_128.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/150_83.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/132_156.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/65_49.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/42_53.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/27_120.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/33_108.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/144_107.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/95_40.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/12_56.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/156_161.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/173_146.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/50_97.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_90.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/102_176.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/94_114.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/107_179.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/96_94.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/26_95.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/123_108.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/152_157.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/12_113.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/49_105.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/160_165.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/122_170.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/125_93.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/16_93.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/98_113.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/38_123.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/124_73.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/22_86.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/111_40.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/33_140.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/101_120.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/144_70.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/88_192.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/57_72.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/50_68.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/124_110.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/116_107.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/42_56.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/125_202.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/105_152.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/41_135.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/95_158.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/132_90.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/54_59.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/13_39.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/99_40.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/39_189.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/52_185.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/161_45.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/54_177.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/122_117.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/49_115.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/151_168.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/112_178.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/122_187.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/34_96.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/130_176.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/104_96.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/130_96.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/88_102.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/120_63.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/57_30.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/111_122.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_51.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/63_110.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/135_163.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/116_191.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/111_160.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/84_89.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/71_78.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/47_71.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_27.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/177_133.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_136.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/106_37.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/99_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/154_62.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/135_142.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/42_43.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/23_149.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/77_31.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/152_150.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/119_121.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/105_48.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/45_72.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/70_44.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/164_149.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/139_80.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/14_114.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/37_52.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/168_145.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/56_71.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/32_71.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/44_95.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/139_202.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/23_30.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/80_110.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/61_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/128_148.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/98_105.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/55_113.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/43_154.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_59.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/24_38.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/83_178.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/30_55.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/149_154.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/35_83.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/88_98.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_59.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/64_189.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/85_42.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/33_96.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/23_24.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/81_40.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/82_188.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/164_115.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/67_26.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/32_90.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/96_111.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/49_63.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/128_166.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/18_86.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/183_139.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/38_19.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/122_169.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/47_156.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/48_53.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/71_104.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/54_122.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_110.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/54_48.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/120_94.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_50.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/36_59.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/26_200.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/51_48.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/32_115.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/37_120.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/86_163.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/126_87.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/76_139.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/174_151.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/25_33.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/25_54.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/178_167.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/128_112.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/60_65.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/67_82.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/30_33.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/48_105.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/15_107.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/35_87.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/79_149.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/78_191.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/93_115.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_184.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/78_189.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/51_106.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/123_148.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/81_64.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/108_39.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/110_32.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/11_72.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/143_81.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/129_105.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/77_138.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/46_51.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/105_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/40_79.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_69.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/163_161.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/114_135.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/135_158.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/38_95.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/76_160.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/118_87.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/48_134.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/55_13.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/51_73.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/138_179.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/144_145.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_40.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/108_177.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/47_93.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/75_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/74_28.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/55_123.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/105_102.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/49_182.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/28_122.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/95_152.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/164_138.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/14_53.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/41_143.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_29.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/63_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/53_179.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/16_100.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/132_88.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/165_88.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/86_161.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/48_61.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/42_47.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/67_155.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/22_80.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/91_166.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/88_173.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/178_171.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/154_48.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/170_146.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/61_87.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/149_75.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/40_115.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/88_174.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/151_179.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/116_74.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/113_144.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/30_81.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/76_187.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/87_118.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/21_108.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/51_124.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/78_108.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/163_114.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/75_174.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/96_166.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/73_37.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/182_151.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/90_122.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/146_93.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/26_147.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_125.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/91_191.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/101_152.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/66_50.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_31.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/127_148.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/116_118.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/69_176.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/160_87.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/92_43.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/112_145.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/84_75.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/175_158.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/170_155.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/121_66.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/84_29.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/39_24.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/74_152.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/24_83.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/140_85.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/122_129.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/64_182.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/132_76.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/110_39.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/17_77.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/28_150.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/53_65.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/27_37.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/28_95.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/167_118.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/92_150.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/119_140.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/44_140.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/32_48.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/73_41.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/73_184.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/37_92.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/136_141.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/30_46.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/98_46.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/167_145.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/50_23.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/70_64.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/125_174.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/32_149.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/41_26.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/34_43.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/28_73.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/169_146.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/35_27.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/27_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/103_153.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/65_185.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/67_107.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/118_143.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/24_22.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/73_102.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/32_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/43_61.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/23_191.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/127_183.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/32_53.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/181_146.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/85_90.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/90_114.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/171_173.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/21_47.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/56_56.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/39_21.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/114_148.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/152_159.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/13_41.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/119_174.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/41_98.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/61_59.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/113_109.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/51_51.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/40_97.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_156.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/140_96.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/127_60.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/28_109.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/173_169.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/27_89.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/47_108.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/156_164.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/71_113.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/86_103.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/130_201.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/153_139.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/33_18.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/21_115.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/109_167.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/169_64.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/47_118.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/74_171.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_190.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/40_98.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/98_153.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/159_113.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/23_49.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/22_66.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/42_57.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/110_31.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/89_61.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/68_138.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/73_170.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/82_111.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/71_69.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/52_80.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/53_50.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/18_104.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/156_137.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/162_84.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/66_27.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/141_144.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/34_94.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/34_108.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/61_157.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/36_89.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/91_165.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/151_172.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/113_107.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/161_117.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/135_153.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/83_40.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/174_157.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/57_116.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/162_121.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/21_53.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/124_105.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/60_137.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/39_85.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/133_206.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/91_99.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/59_81.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/105_91.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/72_40.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/45_56.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/42_106.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/42_19.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/165_162.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/53_86.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/167_112.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_200.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/66_188.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/89_90.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/123_188.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/76_42.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/41_85.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/124_139.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/140_140.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/60_57.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/172_159.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/30_120.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/61_104.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/38_79.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/10_99.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/18_73.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/76_151.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/135_176.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/119_131.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/40_99.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/143_78.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/20_68.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/138_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/35_91.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/114_172.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/152_121.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/52_192.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_60.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_17.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/64_172.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/164_158.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/57_110.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/157_168.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/25_60.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/102_193.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/20_73.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/39_42.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/77_81.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_113.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_80.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/158_57.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/142_107.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/113_169.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/14_108.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/151_93.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/156_170.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/97_199.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/45_197.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/140_150.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/179_150.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/27_184.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_183.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/84_163.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/79_87.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/45_198.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/158_53.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/121_76.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/166_179.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/56_160.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/107_116.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/122_70.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/92_154.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/78_85.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/82_37.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/98_164.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/116_102.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/75_48.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/170_142.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/117_86.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/87_92.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/75_153.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/134_162.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/116_141.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/160_172.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/126_98.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_176.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/123_94.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/83_72.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/140_173.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/26_198.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/93_163.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/160_151.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/136_142.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/137_178.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/22_118.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/121_158.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/56_196.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_81.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/95_155.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/76_76.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/67_68.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/57_90.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/18_72.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/56_184.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/33_84.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/34_156.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/15_60.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/129_72.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_110.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/28_51.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/79_39.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/69_45.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_30.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/66_70.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_81.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/126_176.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/20_86.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/51_54.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/171_127.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/13_59.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/156_121.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/85_119.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/71_73.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/33_54.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/83_46.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/124_146.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/137_202.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/48_71.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/82_68.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/98_162.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/164_137.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/96_104.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/171_147.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/150_162.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_77.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/30_139.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/162_112.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/124_188.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/102_88.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/164_164.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/117_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/7_50.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/70_112.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/146_179.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/37_190.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/116_85.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_157.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/133_75.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/126_170.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_89.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_63.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/90_182.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/83_49.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/57_89.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/153_167.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/116_111.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/104_104.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/123_78.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/163_57.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/23_97.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/176_134.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/134_174.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/43_195.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/38_77.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/33_36.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_84.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/35_21.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/143_181.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/124_94.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/155_141.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/46_44.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/157_141.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/47_185.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/125_60.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/94_107.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/80_90.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/126_191.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/128_136.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/100_146.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/79_175.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/30_192.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/127_76.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_188.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/139_169.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/55_178.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/162_177.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/97_162.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/168_153.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/106_117.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/179_135.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/84_85.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/161_122.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/10_52.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/57_66.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/104_184.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/27_69.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_109.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/74_179.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/69_71.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/133_57.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/133_176.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/122_91.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/85_104.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/107_138.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/133_171.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/125_91.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/30_56.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/177_145.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/129_202.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/38_113.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/34_84.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/109_118.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/151_169.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/127_61.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/123_62.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/165_155.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/54_86.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/21_70.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/158_91.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/64_69.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/117_88.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/105_200.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/100_198.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/26_183.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/73_78.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/122_179.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/87_160.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_185.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/14_41.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/57_134.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/97_106.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_191.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/53_102.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_113.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/160_152.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/118_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/85_161.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/65_27.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/138_77.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/45_70.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/42_41.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/42_199.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/125_69.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/147_164.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/150_176.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/122_168.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/27_115.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/113_43.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/35_200.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_46.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/168_163.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/74_99.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/129_93.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/125_75.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/91_102.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/16_47.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/56_48.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/32_40.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/181_136.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/76_110.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/46_103.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_56.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/165_82.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/80_61.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/114_39.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/145_169.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/37_182.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/43_45.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/166_157.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/59_118.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/34_143.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/54_178.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/83_29.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/77_74.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/132_138.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/65_29.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/91_93.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/162_164.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/68_113.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/32_38.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/86_170.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/181_141.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/150_99.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_161.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/15_79.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/61_160.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/49_186.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/57_50.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/112_158.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/164_140.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/111_190.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/91_163.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/105_39.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/77_61.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/110_103.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/76_31.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/74_178.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/64_67.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/94_152.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/91_45.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/72_152.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/92_60.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/53_70.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/167_142.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/8_38.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/67_38.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/88_50.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/160_115.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/63_87.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/7_44.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/129_145.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/118_119.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/117_147.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/54_14.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/138_90.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/52_90.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/84_151.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/98_103.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/37_102.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/121_96.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/144_148.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/61_111.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/73_88.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/152_154.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/27_34.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/28_86.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/160_145.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/17_39.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/81_175.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/28_94.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/84_40.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/24_193.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/67_144.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_73.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/90_92.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/161_107.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/169_174.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/73_60.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/27_19.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/41_95.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/124_59.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/61_117.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/20_52.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/35_181.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/108_185.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/52_100.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/131_94.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/28_111.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/37_25.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/153_120.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/44_195.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/37_196.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/30_117.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/57_74.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/28_145.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/66_79.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/36_48.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/54_111.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/38_14.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/59_38.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/36_141.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/68_35.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/124_68.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_112.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/124_182.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/115_80.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/151_163.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/74_141.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/150_54.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/90_71.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/179_138.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/112_164.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/120_88.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_96.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/12_58.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/137_138.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/33_98.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/157_51.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/17_115.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/131_70.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/76_179.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/48_92.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_107.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/129_153.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/69_178.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/23_36.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/60_43.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/136_146.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/51_180.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/148_102.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/123_165.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/163_150.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/70_183.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/123_110.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/23_84.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/40_124.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/172_173.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/141_73.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/54_195.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/45_40.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/128_94.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/130_98.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/52_57.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/152_147.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/105_117.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/87_157.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/122_59.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/147_180.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/23_71.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/64_184.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/111_155.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/28_30.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/72_89.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/128_70.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/27_200.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/80_57.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/128_91.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/35_26.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/48_44.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/133_102.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/19_112.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/102_117.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/157_92.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_91.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/160_139.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/157_147.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/168_117.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/109_100.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/82_172.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/26_145.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/22_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/22_48.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/42_26.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/56_67.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/112_103.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/126_70.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/57_103.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/113_186.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/149_187.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/85_63.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/127_69.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/70_144.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/49_121.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/178_153.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/19_86.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/117_116.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/137_200.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/151_157.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/40_87.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/26_191.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/133_95.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/146_96.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/85_57.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/63_63.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/39_193.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/63_175.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/179_147.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/47_55.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/13_37.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/36_154.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/45_41.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/150_181.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/42_197.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/52_197.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/71_76.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_37.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/155_47.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/54_182.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/35_154.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/36_81.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/101_102.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/99_43.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/45_114.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/34_199.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/78_177.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/101_157.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/135_77.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/115_86.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/89_56.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/23_59.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/163_94.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/138_83.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/39_114.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/67_170.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/44_90.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/75_99.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/13_47.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/143_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/78_114.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/76_88.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/100_99.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/108_160.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/66_40.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/131_104.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/76_98.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/85_115.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/43_37.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/114_123.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/75_85.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/68_38.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/147_108.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/117_113.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/28_187.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/51_108.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/35_58.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/55_175.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/37_127.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/138_201.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/135_187.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/153_173.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/183_120.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/54_95.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/90_102.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/108_42.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/109_195.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/97_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/57_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/86_116.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/154_142.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/111_119.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/46_91.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/88_64.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/77_41.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_53.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_195.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/76_81.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/155_49.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/82_183.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/77_79.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_75.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/94_173.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/15_98.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/142_79.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/64_34.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/88_116.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/169_179.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/94_93.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/100_98.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/25_43.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/125_68.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/160_43.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/17_68.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/93_92.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/52_184.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/39_102.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/82_64.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/73_140.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/78_33.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/133_168.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/183_149.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/63_108.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/117_78.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/114_107.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/15_51.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/135_84.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/108_180.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/93_111.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/112_33.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/56_182.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_192.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/73_81.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/36_123.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/48_43.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/73_57.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/50_95.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_102.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/37_109.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/66_35.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/38_22.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/86_107.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/166_155.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/156_172.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/159_161.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/28_190.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/52_71.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/41_58.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/33_83.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/128_164.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/86_70.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/131_173.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/141_99.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/108_148.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/157_115.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/128_65.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/59_161.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/184_122.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/22_79.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/93_187.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/78_178.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/117_63.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/134_143.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/68_56.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/152_89.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_118.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/73_52.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/54_44.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/108_122.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/30_72.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/50_49.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/28_105.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/16_58.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/51_114.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/20_85.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_52.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/35_18.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/125_206.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/43_87.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/44_28.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/166_160.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/52_204.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/91_167.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/36_126.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/83_165.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/45_51.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/145_177.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/57_43.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/135_139.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/46_83.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/36_54.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/76_24.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/157_56.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/95_161.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/11_43.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/131_182.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/80_108.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/137_139.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/38_201.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/87_98.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/21_109.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/41_27.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/50_43.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/47_112.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/79_154.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/42_77.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/85_64.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/41_59.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/61_61.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/18_51.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/161_93.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/103_98.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/40_84.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/134_103.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/153_107.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/22_37.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/80_84.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/86_173.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/56_110.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/11_71.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/164_152.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/89_167.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/121_178.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/158_170.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/165_140.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_53.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/39_123.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/17_106.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/125_90.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/91_52.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/122_135.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/166_139.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/140_103.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/60_31.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/43_32.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/79_30.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/51_24.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/101_191.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/158_114.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/164_96.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/25_148.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/151_164.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/33_95.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/69_74.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/93_93.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/53_54.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/19_45.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/170_122.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/35_150.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/13_54.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/113_104.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/158_141.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_186.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/48_109.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/116_197.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/172_164.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/6_38.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/105_113.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/43_38.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/33_111.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/23_26.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/124_140.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/127_129.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/77_58.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/16_74.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/23_96.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/173_151.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/40_126.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/38_126.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/130_77.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/116_192.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/131_155.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/142_147.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/183_158.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/139_171.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/42_29.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/99_90.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_45.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_116.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/43_91.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/162_178.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/110_199.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/103_109.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/21_147.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/118_74.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/40_188.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/51_68.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/55_45.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/61_62.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/49_195.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/142_83.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/80_176.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/70_32.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/45_113.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/68_32.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/109_156.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/43_44.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/129_62.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/157_89.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/147_169.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/95_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/116_124.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/156_150.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/61_49.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/63_176.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/76_189.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/8_41.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/69_188.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/37_79.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/35_111.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/27_144.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/50_92.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/42_42.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/104_186.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/59_70.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/151_86.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/175_169.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/68_108.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/138_148.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/73_94.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/33_199.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/133_147.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/130_187.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/39_40.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/144_143.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/142_172.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/175_167.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/125_109.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/99_162.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/131_161.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/144_111.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/152_58.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/49_61.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_99.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_87.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/175_160.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/15_115.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/163_52.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/140_88.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/114_104.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/88_93.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/75_98.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/50_191.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/17_43.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/25_57.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/77_87.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/74_62.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/13_55.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/47_62.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/50_188.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_95.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/85_49.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/59_174.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/110_124.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/161_111.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/73_152.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/125_165.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/138_198.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/16_107.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/112_114.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/132_155.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/66_47.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/27_83.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/103_187.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/76_45.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/59_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/27_67.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/19_62.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/128_86.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/60_160.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/52_39.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/28_113.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/48_64.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/123_168.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/117_89.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/30_183.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/87_151.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/89_92.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/166_112.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/110_100.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/183_122.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/129_70.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/133_203.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/167_117.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/79_31.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/17_82.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/24_34.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/40_76.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/128_98.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/126_126.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/125_103.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/91_75.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/133_91.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/140_170.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/35_123.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/81_108.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/157_159.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/49_74.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/114_160.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/46_53.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/15_61.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/163_108.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/178_134.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/72_107.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/73_29.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/121_132.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/64_35.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/22_51.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/74_177.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/169_158.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/83_79.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/149_94.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/167_175.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/163_125.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/157_137.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/6_50.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/79_112.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_104.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/85_36.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/168_64.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/61_184.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/82_30.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/173_145.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/14_60.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/164_111.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/146_145.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/129_107.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/46_114.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/56_46.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/48_104.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/25_196.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/165_172.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/109_38.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/144_175.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/133_142.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/44_31.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/25_66.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/12_52.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/181_160.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/158_171.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/90_60.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/59_56.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/103_100.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/76_156.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/140_76.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/30_103.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/126_105.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/37_49.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/139_137.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/149_145.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/49_78.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/157_116.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/84_113.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/16_79.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/49_117.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/53_74.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/57_77.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/37_100.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/59_29.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/116_122.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/123_59.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/30_147.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/33_144.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/74_191.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/74_73.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/37_76.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/83_105.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/82_103.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/161_49.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/148_75.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/135_147.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/106_100.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/45_110.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/78_90.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/114_169.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/38_27.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/82_29.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/59_109.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/65_188.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/33_79.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/103_192.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/130_165.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/66_74.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/121_64.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/132_78.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/25_75.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/125_200.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/38_29.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/143_69.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/144_141.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_181.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/43_85.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/151_161.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/44_136.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/78_88.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/129_73.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/27_186.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/18_44.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/51_61.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/131_164.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/72_119.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/98_102.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/48_184.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/162_119.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/51_67.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/96_96.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/155_52.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/46_93.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/97_109.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/82_41.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/96_91.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/63_192.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/16_90.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/35_187.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/116_189.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/25_92.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/91_57.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/53_90.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/107_140.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/49_113.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/105_141.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/131_172.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/23_119.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/53_92.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/39_195.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/111_124.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/50_54.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/146_140.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/30_143.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/102_82.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/60_59.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/88_76.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/86_100.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/33_100.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/87_100.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/44_100.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/103_105.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/112_187.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/88_189.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/129_76.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_85.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/123_192.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_148.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_175.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/172_171.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/25_31.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/45_31.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/9_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/92_191.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/116_184.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/59_102.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/123_189.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/14_91.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/149_169.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/147_106.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/163_172.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/66_185.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/154_138.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/91_74.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/119_188.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/112_177.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/74_41.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/74_74.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/21_58.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/99_46.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/20_81.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/28_115.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/137_143.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/41_124.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/74_190.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/34_71.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/125_104.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/66_51.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/74_112.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/137_137.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/73_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/72_62.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/124_78.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/30_49.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/67_79.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/122_114.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/158_107.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/83_181.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/61_203.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/73_151.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/93_152.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/103_106.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/87_120.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/175_166.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/150_103.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/45_39.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/51_192.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/45_107.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/84_38.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/152_177.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/26_78.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/159_88.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/126_195.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/135_185.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/22_115.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/80_45.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/90_105.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/40_24.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/61_109.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/142_98.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/9_103.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/117_193.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/49_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/60_114.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/85_54.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/109_183.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/78_195.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/128_180.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/67_172.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/69_49.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/159_45.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/129_148.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/16_99.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/84_69.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/116_108.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/163_92.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/164_178.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/60_198.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/45_30.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/78_44.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/14_57.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/157_150.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/65_95.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/74_103.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/68_79.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/45_79.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/78_150.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/48_88.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/89_179.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/72_38.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/99_160.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/89_96.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/33_25.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/17_60.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/127_77.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_186.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/176_166.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/134_188.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/132_158.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/61_183.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/118_128.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/72_58.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/118_77.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/61_70.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_149.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/33_93.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/71_80.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/162_163.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/43_74.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/61_114.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/88_68.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/161_137.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/106_115.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/129_162.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/27_201.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_189.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/15_49.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/24_32.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/92_189.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/126_137.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/118_148.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/64_87.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/100_163.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_199.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/131_174.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/175_122.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/50_120.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/36_39.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/77_195.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_140.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/39_141.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/36_58.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/97_113.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/153_145.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/103_43.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/34_103.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/44_60.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/115_118.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/71_37.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/127_82.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_80.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/88_94.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/12_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/81_116.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_181.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/70_84.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/125_189.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/80_82.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/21_91.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/122_175.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/104_192.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/170_126.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/178_162.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/117_107.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/48_93.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/42_25.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/43_138.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/82_90.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_75.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/89_79.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/39_109.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/85_86.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/75_65.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/86_60.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/119_186.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/132_146.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/32_17.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/74_137.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/153_100.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/64_140.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/127_113.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/38_70.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/69_115.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/54_69.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/161_56.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/77_178.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/44_79.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/34_93.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/47_95.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/65_179.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/69_33.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/104_148.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/75_54.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/131_82.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/51_102.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/33_127.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/85_47.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/86_174.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/174_160.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/39_16.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/90_91.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/71_86.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/130_93.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/80_81.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/26_32.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/102_198.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/80_188.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/25_22.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/87_69.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/48_98.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/34_54.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/34_187.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/102_144.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/27_42.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/47_43.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/180_149.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/19_84.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/180_155.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/180_147.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/77_43.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/164_94.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/33_77.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/30_24.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/67_67.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/26_86.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/57_187.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/38_23.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/89_50.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/121_185.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/56_136.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/148_106.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/75_49.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/160_160.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/60_111.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/109_149.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/177_148.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/121_85.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_61.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/163_50.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/104_120.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/110_194.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/144_174.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_34.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/91_190.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/115_150.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/24_24.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/66_32.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/27_118.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/73_62.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/58_58.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/33_142.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/138_147.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/49_54.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/108_124.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/89_88.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/78_39.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_64.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/55_52.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/176_169.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/77_63.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/35_76.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/121_169.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/145_97.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/41_52.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/147_177.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/130_87.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/76_140.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/88_154.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/54_114.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/98_106.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/32_183.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/34_107.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/34_28.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/25_30.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/42_59.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/139_163.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/38_138.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/84_100.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/99_105.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/157_174.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/129_132.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/155_48.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/111_138.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/144_172.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/25_77.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/16_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/132_142.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/96_105.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/83_75.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/33_78.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/81_78.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/170_127.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/163_82.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/159_178.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/74_107.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/129_102.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/95_165.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/87_94.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/111_41.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/65_60.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/77_53.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/18_46.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/145_176.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/93_184.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/36_150.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/103_190.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/168_127.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/69_86.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/79_46.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/122_88.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/53_38.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/109_138.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/134_84.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/27_36.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/15_52.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/97_95.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/158_140.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/133_107.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/99_103.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/137_201.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/100_119.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/36_19.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/20_36.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/33_53.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/82_174.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/79_80.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/121_154.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/153_82.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/51_81.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/60_83.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/61_30.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_189.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/91_46.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/23_190.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/89_194.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/130_133.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/130_76.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/125_107.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/55_135.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/158_138.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/42_157.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/66_187.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/28_182.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/165_81.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/147_148.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/80_48.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/47_99.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/82_56.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/30_73.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/37_137.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/56_18.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/105_146.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/86_55.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/19_58.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/130_202.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/13_46.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/41_116.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/74_58.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/52_42.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/101_176.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/151_73.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_142.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/28_36.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/59_36.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/120_116.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/13_102.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/125_204.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/168_172.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/10_57.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/60_174.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/169_153.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/123_154.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/121_166.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/56_22.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/160_119.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/143_98.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/92_76.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/160_51.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/111_149.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/131_152.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/51_90.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/75_84.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/76_112.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/87_60.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/20_112.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/131_95.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/39_115.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/155_176.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/26_18.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/27_72.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/168_169.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/97_158.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/48_82.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/129_185.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/116_177.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/35_84.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/148_70.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/27_119.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/153_151.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/52_75.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/150_160.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/105_185.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/63_29.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/156_92.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/63_184.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/67_190.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/111_117.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/115_78.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/59_134.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/41_88.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/36_97.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/121_63.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/141_149.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/82_25.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/25_114.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/136_111.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/131_81.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/66_189.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/155_171.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/78_60.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/81_65.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/149_147.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/81_27.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/174_165.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/30_42.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/105_188.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/56_59.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/55_83.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/99_117.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/158_173.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/162_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/157_112.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/57_60.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/157_156.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/173_167.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/49_184.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/136_110.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/36_24.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/45_71.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_141.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/158_137.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_83.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/175_148.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/97_96.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/108_120.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/160_53.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/27_109.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/146_171.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/71_61.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/74_173.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/102_162.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/102_113.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/161_160.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/51_52.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/127_95.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/112_134.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/43_198.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/47_183.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/84_153.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/89_53.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/35_194.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/22_145.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/38_196.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/70_54.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/30_115.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_69.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/132_87.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/68_67.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/41_123.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/72_70.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/158_124.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/41_32.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/72_176.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_23.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/55_100.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/154_107.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/50_110.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/83_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/160_102.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/93_169.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/55_22.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/52_46.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/68_90.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/46_24.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/67_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/42_38.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/161_82.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/100_156.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/56_37.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_41.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/119_120.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/127_203.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/82_50.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/73_95.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/25_83.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/147_104.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/113_156.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/160_42.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/8_46.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/37_97.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/18_106.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_139.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/67_52.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/156_173.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/89_103.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/67_70.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/34_131.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/36_32.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/130_148.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/81_43.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/98_114.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/61_41.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/73_49.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/140_80.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/83_107.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/99_158.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/57_62.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/112_140.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/105_159.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/111_43.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/90_189.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/114_109.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/47_53.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/51_120.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/26_199.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_81.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/49_188.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/54_176.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/72_174.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/110_121.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/73_39.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/88_96.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/63_177.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/138_149.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/178_166.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_146.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/85_177.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/80_85.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/53_100.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/48_65.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/179_141.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/22_87.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/65_153.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/163_43.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/116_88.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/51_111.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/159_170.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/16_60.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/107_105.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/44_39.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/22_28.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/6_53.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_59.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/65_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/121_143.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/133_97.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/63_90.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_81.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/31_107.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/126_113.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/143_74.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/47_100.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/137_174.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/120_192.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/142_110.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/73_155.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/44_117.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/25_46.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/109_28.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/167_124.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/41_109.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/20_83.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/158_144.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/136_86.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/46_60.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/146_160.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/89_190.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/28_152.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/39_26.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/60_37.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/108_118.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_195.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/164_162.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/91_173.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_83.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/159_153.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/48_66.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/34_147.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/144_81.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_98.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/102_112.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/88_151.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_25.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/26_43.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/166_162.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/23_73.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/115_110.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/22_94.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/61_175.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/38_104.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/46_117.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/148_160.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/139_176.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/52_186.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/63_43.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/64_85.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/165_59.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/18_62.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/97_163.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/81_82.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/104_118.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/70_69.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/28_71.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/156_117.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/128_71.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/79_102.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/131_144.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/155_150.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/118_81.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/159_163.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/73_55.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/62_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/49_68.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/144_184.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/28_179.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/74_175.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/27_80.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/99_102.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/39_78.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/54_71.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/145_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/23_33.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/44_192.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/66_90.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/70_50.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/125_108.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/157_170.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/81_179.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/40_197.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/157_155.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/153_176.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/46_90.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/65_177.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/130_203.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/96_90.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/61_176.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/91_192.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/132_160.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/156_153.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/144_142.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/26_122.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/29_194.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/140_174.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/125_180.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/59_178.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/32_18.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/135_181.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/149_175.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/82_42.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/64_75.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/47_45.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/122_145.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/76_38.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/36_67.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/51_198.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/44_93.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/33_181.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/107_185.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/79_58.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/160_144.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/80_153.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/140_102.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/137_140.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/18_45.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/80_22.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/126_131.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/154_122.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/161_80.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/108_40.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/76_190.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/38_194.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/132_84.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/168_63.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/124_176.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/68_188.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/120_151.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/101_147.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/76_39.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/154_158.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/147_153.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/56_16.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/110_38.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/88_113.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/74_43.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/118_116.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/126_143.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/16_89.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/26_118.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/103_48.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/49_192.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/61_53.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/27_21.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/73_113.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/22_44.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/139_106.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/95_92.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/75_40.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/181_123.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/147_96.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/54_110.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/69_101.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/163_176.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/55_104.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/139_75.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/133_182.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/51_72.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/66_85.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/151_175.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/11_52.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/109_103.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/46_89.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/164_154.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/182_159.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/66_141.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/77_36.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/39_76.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/75_70.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/85_180.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/150_154.jpeg\n",
            "  ðŸ“ Added: single/S/M-86/132_98.jpeg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "path = '/content/dsmil-wsi/WSI/ndpi_files/single/E/M-111/65_113.jpeg'\n",
        "try:\n",
        "    img = Image.open(path)\n",
        "    img.show()\n",
        "except Exception as e:\n",
        "    print(\"Cannot open image:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qq3Fi5U3R_pG",
        "outputId": "a07f1768-3b20-444b-f056-1956d5f86a73"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cannot open image: cannot identify image file '/content/dsmil-wsi/WSI/ndpi_files/single/E/M-111/65_113.jpeg'\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": [
        "l6po_sM-3mK6"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}