{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Metti la HF Token  nei secret del colab\n",
        "Serve per l'uso di modelli con req token\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pKHT30kpCvzn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard library\n",
        "import os\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "\n",
        "HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "if HF_TOKEN:\n",
        "    login(HF_TOKEN)\n",
        "    print(\"Successfully logged in to Hugging Face!\")\n",
        "else:\n",
        "    print(\"Token is not set. Please save the token first.\")\n"
      ],
      "metadata": {
        "id": "P1bYrZyl6dlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "msmGkEOapdhL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "# URL for the dataset\n",
        "url = \"https://zenodo.org/records/15700269/files/datasetWSI.zip?download=1\"\n",
        "\n",
        "# Download the file using wget\n",
        "!wget -O /content/Train.zip \"$url\"\n",
        "\n",
        "# Define the extraction path\n",
        "extract_path = './'\n",
        "\n",
        "# Create the extraction directory if it doesn't exist\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "# Extract the ZIP file\n",
        "with zipfile.ZipFile('./Train.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "# List the contents of the extracted folder\n",
        "extracted_files = os.listdir(extract_path)\n",
        "print(\"Extracted files:\", extracted_files)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "\n",
        "!conda create -n \"trident\" python=3.10"
      ],
      "metadata": {
        "id": "65zMcwNeqUSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/mahmoodlab/trident.git\n",
        "!conda run -n trident pip install -e trident/."
      ],
      "metadata": {
        "id": "9oA2b6kqtvtn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crea un archivio ZIP della cartella\n",
        "import zipfile # Import the zipfile module\n",
        "\n",
        "def create_zip_archive(folder_path, zip_name=None):\n",
        "    \"\"\"\n",
        "    Crea un archivio ZIP di una cartella mantenendo la struttura\n",
        "    \"\"\"\n",
        "    if zip_name is None:\n",
        "        zip_name = f\"{os.path.basename(folder_path)}.zip\"\n",
        "\n",
        "    print(f\"üóúÔ∏è Creando archivio ZIP: {zip_name}\")\n",
        "\n",
        "    with zipfile.ZipFile(zip_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for root, dirs, files in os.walk(folder_path):\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                # Mantiene la struttura delle cartelle nell'archivio\n",
        "                arc_name = os.path.relpath(file_path, os.path.dirname(folder_path))\n",
        "                zipf.write(file_path, arc_name)\n",
        "                print(f\"  üìÅ Aggiunto: {arc_name}\")\n",
        "\n",
        "    # Mostra dimensione dell'archivio\n",
        "    zip_size = os.path.getsize(zip_name)\n",
        "    print(f\"‚úÖ Archivio creato: {zip_name} ({zip_size/1024/1024:.2f} MB)\")\n",
        "    return zip_name"
      ],
      "metadata": {
        "id": "MW86do5Z1HZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import requests\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Token di accesso Zenodo (sostituisci con il tuo)\n",
        "ACCESS_TOKEN = 'uVSb7icJqT9efPM71KYgviJ50r7eML9ynei2q7hDkedVlFrf8fBsr9lFaJ3O'\n",
        "\n",
        "# Crea una nuova deposizione\n",
        "def create_deposition(title):\n",
        "    url = 'https://zenodo.org/api/deposit/depositions'\n",
        "    headers = {\"Content-Type\": \"application/json\"}\n",
        "    params = {'access_token': ACCESS_TOKEN}\n",
        "\n",
        "    data = {\n",
        "        'metadata': {\n",
        "            'title': title,\n",
        "            'upload_type': 'dataset',\n",
        "            'description': 'Dataset WSI project MLiA',\n",
        "            'creators': [{'name': 'Raf-Tony-Luca'}]\n",
        "        }\n",
        "    }\n",
        "\n",
        "    r = requests.post(url, params=params, data=json.dumps(data), headers=headers)\n",
        "    return r.json()\n",
        "\n",
        "# Carica il file\n",
        "def upload_file(deposition_id, file_path):\n",
        "    # Get bucket URL\n",
        "    url = f'https://zenodo.org/api/deposit/depositions/{deposition_id}'\n",
        "    params = {'access_token': ACCESS_TOKEN}\n",
        "    r = requests.get(url, params=params)\n",
        "    bucket_url = r.json()[\"links\"][\"bucket\"]\n",
        "\n",
        "    # Upload file\n",
        "    filename = os.path.basename(file_path)\n",
        "    with open(file_path, \"rb\") as fp:\n",
        "        r = requests.put(f\"{bucket_url}/{filename}\",\n",
        "                        data=fp,\n",
        "                        params=params)\n",
        "    return r.json()\n",
        "\n",
        "# Pubblica il dataset\n",
        "def publish_deposition(deposition_id):\n",
        "    url = f'https://zenodo.org/api/deposit/depositions/{deposition_id}/actions/publish'\n",
        "    params = {'access_token': ACCESS_TOKEN}\n",
        "    r = requests.post(url, params=params)\n",
        "    return r.json()\n"
      ],
      "metadata": {
        "id": "BRd0GLUa1T64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import gc\n",
        "\n",
        "def free_memory():\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()    # Libera la cache della GPU\n",
        "        torch.cuda.ipc_collect()    # Raccoglie la memoria non pi√π usata dalla GPU\n",
        "    gc.collect()                    # Libera la RAM\n",
        "\n",
        "free_memory()\n"
      ],
      "metadata": {
        "id": "XPsoq6WiD1Td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!MPLBACKEND=Agg conda run -n trident python trident/run_batch_of_slides.py --task all --wsi_dir ./ndpi_files/B --job_dir ./trident_processed_univ2/B --patch_encoder uni_v2 --patch_size 256 --mag 20"
      ],
      "metadata": {
        "id": "39zp8cAo2jyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import gc\n",
        "\n",
        "def free_memory():\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()    # Libera la cache della GPU\n",
        "        torch.cuda.ipc_collect()    # Raccoglie la memoria non pi√π usata dalla GPU\n",
        "    gc.collect()                    # Libera la RAM\n",
        "\n",
        "free_memory()\n"
      ],
      "metadata": {
        "id": "B36N_E7dD12G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!MPLBACKEND=Agg conda run -n trident python trident/run_batch_of_slides.py --task all --wsi_dir ./ndpi_files/E --job_dir ./trident_processed_univ2/E --patch_encoder uni_v2 --patch_size 256 --mag 20"
      ],
      "metadata": {
        "id": "RMhGpCoF201O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import gc\n",
        "\n",
        "def free_memory():\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()    # Libera la cache della GPU\n",
        "        torch.cuda.ipc_collect()    # Raccoglie la memoria non pi√π usata dalla GPU\n",
        "    gc.collect()                    # Libera la RAM\n",
        "\n",
        "free_memory()\n"
      ],
      "metadata": {
        "id": "dgJ0GNmAD2TU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!MPLBACKEND=Agg conda run -n trident python trident/run_batch_of_slides.py --task all --wsi_dir ./ndpi_files/S --job_dir ./trident_processed_univ2/S --patch_encoder uni_v2 --patch_size 256 --mag 20"
      ],
      "metadata": {
        "id": "_sDmwZCs218G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import gc\n",
        "\n",
        "def free_memory():\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()    # Libera la cache della GPU\n",
        "        torch.cuda.ipc_collect()    # Raccoglie la memoria non pi√π usata dalla GPU\n",
        "    gc.collect()                    # Libera la RAM\n",
        "\n",
        "free_memory()\n"
      ],
      "metadata": {
        "id": "_tYzq9MbD257"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Percorso della cartella da caricare\n",
        "folder_to_upload = '/content/trident_processed_univ2'  # Cambia con il percorso della tua cartella\n",
        "zip_filename = 'datasetTrident_univ2.zip'  # Nome dell'archivio\n",
        "zip_path = create_zip_archive(folder_to_upload, zip_filename)\n"
      ],
      "metadata": {
        "id": "soEy9ncUAraK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Esegui l'upload\n",
        "print(\"Creando deposizione...\")\n",
        "deposition = create_deposition(\"dataset_trident_univ2\")\n",
        "deposition_id = deposition['id']\n",
        "\n",
        "print(f\"Caricando file... (ID: {deposition_id})\")\n",
        "upload_result = upload_file(deposition_id, zip_filename)\n",
        "\n",
        "print(\"Pubblicando dataset...\")\n",
        "publication = publish_deposition(deposition_id)\n",
        "\n",
        "print(f\"Dataset pubblicato! DOI: {publication['doi']}\")\n",
        "print(f\"URL: {publication['links']['record_html']}\")"
      ],
      "metadata": {
        "id": "j0ZbzsQDBK1s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}