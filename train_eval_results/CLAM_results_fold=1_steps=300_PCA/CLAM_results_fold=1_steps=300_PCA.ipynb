{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "fd422ed8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd422ed8",
        "outputId": "68840846-423d-49a3-9ced-f4203f077aaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:pydrive is deprecated and no longer maintained. We recommend that you migrate your projects to pydrive2, the maintained fork of pydrive\n"
          ]
        }
      ],
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f9bdc33a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9bdc33a",
        "outputId": "c1c230d5-4acb-4b48-d9b8-9aa8805c1fd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MLIAProject'...\n",
            "remote: Enumerating objects: 359, done.\u001b[K\n",
            "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 359 (delta 5), reused 14 (delta 3), pack-reused 337 (from 1)\u001b[K\n",
            "Receiving objects: 100% (359/359), 90.97 MiB | 32.11 MiB/s, done.\n",
            "Resolving deltas: 100% (149/149), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/LucaIanniello/MLIAProject.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3dd873af",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dd873af",
        "outputId": "799d0503-d15d-4845-8122-c57da5c20c41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "â¬ Downloading https://github.com/jaimergp/miniforge/releases/download/24.11.2-1_colab/Miniforge3-colab-24.11.2-1_colab-Linux-x86_64.sh...\n",
            "ðŸ“¦ Installing...\n",
            "ðŸ“Œ Adjusting configuration...\n",
            "ðŸ©¹ Patching environment...\n",
            "â² Done in 0:00:10\n",
            "ðŸ” Restarting kernel...\n",
            "Channels:\n",
            " - conda-forge\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Solving environment: | \b\b/ \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "    current version: 24.11.2\n",
            "    latest version: 25.5.1\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "python-3.10.0        | 29.8 MB   | :   0% 0/1 [00:00<?, ?it/s]\n",
            "tk-8.6.13            | 3.1 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "openssl-3.5.0        | 3.0 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pip-25.1.1           | 1.2 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libsqlite-3.50.1     | 898 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sqlite-3.50.1        | 878 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ncurses-6.5          | 871 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-15.1.0        | 810 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "setuptools-80.9.0    | 731 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ld_impl_linux-64-2.4 | 655 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgomp-15.1.0       | 442 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "liblzma-devel-5.8.1  | 430 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "readline-8.2         | 276 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2025 | 149 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tzdata-2025b         | 120 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "liblzma-5.8.1        | 110 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xz-tools-5.8.1       | 94 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libffi-3.4.6         | 56 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-ng-15.1.0     | 34 KB     | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "python-3.10.0        | 29.8 MB   | :   0% 0.0020950271396738573/1 [00:00<00:51, 51.50s/it]\n",
            "\n",
            "openssl-3.5.0        | 3.0 MB    | :   2% 0.02102257964143311/1 [00:00<00:04,  4.97s/it]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pip-25.1.1           | 1.2 MB    | :   3% 0.026362133395548656/1 [00:00<00:03,  4.02s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libsqlite-3.50.1     | 898 KB    | :   4% 0.03562440001782959/1 [00:00<00:02,  2.93s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libsqlite-3.50.1     | 898 KB    | : 100% 1.0/1 [00:00<00:00,  2.93s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pip-25.1.1           | 1.2 MB    | : 100% 1.0/1 [00:00<00:00,  4.02s/it]                 \u001b[A\u001b[A\u001b[A\n",
            "python-3.10.0        | 29.8 MB   | :  12% 0.11941654696140985/1 [00:00<00:01,  1.48s/it]  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ncurses-6.5          | 871 KB    | :   2% 0.018375108367605347/1 [00:00<00:13, 13.46s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sqlite-3.50.1        | 878 KB    | :   2% 0.0182203163644775/1 [00:00<00:13, 14.02s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "tk-8.6.13            | 3.1 MB    | : 100% 1.0/1 [00:00<00:00,  5.54it/s]               \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ncurses-6.5          | 871 KB    | : 100% 1.0/1 [00:00<00:00, 13.46s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.0        | 29.8 MB   | :  30% 0.30011263775828007/1 [00:00<00:00,  1.12it/s]\n",
            "\n",
            "openssl-3.5.0        | 3.0 MB    | : 100% 1.0/1 [00:00<00:00,  3.42it/s]                \u001b[A\u001b[A\n",
            "\n",
            "openssl-3.5.0        | 3.0 MB    | : 100% 1.0/1 [00:00<00:00,  3.42it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libsqlite-3.50.1     | 898 KB    | : 100% 1.0/1 [00:00<00:00,  3.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "libsqlite-3.50.1     | 898 KB    | : 100% 1.0/1 [00:00<00:00,  3.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "setuptools-80.9.0    | 731 KB    | :   2% 0.021880692532465797/1 [00:00<00:14, 15.27s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ld_impl_linux-64-2.4 | 655 KB    | :   2% 0.02443057699046426/1 [00:00<00:13, 14.06s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-15.1.0        | 810 KB    | :   2% 0.019760996154903825/1 [00:00<00:17, 17.50s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgomp-15.1.0       | 442 KB    | :   4% 0.03619693572083467/1 [00:00<00:09, 10.03s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgomp-15.1.0       | 442 KB    | : 100% 1.0/1 [00:00<00:00, 10.03s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ld_impl_linux-64-2.4 | 655 KB    | : 100% 1.0/1 [00:00<00:00, 14.06s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "setuptools-80.9.0    | 731 KB    | : 100% 1.0/1 [00:00<00:00, 15.27s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.0        | 29.8 MB   | :  46% 0.4561921596639824/1 [00:00<00:00,  1.29it/s] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "liblzma-devel-5.8.1  | 430 KB    | :   4% 0.037247537897732955/1 [00:00<00:10, 10.99s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "liblzma-devel-5.8.1  | 430 KB    | : 100% 1.0/1 [00:00<00:00, 10.99s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "readline-8.2         | 276 KB    | :   6% 0.05800056641178136/1 [00:00<00:06,  7.28s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2025 | 149 KB    | :  11% 0.10758915965669182/1 [00:00<00:03,  3.96s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tzdata-2025b         | 120 KB    | :  13% 0.1332379155552664/1 [00:00<00:02,  3.22s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tzdata-2025b         | 120 KB    | : 100% 1.0/1 [00:00<00:00,  3.22s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2025 | 149 KB    | : 100% 1.0/1 [00:00<00:00,  3.96s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "readline-8.2         | 276 KB    | : 100% 1.0/1 [00:00<00:00,  7.28s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "liblzma-5.8.1        | 110 KB    | :  15% 0.1451272875440679/1 [00:00<00:02,  3.17s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "liblzma-5.8.1        | 110 KB    | : 100% 1.0/1 [00:00<00:00,  3.17s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libffi-3.4.6         | 56 KB     | :  29% 0.2852715337871955/1 [00:00<00:01,  1.64s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xz-tools-5.8.1       | 94 KB     | :  17% 0.1699003453174743/1 [00:00<00:02,  2.78s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libffi-3.4.6         | 56 KB     | : 100% 1.0/1 [00:00<00:00,  1.64s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-ng-15.1.0     | 34 KB     | :  47% 0.47371768923842017/1 [00:00<00:00,  1.01s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xz-tools-5.8.1       | 94 KB     | : 100% 1.0/1 [00:00<00:00,  2.78s/it]               \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-ng-15.1.0     | 34 KB     | : 100% 1.0/1 [00:00<00:00,  1.01s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.0        | 29.8 MB   | :  90% 0.9019091836295955/1 [00:00<00:00,  1.80it/s]\n",
            "\n",
            "\n",
            "pip-25.1.1           | 1.2 MB    | : 100% 1.0/1 [00:00<00:00,  1.07it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pip-25.1.1           | 1.2 MB    | : 100% 1.0/1 [00:00<00:00,  1.07it/s]\u001b[A\u001b[A\u001b[A\n",
            "python-3.10.0        | 29.8 MB   | : 100% 1.0/1 [00:01<00:00,  1.80it/s]               \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sqlite-3.50.1        | 878 KB    | : 100% 1.0/1 [00:01<00:00,  1.09s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "sqlite-3.50.1        | 878 KB    | : 100% 1.0/1 [00:01<00:00,  1.09s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "openssl-3.5.0        | 3.0 MB    | : 100% 1.0/1 [00:01<00:00,  3.42it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgomp-15.1.0       | 442 KB    | : 100% 1.0/1 [00:01<00:00,  1.33s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgomp-15.1.0       | 442 KB    | : 100% 1.0/1 [00:01<00:00,  1.33s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ld_impl_linux-64-2.4 | 655 KB    | : 100% 1.0/1 [00:01<00:00,  1.39s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ld_impl_linux-64-2.4 | 655 KB    | : 100% 1.0/1 [00:01<00:00,  1.39s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-15.1.0        | 810 KB    | : 100% 1.0/1 [00:01<00:00,  1.47s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-15.1.0        | 810 KB    | : 100% 1.0/1 [00:01<00:00,  1.47s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "setuptools-80.9.0    | 731 KB    | : 100% 1.0/1 [00:01<00:00,  1.84s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "setuptools-80.9.0    | 731 KB    | : 100% 1.0/1 [00:01<00:00,  1.84s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "liblzma-devel-5.8.1  | 430 KB    | : 100% 1.0/1 [00:02<00:00,  1.98s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "liblzma-devel-5.8.1  | 430 KB    | : 100% 1.0/1 [00:02<00:00,  1.98s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ncurses-6.5          | 871 KB    | : 100% 1.0/1 [00:02<00:00,  2.38s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ncurses-6.5          | 871 KB    | : 100% 1.0/1 [00:02<00:00,  2.38s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2025 | 149 KB    | : 100% 1.0/1 [00:02<00:00,  2.40s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "ca-certificates-2025 | 149 KB    | : 100% 1.0/1 [00:02<00:00,  2.40s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tzdata-2025b         | 120 KB    | : 100% 1.0/1 [00:02<00:00,  2.43s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tzdata-2025b         | 120 KB    | : 100% 1.0/1 [00:02<00:00,  2.43s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "liblzma-5.8.1        | 110 KB    | : 100% 1.0/1 [00:02<00:00,  2.45s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "liblzma-5.8.1        | 110 KB    | : 100% 1.0/1 [00:02<00:00,  2.45s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "readline-8.2         | 276 KB    | : 100% 1.0/1 [00:02<00:00,  2.40s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "readline-8.2         | 276 KB    | : 100% 1.0/1 [00:02<00:00,  2.40s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libffi-3.4.6         | 56 KB     | : 100% 1.0/1 [00:02<00:00,  2.58s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libffi-3.4.6         | 56 KB     | : 100% 1.0/1 [00:02<00:00,  2.58s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xz-tools-5.8.1       | 94 KB     | : 100% 1.0/1 [00:02<00:00,  2.50s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xz-tools-5.8.1       | 94 KB     | : 100% 1.0/1 [00:02<00:00,  2.50s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-ng-15.1.0     | 34 KB     | : 100% 1.0/1 [00:02<00:00,  2.79s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libgcc-ng-15.1.0     | 34 KB     | : 100% 1.0/1 [00:02<00:00,  2.79s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "python-3.10.0        | 29.8 MB   | : 100% 1.0/1 [00:06<00:00,  1.80it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \n",
            "                                                                        \u001b[A\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "Preparing transaction: - \b\b\\ \b\bdone\n",
            "Verifying transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "Executing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Installing pip dependencies: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ Ran pip subprocess with arguments:\n",
            "['/usr/local/envs/clam_latest/bin/python', '-m', 'pip', 'install', '-U', '-r', '/content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt', '--exists-action=b']\n",
            "Pip subprocess output:\n",
            "Collecting git+https://github.com/oval-group/smooth-topk.git (from -r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 13))\n",
            "  Cloning https://github.com/oval-group/smooth-topk.git to /tmp/pip-req-build-w9f5n_jw\n",
            "  Resolved https://github.com/oval-group/smooth-topk.git to commit 12c1645f187e2fa0c05f47bf1fe48864d4bd2707\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting timm==0.9.8 (from -r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 1))\n",
            "  Downloading timm-0.9.8-py3-none-any.whl.metadata (59 kB)\n",
            "Collecting torch (from -r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 2))\n",
            "  Downloading torch-2.7.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
            "Collecting torchvision (from -r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 3))\n",
            "  Downloading torchvision-0.22.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting h5py (from -r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 4))\n",
            "  Downloading h5py-3.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Collecting pandas (from -r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 5))\n",
            "  Downloading pandas-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
            "Collecting PyYAML (from -r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 6))\n",
            "  Downloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting opencv-python (from -r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 7))\n",
            "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting matplotlib (from -r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 8))\n",
            "  Downloading matplotlib-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting scikit-learn (from -r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 9))\n",
            "  Downloading scikit_learn-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (17 kB)\n",
            "Collecting scipy (from -r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 10))\n",
            "  Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting tqdm (from -r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 11))\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting openslide-python (from -r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 12))\n",
            "  Downloading openslide_python-1.4.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting tensorboardX (from -r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 14))\n",
            "  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting numpy (from topk==1.0->-r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 13))\n",
            "  Downloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Collecting huggingface-hub (from timm==0.9.8->-r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 1))\n",
            "  Downloading huggingface_hub-0.33.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting safetensors (from timm==0.9.8->-r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 1))\n",
            "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting filelock (from torch->-r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 2))\n",
            "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting typing-extensions>=4.10.0 (from torch->-r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 2))\n",
            "  Downloading typing_extensions-4.14.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting sympy>=1.13.3 (from torch->-r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 2))\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch->-r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 2))\n",
            "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch->-r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 2))\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec (from torch->-r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 2))\n",
            "  Downloading fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch->-r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 2))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch->-r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 2))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch->-r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 2))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch->-r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 2))\n",
            "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch->-r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 2))\n",
            "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch->-r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 2))\n",
            "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.7.77 (from torch->-r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 2))\n",
            "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch->-r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 2))\n",
            "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch->-r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 2))\n",
            "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch->-r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 2))\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.26.2 (from torch->-r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 2))\n",
            "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.6.77 (from torch->-r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 2))\n",
            "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch->-r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 2))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch->-r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 2))\n",
            "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.3.1 (from torch->-r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 2))\n",
            "  Downloading triton-3.3.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/envs/clam_latest/lib/python3.10/site-packages (from triton==3.3.1->torch->-r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 2)) (80.9.0)\n",
            "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision->-r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 3))\n",
            "  Downloading pillow-11.2.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
            "Collecting python-dateutil>=2.8.2 (from pandas->-r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 5))\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas->-r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 5))\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas->-r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 5))\n",
            "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib->-r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 8))\n",
            "  Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib->-r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 8))\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib->-r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 8))\n",
            "  Downloading fonttools-4.58.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (106 kB)\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib->-r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 8))\n",
            "  Downloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.2 kB)\n",
            "Collecting packaging>=20.0 (from matplotlib->-r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 8))\n",
            "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib->-r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 8))\n",
            "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting joblib>=1.2.0 (from scikit-learn->-r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 9))\n",
            "  Downloading joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn->-r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 9))\n",
            "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting protobuf>=3.20 (from tensorboardX->-r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 14))\n",
            "  Downloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
            "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas->-r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 5))\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch->-r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 2))\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting requests (from huggingface-hub->timm==0.9.8->-r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 1))\n",
            "  Downloading requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface-hub->timm==0.9.8->-r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 1))\n",
            "  Downloading hf_xet-1.1.3-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch->-r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 2))\n",
            "  Downloading MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting charset_normalizer<4,>=2 (from requests->huggingface-hub->timm==0.9.8->-r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 1))\n",
            "  Downloading charset_normalizer-3.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->huggingface-hub->timm==0.9.8->-r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 1))\n",
            "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests->huggingface-hub->timm==0.9.8->-r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 1))\n",
            "  Downloading urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->huggingface-hub->timm==0.9.8->-r /content/MLIAProject/CLAM/condaenv.qzogbozm.requirements.txt (line 1))\n",
            "  Downloading certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
            "Downloading timm-0.9.8-py3-none-any.whl (2.2 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2.2/2.2 MB 60.2 MB/s eta 0:00:00\n",
            "Downloading torch-2.7.1-cp310-cp310-manylinux_2_28_x86_64.whl (821.2 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 821.2/821.2 MB 29.1 MB/s eta 0:00:00\n",
            "Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 393.1/393.1 MB 27.5 MB/s eta 0:00:00\n",
            "Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 8.9/8.9 MB 160.4 MB/s eta 0:00:00\n",
            "Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 23.7/23.7 MB 197.5 MB/s eta 0:00:00\n",
            "Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 897.7/897.7 kB 55.7 MB/s eta 0:00:00\n",
            "Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 571.0/571.0 MB 26.9 MB/s eta 0:00:00\n",
            "Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 200.2/200.2 MB 73.9 MB/s eta 0:00:00\n",
            "Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.1/1.1 MB 66.9 MB/s eta 0:00:00\n",
            "Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 56.3/56.3 MB 70.7 MB/s eta 0:00:00\n",
            "Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 158.2/158.2 MB 76.0 MB/s eta 0:00:00\n",
            "Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 216.6/216.6 MB 74.0 MB/s eta 0:00:00\n",
            "Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 156.8/156.8 MB 67.7 MB/s eta 0:00:00\n",
            "Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 201.3/201.3 MB 72.7 MB/s eta 0:00:00\n",
            "Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 19.7/19.7 MB 193.3 MB/s eta 0:00:00\n",
            "Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "Downloading triton-3.3.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.6 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 155.6/155.6 MB 70.3 MB/s eta 0:00:00\n",
            "Downloading torchvision-0.22.1-cp310-cp310-manylinux_2_28_x86_64.whl (7.5 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7.5/7.5 MB 127.1 MB/s eta 0:00:00\n",
            "Downloading h5py-3.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4.6/4.6 MB 116.9 MB/s eta 0:00:00\n",
            "Downloading pandas-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 12.3/12.3 MB 87.3 MB/s eta 0:00:00\n",
            "Downloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 751.2/751.2 kB 44.8 MB/s eta 0:00:00\n",
            "Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 63.0/63.0 MB 72.0 MB/s eta 0:00:00\n",
            "Downloading matplotlib-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 8.6/8.6 MB 172.6 MB/s eta 0:00:00\n",
            "Downloading scikit_learn-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.9 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 12.9/12.9 MB 185.4 MB/s eta 0:00:00\n",
            "Downloading scipy-1.15.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.7 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 37.7/37.7 MB 60.6 MB/s eta 0:00:00\n",
            "Downloading numpy-2.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 16.8/16.8 MB 185.5 MB/s eta 0:00:00\n",
            "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Downloading openslide_python-1.4.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.whl (40 kB)\n",
            "Downloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n",
            "Downloading contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
            "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading fonttools-4.58.4-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.8 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4.8/4.8 MB 143.2 MB/s eta 0:00:00\n",
            "Downloading joblib-1.5.1-py3-none-any.whl (307 kB)\n",
            "Downloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.6/1.6 MB 85.1 MB/s eta 0:00:00\n",
            "Downloading packaging-25.0-py3-none-any.whl (66 kB)\n",
            "Downloading pillow-11.2.1-cp310-cp310-manylinux_2_28_x86_64.whl (4.6 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4.6/4.6 MB 153.1 MB/s eta 0:00:00\n",
            "Downloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl (321 kB)\n",
            "Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
            "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 6.3/6.3 MB 29.6 MB/s eta 0:00:00\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 536.2/536.2 kB 26.3 MB/s eta 0:00:00\n",
            "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Downloading typing_extensions-4.14.0-py3-none-any.whl (43 kB)\n",
            "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Downloading fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
            "Downloading huggingface_hub-0.33.0-py3-none-any.whl (514 kB)\n",
            "Downloading hf_xet-1.1.3-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4.8/4.8 MB 140.7 MB/s eta 0:00:00\n",
            "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Downloading MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20 kB)\n",
            "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "   â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.7/1.7 MB 87.6 MB/s eta 0:00:00\n",
            "Downloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
            "Downloading charset_normalizer-3.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "Downloading urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
            "Downloading certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
            "Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
            "Building wheels for collected packages: topk\n",
            "  Building wheel for topk (setup.py): started\n",
            "  Building wheel for topk (setup.py): finished with status 'done'\n",
            "  Created wheel for topk: filename=topk-1.0-py3-none-any.whl size=10041 sha256=6fd5caaee13531fad655a0a6f664b721b79681cd623dbf6935c3decaf1d390fc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-sma9dnqm/wheels/b5/e1/65/94fdd820e9a24c2f8520b542ddea5a1d05e88fb34fd768d536\n",
            "Successfully built topk\n",
            "Installing collected packages: pytz, nvidia-cusparselt-cu12, mpmath, urllib3, tzdata, typing-extensions, triton, tqdm, threadpoolctl, sympy, six, safetensors, PyYAML, pyparsing, protobuf, pillow, packaging, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, kiwisolver, joblib, idna, hf-xet, fsspec, fonttools, filelock, cycler, charset_normalizer, certifi, tensorboardX, scipy, requests, python-dateutil, openslide-python, opencv-python, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, jinja2, h5py, contourpy, scikit-learn, pandas, nvidia-cusolver-cu12, matplotlib, huggingface-hub, torch, torchvision, topk, timm\n",
            "\n",
            "Successfully installed MarkupSafe-3.0.2 PyYAML-6.0.2 certifi-2025.4.26 charset_normalizer-3.4.2 contourpy-1.3.2 cycler-0.12.1 filelock-3.18.0 fonttools-4.58.4 fsspec-2025.5.1 h5py-3.14.0 hf-xet-1.1.3 huggingface-hub-0.33.0 idna-3.10 jinja2-3.1.6 joblib-1.5.1 kiwisolver-1.4.8 matplotlib-3.10.3 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.6 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 opencv-python-4.11.0.86 openslide-python-1.4.2 packaging-25.0 pandas-2.3.0 pillow-11.2.1 protobuf-6.31.1 pyparsing-3.2.3 python-dateutil-2.9.0.post0 pytz-2025.2 requests-2.32.4 safetensors-0.5.3 scikit-learn-1.7.0 scipy-1.15.3 six-1.17.0 sympy-1.14.0 tensorboardX-2.6.4 threadpoolctl-3.6.0 timm-0.9.8 topk-1.0 torch-2.7.1 torchvision-0.22.1 tqdm-4.67.1 triton-3.3.1 typing-extensions-4.14.0 tzdata-2025.2 urllib3-2.4.0\n",
            "\n",
            "\b\b- \b\bdone\n",
            "#\n",
            "# To activate this environment, use\n",
            "#\n",
            "#     $ conda activate clam_latest\n",
            "#\n",
            "# To deactivate an active environment, use\n",
            "#\n",
            "#     $ conda deactivate\n",
            "\n",
            "Channels:\n",
            " - conda-forge\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\b\\ \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "    current version: 24.11.2\n",
            "    latest version: 25.5.1\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/clam_latest\n",
            "\n",
            "  added / updated specs:\n",
            "    - openslide\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    cairo-1.18.4               |       h3394656_0         955 KB  conda-forge\n",
            "    font-ttf-dejavu-sans-mono-2.37|       hab24e00_0         388 KB  conda-forge\n",
            "    font-ttf-inconsolata-3.000 |       h77eed37_0          94 KB  conda-forge\n",
            "    font-ttf-source-code-pro-2.038|       h77eed37_0         684 KB  conda-forge\n",
            "    font-ttf-ubuntu-0.83       |       h77eed37_3         1.5 MB  conda-forge\n",
            "    fontconfig-2.15.0          |       h7e30c49_1         259 KB  conda-forge\n",
            "    fonts-conda-ecosystem-1    |                0           4 KB  conda-forge\n",
            "    fonts-conda-forge-1        |                0           4 KB  conda-forge\n",
            "    freetype-2.13.3            |       ha770c72_1         168 KB  conda-forge\n",
            "    gdk-pixbuf-2.42.12         |       hb9ae30d_0         516 KB  conda-forge\n",
            "    icu-75.1                   |       he02047a_0        11.6 MB  conda-forge\n",
            "    lerc-4.0.0                 |       h0aef613_1         258 KB  conda-forge\n",
            "    libdeflate-1.24            |       h86f0d12_0          71 KB  conda-forge\n",
            "    libdicom-1.0.5             |       hd590300_1          99 KB  conda-forge\n",
            "    libexpat-2.7.0             |       h5888daf_0          73 KB  conda-forge\n",
            "    libfreetype-2.13.3         |       ha770c72_1           8 KB  conda-forge\n",
            "    libfreetype6-2.13.3        |       h48d6fc4_1         371 KB  conda-forge\n",
            "    libglib-2.84.2             |       h3618099_0         3.8 MB  conda-forge\n",
            "    libiconv-1.18              |       h4ce23a2_1         696 KB  conda-forge\n",
            "    libjpeg-turbo-3.1.0        |       hb9d3cd8_0         614 KB  conda-forge\n",
            "    libpng-1.6.47              |       h943b412_0         282 KB  conda-forge\n",
            "    libstdcxx-15.1.0           |       h8f9b012_2         3.7 MB  conda-forge\n",
            "    libstdcxx-ng-15.1.0        |       h4852527_2          34 KB  conda-forge\n",
            "    libtiff-4.7.0              |       hf01ce69_5         420 KB  conda-forge\n",
            "    libwebp-base-1.5.0         |       h851e524_0         420 KB  conda-forge\n",
            "    libxcb-1.17.0              |       h8a09558_0         387 KB  conda-forge\n",
            "    libxml2-2.13.8             |       h4bc477f_0         675 KB  conda-forge\n",
            "    openjpeg-2.5.3             |       h5fbd93e_0         335 KB  conda-forge\n",
            "    openslide-4.0.0            |       h58ba908_1         139 KB  conda-forge\n",
            "    pcre2-10.45                |       hc749103_0         1.1 MB  conda-forge\n",
            "    pixman-0.46.2              |       h29eaf8c_0         393 KB  conda-forge\n",
            "    pthread-stubs-0.4          |    hb9d3cd8_1002           8 KB  conda-forge\n",
            "    xorg-libice-1.1.2          |       hb9d3cd8_0          57 KB  conda-forge\n",
            "    xorg-libsm-1.2.6           |       he73a12e_0          27 KB  conda-forge\n",
            "    xorg-libx11-1.8.12         |       h4f16b4b_0         816 KB  conda-forge\n",
            "    xorg-libxau-1.0.12         |       hb9d3cd8_0          14 KB  conda-forge\n",
            "    xorg-libxdmcp-1.1.5        |       hb9d3cd8_0          19 KB  conda-forge\n",
            "    xorg-libxext-1.3.6         |       hb9d3cd8_0          49 KB  conda-forge\n",
            "    xorg-libxrender-0.9.12     |       hb9d3cd8_0          32 KB  conda-forge\n",
            "    zstd-1.5.7                 |       hb8e6e7a_2         554 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        31.4 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  cairo              conda-forge/linux-64::cairo-1.18.4-h3394656_0 \n",
            "  font-ttf-dejavu-s~ conda-forge/noarch::font-ttf-dejavu-sans-mono-2.37-hab24e00_0 \n",
            "  font-ttf-inconsol~ conda-forge/noarch::font-ttf-inconsolata-3.000-h77eed37_0 \n",
            "  font-ttf-source-c~ conda-forge/noarch::font-ttf-source-code-pro-2.038-h77eed37_0 \n",
            "  font-ttf-ubuntu    conda-forge/noarch::font-ttf-ubuntu-0.83-h77eed37_3 \n",
            "  fontconfig         conda-forge/linux-64::fontconfig-2.15.0-h7e30c49_1 \n",
            "  fonts-conda-ecosy~ conda-forge/noarch::fonts-conda-ecosystem-1-0 \n",
            "  fonts-conda-forge  conda-forge/noarch::fonts-conda-forge-1-0 \n",
            "  freetype           conda-forge/linux-64::freetype-2.13.3-ha770c72_1 \n",
            "  gdk-pixbuf         conda-forge/linux-64::gdk-pixbuf-2.42.12-hb9ae30d_0 \n",
            "  icu                conda-forge/linux-64::icu-75.1-he02047a_0 \n",
            "  lerc               conda-forge/linux-64::lerc-4.0.0-h0aef613_1 \n",
            "  libdeflate         conda-forge/linux-64::libdeflate-1.24-h86f0d12_0 \n",
            "  libdicom           conda-forge/linux-64::libdicom-1.0.5-hd590300_1 \n",
            "  libexpat           conda-forge/linux-64::libexpat-2.7.0-h5888daf_0 \n",
            "  libfreetype        conda-forge/linux-64::libfreetype-2.13.3-ha770c72_1 \n",
            "  libfreetype6       conda-forge/linux-64::libfreetype6-2.13.3-h48d6fc4_1 \n",
            "  libglib            conda-forge/linux-64::libglib-2.84.2-h3618099_0 \n",
            "  libiconv           conda-forge/linux-64::libiconv-1.18-h4ce23a2_1 \n",
            "  libjpeg-turbo      conda-forge/linux-64::libjpeg-turbo-3.1.0-hb9d3cd8_0 \n",
            "  libpng             conda-forge/linux-64::libpng-1.6.47-h943b412_0 \n",
            "  libstdcxx          conda-forge/linux-64::libstdcxx-15.1.0-h8f9b012_2 \n",
            "  libstdcxx-ng       conda-forge/linux-64::libstdcxx-ng-15.1.0-h4852527_2 \n",
            "  libtiff            conda-forge/linux-64::libtiff-4.7.0-hf01ce69_5 \n",
            "  libwebp-base       conda-forge/linux-64::libwebp-base-1.5.0-h851e524_0 \n",
            "  libxcb             conda-forge/linux-64::libxcb-1.17.0-h8a09558_0 \n",
            "  libxml2            conda-forge/linux-64::libxml2-2.13.8-h4bc477f_0 \n",
            "  openjpeg           conda-forge/linux-64::openjpeg-2.5.3-h5fbd93e_0 \n",
            "  openslide          conda-forge/linux-64::openslide-4.0.0-h58ba908_1 \n",
            "  pcre2              conda-forge/linux-64::pcre2-10.45-hc749103_0 \n",
            "  pixman             conda-forge/linux-64::pixman-0.46.2-h29eaf8c_0 \n",
            "  pthread-stubs      conda-forge/linux-64::pthread-stubs-0.4-hb9d3cd8_1002 \n",
            "  xorg-libice        conda-forge/linux-64::xorg-libice-1.1.2-hb9d3cd8_0 \n",
            "  xorg-libsm         conda-forge/linux-64::xorg-libsm-1.2.6-he73a12e_0 \n",
            "  xorg-libx11        conda-forge/linux-64::xorg-libx11-1.8.12-h4f16b4b_0 \n",
            "  xorg-libxau        conda-forge/linux-64::xorg-libxau-1.0.12-hb9d3cd8_0 \n",
            "  xorg-libxdmcp      conda-forge/linux-64::xorg-libxdmcp-1.1.5-hb9d3cd8_0 \n",
            "  xorg-libxext       conda-forge/linux-64::xorg-libxext-1.3.6-hb9d3cd8_0 \n",
            "  xorg-libxrender    conda-forge/linux-64::xorg-libxrender-0.9.12-hb9d3cd8_0 \n",
            "  zstd               conda-forge/linux-64::zstd-1.5.7-hb8e6e7a_2 \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "icu-75.1             | 11.6 MB   | :   0% 0/1 [00:00<?, ?it/s]\n",
            "libglib-2.84.2       | 3.8 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "libstdcxx-15.1.0     | 3.7 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "font-ttf-ubuntu-0.83 | 1.5 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pcre2-10.45          | 1.1 MB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cairo-1.18.4         | 955 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xorg-libx11-1.8.12   | 816 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libiconv-1.18        | 696 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "font-ttf-source-code | 684 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libxml2-2.13.8       | 675 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libjpeg-turbo-3.1.0  | 614 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "zstd-1.5.7           | 554 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "gdk-pixbuf-2.42.12   | 516 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libwebp-base-1.5.0   | 420 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libtiff-4.7.0        | 420 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pixman-0.46.2        | 393 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "font-ttf-dejavu-sans | 388 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libxcb-1.17.0        | 387 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libfreetype6-2.13.3  | 371 KB    | :   0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "icu-75.1             | 11.6 MB   | :   0% 0.00270157899080426/1 [00:00<00:38, 38.49s/it]\n",
            "libglib-2.84.2       | 3.8 MB    | :   1% 0.008285070337637855/1 [00:00<00:12, 12.57s/it]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pcre2-10.45          | 1.1 MB    | :   3% 0.027368062353212375/1 [00:00<00:03,  3.83s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "font-ttf-ubuntu-0.83 | 1.5 MB    | :   1% 0.010110434778315882/1 [00:00<00:10, 10.53s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "icu-75.1             | 11.6 MB   | :  30% 0.3039276364654792/1 [00:00<00:00,  1.75it/s] \n",
            "libglib-2.84.2       | 3.8 MB    | :  64% 0.6379504159981149/1 [00:00<00:00,  3.51it/s]  \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pcre2-10.45          | 1.1 MB    | : 100% 1.0/1 [00:00<00:00,  5.50it/s]                 \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pcre2-10.45          | 1.1 MB    | : 100% 1.0/1 [00:00<00:00,  5.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "font-ttf-ubuntu-0.83 | 1.5 MB    | : 100% 1.0/1 [00:00<00:00,  5.06it/s]                 \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "font-ttf-ubuntu-0.83 | 1.5 MB    | : 100% 1.0/1 [00:00<00:00,  5.06it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cairo-1.18.4         | 955 KB    | :   2% 0.016750603712859646/1 [00:00<00:14, 14.82s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xorg-libx11-1.8.12   | 816 KB    | :   2% 0.019600524467158594/1 [00:00<00:13, 13.70s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libstdcxx-15.1.0     | 3.7 MB    | : 100% 1.0/1 [00:00<00:00,  3.84it/s]                 \u001b[A\u001b[A\n",
            "\n",
            "libstdcxx-15.1.0     | 3.7 MB    | : 100% 1.0/1 [00:00<00:00,  3.84it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "icu-75.1             | 11.6 MB   | :  65% 0.6537821157746309/1 [00:00<00:00,  2.53it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xorg-libx11-1.8.12   | 816 KB    | : 100% 1.0/1 [00:00<00:00, 13.70s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libiconv-1.18        | 696 KB    | :   2% 0.02297625525183569/1 [00:00<00:13, 14.13s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "font-ttf-source-code | 684 KB    | :   2% 0.02337852839697837/1 [00:00<00:13, 14.27s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libiconv-1.18        | 696 KB    | : 100% 1.0/1 [00:00<00:00, 14.13s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libglib-2.84.2       | 3.8 MB    | : 100% 1.0/1 [00:00<00:00,  3.04it/s]               \u001b[A\n",
            "libglib-2.84.2       | 3.8 MB    | : 100% 1.0/1 [00:00<00:00,  3.04it/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libxml2-2.13.8       | 675 KB    | :   2% 0.02371523194145302/1 [00:00<00:14, 14.51s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libxml2-2.13.8       | 675 KB    | : 100% 1.0/1 [00:00<00:00, 14.51s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "font-ttf-source-code | 684 KB    | : 100% 1.0/1 [00:00<00:00, 14.27s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libjpeg-turbo-3.1.0  | 614 KB    | :   3% 0.026049889736337085/1 [00:00<00:14, 14.40s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "zstd-1.5.7           | 554 KB    | :   3% 0.02886651702497278/1 [00:00<00:12, 13.06s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "zstd-1.5.7           | 554 KB    | : 100% 1.0/1 [00:00<00:00, 13.06s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libwebp-base-1.5.0   | 420 KB    | :   4% 0.038104718203236014/1 [00:00<00:09, 10.34s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libjpeg-turbo-3.1.0  | 614 KB    | : 100% 1.0/1 [00:00<00:00, 14.40s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "gdk-pixbuf-2.42.12   | 516 KB    | :   3% 0.031021548843224167/1 [00:00<00:12, 12.82s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libwebp-base-1.5.0   | 420 KB    | : 100% 1.0/1 [00:00<00:00, 10.34s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "font-ttf-ubuntu-0.83 | 1.5 MB    | : 100% 1.0/1 [00:00<00:00,  5.06it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "gdk-pixbuf-2.42.12   | 516 KB    | : 100% 1.0/1 [00:00<00:00, 12.82s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libtiff-4.7.0        | 420 KB    | :   4% 0.03814002211488099/1 [00:00<00:10, 11.28s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libtiff-4.7.0        | 420 KB    | : 100% 1.0/1 [00:00<00:00, 11.28s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pixman-0.46.2        | 393 KB    | :   4% 0.040733724162278544/1 [00:00<00:10, 10.83s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "font-ttf-dejavu-sans | 388 KB    | :   4% 0.04123109444598234/1 [00:00<00:10, 10.76s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pixman-0.46.2        | 393 KB    | : 100% 1.0/1 [00:00<00:00, 10.83s/it]                 \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libxcb-1.17.0        | 387 KB    | :   4% 0.04138544234733056/1 [00:00<00:10, 10.89s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "font-ttf-dejavu-sans | 388 KB    | : 100% 1.0/1 [00:00<00:00, 10.76s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libxcb-1.17.0        | 387 KB    | : 100% 1.0/1 [00:00<00:00, 10.89s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libfreetype6-2.13.3  | 371 KB    | :   4% 0.04310059084428123/1 [00:00<00:10, 10.93s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libfreetype6-2.13.3  | 371 KB    | : 100% 1.0/1 [00:00<00:00, 10.93s/it]                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "icu-75.1             | 11.6 MB   | : 100% 1.0/1 [00:00<00:00,  1.68it/s]\n",
            "\n",
            "\n",
            "\n",
            "pcre2-10.45          | 1.1 MB    | : 100% 1.0/1 [00:00<00:00,  5.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "libstdcxx-15.1.0     | 3.7 MB    | : 100% 1.0/1 [00:00<00:00,  3.84it/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cairo-1.18.4         | 955 KB    | : 100% 1.0/1 [00:00<00:00,  1.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "cairo-1.18.4         | 955 KB    | : 100% 1.0/1 [00:00<00:00,  1.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libiconv-1.18        | 696 KB    | : 100% 1.0/1 [00:00<00:00,  1.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libiconv-1.18        | 696 KB    | : 100% 1.0/1 [00:00<00:00,  1.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xorg-libx11-1.8.12   | 816 KB    | : 100% 1.0/1 [00:00<00:00,  1.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xorg-libx11-1.8.12   | 816 KB    | : 100% 1.0/1 [00:00<00:00,  1.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libxml2-2.13.8       | 675 KB    | : 100% 1.0/1 [00:00<00:00,  1.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libxml2-2.13.8       | 675 KB    | : 100% 1.0/1 [00:00<00:00,  1.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "font-ttf-source-code | 684 KB    | : 100% 1.0/1 [00:01<00:00,  1.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "font-ttf-source-code | 684 KB    | : 100% 1.0/1 [00:01<00:00,  1.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "libglib-2.84.2       | 3.8 MB    | : 100% 1.0/1 [00:01<00:00,  3.04it/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "zstd-1.5.7           | 554 KB    | : 100% 1.0/1 [00:01<00:00,  1.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "zstd-1.5.7           | 554 KB    | : 100% 1.0/1 [00:01<00:00,  1.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libjpeg-turbo-3.1.0  | 614 KB    | : 100% 1.0/1 [00:01<00:00,  1.09s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libjpeg-turbo-3.1.0  | 614 KB    | : 100% 1.0/1 [00:01<00:00,  1.09s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libwebp-base-1.5.0   | 420 KB    | : 100% 1.0/1 [00:01<00:00,  1.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libwebp-base-1.5.0   | 420 KB    | : 100% 1.0/1 [00:01<00:00,  1.10s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libtiff-4.7.0        | 420 KB    | : 100% 1.0/1 [00:01<00:00,  1.14s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libtiff-4.7.0        | 420 KB    | : 100% 1.0/1 [00:01<00:00,  1.14s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pixman-0.46.2        | 393 KB    | : 100% 1.0/1 [00:01<00:00,  1.18s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pixman-0.46.2        | 393 KB    | : 100% 1.0/1 [00:01<00:00,  1.18s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "gdk-pixbuf-2.42.12   | 516 KB    | : 100% 1.0/1 [00:01<00:00,  1.26s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "gdk-pixbuf-2.42.12   | 516 KB    | : 100% 1.0/1 [00:01<00:00,  1.26s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "font-ttf-dejavu-sans | 388 KB    | : 100% 1.0/1 [00:01<00:00,  1.31s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "font-ttf-dejavu-sans | 388 KB    | : 100% 1.0/1 [00:01<00:00,  1.31s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libfreetype6-2.13.3  | 371 KB    | : 100% 1.0/1 [00:01<00:00,  1.33s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libfreetype6-2.13.3  | 371 KB    | : 100% 1.0/1 [00:01<00:00,  1.33s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libxcb-1.17.0        | 387 KB    | : 100% 1.0/1 [00:01<00:00,  1.34s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "libxcb-1.17.0        | 387 KB    | : 100% 1.0/1 [00:01<00:00,  1.34s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " ... (more hidden) ...\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "icu-75.1             | 11.6 MB   | : 100% 1.0/1 [00:02<00:00,  1.68it/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \n",
            "                                                                        \u001b[A\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                                                                        \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\u001b[A\n",
            "Preparing transaction: - \b\bdone\n",
            "Verifying transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \n",
            "\b\bdone\n",
            "Channels:\n",
            " - conda-forge\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\b\\ \b\b| \b\bfailed\n",
            "\n",
            "PackagesNotFoundError: The following packages are not available from current channels:\n",
            "\n",
            "  - openslide-tools\n",
            "  - libtiff-dev\n",
            "  - libopenslide0\n",
            "  - libjpeg-dev\n",
            "\n",
            "Current channels:\n",
            "\n",
            "  - https://conda.anaconda.org/conda-forge\n",
            "\n",
            "To search for alternate channels that may provide the conda package you're\n",
            "looking for, navigate to\n",
            "\n",
            "    https://anaconda.org\n",
            "\n",
            "and use the search bar at the top of the page.\n",
            "\n",
            "\n",
            "Channels:\n",
            " - conda-forge\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "\n",
            "\n",
            "==> WARNING: A newer version of conda exists. <==\n",
            "    current version: 24.11.2\n",
            "    latest version: 25.5.1\n",
            "\n",
            "Please update conda by running\n",
            "\n",
            "    $ conda update -n base -c conda-forge conda\n",
            "\n",
            "\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local/envs/clam_latest\n",
            "\n",
            "  added / updated specs:\n",
            "    - future\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    future-1.0.0               |     pyhd8ed1ab_2         356 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:         356 KB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  future             conda-forge/noarch::future-1.0.0-pyhd8ed1ab_2 \n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages:\n",
            "                                                                        \n",
            "Preparing transaction: - \b\bdone\n",
            "Verifying transaction: | \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Python 3.10.0\n",
            "\n",
            "Package                  Version\n",
            "------------------------ -----------\n",
            "certifi                  2025.4.26\n",
            "charset-normalizer       3.4.2\n",
            "contourpy                1.3.2\n",
            "cycler                   0.12.1\n",
            "filelock                 3.18.0\n",
            "fonttools                4.58.4\n",
            "fsspec                   2025.5.1\n",
            "future                   1.0.0\n",
            "h5py                     3.14.0\n",
            "hf-xet                   1.1.3\n",
            "huggingface-hub          0.33.0\n",
            "idna                     3.10\n",
            "Jinja2                   3.1.6\n",
            "joblib                   1.5.1\n",
            "kiwisolver               1.4.8\n",
            "MarkupSafe               3.0.2\n",
            "matplotlib               3.10.3\n",
            "mpmath                   1.3.0\n",
            "networkx                 3.4.2\n",
            "numpy                    2.2.6\n",
            "nvidia-cublas-cu12       12.6.4.1\n",
            "nvidia-cuda-cupti-cu12   12.6.80\n",
            "nvidia-cuda-nvrtc-cu12   12.6.77\n",
            "nvidia-cuda-runtime-cu12 12.6.77\n",
            "nvidia-cudnn-cu12        9.5.1.17\n",
            "nvidia-cufft-cu12        11.3.0.4\n",
            "nvidia-cufile-cu12       1.11.1.6\n",
            "nvidia-curand-cu12       10.3.7.77\n",
            "nvidia-cusolver-cu12     11.7.1.2\n",
            "nvidia-cusparse-cu12     12.5.4.2\n",
            "nvidia-cusparselt-cu12   0.6.3\n",
            "nvidia-nccl-cu12         2.26.2\n",
            "nvidia-nvjitlink-cu12    12.6.85\n",
            "nvidia-nvtx-cu12         12.6.77\n",
            "opencv-python            4.11.0.86\n",
            "openslide-python         1.4.2\n",
            "packaging                25.0\n",
            "pandas                   2.3.0\n",
            "pillow                   11.2.1\n",
            "pip                      25.1.1\n",
            "protobuf                 6.31.1\n",
            "pyparsing                3.2.3\n",
            "python-dateutil          2.9.0.post0\n",
            "pytz                     2025.2\n",
            "PyYAML                   6.0.2\n",
            "requests                 2.32.4\n",
            "safetensors              0.5.3\n",
            "scikit-learn             1.7.0\n",
            "scipy                    1.15.3\n",
            "setuptools               80.9.0\n",
            "six                      1.17.0\n",
            "sympy                    1.14.0\n",
            "tensorboardX             2.6.4\n",
            "threadpoolctl            3.6.0\n",
            "timm                     0.9.8\n",
            "topk                     1.0\n",
            "torch                    2.7.1\n",
            "torchvision              0.22.1\n",
            "tqdm                     4.67.1\n",
            "triton                   3.3.1\n",
            "typing_extensions        4.14.0\n",
            "tzdata                   2025.2\n",
            "urllib3                  2.4.0\n",
            "wheel                    0.45.1\n",
            "\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,776 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:7 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,750 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,296 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,037 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,556 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,986 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,249 kB]\n",
            "Fetched 23.0 MB in 2s (10.2 MB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libjpeg-dev is already the newest version (8c-2ubuntu10).\n",
            "libjpeg-dev set to manually installed.\n",
            "libtiff-dev is already the newest version (4.3.0-6ubuntu0.10).\n",
            "libtiff-dev set to manually installed.\n",
            "Suggested packages:\n",
            "  libtiff-tools\n",
            "The following NEW packages will be installed:\n",
            "  libopenslide0 openslide-tools\n",
            "0 upgraded, 2 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 104 kB of archives.\n",
            "After this operation, 297 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libopenslide0 amd64 3.4.1+dfsg-5build1 [89.8 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 openslide-tools amd64 3.4.1+dfsg-5build1 [13.8 kB]\n",
            "Fetched 104 kB in 0s (228 kB/s)\n",
            "Selecting previously unselected package libopenslide0.\n",
            "(Reading database ... 126111 files and directories currently installed.)\n",
            "Preparing to unpack .../libopenslide0_3.4.1+dfsg-5build1_amd64.deb ...\n",
            "Unpacking libopenslide0 (3.4.1+dfsg-5build1) ...\n",
            "Selecting previously unselected package openslide-tools.\n",
            "Preparing to unpack .../openslide-tools_3.4.1+dfsg-5build1_amd64.deb ...\n",
            "Unpacking openslide-tools (3.4.1+dfsg-5build1) ...\n",
            "Setting up libopenslide0 (3.4.1+dfsg-5build1) ...\n",
            "Setting up openslide-tools (3.4.1+dfsg-5build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/liblzma.so.5 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "\n",
        "!conda env create -f MLIAProject/CLAM/env.yml\n",
        "!conda install -n clam_latest -c conda-forge openslide\n",
        "!conda install -n clam_latest -c conda-forge openslide-tools libopenslide0 libtiff-dev libjpeg-dev\n",
        "!conda install -n clam_latest -c conda-forge future\n",
        "!conda run -n clam_latest python --version\n",
        "!conda run -n clam_latest pip list\n",
        "\n",
        "!apt-get update\n",
        "!apt-get install -y openslide-tools libopenslide0 libtiff-dev libjpeg-dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8fd5feb0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fd5feb0",
        "outputId": "a942e98a-62b4-487a-cc7c-6c4ea951c82b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conda 24.11.2\n",
            "/usr/local/bin/conda\n",
            "==> /usr/local/.condarc <==\n",
            "channels:\n",
            "  - conda-forge\n",
            "always_yes: True\n",
            "\n",
            "Channels:\n",
            " - conda-forge\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\bfailed\n",
            "\n",
            "SpecsConfigurationConflictError: Requested specs conflict with configured specs.\n",
            "  requested specs: \n",
            "    - pip\n",
            "    - python==3.10\n",
            "  pinned specs: \n",
            "    - cuda-version=12\n",
            "    - python=3.11\n",
            "    - python_abi=3.11[build=*cp311*]\n",
            "Use 'conda config --show-sources' to look for 'pinned_specs' and 'track_features'\n",
            "configuration parameters.  Pinned specs may also be defined in the file\n",
            "/usr/local/conda-meta/pinned.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!conda --version\n",
        "!which conda\n",
        "!conda config --show-sources\n",
        "!conda env update -n base -f MLIAProject/CLAM/env.yml\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "51057077",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51057077",
        "outputId": "4994f4cd-da99-4b6a-8a7d-07d3ee617706"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-06-14 07:41:33--  https://zenodo.org/records/15547611/files/datasetUnified_PT.zip?download=1\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.48.194, 188.185.43.25, 188.185.45.92, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.48.194|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2005901570 (1.9G) [application/octet-stream]\n",
            "Saving to: â€˜/content/Train.zipâ€™\n",
            "\n",
            "/content/Train.zip  100%[===================>]   1.87G  18.7MB/s    in 1m 56s  \n",
            "\n",
            "2025-06-14 07:43:29 (16.5 MB/s) - â€˜/content/Train.zipâ€™ saved [2005901570/2005901570]\n",
            "\n",
            "Extracted files: ['.config', 'condacolab_install.log', 'Train.zip', 'MLIAProject', 'results_features', 'sample_data']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "# URL for the dataset\n",
        "url = \"https://zenodo.org/records/15547611/files/datasetUnified_PT.zip?download=1\"\n",
        "\n",
        "# Download the file using wget\n",
        "!wget -O /content/Train.zip \"$url\"\n",
        "\n",
        "# Define the extraction path\n",
        "extract_path = './'\n",
        "\n",
        "# Create the extraction directory if it doesn't exist\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "# Extract the ZIP file\n",
        "with zipfile.ZipFile('./Train.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "# List the contents of the extracted folder\n",
        "extracted_files = os.listdir(extract_path)\n",
        "print(\"Extracted files:\", extracted_files)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## PCA TO REDUCE DIMENSIONALITY\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import os\n",
        "\n",
        "# Load all features\n",
        "feature_dir = '/content/results_features/pt_files'\n",
        "features = []\n",
        "\n",
        "for fname in os.listdir(feature_dir):\n",
        "    if fname.endswith('.pt'):\n",
        "        data = torch.load(os.path.join(feature_dir, fname))\n",
        "        features.append(data.numpy())\n",
        "\n",
        "print(len(features))\n",
        "\n",
        "all_features = np.vstack(features)\n",
        "\n",
        "# Fit PCA\n",
        "pca = PCA(n_components=min(512, all_features.shape[1]))\n",
        "pca.fit(all_features)\n",
        "\n",
        "# Plot explained variance\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "# 1. Explained variance per component\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(pca.explained_variance_ratio_, marker='o')\n",
        "plt.title(\"Explained Variance Ratio\")\n",
        "plt.xlabel(\"Principal Component\")\n",
        "plt.ylabel(\"Explained Variance\")\n",
        "\n",
        "# 2. Cumulative explained variance\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_), marker='o')\n",
        "plt.title(\"Cumulative Explained Variance\")\n",
        "plt.xlabel(\"Number of Components\")\n",
        "plt.ylabel(\"Cumulative Variance Explained\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "Qj9ytVk5LGC9",
        "outputId": "b16eec46-8bdb-4489-a42e-1f2bf2a719e2"
      },
      "id": "Qj9ytVk5LGC9",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.decomposition import PCA\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Set paths\n",
        "input_dir = '/content/results_features/pt_files'         # original features\n",
        "output_dir = '/content/results_features_pca100/pt_files' # reduced features\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Collect all features\n",
        "features = []\n",
        "file_paths = []\n",
        "\n",
        "print(\"Loading features...\")\n",
        "for fname in os.listdir(input_dir):\n",
        "    if fname.endswith('.pt'):\n",
        "        fpath = os.path.join(input_dir, fname)\n",
        "        data = torch.load(fpath)\n",
        "        features.append(data.numpy())\n",
        "        file_paths.append(fname)\n",
        "\n",
        "features = np.vstack(features)\n",
        "\n",
        "# Apply PCA\n",
        "print(\"Fitting PCA...\")\n",
        "pca = PCA(n_components=100)\n",
        "pca.fit(features)\n",
        "\n",
        "# Transform and save\n",
        "print(\"Transforming and saving reduced features...\")\n",
        "start = 0\n",
        "for i, fname in tqdm(enumerate(file_paths), total=len(file_paths)):\n",
        "    original = torch.load(os.path.join(input_dir, fname)).numpy()\n",
        "    reduced = pca.transform(original)\n",
        "    torch.save(torch.tensor(reduced), os.path.join(output_dir, fname))\n",
        "\n",
        "print(f\"Saved PCA-reduced features to: {output_dir}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3B9qKjDPInv",
        "outputId": "6f2f871e-dd86-406a-d5df-4dad108b1db8"
      },
      "id": "n3B9qKjDPInv",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading features...\n",
            "Fitting PCA...\n",
            "Transforming and saving reduced features...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:02<00:00,  9.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PCA-reduced features to: /content/results_features_pca100/pt_files\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "original_dir = '/content/results_features'\n",
        "pca_dir = '/content/results_features_pca100'\n",
        "\n",
        "for fname in os.listdir(original_dir):\n",
        "    if fname.endswith('.h5'):\n",
        "        shutil.copy(os.path.join(original_dir, fname), os.path.join(pca_dir, fname))\n",
        "\n",
        "print(\"Copied .h5 files to PCA directory.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQdx4xfRPQ2C",
        "outputId": "16ef654c-db37-438d-e108-2f5ad694081e"
      },
      "id": "fQdx4xfRPQ2C",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copied .h5 files to PCA directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "80d39199",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80d39199",
        "outputId": "910c3e14-8d58-4d45-97d1-d974e17e11aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label column: label\n",
            "label dictionary: {'B': 0, 'S': 1, 'E': 2}\n",
            "number of classes: 3\n",
            "slide-level counts:  \n",
            " label\n",
            "0    9\n",
            "1    5\n",
            "2    8\n",
            "Name: count, dtype: int64\n",
            "Patient-LVL; Number of samples registered in class 0: 9\n",
            "Slide-LVL; Number of samples registered in class 0: 9\n",
            "Patient-LVL; Number of samples registered in class 1: 5\n",
            "Slide-LVL; Number of samples registered in class 1: 5\n",
            "Patient-LVL; Number of samples registered in class 2: 8\n",
            "Slide-LVL; Number of samples registered in class 2: 8\n",
            "\n",
            "number of training samples: 12\n",
            "number of samples in cls 0: 5\n",
            "number of samples in cls 1: 3\n",
            "number of samples in cls 2: 4\n",
            "\n",
            "number of val samples: 5\n",
            "number of samples in cls 0: 2\n",
            "number of samples in cls 1: 1\n",
            "number of samples in cls 2: 2\n",
            "\n",
            "number of test samples: 5\n",
            "number of samples in cls 0: 2\n",
            "number of samples in cls 1: 1\n",
            "number of samples in cls 2: 2\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!MPLBACKEND=Agg conda run -n clam_latest python MLIAProject/CLAM/create_splits_seq.py --task MLIA_Project --seed 1 --k 1 --val_frac 0.2 --test_frac 0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "81c25ebc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81c25ebc",
        "outputId": "e18aa764-35f1-46d6-9f0e-62ae137757e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Load Dataset\n",
            "label column: label\n",
            "label dictionary: {'B': 0, 'S': 1, 'E': 2}\n",
            "number of classes: 3\n",
            "slide-level counts:  \n",
            " label\n",
            "0    9\n",
            "1    5\n",
            "2    8\n",
            "Name: count, dtype: int64\n",
            "Patient-LVL; Number of samples registered in class 0: 9\n",
            "Slide-LVL; Number of samples registered in class 0: 9\n",
            "Patient-LVL; Number of samples registered in class 1: 5\n",
            "Slide-LVL; Number of samples registered in class 1: 5\n",
            "Patient-LVL; Number of samples registered in class 2: 8\n",
            "Slide-LVL; Number of samples registered in class 2: 8\n",
            "split_dir:  splits/MLIA_Project_100\n",
            "################# Settings ###################\n",
            "num_splits:  1\n",
            "k_start:  -1\n",
            "k_end:  -1\n",
            "task:  MLIA_Project\n",
            "max_epochs:  300\n",
            "results_dir:  ./results\n",
            "lr:  0.0001\n",
            "experiment:  MLIA_CLAM_50\n",
            "reg:  1e-05\n",
            "label_frac:  1.0\n",
            "bag_loss:  ce\n",
            "seed:  1\n",
            "model_type:  clam_sb\n",
            "model_size:  small\n",
            "use_drop_out:  0.25\n",
            "weighted_sample:  True\n",
            "opt:  adam\n",
            "bag_weight:  0.7\n",
            "inst_loss:  svm\n",
            "B:  8\n",
            "split_dir:  splits/MLIA_Project_100\n",
            "\n",
            "Training Fold 0!\n",
            "\n",
            "Init train/val/test splits... \n",
            "Done!\n",
            "Training on 12 samples\n",
            "Validating on 5 samples\n",
            "Testing on 5 samples\n",
            "\n",
            "Init loss function... Done!\n",
            "\n",
            "Init Model... Setting tau to 1.0\n",
            "Done!\n",
            "CLAM_SB(\n",
            "  (attention_net): Sequential(\n",
            "    (0): Linear(in_features=100, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.25, inplace=False)\n",
            "    (3): Attn_Net_Gated(\n",
            "      (attention_a): Sequential(\n",
            "        (0): Linear(in_features=512, out_features=256, bias=True)\n",
            "        (1): Tanh()\n",
            "        (2): Dropout(p=0.25, inplace=False)\n",
            "      )\n",
            "      (attention_b): Sequential(\n",
            "        (0): Linear(in_features=512, out_features=256, bias=True)\n",
            "        (1): Sigmoid()\n",
            "        (2): Dropout(p=0.25, inplace=False)\n",
            "      )\n",
            "      (attention_c): Linear(in_features=256, out_features=1, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (classifiers): Linear(in_features=512, out_features=3, bias=True)\n",
            "  (instance_classifiers): ModuleList(\n",
            "    (0-2): 3 x Linear(in_features=512, out_features=2, bias=True)\n",
            "  )\n",
            "  (instance_loss_fn): SmoothTop1SVM()\n",
            ")\n",
            "Total number of parameters: 319242\n",
            "Total number of trainable parameters: 319242\n",
            "\n",
            "Init optimizer ... Done!\n",
            "\n",
            "Init Loaders... Done!\n",
            "\n",
            "Setup EarlyStopping... Done!\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.6006944444444444: correct 173/288\n",
            "class 1 clustering acc 0.2916666666666667: correct 28/96\n",
            "Epoch: 0, train_loss: 1.0947, train_clustering_loss:  1.3125, train_error: 0.5833\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/3\n",
            "class 2: acc 0.0, correct 0/4\n",
            "\n",
            "Val Set, val_loss: 1.0868, val_error: 0.4000, auc: 0.8889\n",
            "class 0 clustering acc 0.675: correct 81/120\n",
            "class 1 clustering acc 0.2: correct 8/40\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.5, correct 1/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.75: correct 216/288\n",
            "class 1 clustering acc 0.3125: correct 30/96\n",
            "Epoch: 1, train_loss: 1.0902, train_clustering_loss:  1.2941, train_error: 0.5000\n",
            "class 0: acc 1.0, correct 6/6\n",
            "class 1: acc 0.0, correct 0/4\n",
            "class 2: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 1.0870, val_error: 0.6000, auc: 0.8889\n",
            "class 0 clustering acc 0.7333333333333333: correct 88/120\n",
            "class 1 clustering acc 0.2: correct 8/40\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.0, correct 0/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.8263888888888888: correct 238/288\n",
            "class 1 clustering acc 0.3645833333333333: correct 35/96\n",
            "Epoch: 2, train_loss: 1.0918, train_clustering_loss:  1.2748, train_error: 0.5833\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/5\n",
            "class 2: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 1.0878, val_error: 0.6000, auc: 0.8889\n",
            "class 0 clustering acc 0.7666666666666667: correct 92/120\n",
            "class 1 clustering acc 0.2: correct 8/40\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.0, correct 0/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.8784722222222222: correct 253/288\n",
            "class 1 clustering acc 0.19791666666666666: correct 19/96\n",
            "Epoch: 3, train_loss: 1.0760, train_clustering_loss:  1.2576, train_error: 0.4167\n",
            "class 0: acc 1.0, correct 7/7\n",
            "class 1: acc 0.0, correct 0/4\n",
            "class 2: acc 0.0, correct 0/1\n",
            "\n",
            "Val Set, val_loss: 1.0887, val_error: 0.6000, auc: 0.8889\n",
            "class 0 clustering acc 0.9416666666666667: correct 113/120\n",
            "class 1 clustering acc 0.05: correct 2/40\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.0, correct 0/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9270833333333334: correct 267/288\n",
            "class 1 clustering acc 0.08333333333333333: correct 8/96\n",
            "Epoch: 4, train_loss: 1.1004, train_clustering_loss:  1.2518, train_error: 0.7500\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 0.0, correct 0/4\n",
            "class 2: acc 0.0, correct 0/5\n",
            "\n",
            "Val Set, val_loss: 1.0889, val_error: 0.6000, auc: 0.8333\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.0, correct 0/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9826388888888888: correct 283/288\n",
            "class 1 clustering acc 0.010416666666666666: correct 1/96\n",
            "Epoch: 5, train_loss: 1.1100, train_clustering_loss:  1.2373, train_error: 0.8333\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/3\n",
            "class 2: acc 0.0, correct 0/7\n",
            "\n",
            "Val Set, val_loss: 1.0882, val_error: 0.6000, auc: 0.8333\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.0, correct 0/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.010416666666666666: correct 1/96\n",
            "Epoch: 6, train_loss: 1.0962, train_clustering_loss:  1.2191, train_error: 0.7500\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 0.0, correct 0/3\n",
            "class 2: acc 0.0, correct 0/6\n",
            "\n",
            "Val Set, val_loss: 1.0874, val_error: 0.6000, auc: 0.8333\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.0, correct 0/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 7, train_loss: 1.0850, train_clustering_loss:  1.2014, train_error: 0.5833\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/3\n",
            "class 2: acc 0.0, correct 0/4\n",
            "\n",
            "Val Set, val_loss: 1.0864, val_error: 0.6000, auc: 0.8333\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.0, correct 0/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 8, train_loss: 1.0986, train_clustering_loss:  1.1735, train_error: 0.9167\n",
            "class 0: acc 1.0, correct 1/1\n",
            "class 1: acc 0.0, correct 0/6\n",
            "class 2: acc 0.0, correct 0/5\n",
            "\n",
            "Val Set, val_loss: 1.0864, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.5, correct 1/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 9, train_loss: 1.0836, train_clustering_loss:  1.1708, train_error: 0.4167\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 0.0, correct 0/3\n",
            "class 2: acc 0.6, correct 3/5\n",
            "\n",
            "Val Set, val_loss: 1.0863, val_error: 0.6000, auc: 0.8333\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.5, correct 1/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 10, train_loss: 1.0891, train_clustering_loss:  1.1471, train_error: 0.5833\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/5\n",
            "class 2: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 1.0867, val_error: 0.6000, auc: 0.8333\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.5, correct 1/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 11, train_loss: 1.0839, train_clustering_loss:  1.1300, train_error: 0.5000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/5\n",
            "class 2: acc 0.5, correct 1/2\n",
            "\n",
            "Val Set, val_loss: 1.0872, val_error: 0.6000, auc: 0.8333\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.5, correct 1/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 12, train_loss: 1.0897, train_clustering_loss:  1.1131, train_error: 0.6667\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/6\n",
            "class 2: acc 0.5, correct 2/4\n",
            "\n",
            "Val Set, val_loss: 1.0893, val_error: 0.6000, auc: 0.8333\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.5, correct 1/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 13, train_loss: 1.0782, train_clustering_loss:  1.1163, train_error: 0.3333\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/2\n",
            "class 2: acc 0.6, correct 3/5\n",
            "\n",
            "Val Set, val_loss: 1.0888, val_error: 0.6000, auc: 0.8333\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.5, correct 1/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 14, train_loss: 1.0815, train_clustering_loss:  1.1073, train_error: 0.4167\n",
            "class 0: acc 1.0, correct 6/6\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.2, correct 1/5\n",
            "\n",
            "Val Set, val_loss: 1.0868, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.5, correct 1/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 15, train_loss: 1.0650, train_clustering_loss:  1.0790, train_error: 0.3333\n",
            "class 0: acc 1.0, correct 6/6\n",
            "class 1: acc 0.0, correct 0/3\n",
            "class 2: acc 0.6666666666666666, correct 2/3\n",
            "\n",
            "Val Set, val_loss: 1.0862, val_error: 0.6000, auc: 0.7222\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.5, correct 1/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 16, train_loss: 1.0785, train_clustering_loss:  1.0477, train_error: 0.5833\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/5\n",
            "class 2: acc 0.0, correct 0/2\n",
            "\n",
            "Val Set, val_loss: 1.0858, val_error: 0.6000, auc: 0.7222\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.5, correct 1/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 17, train_loss: 1.0685, train_clustering_loss:  1.0322, train_error: 0.4167\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/5\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 1.0868, val_error: 0.8000, auc: 0.6667\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.0, correct 0/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 18, train_loss: 1.0713, train_clustering_loss:  1.0323, train_error: 0.5833\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/3\n",
            "class 2: acc 0.0, correct 0/4\n",
            "\n",
            "Val Set, val_loss: 1.0868, val_error: 0.6000, auc: 0.6667\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.0, correct 0/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 19, train_loss: 1.0728, train_clustering_loss:  1.0160, train_error: 0.6667\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 0.0, correct 0/3\n",
            "class 2: acc 0.0, correct 0/5\n",
            "\n",
            "Val Set, val_loss: 1.0865, val_error: 0.8000, auc: 0.6667\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.0, correct 0/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 20, train_loss: 1.0703, train_clustering_loss:  0.9911, train_error: 0.6667\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 0.0, correct 0/5\n",
            "class 2: acc 0.0, correct 0/3\n",
            "\n",
            "Val Set, val_loss: 1.0859, val_error: 0.8000, auc: 0.6667\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.0, correct 0/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 21, train_loss: 1.0769, train_clustering_loss:  0.9624, train_error: 0.7500\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/8\n",
            "class 2: acc 0.5, correct 1/2\n",
            "\n",
            "Val Set, val_loss: 1.0877, val_error: 0.8000, auc: 0.6667\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.0, correct 0/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 22, train_loss: 1.0538, train_clustering_loss:  0.9560, train_error: 0.3333\n",
            "class 0: acc 1.0, correct 7/7\n",
            "class 1: acc 0.0, correct 0/3\n",
            "class 2: acc 0.5, correct 1/2\n",
            "\n",
            "Val Set, val_loss: 1.0895, val_error: 0.8000, auc: 0.6667\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.0, correct 0/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 23, train_loss: 1.0659, train_clustering_loss:  0.9607, train_error: 0.5000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/2\n",
            "class 2: acc 0.2, correct 1/5\n",
            "\n",
            "Val Set, val_loss: 1.0891, val_error: 0.8000, auc: 0.6667\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.0, correct 0/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 24, train_loss: 1.0518, train_clustering_loss:  0.9387, train_error: 0.5000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.0, correct 0/3\n",
            "class 2: acc 0.25, correct 1/4\n",
            "\n",
            "Val Set, val_loss: 1.0881, val_error: 0.8000, auc: 0.6667\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.0, correct 0/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 25, train_loss: 1.0663, train_clustering_loss:  0.9231, train_error: 0.5833\n",
            "class 0: acc 1.0, correct 1/1\n",
            "class 1: acc 0.0, correct 0/6\n",
            "class 2: acc 0.8, correct 4/5\n",
            "\n",
            "Val Set, val_loss: 1.0879, val_error: 0.8000, auc: 0.6111\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.0, correct 0/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 26, train_loss: 1.0549, train_clustering_loss:  0.8935, train_error: 0.5000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 0.0, correct 0/6\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.0888, val_error: 0.8000, auc: 0.6111\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.0, correct 0/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 27, train_loss: 1.0452, train_clustering_loss:  0.8950, train_error: 0.3333\n",
            "class 0: acc 1.0, correct 7/7\n",
            "class 1: acc 0.0, correct 0/3\n",
            "class 2: acc 0.5, correct 1/2\n",
            "\n",
            "Val Set, val_loss: 1.0896, val_error: 0.8000, auc: 0.6111\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.0, correct 0/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 28, train_loss: 1.0602, train_clustering_loss:  0.8882, train_error: 0.7500\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 0.0, correct 0/5\n",
            "class 2: acc 0.0, correct 0/4\n",
            "\n",
            "Val Set, val_loss: 1.0903, val_error: 0.8000, auc: 0.6111\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.0, correct 0/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 29, train_loss: 1.0357, train_clustering_loss:  0.8542, train_error: 0.2500\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 0.5, correct 3/6\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.0918, val_error: 0.8000, auc: 0.6111\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.0, correct 0/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 30, train_loss: 1.0505, train_clustering_loss:  0.8541, train_error: 0.4167\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 0.4, correct 2/5\n",
            "class 2: acc 0.3333333333333333, correct 1/3\n",
            "\n",
            "Val Set, val_loss: 1.0936, val_error: 0.8000, auc: 0.6111\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.0, correct 0/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 31, train_loss: 1.0654, train_clustering_loss:  0.8745, train_error: 0.3333\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 2/2\n",
            "class 2: acc 0.42857142857142855, correct 3/7\n",
            "\n",
            "Val Set, val_loss: 1.0928, val_error: 0.6000, auc: 0.6111\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.5, correct 1/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 32, train_loss: 1.0428, train_clustering_loss:  0.8457, train_error: 0.0833\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 0.8333333333333334, correct 5/6\n",
            "\n",
            "Val Set, val_loss: 1.0919, val_error: 0.6000, auc: 0.6111\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.5, correct 1/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 33, train_loss: 1.0224, train_clustering_loss:  0.8306, train_error: 0.0833\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.6666666666666666, correct 2/3\n",
            "class 2: acc 1.0, correct 7/7\n",
            "\n",
            "Val Set, val_loss: 1.0911, val_error: 0.6000, auc: 0.6111\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.5, correct 1/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 34, train_loss: 1.0218, train_clustering_loss:  0.8194, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.0906, val_error: 0.6000, auc: 0.6111\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.5, correct 1/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 35, train_loss: 1.0250, train_clustering_loss:  0.8003, train_error: 0.0833\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.75, correct 3/4\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.0908, val_error: 0.6000, auc: 0.6111\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.5, correct 1/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 36, train_loss: 1.0186, train_clustering_loss:  0.7886, train_error: 0.1667\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.6, correct 3/5\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 1.0916, val_error: 0.6000, auc: 0.6111\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.5, correct 1/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 37, train_loss: 1.0126, train_clustering_loss:  0.7845, train_error: 0.1667\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 0.5, correct 2/4\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 1.0927, val_error: 0.6000, auc: 0.6111\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.5, correct 1/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 38, train_loss: 1.0032, train_clustering_loss:  0.7896, train_error: 0.0833\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 0.5, correct 1/2\n",
            "class 2: acc 1.0, correct 6/6\n",
            "\n",
            "Val Set, val_loss: 1.0923, val_error: 0.6000, auc: 0.6111\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.5, correct 1/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 39, train_loss: 1.0055, train_clustering_loss:  0.7644, train_error: 0.0833\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 0.8, correct 4/5\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.0931, val_error: 0.6000, auc: 0.6111\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.5, correct 1/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 40, train_loss: 0.9814, train_clustering_loss:  0.7637, train_error: 0.0833\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 0.6666666666666666, correct 2/3\n",
            "class 2: acc 1.0, correct 6/6\n",
            "\n",
            "Val Set, val_loss: 1.0942, val_error: 0.6000, auc: 0.6111\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.5, correct 1/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 41, train_loss: 0.9879, train_clustering_loss:  0.7585, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 6/6\n",
            "class 1: acc 1.0, correct 2/2\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.0946, val_error: 0.6000, auc: 0.6111\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.5, correct 1/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 42, train_loss: 0.9929, train_clustering_loss:  0.7511, train_error: 0.3333\n",
            "class 0: acc 1.0, correct 6/6\n",
            "class 1: acc 0.0, correct 0/4\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 1.0957, val_error: 0.6000, auc: 0.6111\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.5, correct 1/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 43, train_loss: 0.9830, train_clustering_loss:  0.7572, train_error: 0.0833\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.6666666666666666, correct 2/3\n",
            "class 2: acc 1.0, correct 7/7\n",
            "\n",
            "Val Set, val_loss: 1.0957, val_error: 0.6000, auc: 0.6111\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.5, correct 1/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 44, train_loss: 0.9748, train_clustering_loss:  0.7478, train_error: 0.1667\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.5, correct 2/4\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.0963, val_error: 0.6000, auc: 0.6111\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.5, correct 1/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 45, train_loss: 0.9445, train_clustering_loss:  0.7341, train_error: 0.3333\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 0.0, correct 0/4\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 1.0971, val_error: 0.6000, auc: 0.6111\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.5, correct 1/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 46, train_loss: 0.9620, train_clustering_loss:  0.7490, train_error: 0.0833\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 0.8, correct 4/5\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.0983, val_error: 0.6000, auc: 0.6111\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.5, correct 1/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 47, train_loss: 0.9475, train_clustering_loss:  0.7428, train_error: 0.1667\n",
            "class 0: acc 1.0, correct 6/6\n",
            "class 1: acc 0.3333333333333333, correct 1/3\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.0994, val_error: 0.6000, auc: 0.6111\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.5, correct 1/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 48, train_loss: 0.8998, train_clustering_loss:  0.7235, train_error: 0.1667\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 0.5, correct 2/4\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 1.1009, val_error: 0.6000, auc: 0.6111\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.5, correct 1/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 49, train_loss: 0.8915, train_clustering_loss:  0.7222, train_error: 0.1667\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 0.3333333333333333, correct 1/3\n",
            "class 2: acc 1.0, correct 6/6\n",
            "\n",
            "Val Set, val_loss: 1.0964, val_error: 0.6000, auc: 0.6111\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.5, correct 1/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 50, train_loss: 0.9108, train_clustering_loss:  0.7251, train_error: 0.0833\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 0.75, correct 3/4\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.0922, val_error: 0.6000, auc: 0.6111\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.5, correct 1/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 51, train_loss: 0.8630, train_clustering_loss:  0.7180, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 1.0888, val_error: 0.6000, auc: 0.6111\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.5, correct 1/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 52, train_loss: 0.8932, train_clustering_loss:  0.7247, train_error: 0.0833\n",
            "class 0: acc 1.0, correct 7/7\n",
            "class 1: acc 0.5, correct 1/2\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.0876, val_error: 0.6000, auc: 0.6111\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.5, correct 1/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 53, train_loss: 0.9211, train_clustering_loss:  0.7073, train_error: 0.2500\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 0.5, correct 3/6\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 1.0939, val_error: 0.6000, auc: 0.6111\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.5, correct 1/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 54, train_loss: 0.8812, train_clustering_loss:  0.7175, train_error: 0.0833\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 0.8, correct 4/5\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.0989, val_error: 0.6000, auc: 0.6111\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.5, correct 1/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 55, train_loss: 0.8364, train_clustering_loss:  0.7023, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.1010, val_error: 0.6000, auc: 0.6111\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.5, correct 1/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 56, train_loss: 0.8512, train_clustering_loss:  0.7049, train_error: 0.0833\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 0.6666666666666666, correct 2/3\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.1035, val_error: 0.6000, auc: 0.6111\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.5, correct 1/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 57, train_loss: 0.8243, train_clustering_loss:  0.6966, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.1026, val_error: 0.6000, auc: 0.6111\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.5, correct 1/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 58, train_loss: 0.7482, train_clustering_loss:  0.6631, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 6/6\n",
            "\n",
            "Val Set, val_loss: 1.0731, val_error: 0.6000, auc: 0.6111\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.5, correct 1/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 59, train_loss: 0.8140, train_clustering_loss:  0.6796, train_error: 0.2500\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 0.5, correct 3/6\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 1.0541, val_error: 0.6000, auc: 0.6111\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.5, correct 1/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 60, train_loss: 0.7409, train_clustering_loss:  0.6604, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 6/6\n",
            "\n",
            "Val Set, val_loss: 1.0331, val_error: 0.6000, auc: 0.7222\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 0.5, correct 1/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 61, train_loss: 0.6797, train_clustering_loss:  0.6430, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 1.0179, val_error: 0.4000, auc: 0.7778\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 62, train_loss: 0.7842, train_clustering_loss:  0.6823, train_error: 0.0833\n",
            "class 0: acc 0.8333333333333334, correct 5/6\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 1.0090, val_error: 0.4000, auc: 0.7778\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 63, train_loss: 0.7532, train_clustering_loss:  0.6608, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 0.9968, val_error: 0.4000, auc: 0.7778\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 64, train_loss: 0.8153, train_clustering_loss:  0.6822, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 0.9909, val_error: 0.4000, auc: 0.7778\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 65, train_loss: 0.7264, train_clustering_loss:  0.6544, train_error: 0.0833\n",
            "class 0: acc 0.8333333333333334, correct 5/6\n",
            "class 1: acc 1.0, correct 1/1\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 0.9799, val_error: 0.4000, auc: 0.7778\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 66, train_loss: 0.7209, train_clustering_loss:  0.6607, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 6/6\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 0.9721, val_error: 0.4000, auc: 0.7778\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 67, train_loss: 0.7174, train_clustering_loss:  0.6497, train_error: 0.1667\n",
            "class 0: acc 1.0, correct 6/6\n",
            "class 1: acc 0.5, correct 2/4\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 0.9687, val_error: 0.4000, auc: 0.7778\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 68, train_loss: 0.5695, train_clustering_loss:  0.5993, train_error: 0.1667\n",
            "class 0: acc 0.75, correct 3/4\n",
            "class 1: acc 0.5, correct 1/2\n",
            "class 2: acc 1.0, correct 6/6\n",
            "\n",
            "Val Set, val_loss: 0.9592, val_error: 0.4000, auc: 0.7778\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 69, train_loss: 0.7478, train_clustering_loss:  0.6387, train_error: 0.2500\n",
            "class 0: acc None, correct 0/0\n",
            "class 1: acc 0.7272727272727273, correct 8/11\n",
            "class 2: acc 1.0, correct 1/1\n",
            "\n",
            "Val Set, val_loss: 0.9552, val_error: 0.4000, auc: 0.7778\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 70, train_loss: 0.6793, train_clustering_loss:  0.6224, train_error: 0.0833\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 1.0, correct 6/6\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 0.9485, val_error: 0.4000, auc: 0.7778\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 71, train_loss: 0.6385, train_clustering_loss:  0.6061, train_error: 0.0833\n",
            "class 0: acc 0.75, correct 3/4\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 0.9432, val_error: 0.4000, auc: 0.7778\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 72, train_loss: 0.6776, train_clustering_loss:  0.6354, train_error: 0.0833\n",
            "class 0: acc 0.8333333333333334, correct 5/6\n",
            "class 1: acc 1.0, correct 1/1\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 0.9445, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 73, train_loss: 0.6883, train_clustering_loss:  0.6333, train_error: 0.3333\n",
            "class 0: acc 0.3333333333333333, correct 2/6\n",
            "class 1: acc 1.0, correct 2/2\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 0.9448, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 74, train_loss: 0.6534, train_clustering_loss:  0.6158, train_error: 0.0833\n",
            "class 0: acc 0.8, correct 4/5\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 0.9406, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 75, train_loss: 0.6886, train_clustering_loss:  0.6288, train_error: 0.0833\n",
            "class 0: acc 0.8, correct 4/5\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 0.9369, val_error: 0.4000, auc: 0.7778\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 76, train_loss: 0.6114, train_clustering_loss:  0.5952, train_error: 0.1667\n",
            "class 0: acc 0.5, correct 2/4\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 0.9340, val_error: 0.4000, auc: 0.7778\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.0: correct 0/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.010416666666666666: correct 1/96\n",
            "Epoch: 77, train_loss: 0.5671, train_clustering_loss:  0.5864, train_error: 0.1667\n",
            "class 0: acc 0.5, correct 2/4\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 0.9353, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.025: correct 1/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 78, train_loss: 0.5784, train_clustering_loss:  0.5825, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 2/2\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 0.9378, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.075: correct 3/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.010416666666666666: correct 1/96\n",
            "Epoch: 79, train_loss: 0.5162, train_clustering_loss:  0.5377, train_error: 0.1667\n",
            "class 0: acc 0.75, correct 3/4\n",
            "class 1: acc 0.6666666666666666, correct 2/3\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 0.9451, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.1: correct 4/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.07291666666666667: correct 7/96\n",
            "Epoch: 80, train_loss: 0.5003, train_clustering_loss:  0.5431, train_error: 0.0833\n",
            "class 0: acc 0.75, correct 3/4\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 0.9480, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.1: correct 4/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.09375: correct 9/96\n",
            "Epoch: 81, train_loss: 0.5216, train_clustering_loss:  0.5324, train_error: 0.0833\n",
            "class 0: acc 1.0, correct 1/1\n",
            "class 1: acc 0.8571428571428571, correct 6/7\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 0.9568, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 1.0: correct 120/120\n",
            "class 1 clustering acc 0.1: correct 4/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.17708333333333334: correct 17/96\n",
            "Epoch: 82, train_loss: 0.4247, train_clustering_loss:  0.5069, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 0.9643, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.975: correct 117/120\n",
            "class 1 clustering acc 0.1: correct 4/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.11458333333333333: correct 11/96\n",
            "Epoch: 83, train_loss: 0.5339, train_clustering_loss:  0.5517, train_error: 0.1667\n",
            "class 0: acc 0.6666666666666666, correct 4/6\n",
            "class 1: acc 1.0, correct 2/2\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 0.9724, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.9583333333333334: correct 115/120\n",
            "class 1 clustering acc 0.175: correct 7/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.041666666666666664: correct 4/96\n",
            "Epoch: 84, train_loss: 0.5515, train_clustering_loss:  0.5572, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 6/6\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 0.9730, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.95: correct 114/120\n",
            "class 1 clustering acc 0.2: correct 8/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.0: correct 0/96\n",
            "Epoch: 85, train_loss: 0.6326, train_clustering_loss:  0.6055, train_error: 0.1667\n",
            "class 0: acc 0.7142857142857143, correct 5/7\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 0.9725, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.95: correct 114/120\n",
            "class 1 clustering acc 0.2: correct 8/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.23958333333333334: correct 23/96\n",
            "Epoch: 86, train_loss: 0.4401, train_clustering_loss:  0.5051, train_error: 0.0833\n",
            "class 0: acc 1.0, correct 6/6\n",
            "class 1: acc 0.5, correct 1/2\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 0.9680, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.95: correct 114/120\n",
            "class 1 clustering acc 0.2: correct 8/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.23958333333333334: correct 23/96\n",
            "Epoch: 87, train_loss: 0.4206, train_clustering_loss:  0.4783, train_error: 0.1667\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 0.3333333333333333, correct 1/3\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 0.9702, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.95: correct 114/120\n",
            "class 1 clustering acc 0.2: correct 8/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.25: correct 24/96\n",
            "Epoch: 88, train_loss: 0.4022, train_clustering_loss:  0.4604, train_error: 0.1667\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.75, correct 3/4\n",
            "class 2: acc 1.0, correct 6/6\n",
            "\n",
            "Val Set, val_loss: 0.9769, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.95: correct 114/120\n",
            "class 1 clustering acc 0.25: correct 10/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.21875: correct 21/96\n",
            "Epoch: 89, train_loss: 0.4389, train_clustering_loss:  0.4977, train_error: 0.1667\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 0.5, correct 2/4\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 0.9832, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.95: correct 114/120\n",
            "class 1 clustering acc 0.25: correct 10/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.125: correct 12/96\n",
            "Epoch: 90, train_loss: 0.4752, train_clustering_loss:  0.5213, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 1.0, correct 6/6\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 0.9974, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.9416666666666667: correct 113/120\n",
            "class 1 clustering acc 0.25: correct 10/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.25: correct 24/96\n",
            "Epoch: 91, train_loss: 0.4337, train_clustering_loss:  0.4796, train_error: 0.0833\n",
            "class 0: acc 0.75, correct 3/4\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 1.0051, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.9333333333333333: correct 112/120\n",
            "class 1 clustering acc 0.3: correct 12/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.3020833333333333: correct 29/96\n",
            "Epoch: 92, train_loss: 0.3982, train_clustering_loss:  0.4752, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 6/6\n",
            "class 1: acc 1.0, correct 1/1\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 1.0182, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.925: correct 111/120\n",
            "class 1 clustering acc 0.3: correct 12/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.3020833333333333: correct 29/96\n",
            "Epoch: 93, train_loss: 0.3978, train_clustering_loss:  0.4680, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.0310, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.9166666666666666: correct 110/120\n",
            "class 1 clustering acc 0.3: correct 12/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.22916666666666666: correct 22/96\n",
            "Epoch: 94, train_loss: 0.3967, train_clustering_loss:  0.4968, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 6/6\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.0375, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.9: correct 108/120\n",
            "class 1 clustering acc 0.325: correct 13/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.23958333333333334: correct 23/96\n",
            "Epoch: 95, train_loss: 0.4624, train_clustering_loss:  0.4929, train_error: 0.0833\n",
            "class 0: acc 0.8, correct 4/5\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.0506, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8916666666666667: correct 107/120\n",
            "class 1 clustering acc 0.325: correct 13/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.09375: correct 9/96\n",
            "Epoch: 96, train_loss: 0.4976, train_clustering_loss:  0.5321, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 6/6\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 1.0514, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8916666666666667: correct 107/120\n",
            "class 1 clustering acc 0.325: correct 13/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.19791666666666666: correct 19/96\n",
            "Epoch: 97, train_loss: 0.4394, train_clustering_loss:  0.4924, train_error: 0.0833\n",
            "class 0: acc 0.6666666666666666, correct 2/3\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.0795, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8916666666666667: correct 107/120\n",
            "class 1 clustering acc 0.35: correct 14/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.3020833333333333: correct 29/96\n",
            "Epoch: 98, train_loss: 0.4266, train_clustering_loss:  0.4582, train_error: 0.0833\n",
            "class 0: acc 0.6666666666666666, correct 2/3\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 1.0935, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8916666666666667: correct 107/120\n",
            "class 1 clustering acc 0.35: correct 14/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.3125: correct 30/96\n",
            "Epoch: 99, train_loss: 0.4209, train_clustering_loss:  0.4856, train_error: 0.1667\n",
            "class 0: acc 0.6666666666666666, correct 4/6\n",
            "class 1: acc 1.0, correct 2/2\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.1007, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8916666666666667: correct 107/120\n",
            "class 1 clustering acc 0.35: correct 14/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.19791666666666666: correct 19/96\n",
            "Epoch: 100, train_loss: 0.4231, train_clustering_loss:  0.4909, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.1178, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8916666666666667: correct 107/120\n",
            "class 1 clustering acc 0.35: correct 14/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.4270833333333333: correct 41/96\n",
            "Epoch: 101, train_loss: 0.2975, train_clustering_loss:  0.4020, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 1/1\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 6/6\n",
            "\n",
            "Val Set, val_loss: 1.1393, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8916666666666667: correct 107/120\n",
            "class 1 clustering acc 0.375: correct 15/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.21875: correct 21/96\n",
            "Epoch: 102, train_loss: 0.3557, train_clustering_loss:  0.4653, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.1344, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8833333333333333: correct 106/120\n",
            "class 1 clustering acc 0.375: correct 15/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.3333333333333333: correct 32/96\n",
            "Epoch: 103, train_loss: 0.3454, train_clustering_loss:  0.4348, train_error: 0.0833\n",
            "class 0: acc 0.8, correct 4/5\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.1301, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8833333333333333: correct 106/120\n",
            "class 1 clustering acc 0.375: correct 15/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.3020833333333333: correct 29/96\n",
            "Epoch: 104, train_loss: 0.4188, train_clustering_loss:  0.4590, train_error: 0.1667\n",
            "class 0: acc 0.5, correct 2/4\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.1355, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8916666666666667: correct 107/120\n",
            "class 1 clustering acc 0.375: correct 15/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.23958333333333334: correct 23/96\n",
            "Epoch: 105, train_loss: 0.3843, train_clustering_loss:  0.4800, train_error: 0.0833\n",
            "class 0: acc 0.8333333333333334, correct 5/6\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.1481, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8916666666666667: correct 107/120\n",
            "class 1 clustering acc 0.375: correct 15/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.5416666666666666: correct 52/96\n",
            "Epoch: 106, train_loss: 0.2214, train_clustering_loss:  0.3337, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 2/2\n",
            "class 2: acc 1.0, correct 7/7\n",
            "\n",
            "Val Set, val_loss: 1.1561, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8833333333333333: correct 106/120\n",
            "class 1 clustering acc 0.375: correct 15/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.3229166666666667: correct 31/96\n",
            "Epoch: 107, train_loss: 0.3009, train_clustering_loss:  0.4276, train_error: 0.0833\n",
            "class 0: acc 0.8, correct 4/5\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.1674, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8833333333333333: correct 106/120\n",
            "class 1 clustering acc 0.375: correct 15/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.7395833333333334: correct 71/96\n",
            "Epoch: 108, train_loss: 0.1474, train_clustering_loss:  0.2516, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 1/1\n",
            "class 1: acc 1.0, correct 2/2\n",
            "class 2: acc 1.0, correct 9/9\n",
            "\n",
            "Val Set, val_loss: 1.1859, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8833333333333333: correct 106/120\n",
            "class 1 clustering acc 0.375: correct 15/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.22916666666666666: correct 22/96\n",
            "Epoch: 109, train_loss: 0.3284, train_clustering_loss:  0.4594, train_error: 0.0833\n",
            "class 0: acc 0.8571428571428571, correct 6/7\n",
            "class 1: acc 1.0, correct 2/2\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.2014, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8833333333333333: correct 106/120\n",
            "class 1 clustering acc 0.375: correct 15/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.40625: correct 39/96\n",
            "Epoch: 110, train_loss: 0.2669, train_clustering_loss:  0.3721, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 1.2173, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8833333333333333: correct 106/120\n",
            "class 1 clustering acc 0.375: correct 15/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.3958333333333333: correct 38/96\n",
            "Epoch: 111, train_loss: 0.2696, train_clustering_loss:  0.3800, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 2/2\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 1.2273, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.875: correct 105/120\n",
            "class 1 clustering acc 0.375: correct 15/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.25: correct 24/96\n",
            "Epoch: 112, train_loss: 0.3809, train_clustering_loss:  0.4591, train_error: 0.1667\n",
            "class 0: acc 0.6, correct 3/5\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.2200, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8833333333333333: correct 106/120\n",
            "class 1 clustering acc 0.375: correct 15/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.3333333333333333: correct 32/96\n",
            "Epoch: 113, train_loss: 0.3657, train_clustering_loss:  0.4239, train_error: 0.0833\n",
            "class 0: acc 0.8333333333333334, correct 5/6\n",
            "class 1: acc 1.0, correct 2/2\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.2202, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8833333333333333: correct 106/120\n",
            "class 1 clustering acc 0.375: correct 15/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.25: correct 24/96\n",
            "Epoch: 114, train_loss: 0.3092, train_clustering_loss:  0.4328, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.1950, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8916666666666667: correct 107/120\n",
            "class 1 clustering acc 0.375: correct 15/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.4166666666666667: correct 40/96\n",
            "Epoch: 115, train_loss: 0.3171, train_clustering_loss:  0.3842, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 1.1802, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8916666666666667: correct 107/120\n",
            "class 1 clustering acc 0.375: correct 15/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.3333333333333333: correct 32/96\n",
            "Epoch: 116, train_loss: 0.3394, train_clustering_loss:  0.4152, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.1889, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8916666666666667: correct 107/120\n",
            "class 1 clustering acc 0.375: correct 15/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.23958333333333334: correct 23/96\n",
            "Epoch: 117, train_loss: 0.3623, train_clustering_loss:  0.4448, train_error: 0.0833\n",
            "class 0: acc 0.875, correct 7/8\n",
            "class 1: acc 1.0, correct 1/1\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.2001, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8916666666666667: correct 107/120\n",
            "class 1 clustering acc 0.375: correct 15/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.25: correct 24/96\n",
            "Epoch: 118, train_loss: 0.2557, train_clustering_loss:  0.4108, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.2076, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8916666666666667: correct 107/120\n",
            "class 1 clustering acc 0.375: correct 15/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.3229166666666667: correct 31/96\n",
            "Epoch: 119, train_loss: 0.2431, train_clustering_loss:  0.3843, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.2040, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8916666666666667: correct 107/120\n",
            "class 1 clustering acc 0.375: correct 15/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.40625: correct 39/96\n",
            "Epoch: 120, train_loss: 0.2696, train_clustering_loss:  0.3667, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 1.2030, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8916666666666667: correct 107/120\n",
            "class 1 clustering acc 0.375: correct 15/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.4791666666666667: correct 46/96\n",
            "Epoch: 121, train_loss: 0.2053, train_clustering_loss:  0.3041, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 2/2\n",
            "class 2: acc 1.0, correct 6/6\n",
            "\n",
            "Val Set, val_loss: 1.2187, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8916666666666667: correct 107/120\n",
            "class 1 clustering acc 0.375: correct 15/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.3229166666666667: correct 31/96\n",
            "Epoch: 122, train_loss: 0.1798, train_clustering_loss:  0.3380, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.2288, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8916666666666667: correct 107/120\n",
            "class 1 clustering acc 0.375: correct 15/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.25: correct 24/96\n",
            "Epoch: 123, train_loss: 0.2370, train_clustering_loss:  0.3919, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 6/6\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.2425, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8916666666666667: correct 107/120\n",
            "class 1 clustering acc 0.375: correct 15/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.2708333333333333: correct 26/96\n",
            "Epoch: 124, train_loss: 0.2365, train_clustering_loss:  0.3705, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 6/6\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.2471, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8916666666666667: correct 107/120\n",
            "class 1 clustering acc 0.375: correct 15/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.3541666666666667: correct 34/96\n",
            "Epoch: 125, train_loss: 0.2146, train_clustering_loss:  0.3308, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.2570, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8916666666666667: correct 107/120\n",
            "class 1 clustering acc 0.375: correct 15/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.5208333333333334: correct 50/96\n",
            "Epoch: 126, train_loss: 0.2071, train_clustering_loss:  0.3148, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 6/6\n",
            "\n",
            "Val Set, val_loss: 1.2859, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8833333333333333: correct 106/120\n",
            "class 1 clustering acc 0.375: correct 15/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.34375: correct 33/96\n",
            "Epoch: 127, train_loss: 0.2159, train_clustering_loss:  0.3337, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 6/6\n",
            "class 1: acc 1.0, correct 2/2\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.3062, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8833333333333333: correct 106/120\n",
            "class 1 clustering acc 0.375: correct 15/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.3854166666666667: correct 37/96\n",
            "Epoch: 128, train_loss: 0.2008, train_clustering_loss:  0.3339, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.3319, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8833333333333333: correct 106/120\n",
            "class 1 clustering acc 0.375: correct 15/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.5729166666666666: correct 55/96\n",
            "Epoch: 129, train_loss: 0.1874, train_clustering_loss:  0.2763, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 7/7\n",
            "\n",
            "Val Set, val_loss: 1.3730, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8833333333333333: correct 106/120\n",
            "class 1 clustering acc 0.375: correct 15/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.5520833333333334: correct 53/96\n",
            "Epoch: 130, train_loss: 0.1442, train_clustering_loss:  0.2605, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 6/6\n",
            "\n",
            "Val Set, val_loss: 1.4240, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8583333333333333: correct 103/120\n",
            "class 1 clustering acc 0.4: correct 16/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.3541666666666667: correct 34/96\n",
            "Epoch: 131, train_loss: 0.2395, train_clustering_loss:  0.3574, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.4536, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8583333333333333: correct 103/120\n",
            "class 1 clustering acc 0.4: correct 16/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.15625: correct 15/96\n",
            "Epoch: 132, train_loss: 0.3632, train_clustering_loss:  0.4487, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 1.4790, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8583333333333333: correct 103/120\n",
            "class 1 clustering acc 0.4: correct 16/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.3958333333333333: correct 38/96\n",
            "Epoch: 133, train_loss: 0.1698, train_clustering_loss:  0.3136, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 6/6\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.4848, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8583333333333333: correct 103/120\n",
            "class 1 clustering acc 0.4: correct 16/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.4791666666666667: correct 46/96\n",
            "Epoch: 134, train_loss: 0.1377, train_clustering_loss:  0.2681, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 1.4892, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8666666666666667: correct 104/120\n",
            "class 1 clustering acc 0.4: correct 16/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.7291666666666666: correct 70/96\n",
            "Epoch: 135, train_loss: 0.1158, train_clustering_loss:  0.2113, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 1/1\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 8/8\n",
            "\n",
            "Val Set, val_loss: 1.5165, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8583333333333333: correct 103/120\n",
            "class 1 clustering acc 0.4: correct 16/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.3333333333333333: correct 32/96\n",
            "Epoch: 136, train_loss: 0.1630, train_clustering_loss:  0.3331, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.5268, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8583333333333333: correct 103/120\n",
            "class 1 clustering acc 0.4: correct 16/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.4895833333333333: correct 47/96\n",
            "Epoch: 137, train_loss: 0.1683, train_clustering_loss:  0.2999, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 1/1\n",
            "class 1: acc 1.0, correct 6/6\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 1.4719, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8666666666666667: correct 104/120\n",
            "class 1 clustering acc 0.4: correct 16/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.3854166666666667: correct 37/96\n",
            "Epoch: 138, train_loss: 0.2263, train_clustering_loss:  0.3510, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 7/7\n",
            "class 1: acc 1.0, correct 2/2\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.4552, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8833333333333333: correct 106/120\n",
            "class 1 clustering acc 0.4: correct 16/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.4166666666666667: correct 40/96\n",
            "Epoch: 139, train_loss: 0.1758, train_clustering_loss:  0.3292, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 1.0, correct 8/8\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 1.4085, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8833333333333333: correct 106/120\n",
            "class 1 clustering acc 0.375: correct 15/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.6770833333333334: correct 65/96\n",
            "Epoch: 140, train_loss: 0.1551, train_clustering_loss:  0.2186, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 1/1\n",
            "class 2: acc 1.0, correct 8/8\n",
            "\n",
            "Val Set, val_loss: 1.3674, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8833333333333333: correct 106/120\n",
            "class 1 clustering acc 0.375: correct 15/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.5625: correct 54/96\n",
            "Epoch: 141, train_loss: 0.1924, train_clustering_loss:  0.2857, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 2/2\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 1.3967, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8833333333333333: correct 106/120\n",
            "class 1 clustering acc 0.375: correct 15/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.4791666666666667: correct 46/96\n",
            "Epoch: 142, train_loss: 0.1989, train_clustering_loss:  0.2915, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 2/2\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 1.4377, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8833333333333333: correct 106/120\n",
            "class 1 clustering acc 0.425: correct 17/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.3020833333333333: correct 29/96\n",
            "Epoch: 143, train_loss: 0.2415, train_clustering_loss:  0.3707, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 1.4416, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8833333333333333: correct 106/120\n",
            "class 1 clustering acc 0.425: correct 17/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.4583333333333333: correct 44/96\n",
            "Epoch: 144, train_loss: 0.1526, train_clustering_loss:  0.2758, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 1.0, correct 6/6\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.4552, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8833333333333333: correct 106/120\n",
            "class 1 clustering acc 0.425: correct 17/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.4270833333333333: correct 41/96\n",
            "Epoch: 145, train_loss: 0.1476, train_clustering_loss:  0.2868, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.4832, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.875: correct 105/120\n",
            "class 1 clustering acc 0.425: correct 17/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.75: correct 72/96\n",
            "Epoch: 146, train_loss: 0.0905, train_clustering_loss:  0.1727, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 1/1\n",
            "class 2: acc 1.0, correct 8/8\n",
            "\n",
            "Val Set, val_loss: 1.5360, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8583333333333333: correct 103/120\n",
            "class 1 clustering acc 0.425: correct 17/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.71875: correct 69/96\n",
            "Epoch: 147, train_loss: 0.0837, train_clustering_loss:  0.1897, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 1/1\n",
            "class 2: acc 1.0, correct 6/6\n",
            "\n",
            "Val Set, val_loss: 1.5517, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8583333333333333: correct 103/120\n",
            "class 1 clustering acc 0.425: correct 17/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.4791666666666667: correct 46/96\n",
            "Epoch: 148, train_loss: 0.1869, train_clustering_loss:  0.2790, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 1.5830, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.85: correct 102/120\n",
            "class 1 clustering acc 0.425: correct 17/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.5625: correct 54/96\n",
            "Epoch: 149, train_loss: 0.1554, train_clustering_loss:  0.3197, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 6/6\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 1.5769, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.85: correct 102/120\n",
            "class 1 clustering acc 0.425: correct 17/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.8333333333333334: correct 80/96\n",
            "Epoch: 150, train_loss: 0.0484, train_clustering_loss:  0.1719, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 1.0, correct 2/2\n",
            "class 2: acc 1.0, correct 8/8\n",
            "\n",
            "Val Set, val_loss: 1.5759, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8416666666666667: correct 101/120\n",
            "class 1 clustering acc 0.425: correct 17/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.8958333333333334: correct 86/96\n",
            "Epoch: 151, train_loss: 0.0511, train_clustering_loss:  0.1327, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 1/1\n",
            "class 1: acc 1.0, correct 2/2\n",
            "class 2: acc 1.0, correct 9/9\n",
            "\n",
            "Val Set, val_loss: 1.6153, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8416666666666667: correct 101/120\n",
            "class 1 clustering acc 0.425: correct 17/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9930555555555556: correct 286/288\n",
            "class 1 clustering acc 0.7395833333333334: correct 71/96\n",
            "Epoch: 152, train_loss: 0.1220, train_clustering_loss:  0.2507, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 1.5510, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8583333333333333: correct 103/120\n",
            "class 1 clustering acc 0.425: correct 17/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.4479166666666667: correct 43/96\n",
            "Epoch: 153, train_loss: 0.1765, train_clustering_loss:  0.2950, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 6/6\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.5504, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8583333333333333: correct 103/120\n",
            "class 1 clustering acc 0.425: correct 17/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.65625: correct 63/96\n",
            "Epoch: 154, train_loss: 0.0974, train_clustering_loss:  0.2361, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.5485, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8583333333333333: correct 103/120\n",
            "class 1 clustering acc 0.425: correct 17/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9930555555555556: correct 286/288\n",
            "class 1 clustering acc 0.5625: correct 54/96\n",
            "Epoch: 155, train_loss: 0.1600, train_clustering_loss:  0.3349, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 1.4987, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8583333333333333: correct 103/120\n",
            "class 1 clustering acc 0.425: correct 17/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.8333333333333334: correct 80/96\n",
            "Epoch: 156, train_loss: 0.1165, train_clustering_loss:  0.2209, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 1/1\n",
            "class 1: acc 1.0, correct 6/6\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 1.4814, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8666666666666667: correct 104/120\n",
            "class 1 clustering acc 0.425: correct 17/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.75: correct 72/96\n",
            "Epoch: 157, train_loss: 0.1780, train_clustering_loss:  0.2777, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.4662, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8583333333333333: correct 103/120\n",
            "class 1 clustering acc 0.425: correct 17/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.6979166666666666: correct 67/96\n",
            "Epoch: 158, train_loss: 0.1594, train_clustering_loss:  0.2825, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.4503, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8583333333333333: correct 103/120\n",
            "class 1 clustering acc 0.425: correct 17/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.6666666666666666: correct 64/96\n",
            "Epoch: 159, train_loss: 0.1508, train_clustering_loss:  0.2720, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.4382, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8583333333333333: correct 103/120\n",
            "class 1 clustering acc 0.425: correct 17/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.8229166666666666: correct 79/96\n",
            "Epoch: 160, train_loss: 0.0923, train_clustering_loss:  0.2044, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 1.4584, val_error: 0.6000, auc: 0.7778\n",
            "class 0 clustering acc 0.8583333333333333: correct 103/120\n",
            "class 1 clustering acc 0.425: correct 17/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.7395833333333334: correct 71/96\n",
            "Epoch: 161, train_loss: 0.1252, train_clustering_loss:  0.2350, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 8/8\n",
            "class 1: acc 1.0, correct 1/1\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.4629, val_error: 0.6000, auc: 0.8333\n",
            "class 0 clustering acc 0.85: correct 102/120\n",
            "class 1 clustering acc 0.425: correct 17/40\n",
            "class 0: acc 0.0, correct 0/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.6875: correct 66/96\n",
            "Epoch: 162, train_loss: 0.1426, train_clustering_loss:  0.2456, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.4640, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.85: correct 102/120\n",
            "class 1 clustering acc 0.45: correct 18/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.84375: correct 81/96\n",
            "Epoch: 163, train_loss: 0.0765, train_clustering_loss:  0.2285, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 6/6\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.4554, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.85: correct 102/120\n",
            "class 1 clustering acc 0.45: correct 18/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.875: correct 84/96\n",
            "Epoch: 164, train_loss: 0.1244, train_clustering_loss:  0.2193, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 1/1\n",
            "class 1: acc 1.0, correct 6/6\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 1.3399, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8583333333333333: correct 103/120\n",
            "class 1 clustering acc 0.425: correct 17/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.8541666666666666: correct 82/96\n",
            "Epoch: 165, train_loss: 0.0637, train_clustering_loss:  0.1627, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 6/6\n",
            "\n",
            "Val Set, val_loss: 1.2703, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8666666666666667: correct 104/120\n",
            "class 1 clustering acc 0.425: correct 17/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.9270833333333334: correct 89/96\n",
            "Epoch: 166, train_loss: 0.0481, train_clustering_loss:  0.1784, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 1/1\n",
            "class 1: acc 1.0, correct 7/7\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.2615, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8666666666666667: correct 104/120\n",
            "class 1 clustering acc 0.425: correct 17/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.9583333333333334: correct 92/96\n",
            "Epoch: 167, train_loss: 0.0770, train_clustering_loss:  0.1631, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 1/1\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 6/6\n",
            "\n",
            "Val Set, val_loss: 1.2760, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8666666666666667: correct 104/120\n",
            "class 1 clustering acc 0.425: correct 17/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.8958333333333334: correct 86/96\n",
            "Epoch: 168, train_loss: 0.0783, train_clustering_loss:  0.1631, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 7/7\n",
            "\n",
            "Val Set, val_loss: 1.2946, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8666666666666667: correct 104/120\n",
            "class 1 clustering acc 0.425: correct 17/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.8020833333333334: correct 77/96\n",
            "Epoch: 169, train_loss: 0.0846, train_clustering_loss:  0.2167, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.3077, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8666666666666667: correct 104/120\n",
            "class 1 clustering acc 0.425: correct 17/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.9583333333333334: correct 92/96\n",
            "Epoch: 170, train_loss: 0.0577, train_clustering_loss:  0.1442, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 1/1\n",
            "class 2: acc 1.0, correct 6/6\n",
            "\n",
            "Val Set, val_loss: 1.3235, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8583333333333333: correct 103/120\n",
            "class 1 clustering acc 0.425: correct 17/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.8541666666666666: correct 82/96\n",
            "Epoch: 171, train_loss: 0.1107, train_clustering_loss:  0.2063, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.3319, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8583333333333333: correct 103/120\n",
            "class 1 clustering acc 0.425: correct 17/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.71875: correct 69/96\n",
            "Epoch: 172, train_loss: 0.0911, train_clustering_loss:  0.2242, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 8/8\n",
            "class 1: acc 1.0, correct 2/2\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 1.3231, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.85: correct 102/120\n",
            "class 1 clustering acc 0.425: correct 17/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.7708333333333334: correct 74/96\n",
            "Epoch: 173, train_loss: 0.1451, train_clustering_loss:  0.2499, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 1.3130, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.85: correct 102/120\n",
            "class 1 clustering acc 0.45: correct 18/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.9375: correct 90/96\n",
            "Epoch: 174, train_loss: 0.0779, train_clustering_loss:  0.1844, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 6/6\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 1/1\n",
            "\n",
            "Val Set, val_loss: 1.3000, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.85: correct 102/120\n",
            "class 1 clustering acc 0.45: correct 18/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.8229166666666666: correct 79/96\n",
            "Epoch: 175, train_loss: 0.0833, train_clustering_loss:  0.1731, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 2/2\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 1.2941, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.85: correct 102/120\n",
            "class 1 clustering acc 0.45: correct 18/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.9270833333333334: correct 89/96\n",
            "Epoch: 176, train_loss: 0.1048, train_clustering_loss:  0.1916, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 1.0, correct 6/6\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.2990, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.85: correct 102/120\n",
            "class 1 clustering acc 0.45: correct 18/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.8020833333333334: correct 77/96\n",
            "Epoch: 177, train_loss: 0.0986, train_clustering_loss:  0.2353, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 6/6\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.3063, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.85: correct 102/120\n",
            "class 1 clustering acc 0.475: correct 19/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.84375: correct 81/96\n",
            "Epoch: 178, train_loss: 0.0609, train_clustering_loss:  0.1698, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 2/2\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 1.3136, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.85: correct 102/120\n",
            "class 1 clustering acc 0.475: correct 19/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.90625: correct 87/96\n",
            "Epoch: 179, train_loss: 0.0992, train_clustering_loss:  0.2188, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 1.0, correct 7/7\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.3195, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.85: correct 102/120\n",
            "class 1 clustering acc 0.475: correct 19/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.90625: correct 87/96\n",
            "Epoch: 180, train_loss: 0.0573, train_clustering_loss:  0.1422, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 7/7\n",
            "\n",
            "Val Set, val_loss: 1.3353, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.85: correct 102/120\n",
            "class 1 clustering acc 0.475: correct 19/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.8854166666666666: correct 85/96\n",
            "Epoch: 181, train_loss: 0.0647, train_clustering_loss:  0.1653, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 7/7\n",
            "class 1: acc 1.0, correct 1/1\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.3546, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.85: correct 102/120\n",
            "class 1 clustering acc 0.475: correct 19/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.8541666666666666: correct 82/96\n",
            "Epoch: 182, train_loss: 0.1071, train_clustering_loss:  0.2069, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.3601, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8416666666666667: correct 101/120\n",
            "class 1 clustering acc 0.475: correct 19/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.875: correct 84/96\n",
            "Epoch: 183, train_loss: 0.0783, train_clustering_loss:  0.1815, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 1.3616, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.85: correct 102/120\n",
            "class 1 clustering acc 0.475: correct 19/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9930555555555556: correct 286/288\n",
            "class 1 clustering acc 0.8645833333333334: correct 83/96\n",
            "Epoch: 184, train_loss: 0.0693, train_clustering_loss:  0.1861, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 6/6\n",
            "\n",
            "Val Set, val_loss: 1.3575, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.85: correct 102/120\n",
            "class 1 clustering acc 0.475: correct 19/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.9479166666666666: correct 91/96\n",
            "Epoch: 185, train_loss: 0.0740, train_clustering_loss:  0.1669, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 7/7\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 1/1\n",
            "\n",
            "Val Set, val_loss: 1.3554, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.85: correct 102/120\n",
            "class 1 clustering acc 0.475: correct 19/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.9270833333333334: correct 89/96\n",
            "Epoch: 186, train_loss: 0.0727, train_clustering_loss:  0.1465, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 6/6\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.3620, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8416666666666667: correct 101/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.875: correct 84/96\n",
            "Epoch: 187, train_loss: 0.0595, train_clustering_loss:  0.1515, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 1.3633, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8416666666666667: correct 101/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.9270833333333334: correct 89/96\n",
            "Epoch: 188, train_loss: 0.0602, train_clustering_loss:  0.1639, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 1.0, correct 6/6\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.3771, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8416666666666667: correct 101/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.8541666666666666: correct 82/96\n",
            "Epoch: 189, train_loss: 0.0710, train_clustering_loss:  0.1860, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 1.3827, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8416666666666667: correct 101/120\n",
            "class 1 clustering acc 0.525: correct 21/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9930555555555556: correct 286/288\n",
            "class 1 clustering acc 0.90625: correct 87/96\n",
            "Epoch: 190, train_loss: 0.0452, train_clustering_loss:  0.1622, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.3823, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8416666666666667: correct 101/120\n",
            "class 1 clustering acc 0.525: correct 21/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9930555555555556: correct 286/288\n",
            "class 1 clustering acc 0.8854166666666666: correct 85/96\n",
            "Epoch: 191, train_loss: 0.0828, train_clustering_loss:  0.1997, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 7/7\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 1.3739, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8416666666666667: correct 101/120\n",
            "class 1 clustering acc 0.525: correct 21/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.9270833333333334: correct 89/96\n",
            "Epoch: 192, train_loss: 0.0458, train_clustering_loss:  0.1338, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 2/2\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 1.3709, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8416666666666667: correct 101/120\n",
            "class 1 clustering acc 0.525: correct 21/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.9270833333333334: correct 89/96\n",
            "Epoch: 193, train_loss: 0.0501, train_clustering_loss:  0.1395, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.3706, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8416666666666667: correct 101/120\n",
            "class 1 clustering acc 0.525: correct 21/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.8958333333333334: correct 86/96\n",
            "Epoch: 194, train_loss: 0.0408, train_clustering_loss:  0.1290, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 1/1\n",
            "class 2: acc 1.0, correct 7/7\n",
            "\n",
            "Val Set, val_loss: 1.3899, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8416666666666667: correct 101/120\n",
            "class 1 clustering acc 0.525: correct 21/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9930555555555556: correct 286/288\n",
            "class 1 clustering acc 0.9479166666666666: correct 91/96\n",
            "Epoch: 195, train_loss: 0.0488, train_clustering_loss:  0.1537, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.3924, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8416666666666667: correct 101/120\n",
            "class 1 clustering acc 0.525: correct 21/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.9270833333333334: correct 89/96\n",
            "Epoch: 196, train_loss: 0.0497, train_clustering_loss:  0.1608, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 1.0, correct 7/7\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.4028, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8416666666666667: correct 101/120\n",
            "class 1 clustering acc 0.525: correct 21/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.96875: correct 93/96\n",
            "Epoch: 197, train_loss: 0.0268, train_clustering_loss:  0.0819, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 2/2\n",
            "class 2: acc 1.0, correct 7/7\n",
            "\n",
            "Val Set, val_loss: 1.4178, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8416666666666667: correct 101/120\n",
            "class 1 clustering acc 0.525: correct 21/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.8541666666666666: correct 82/96\n",
            "Epoch: 198, train_loss: 0.0643, train_clustering_loss:  0.1699, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 1.4434, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8416666666666667: correct 101/120\n",
            "class 1 clustering acc 0.525: correct 21/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.9270833333333334: correct 89/96\n",
            "Epoch: 199, train_loss: 0.0354, train_clustering_loss:  0.1176, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 1.4539, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8416666666666667: correct 101/120\n",
            "class 1 clustering acc 0.525: correct 21/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.9166666666666666: correct 88/96\n",
            "Epoch: 200, train_loss: 0.0415, train_clustering_loss:  0.1439, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.4576, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8416666666666667: correct 101/120\n",
            "class 1 clustering acc 0.525: correct 21/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.96875: correct 93/96\n",
            "Epoch: 201, train_loss: 0.0423, train_clustering_loss:  0.1264, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 6/6\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.4586, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8416666666666667: correct 101/120\n",
            "class 1 clustering acc 0.525: correct 21/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.8541666666666666: correct 82/96\n",
            "Epoch: 202, train_loss: 0.0825, train_clustering_loss:  0.1787, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 6/6\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 1.4576, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8416666666666667: correct 101/120\n",
            "class 1 clustering acc 0.525: correct 21/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.875: correct 84/96\n",
            "Epoch: 203, train_loss: 0.0587, train_clustering_loss:  0.1445, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 1.4525, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8416666666666667: correct 101/120\n",
            "class 1 clustering acc 0.525: correct 21/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.9583333333333334: correct 92/96\n",
            "Epoch: 204, train_loss: 0.0466, train_clustering_loss:  0.1078, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 1.4576, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8416666666666667: correct 101/120\n",
            "class 1 clustering acc 0.525: correct 21/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.9583333333333334: correct 92/96\n",
            "Epoch: 205, train_loss: 0.0496, train_clustering_loss:  0.1414, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 7/7\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 1.4600, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8416666666666667: correct 101/120\n",
            "class 1 clustering acc 0.525: correct 21/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.9583333333333334: correct 92/96\n",
            "Epoch: 206, train_loss: 0.0270, train_clustering_loss:  0.0970, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 1.0, correct 6/6\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.4581, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8416666666666667: correct 101/120\n",
            "class 1 clustering acc 0.525: correct 21/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.9791666666666666: correct 94/96\n",
            "Epoch: 207, train_loss: 0.0388, train_clustering_loss:  0.1157, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.4586, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.85: correct 102/120\n",
            "class 1 clustering acc 0.525: correct 21/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.9166666666666666: correct 88/96\n",
            "Epoch: 208, train_loss: 0.0637, train_clustering_loss:  0.1424, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.4545, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8416666666666667: correct 101/120\n",
            "class 1 clustering acc 0.525: correct 21/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9930555555555556: correct 286/288\n",
            "class 1 clustering acc 0.9479166666666666: correct 91/96\n",
            "Epoch: 209, train_loss: 0.0605, train_clustering_loss:  0.1699, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 6/6\n",
            "class 2: acc 1.0, correct 1/1\n",
            "\n",
            "Val Set, val_loss: 1.4448, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8416666666666667: correct 101/120\n",
            "class 1 clustering acc 0.525: correct 21/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.9375: correct 90/96\n",
            "Epoch: 210, train_loss: 0.0463, train_clustering_loss:  0.1317, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 6/6\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.4465, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8416666666666667: correct 101/120\n",
            "class 1 clustering acc 0.525: correct 21/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.9270833333333334: correct 89/96\n",
            "Epoch: 211, train_loss: 0.0244, train_clustering_loss:  0.1101, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 1.4488, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8416666666666667: correct 101/120\n",
            "class 1 clustering acc 0.525: correct 21/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.9166666666666666: correct 88/96\n",
            "Epoch: 212, train_loss: 0.0507, train_clustering_loss:  0.1500, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 6/6\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 1/1\n",
            "\n",
            "Val Set, val_loss: 1.4488, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8416666666666667: correct 101/120\n",
            "class 1 clustering acc 0.525: correct 21/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.9375: correct 90/96\n",
            "Epoch: 213, train_loss: 0.0460, train_clustering_loss:  0.1011, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 2/2\n",
            "class 2: acc 1.0, correct 6/6\n",
            "\n",
            "Val Set, val_loss: 1.4630, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.90625: correct 87/96\n",
            "Epoch: 214, train_loss: 0.0406, train_clustering_loss:  0.1204, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.4812, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.9375: correct 90/96\n",
            "Epoch: 215, train_loss: 0.0421, train_clustering_loss:  0.1338, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 7/7\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 1.4869, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.90625: correct 87/96\n",
            "Epoch: 216, train_loss: 0.0423, train_clustering_loss:  0.1326, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.4955, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9930555555555556: correct 286/288\n",
            "class 1 clustering acc 0.9375: correct 90/96\n",
            "Epoch: 217, train_loss: 0.0535, train_clustering_loss:  0.1628, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 7/7\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 1/1\n",
            "\n",
            "Val Set, val_loss: 1.4847, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9930555555555556: correct 286/288\n",
            "class 1 clustering acc 0.90625: correct 87/96\n",
            "Epoch: 218, train_loss: 0.0391, train_clustering_loss:  0.1485, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.4758, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.9270833333333334: correct 89/96\n",
            "Epoch: 219, train_loss: 0.0337, train_clustering_loss:  0.1153, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 1.4745, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.9166666666666666: correct 88/96\n",
            "Epoch: 220, train_loss: 0.0367, train_clustering_loss:  0.1131, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 6/6\n",
            "\n",
            "Val Set, val_loss: 1.4842, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.9479166666666666: correct 91/96\n",
            "Epoch: 221, train_loss: 0.0411, train_clustering_loss:  0.1067, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.4903, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.9479166666666666: correct 91/96\n",
            "Epoch: 222, train_loss: 0.0268, train_clustering_loss:  0.1036, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.4838, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.9791666666666666: correct 94/96\n",
            "Epoch: 223, train_loss: 0.0457, train_clustering_loss:  0.1105, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 6/6\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 1.4641, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.9375: correct 90/96\n",
            "Epoch: 224, train_loss: 0.0426, train_clustering_loss:  0.1303, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.4635, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.9583333333333334: correct 92/96\n",
            "Epoch: 225, train_loss: 0.0208, train_clustering_loss:  0.0827, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 2/2\n",
            "class 2: acc 1.0, correct 7/7\n",
            "\n",
            "Val Set, val_loss: 1.4762, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9930555555555556: correct 286/288\n",
            "class 1 clustering acc 0.9375: correct 90/96\n",
            "Epoch: 226, train_loss: 0.0365, train_clustering_loss:  0.1413, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.4776, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.9479166666666666: correct 91/96\n",
            "Epoch: 227, train_loss: 0.0159, train_clustering_loss:  0.0945, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 1/1\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 6/6\n",
            "\n",
            "Val Set, val_loss: 1.4745, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.96875: correct 93/96\n",
            "Epoch: 228, train_loss: 0.0217, train_clustering_loss:  0.0866, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 1.4817, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.9375: correct 90/96\n",
            "Epoch: 229, train_loss: 0.0455, train_clustering_loss:  0.1335, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 1.4942, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.9895833333333334: correct 95/96\n",
            "Epoch: 230, train_loss: 0.0199, train_clustering_loss:  0.0664, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 8/8\n",
            "class 1: acc 1.0, correct 1/1\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.5067, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.9479166666666666: correct 91/96\n",
            "Epoch: 231, train_loss: 0.0363, train_clustering_loss:  0.1260, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 6/6\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 1.5149, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.9166666666666666: correct 88/96\n",
            "Epoch: 232, train_loss: 0.0397, train_clustering_loss:  0.1452, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 1.5142, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.9791666666666666: correct 94/96\n",
            "Epoch: 233, train_loss: 0.0355, train_clustering_loss:  0.1047, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 1.5229, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.9583333333333334: correct 92/96\n",
            "Epoch: 234, train_loss: 0.0257, train_clustering_loss:  0.1150, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 8/8\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 1/1\n",
            "\n",
            "Val Set, val_loss: 1.5169, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.96875: correct 93/96\n",
            "Epoch: 235, train_loss: 0.0293, train_clustering_loss:  0.1008, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 1.5148, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.96875: correct 93/96\n",
            "Epoch: 236, train_loss: 0.0322, train_clustering_loss:  0.0932, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.5175, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9930555555555556: correct 286/288\n",
            "class 1 clustering acc 0.9166666666666666: correct 88/96\n",
            "Epoch: 237, train_loss: 0.0148, train_clustering_loss:  0.1177, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.5175, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.9583333333333334: correct 92/96\n",
            "Epoch: 238, train_loss: 0.0357, train_clustering_loss:  0.1202, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.5220, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.9166666666666666: correct 88/96\n",
            "Epoch: 239, train_loss: 0.0319, train_clustering_loss:  0.1194, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 1.5205, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.9895833333333334: correct 95/96\n",
            "Epoch: 240, train_loss: 0.0382, train_clustering_loss:  0.0998, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 1.0, correct 6/6\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.5186, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.825: correct 99/120\n",
            "class 1 clustering acc 0.475: correct 19/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.96875: correct 93/96\n",
            "Epoch: 241, train_loss: 0.0152, train_clustering_loss:  0.0627, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 1.5229, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.9270833333333334: correct 89/96\n",
            "Epoch: 242, train_loss: 0.0271, train_clustering_loss:  0.1021, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 6/6\n",
            "\n",
            "Val Set, val_loss: 1.5368, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 1.0: correct 96/96\n",
            "Epoch: 243, train_loss: 0.0232, train_clustering_loss:  0.0587, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.5239, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.825: correct 99/120\n",
            "class 1 clustering acc 0.475: correct 19/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.9583333333333334: correct 92/96\n",
            "Epoch: 244, train_loss: 0.0266, train_clustering_loss:  0.1092, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.5209, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.825: correct 99/120\n",
            "class 1 clustering acc 0.475: correct 19/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 1.0: correct 96/96\n",
            "Epoch: 245, train_loss: 0.0184, train_clustering_loss:  0.0499, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.5254, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.825: correct 99/120\n",
            "class 1 clustering acc 0.475: correct 19/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.96875: correct 93/96\n",
            "Epoch: 246, train_loss: 0.0330, train_clustering_loss:  0.0943, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.5173, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.9583333333333334: correct 92/96\n",
            "Epoch: 247, train_loss: 0.0336, train_clustering_loss:  0.0961, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 1.5151, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8416666666666667: correct 101/120\n",
            "class 1 clustering acc 0.525: correct 21/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9930555555555556: correct 286/288\n",
            "class 1 clustering acc 0.9583333333333334: correct 92/96\n",
            "Epoch: 248, train_loss: 0.0150, train_clustering_loss:  0.0928, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 1.5175, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8416666666666667: correct 101/120\n",
            "class 1 clustering acc 0.525: correct 21/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.9895833333333334: correct 95/96\n",
            "Epoch: 249, train_loss: 0.0160, train_clustering_loss:  0.0490, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 1/1\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 8/8\n",
            "\n",
            "Val Set, val_loss: 1.5305, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8416666666666667: correct 101/120\n",
            "class 1 clustering acc 0.525: correct 21/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.9583333333333334: correct 92/96\n",
            "Epoch: 250, train_loss: 0.0225, train_clustering_loss:  0.0874, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 2/2\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 1.5528, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.9791666666666666: correct 94/96\n",
            "Epoch: 251, train_loss: 0.0226, train_clustering_loss:  0.0766, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 1.0, correct 6/6\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.5672, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.9270833333333334: correct 89/96\n",
            "Epoch: 252, train_loss: 0.0231, train_clustering_loss:  0.1000, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.5719, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.9791666666666666: correct 94/96\n",
            "Epoch: 253, train_loss: 0.0231, train_clustering_loss:  0.0675, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 6/6\n",
            "\n",
            "Val Set, val_loss: 1.5796, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.9375: correct 90/96\n",
            "Epoch: 254, train_loss: 0.0218, train_clustering_loss:  0.0980, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 7/7\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 1.5860, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.9895833333333334: correct 95/96\n",
            "Epoch: 255, train_loss: 0.0143, train_clustering_loss:  0.0501, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 6/6\n",
            "\n",
            "Val Set, val_loss: 1.5855, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 1.0: correct 96/96\n",
            "Epoch: 256, train_loss: 0.0223, train_clustering_loss:  0.0602, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.6026, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9930555555555556: correct 286/288\n",
            "class 1 clustering acc 0.9270833333333334: correct 89/96\n",
            "Epoch: 257, train_loss: 0.0206, train_clustering_loss:  0.1076, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 6/6\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 1.6230, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.9791666666666666: correct 94/96\n",
            "Epoch: 258, train_loss: 0.0144, train_clustering_loss:  0.0493, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 7/7\n",
            "\n",
            "Val Set, val_loss: 1.6433, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.96875: correct 93/96\n",
            "Epoch: 259, train_loss: 0.0157, train_clustering_loss:  0.0857, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.6538, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.96875: correct 93/96\n",
            "Epoch: 260, train_loss: 0.0257, train_clustering_loss:  0.0982, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 6/6\n",
            "class 2: acc 1.0, correct 1/1\n",
            "\n",
            "Val Set, val_loss: 1.6583, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.96875: correct 93/96\n",
            "Epoch: 261, train_loss: 0.0198, train_clustering_loss:  0.0728, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.6688, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.9895833333333334: correct 95/96\n",
            "Epoch: 262, train_loss: 0.0228, train_clustering_loss:  0.0626, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 6/6\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 1.6730, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9930555555555556: correct 286/288\n",
            "class 1 clustering acc 0.90625: correct 87/96\n",
            "Epoch: 263, train_loss: 0.0203, train_clustering_loss:  0.1278, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.6703, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.9791666666666666: correct 94/96\n",
            "Epoch: 264, train_loss: 0.0106, train_clustering_loss:  0.0528, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 2/2\n",
            "class 2: acc 1.0, correct 7/7\n",
            "\n",
            "Val Set, val_loss: 1.6599, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.96875: correct 93/96\n",
            "Epoch: 265, train_loss: 0.0177, train_clustering_loss:  0.1072, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.6561, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9861111111111112: correct 284/288\n",
            "class 1 clustering acc 0.9375: correct 90/96\n",
            "Epoch: 266, train_loss: 0.0143, train_clustering_loss:  0.1154, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.6316, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.9375: correct 90/96\n",
            "Epoch: 267, train_loss: 0.0180, train_clustering_loss:  0.0990, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.6283, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9930555555555556: correct 286/288\n",
            "class 1 clustering acc 0.9166666666666666: correct 88/96\n",
            "Epoch: 268, train_loss: 0.0205, train_clustering_loss:  0.1296, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 6/6\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.6209, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.9583333333333334: correct 92/96\n",
            "Epoch: 269, train_loss: 0.0277, train_clustering_loss:  0.0920, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 1.0, correct 6/6\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.6196, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.96875: correct 93/96\n",
            "Epoch: 270, train_loss: 0.0143, train_clustering_loss:  0.0759, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 1.6335, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.96875: correct 93/96\n",
            "Epoch: 271, train_loss: 0.0082, train_clustering_loss:  0.0476, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 1.6513, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.9479166666666666: correct 91/96\n",
            "Epoch: 272, train_loss: 0.0115, train_clustering_loss:  0.0579, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 1.6642, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.96875: correct 93/96\n",
            "Epoch: 273, train_loss: 0.0142, train_clustering_loss:  0.0616, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 1.0, correct 6/6\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.6795, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.96875: correct 93/96\n",
            "Epoch: 274, train_loss: 0.0077, train_clustering_loss:  0.0549, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 2/2\n",
            "class 2: acc 1.0, correct 7/7\n",
            "\n",
            "Val Set, val_loss: 1.6944, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9930555555555556: correct 286/288\n",
            "class 1 clustering acc 0.9583333333333334: correct 92/96\n",
            "Epoch: 275, train_loss: 0.0141, train_clustering_loss:  0.1117, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 1.6851, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.9791666666666666: correct 94/96\n",
            "Epoch: 276, train_loss: 0.0132, train_clustering_loss:  0.0582, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 1/1\n",
            "class 1: acc 1.0, correct 6/6\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 1.6829, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.9791666666666666: correct 94/96\n",
            "Epoch: 277, train_loss: 0.0140, train_clustering_loss:  0.0527, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.6967, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.96875: correct 93/96\n",
            "Epoch: 278, train_loss: 0.0222, train_clustering_loss:  0.0877, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 8/8\n",
            "class 1: acc 1.0, correct 2/2\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 1.7018, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.9791666666666666: correct 94/96\n",
            "Epoch: 279, train_loss: 0.0199, train_clustering_loss:  0.0747, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 6/6\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 1.6657, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.9583333333333334: correct 92/96\n",
            "Epoch: 280, train_loss: 0.0168, train_clustering_loss:  0.0855, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 6/6\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 1.6405, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8416666666666667: correct 101/120\n",
            "class 1 clustering acc 0.525: correct 21/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.9791666666666666: correct 94/96\n",
            "Epoch: 281, train_loss: 0.0097, train_clustering_loss:  0.0531, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 1/1\n",
            "class 2: acc 1.0, correct 7/7\n",
            "\n",
            "Val Set, val_loss: 1.6330, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8416666666666667: correct 101/120\n",
            "class 1 clustering acc 0.525: correct 21/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.9895833333333334: correct 95/96\n",
            "Epoch: 282, train_loss: 0.0130, train_clustering_loss:  0.0646, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 1.6408, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8416666666666667: correct 101/120\n",
            "class 1 clustering acc 0.525: correct 21/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.96875: correct 93/96\n",
            "Epoch: 283, train_loss: 0.0170, train_clustering_loss:  0.0601, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 6/6\n",
            "\n",
            "Val Set, val_loss: 1.6467, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.9791666666666666: correct 94/96\n",
            "Epoch: 284, train_loss: 0.0185, train_clustering_loss:  0.0601, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.6536, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9930555555555556: correct 286/288\n",
            "class 1 clustering acc 0.96875: correct 93/96\n",
            "Epoch: 285, train_loss: 0.0156, train_clustering_loss:  0.0892, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.6653, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.9895833333333334: correct 95/96\n",
            "Epoch: 286, train_loss: 0.0143, train_clustering_loss:  0.0719, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 1.6788, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.9583333333333334: correct 92/96\n",
            "Epoch: 287, train_loss: 0.0104, train_clustering_loss:  0.0685, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 6/6\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 1.6840, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.96875: correct 93/96\n",
            "Epoch: 288, train_loss: 0.0141, train_clustering_loss:  0.0691, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 2/2\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 1.6907, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.9791666666666666: correct 94/96\n",
            "Epoch: 289, train_loss: 0.0083, train_clustering_loss:  0.0700, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 1.6945, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.9583333333333334: correct 92/96\n",
            "Epoch: 290, train_loss: 0.0060, train_clustering_loss:  0.0552, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 1.0, correct 6/6\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.6986, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 1.0: correct 96/96\n",
            "Epoch: 291, train_loss: 0.0127, train_clustering_loss:  0.0428, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.7071, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.9895833333333334: correct 95/96\n",
            "Epoch: 292, train_loss: 0.0084, train_clustering_loss:  0.0441, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 1.7134, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8333333333333334: correct 100/120\n",
            "class 1 clustering acc 0.5: correct 20/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.9583333333333334: correct 92/96\n",
            "Epoch: 293, train_loss: 0.0156, train_clustering_loss:  0.0743, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 1.0, correct 6/6\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.7189, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8416666666666667: correct 101/120\n",
            "class 1 clustering acc 0.525: correct 21/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.9895833333333334: correct 95/96\n",
            "Epoch: 294, train_loss: 0.0093, train_clustering_loss:  0.0391, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 6/6\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.7151, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8416666666666667: correct 101/120\n",
            "class 1 clustering acc 0.525: correct 21/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.96875: correct 93/96\n",
            "Epoch: 295, train_loss: 0.0197, train_clustering_loss:  0.0921, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.7094, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8416666666666667: correct 101/120\n",
            "class 1 clustering acc 0.525: correct 21/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.9895833333333334: correct 95/96\n",
            "Epoch: 296, train_loss: 0.0159, train_clustering_loss:  0.0669, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 6/6\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "Val Set, val_loss: 1.7099, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8416666666666667: correct 101/120\n",
            "class 1 clustering acc 0.525: correct 21/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.9895833333333334: correct 95/96\n",
            "Epoch: 297, train_loss: 0.0138, train_clustering_loss:  0.0559, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 3/3\n",
            "class 1: acc 1.0, correct 5/5\n",
            "class 2: acc 1.0, correct 4/4\n",
            "\n",
            "Val Set, val_loss: 1.7114, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8416666666666667: correct 101/120\n",
            "class 1 clustering acc 0.525: correct 21/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 1.0: correct 288/288\n",
            "class 1 clustering acc 0.9895833333333334: correct 95/96\n",
            "Epoch: 298, train_loss: 0.0104, train_clustering_loss:  0.0347, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 5/5\n",
            "class 1: acc 1.0, correct 4/4\n",
            "class 2: acc 1.0, correct 3/3\n",
            "\n",
            "Val Set, val_loss: 1.7182, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8416666666666667: correct 101/120\n",
            "class 1 clustering acc 0.525: correct 21/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "class 0 clustering acc 0.9965277777777778: correct 287/288\n",
            "class 1 clustering acc 0.9895833333333334: correct 95/96\n",
            "Epoch: 299, train_loss: 0.0158, train_clustering_loss:  0.0781, train_error: 0.0000\n",
            "class 0: acc 1.0, correct 4/4\n",
            "class 1: acc 1.0, correct 3/3\n",
            "class 2: acc 1.0, correct 5/5\n",
            "\n",
            "Val Set, val_loss: 1.7122, val_error: 0.4000, auc: 0.8333\n",
            "class 0 clustering acc 0.8416666666666667: correct 101/120\n",
            "class 1 clustering acc 0.525: correct 21/40\n",
            "class 0: acc 0.5, correct 1/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "Val error: 0.4000, ROC AUC: 0.8333\n",
            "\n",
            "Test Set, test_error: 0.2000, test_auc: 0.9167\n",
            "Test error: 0.2000, ROC AUC: 0.9167\n",
            "class 0: acc 1.0, correct 2/2\n",
            "class 1: acc 0.0, correct 0/1\n",
            "class 2: acc 1.0, correct 2/2\n",
            "finished!\n",
            "end script\n",
            "\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/envs/clam_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!MPLBACKEND=Agg CUDA_VISIBLE_DEVICES=0 conda run -n clam_latest python MLIAProject/CLAM/main.py --max_epoch 300 --drop_out 0.25 --lr 1e-4 --k 1 --exp_code MLIA_CLAM_50 --weighted_sample --bag_loss ce --inst_loss svm --task MLIA_Project --model_type clam_sb --log_data --subtyping --data_root_dir /content/results_features_pca100 --embed_dim 100"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r result_classifier.zip 'results/'"
      ],
      "metadata": {
        "id": "gEuf3d7qGCGx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac760d83-87ba-4ef6-f1e3-45ba34eb1c0b"
      },
      "id": "gEuf3d7qGCGx",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: results/ (stored 0%)\n",
            "  adding: results/MLIA_CLAM_50_s1/ (stored 0%)\n",
            "  adding: results/MLIA_CLAM_50_s1/s_0_checkpoint.pt (deflated 9%)\n",
            "  adding: results/MLIA_CLAM_50_s1/splits_0.csv (deflated 44%)\n",
            "  adding: results/MLIA_CLAM_50_s1/experiment_MLIA_CLAM_50.txt (deflated 40%)\n",
            "  adding: results/MLIA_CLAM_50_s1/summary.csv (deflated 44%)\n",
            "  adding: results/MLIA_CLAM_50_s1/0/ (stored 0%)\n",
            "  adding: results/MLIA_CLAM_50_s1/0/events.out.tfevents.1749887149.cf4b0397372d (deflated 75%)\n",
            "  adding: results/MLIA_CLAM_50_s1/split_0_results.pkl (deflated 55%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!MPLBACKEND=Agg CUDA_VISIBLE_DEVICES=0 conda run -n clam_latest python MLIAProject/CLAM/eval.py --k 1 --models_exp_code MLIA_CLAM_50_s1 --save_exp_code MLIA_CLAM_eval --task MLIA_Project --model_type clam_sb --results_dir results --data_root_dir  /content/results_features_pca100 --embed_dim 100"
      ],
      "metadata": {
        "id": "VMHlGDTIGC4E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aed7665e-7ea0-46e9-c632-cf2e402af2e5"
      },
      "id": "VMHlGDTIGC4E",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models directory: results/MLIA_CLAM_50_s1\n",
            "{'task': 'MLIA_Project', 'split': 'test', 'save_dir': './eval_results/EVAL_MLIA_CLAM_eval', 'models_dir': 'results/MLIA_CLAM_50_s1', 'model_type': 'clam_sb', 'drop_out': 0.25, 'model_size': 'small'}\n",
            "label column: label\n",
            "label dictionary: {'B': 0, 'S': 1, 'E': 2}\n",
            "number of classes: 3\n",
            "slide-level counts:  \n",
            " label\n",
            "0    9\n",
            "1    5\n",
            "2    8\n",
            "Name: count, dtype: int64\n",
            "Patient-LVL; Number of samples registered in class 0: 9\n",
            "Slide-LVL; Number of samples registered in class 0: 9\n",
            "Patient-LVL; Number of samples registered in class 1: 5\n",
            "Slide-LVL; Number of samples registered in class 1: 5\n",
            "Patient-LVL; Number of samples registered in class 2: 8\n",
            "Slide-LVL; Number of samples registered in class 2: 8\n",
            "Init Model\n",
            "CLAM_SB(\n",
            "  (attention_net): Sequential(\n",
            "    (0): Linear(in_features=100, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Dropout(p=0.25, inplace=False)\n",
            "    (3): Attn_Net_Gated(\n",
            "      (attention_a): Sequential(\n",
            "        (0): Linear(in_features=512, out_features=256, bias=True)\n",
            "        (1): Tanh()\n",
            "        (2): Dropout(p=0.25, inplace=False)\n",
            "      )\n",
            "      (attention_b): Sequential(\n",
            "        (0): Linear(in_features=512, out_features=256, bias=True)\n",
            "        (1): Sigmoid()\n",
            "        (2): Dropout(p=0.25, inplace=False)\n",
            "      )\n",
            "      (attention_c): Linear(in_features=256, out_features=1, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (classifiers): Linear(in_features=512, out_features=3, bias=True)\n",
            "  (instance_classifiers): ModuleList(\n",
            "    (0-2): 3 x Linear(in_features=512, out_features=2, bias=True)\n",
            "  )\n",
            "  (instance_loss_fn): CrossEntropyLoss()\n",
            ")\n",
            "Total number of parameters: 319242\n",
            "Total number of trainable parameters: 319242\n",
            "Init Loaders\n",
            "test_error:  0.2\n",
            "auc:  0.9166666666666666\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r result_evaluation.zip 'eval_results/'"
      ],
      "metadata": {
        "id": "AJvsLg15GGRl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8e4fa48-2181-4037-97d9-c7a8da429728"
      },
      "id": "AJvsLg15GGRl",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: eval_results/ (stored 0%)\n",
            "  adding: eval_results/EVAL_MLIA_CLAM_eval/ (stored 0%)\n",
            "  adding: eval_results/EVAL_MLIA_CLAM_eval/fold_0.csv (deflated 45%)\n",
            "  adding: eval_results/EVAL_MLIA_CLAM_eval/summary.csv (deflated 35%)\n",
            "  adding: eval_results/EVAL_MLIA_CLAM_eval/eval_experiment_MLIA_CLAM_eval.txt (deflated 31%)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}